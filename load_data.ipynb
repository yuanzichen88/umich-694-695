{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import altair as alt\n",
    "import seaborn as sns\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\mryua\\anaconda3\\lib\\site-packages (4.1.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from gensim) (6.0.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from gensim) (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from gensim) (1.18.5)\n",
      "Requirement already satisfied: Cython==0.29.23 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from gensim) (0.29.23)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mryua\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mryua\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mryua\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "from tqdm.notebook import tqdm\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED=694"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There is manuscript evidence that Austen conti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In a remarkable comparative analysis , Mandaea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Before Persephone was released to Hermes , who...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cogeneration plants are commonly found in dist...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Geneva -LRB- , ; , ; , ; ; -RRB- is the second...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416763</th>\n",
       "      <td>A Duke Nukem 3D version has been sold for Xbox...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416764</th>\n",
       "      <td>However , it is becoming replaced as a method ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416765</th>\n",
       "      <td>There are hand gestures in both Hindu and Budd...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416766</th>\n",
       "      <td>If it is necessary to use colors , try to choo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416767</th>\n",
       "      <td>Calgary Stampeders ,</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>416768 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            original_text  label\n",
       "0       There is manuscript evidence that Austen conti...      1\n",
       "1       In a remarkable comparative analysis , Mandaea...      1\n",
       "2       Before Persephone was released to Hermes , who...      1\n",
       "3       Cogeneration plants are commonly found in dist...      1\n",
       "4       Geneva -LRB- , ; , ; , ; ; -RRB- is the second...      1\n",
       "...                                                   ...    ...\n",
       "416763  A Duke Nukem 3D version has been sold for Xbox...      0\n",
       "416764  However , it is becoming replaced as a method ...      0\n",
       "416765  There are hand gestures in both Hindu and Budd...      0\n",
       "416766  If it is necessary to use colors , try to choo...      0\n",
       "416767                               Calgary Stampeders ,      0\n",
       "\n",
       "[416768 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = 'Data/WikiLarge_Train.csv'\n",
    "df = pd.read_csv(train_path, skiprows=0, skipfooter=0, engine='python')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['label']==1])/len(df) # the dataset label is well balanced "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'He studied in Armenia and Istanbul , then at Wisconsin University which he finished in 1915 .'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[50]['original_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117.921906192414"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['original_text'].apply(lambda x: len(x)).mean()\n",
    "# This means all texts are considered short text, which allows us to use dense representations, \n",
    "# as dense representations work well with short text.\n",
    "# Gensim.KeyedVectors.load('assets/wikipedia.100.word-vecs.kv')??? How to generate and use this???\n",
    "# Maybe we should train word2vec model on the entire corpus. Just training data? TOP 100 word-vectors(features)\n",
    "# Alternatively we could use bag-of-words model, which is term-document matrix representation, having much more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['original_text']\n",
    "y = df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>original_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-2011</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-2011</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-2000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-1997</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.636</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119087</th>\n",
       "      <td>119087</td>\n",
       "      <td>#NAME?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119088</th>\n",
       "      <td>119088</td>\n",
       "      <td>#NAME?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119089</th>\n",
       "      <td>119089</td>\n",
       "      <td>#NAME?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119090</th>\n",
       "      <td>119090</td>\n",
       "      <td>#NAME?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119091</th>\n",
       "      <td>119091</td>\n",
       "      <td>#NAME?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119092 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id original_text  label\n",
       "0            0         -2011    NaN\n",
       "1            1         -2011    NaN\n",
       "2            2         -2000    NaN\n",
       "3            3         -1997    NaN\n",
       "4            4         1.636    NaN\n",
       "...        ...           ...    ...\n",
       "119087  119087        #NAME?    NaN\n",
       "119088  119088        #NAME?    NaN\n",
       "119089  119089        #NAME?    NaN\n",
       "119090  119090        #NAME?    NaN\n",
       "119091  119091        #NAME?    NaN\n",
       "\n",
       "[119092 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_path = 'Data/WikiLarge_Test.csv'\n",
    "test_df = pd.read_csv(test_path, skiprows=0, skipfooter=0, engine='python')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                           10000\n",
       "original_text    An atheist would say that this argument proves...\n",
       "label                                                          NaN\n",
       "Name: 10000, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.iloc[10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119087</th>\n",
       "      <td>119087</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119088</th>\n",
       "      <td>119088</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119089</th>\n",
       "      <td>119089</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119090</th>\n",
       "      <td>119090</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119091</th>\n",
       "      <td>119091</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119092 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  label\n",
       "0            0      0\n",
       "1            1      0\n",
       "2            2      1\n",
       "3            3      1\n",
       "4            4      0\n",
       "...        ...    ...\n",
       "119087  119087      0\n",
       "119088  119088      1\n",
       "119089  119089      1\n",
       "119090  119090      1\n",
       "119091  119091      1\n",
       "\n",
       "[119092 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samplesubmission_path = 'Data/sampleSubmission.csv'\n",
    "samplesubmission_df = pd.read_csv(samplesubmission_path, skiprows=0, skipfooter=0, engine='python')\n",
    "samplesubmission_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conclude, the dataframes we are working with are:\n",
    "\n",
    "dalechall_df, concreteness_df, aoawords_df, train_df, test_df, samplesubmission_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=10,stop_words='english',ngram_range=(1,2))\n",
    "X_train_transform = vectorizer.fit_transform(X_train)\n",
    "X_test_transform  = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<333414x57773 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4071111 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f46fade75ee340da92351360d019d1dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=333414.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a357ad87220b49d3b91841fb7c044360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=83354.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized_text_train=[]\n",
    "tokenized_text_test=[]\n",
    "stopWords = set(stopwords.words('english'))\n",
    "\n",
    "for text in tqdm(X_train):\n",
    "    tokens_in_text = word_tokenize(text)\n",
    "    tokens_in_text = [word for word in tokens_in_text if word.lower() not in stopWords]\n",
    "    tokenized_text_train.append(tokens_in_text)\n",
    "    \n",
    "for text in tqdm(X_test):\n",
    "    tokens_in_text = word_tokenize(text)\n",
    "    tokens_in_text = [word for word in tokens_in_text if word.lower() not in stopWords]\n",
    "    tokenized_text_test.append(tokens_in_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14267386, 24273560)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Word2Vec(vector_size=100,window=2,min_count=100,seed= RANDOM_SEED,workers=4)\n",
    "model.build_vocab(tokenized_text_train)\n",
    "model.train(tokenized_text_train,total_examples=model.corpus_count,epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dense_features(tokenized_text,word_vectors):\n",
    "    dense_list=[]\n",
    "    words=[]\n",
    "    for _ in tokenized_text: \n",
    "        words =[word for word in _ if word in word_vectors.key_to_index]\n",
    "        \n",
    "        if len(words) >0:\n",
    "            dense_list.append(np.mean(word_vectors[words],axis=0))\n",
    "            \n",
    "        else: \n",
    "            dense_list.append(np.zeros(word_vectors.vector_size))\n",
    "            \n",
    "    return np.array(dense_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_wv = generate_dense_features(tokenized_text_train,word_vectors)\n",
    "X_test_wv = generate_dense_features(tokenized_text_test,word_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word's Difficulty Considered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "== dale_chall.txt ==\n",
    "\n",
    "This is the Dale Chall 3000 Word List, which is one definition of words that are considered \"basic\" English.\n",
    "\n",
    "A summary is at https://www.readabilityformulas.com/articles/dale-chall-readability-word-list.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic english words\n",
    "dalechall_path = 'Data/dale_chall.txt'\n",
    "dale_chall = pd.read_csv(dalechall_path,delimiter='\\t',header=None,names=['word'])\n",
    "dale = set(dale_chall['word'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2946"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The 2946 words in dale can be combined with the nltk stopwords."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "== Concreteness_ratings_Brysbaert_et_al_BRM.txt ==\n",
    "\n",
    "This file contains concreteness ratings for 40 thousand English lemma words gathered via Amazon Mechanical Turk. The ratings come from a larger list of 63 thousand words and represent all English words known to 85% of the raters.\n",
    "\n",
    "The file contains eight columns:\n",
    "1. The word\n",
    "2. Whether it is a single word or a two-word expression \n",
    "3. The mean concreteness rating\n",
    "4. The standard deviation of the concreteness ratings\n",
    "5. The number of persons indicating they did not know the word\n",
    "6. The total number of persons who rated the word\n",
    "7. Percentage participants who knew the word\n",
    "8. The SUBTLEX-US frequency count (on a total of 51 million; Brysbaert & New, 2009) \n",
    "9. The dominant part-of-speech usage\n",
    "\n",
    "Original source: http://crr.ugent.be/archives/1330\n",
    "\n",
    "Brysbaert, M., Warriner, A.B., & Kuperman, V. (2014). Concreteness ratings for 40 thousand generally known English word lemmas. Behavior Research Methods, 46, 904-911.\n",
    "http://crr.ugent.be/papers/Brysbaert_Warriner_Kuperman_BRM_Concreteness_ratings.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concreteness rating - the higher Conc.M, the easier the word is.\n",
    "concreteness_path = 'Data/Concreteness_ratings_Brysbaert_et_al_BRM.txt'\n",
    "concrete_df = pd.read_csv(concreteness_path,delimiter='\\t', keep_default_na=False)\n",
    "concreteset=(concrete_df['Word'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Bigram</th>\n",
       "      <th>Conc.M</th>\n",
       "      <th>Conc.SD</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent_known</th>\n",
       "      <th>SUBTLEX</th>\n",
       "      <th>Dom_Pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>roadsweeper</td>\n",
       "      <td>0</td>\n",
       "      <td>4.85</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>traindriver</td>\n",
       "      <td>0</td>\n",
       "      <td>4.54</td>\n",
       "      <td>0.71</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tush</td>\n",
       "      <td>0</td>\n",
       "      <td>4.45</td>\n",
       "      <td>1.01</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>0.88</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hairdress</td>\n",
       "      <td>0</td>\n",
       "      <td>3.93</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pharmaceutics</td>\n",
       "      <td>0</td>\n",
       "      <td>3.77</td>\n",
       "      <td>1.41</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39949</th>\n",
       "      <td>unenvied</td>\n",
       "      <td>0</td>\n",
       "      <td>1.21</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39950</th>\n",
       "      <td>agnostically</td>\n",
       "      <td>0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39951</th>\n",
       "      <td>conceptualistic</td>\n",
       "      <td>0</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.50</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39952</th>\n",
       "      <td>conventionalism</td>\n",
       "      <td>0</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39953</th>\n",
       "      <td>essentialness</td>\n",
       "      <td>0</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39954 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Word  Bigram  Conc.M  Conc.SD  Unknown  Total  \\\n",
       "0          roadsweeper       0    4.85     0.37        1     27   \n",
       "1          traindriver       0    4.54     0.71        3     29   \n",
       "2                 tush       0    4.45     1.01        3     25   \n",
       "3            hairdress       0    3.93     1.28        0     29   \n",
       "4        pharmaceutics       0    3.77     1.41        4     26   \n",
       "...                ...     ...     ...      ...      ...    ...   \n",
       "39949         unenvied       0    1.21     0.62        1     30   \n",
       "39950     agnostically       0    1.20     0.50        2     27   \n",
       "39951  conceptualistic       0    1.18     0.50        4     26   \n",
       "39952  conventionalism       0    1.18     0.48        1     29   \n",
       "39953    essentialness       0    1.04     0.20        2     26   \n",
       "\n",
       "       Percent_known  SUBTLEX Dom_Pos  \n",
       "0               0.96        0       0  \n",
       "1               0.90        0       0  \n",
       "2               0.88       66       0  \n",
       "3               1.00        1       0  \n",
       "4               0.85        0       0  \n",
       "...              ...      ...     ...  \n",
       "39949           0.97        0    #N/A  \n",
       "39950           0.93        0    #N/A  \n",
       "39951           0.85        0    #N/A  \n",
       "39952           0.97        0    #N/A  \n",
       "39953           0.92        0    #N/A  \n",
       "\n",
       "[39954 rows x 9 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    37058\n",
       "1     2896\n",
       "Name: Bigram, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_df.Bigram.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Bigram</th>\n",
       "      <th>Conc.M</th>\n",
       "      <th>Conc.SD</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent_known</th>\n",
       "      <th>SUBTLEX</th>\n",
       "      <th>Dom_Pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28707</th>\n",
       "      <td>baking soda</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28709</th>\n",
       "      <td>baseball bat</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28710</th>\n",
       "      <td>bath towel</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28711</th>\n",
       "      <td>beach ball</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28712</th>\n",
       "      <td>bed sheet</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39619</th>\n",
       "      <td>tantamount to</td>\n",
       "      <td>1</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.85</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39857</th>\n",
       "      <td>chance on</td>\n",
       "      <td>1</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39871</th>\n",
       "      <td>free rein</td>\n",
       "      <td>1</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0.63</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39899</th>\n",
       "      <td>by chance</td>\n",
       "      <td>1</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39947</th>\n",
       "      <td>in principle</td>\n",
       "      <td>1</td>\n",
       "      <td>1.21</td>\n",
       "      <td>0.41</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2896 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Word  Bigram  Conc.M  Conc.SD  Unknown  Total  Percent_known  \\\n",
       "28707    baking soda       1    5.00     0.00        0     30           1.00   \n",
       "28709   baseball bat       1    5.00     0.00        0     29           1.00   \n",
       "28710     bath towel       1    5.00     0.00        0     29           1.00   \n",
       "28711     beach ball       1    5.00     0.00        0     28           1.00   \n",
       "28712      bed sheet       1    5.00     0.00        0     28           1.00   \n",
       "...              ...     ...     ...      ...      ...    ...            ...   \n",
       "39619  tantamount to       1    1.52     0.85        4     27           0.85   \n",
       "39857      chance on       1    1.38     0.75        2     28           0.93   \n",
       "39871      free rein       1    1.37     0.63        2     29           0.93   \n",
       "39899      by chance       1    1.34     0.72        1     30           0.97   \n",
       "39947   in principle       1    1.21     0.41        4     28           0.86   \n",
       "\n",
       "       SUBTLEX Dom_Pos  \n",
       "28707        0    #N/A  \n",
       "28709        0    #N/A  \n",
       "28710        0    #N/A  \n",
       "28711        0    #N/A  \n",
       "28712        0    #N/A  \n",
       "...        ...     ...  \n",
       "39619        0    #N/A  \n",
       "39857        0    #N/A  \n",
       "39871        0    #N/A  \n",
       "39899        0    #N/A  \n",
       "39947        0    #N/A  \n",
       "\n",
       "[2896 rows x 9 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_df[concrete_df.Bigram==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Bigram</th>\n",
       "      <th>Conc.M</th>\n",
       "      <th>Conc.SD</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent_known</th>\n",
       "      <th>SUBTLEX</th>\n",
       "      <th>Dom_Pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Word, Bigram, Conc.M, Conc.SD, Unknown, Total, Percent_known, SUBTLEX, Dom_Pos]\n",
       "Index: []"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#There is no Nan value in Conc.M column\n",
    "concrete_df[concrete_df['Conc.M'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are we gonna consider bigrams in this dataset, given it's only a small fraction ~ 8% in size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.04"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(concrete_df['Conc.M'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(concrete_df['Conc.M'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concreteness values range from 1 - 5, we could possible use the inverse value of concreteness to scale it to a 0-1 range and give easier words less weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "== AoA_51715_words.csv ==\n",
    "\n",
    "This file contains \"Age of Acquisition\" (AoA) estimates for about 51k English words, which refers to the approximate age (in years) when a word was learned. Early words, being more basic, have lower average AoA.\n",
    "\n",
    "The main columns you will be interested in are \"Word\" and \"AoA_Kup_lem\". But the others may be useful too.\n",
    "\n",
    "The file contains these columns:\n",
    "\n",
    "Word :: The word in question\n",
    "Alternative.spelling :: if the Word may be spelled frequently in another form\t\n",
    "Freq_pm\t:: Freq of the Word in general English (larger -> more common)\n",
    "Dom_PoS_SUBTLEX\t:: Dominant part of speech in general usage\n",
    "Nletters :: number of letters \n",
    "Nphon :: number of phonemes\n",
    "Nsyll :: number of syllables\n",
    "Lemma_highest_PoS :: the \"lemmatized\" or \"root\" form of the word (in the dominant part of speech. e.g. The root form of the verb \"abates\" is \"abate\".\n",
    "AoA_Kup\t:: The AoA from a previous study by Kuperman et al.\n",
    "Perc_known :: Percent of people who knew the word in the Kuperman et al. study\n",
    "AoA_Kup_lem :: Estimated AoA based on Kuperman et al. study lemmatized words. THIS IS THE MAIN COLUMN OF INTEREST.\n",
    "Perc_known_lem\t:: Estimated percentage of people who would know this form of the word in the Kuperman study.\n",
    "AoA_Bird_lem :: AoA reported in previous study by Bird (2001) \n",
    "AoA_Bristol_lem\t:: AoA reported in previous study from Bristol Univ. (2006)\n",
    "AoA_Cort_lem :: AoA reported in previous study by Cortese & Khanna (2008)\n",
    "AoA_Schock :: AoA reported in previous study by Schock (2012)\n",
    "\n",
    "Original source : http://crr.ugent.be/archives/806"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Alternative.spelling</th>\n",
       "      <th>Freq_pm</th>\n",
       "      <th>Dom_PoS_SUBTLEX</th>\n",
       "      <th>Nletters</th>\n",
       "      <th>Nphon</th>\n",
       "      <th>Nsyll</th>\n",
       "      <th>Lemma_highest_PoS</th>\n",
       "      <th>AoA_Kup</th>\n",
       "      <th>Perc_known</th>\n",
       "      <th>AoA_Kup_lem</th>\n",
       "      <th>Perc_known_lem</th>\n",
       "      <th>AoA_Bird_lem</th>\n",
       "      <th>AoA_Bristol_lem</th>\n",
       "      <th>AoA_Cort_lem</th>\n",
       "      <th>AoA_Schock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>20415.27</td>\n",
       "      <td>Article</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>2.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aardvark</td>\n",
       "      <td>aardvark</td>\n",
       "      <td>0.41</td>\n",
       "      <td>Noun</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>aardvark</td>\n",
       "      <td>9.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abacus</td>\n",
       "      <td>abacus</td>\n",
       "      <td>0.24</td>\n",
       "      <td>Noun</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>abacus</td>\n",
       "      <td>8.69</td>\n",
       "      <td>0.65</td>\n",
       "      <td>8.69</td>\n",
       "      <td>0.65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abacuses</td>\n",
       "      <td>abacuses</td>\n",
       "      <td>0.02</td>\n",
       "      <td>Noun</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>abacus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.69</td>\n",
       "      <td>0.65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abalone</td>\n",
       "      <td>abalone</td>\n",
       "      <td>0.51</td>\n",
       "      <td>Verb</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>abalone</td>\n",
       "      <td>12.23</td>\n",
       "      <td>0.72</td>\n",
       "      <td>12.23</td>\n",
       "      <td>0.72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word Alternative.spelling   Freq_pm Dom_PoS_SUBTLEX  Nletters  Nphon  \\\n",
       "0         a                    a  20415.27         Article         1      1   \n",
       "1  aardvark             aardvark      0.41            Noun         8      7   \n",
       "2    abacus               abacus      0.24            Noun         6      6   \n",
       "3  abacuses             abacuses      0.02            Noun         8      9   \n",
       "4   abalone              abalone      0.51            Verb         7      7   \n",
       "\n",
       "   Nsyll Lemma_highest_PoS  AoA_Kup  Perc_known  AoA_Kup_lem  Perc_known_lem  \\\n",
       "0      1                 a     2.89        1.00         2.89            1.00   \n",
       "1      2          aardvark     9.89        1.00         9.89            1.00   \n",
       "2      3            abacus     8.69        0.65         8.69            0.65   \n",
       "3      4            abacus      NaN         NaN         8.69            0.65   \n",
       "4      4           abalone    12.23        0.72        12.23            0.72   \n",
       "\n",
       "   AoA_Bird_lem  AoA_Bristol_lem  AoA_Cort_lem  AoA_Schock  \n",
       "0          3.16              NaN           NaN         NaN  \n",
       "1           NaN              NaN           NaN         NaN  \n",
       "2           NaN              NaN           NaN         NaN  \n",
       "3           NaN              NaN           NaN         NaN  \n",
       "4           NaN              NaN           NaN         NaN  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AoA\n",
    "#Perc_known_lem, AoA_Kup_lem\n",
    "aoawords_path = 'Data/AoA_51715_words.csv'\n",
    "AoA = pd.read_csv(aoawords_path,encoding = 'unicode_escape')\n",
    "AoA_set = set(AoA['Word'].values)\n",
    "AoA.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51715"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(AoA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.58"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AoA.AoA_Kup_lem.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AoA.AoA_Kup_lem.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Alternative.spelling</th>\n",
       "      <th>Freq_pm</th>\n",
       "      <th>Dom_PoS_SUBTLEX</th>\n",
       "      <th>Nletters</th>\n",
       "      <th>Nphon</th>\n",
       "      <th>Nsyll</th>\n",
       "      <th>Lemma_highest_PoS</th>\n",
       "      <th>AoA_Kup</th>\n",
       "      <th>Perc_known</th>\n",
       "      <th>AoA_Kup_lem</th>\n",
       "      <th>Perc_known_lem</th>\n",
       "      <th>AoA_Bird_lem</th>\n",
       "      <th>AoA_Bristol_lem</th>\n",
       "      <th>AoA_Cort_lem</th>\n",
       "      <th>AoA_Schock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14878</th>\n",
       "      <td>eisteddfod</td>\n",
       "      <td>eisteddfod</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>eisteddfod</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2084</th>\n",
       "      <td>architrave</td>\n",
       "      <td>architrave</td>\n",
       "      <td>0.04</td>\n",
       "      <td>Noun</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>architrave</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6274</th>\n",
       "      <td>calceolaria</td>\n",
       "      <td>calceolaria</td>\n",
       "      <td>0.02</td>\n",
       "      <td>Noun</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>calceolaria</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32931</th>\n",
       "      <td>penury</td>\n",
       "      <td>penury</td>\n",
       "      <td>0.02</td>\n",
       "      <td>Noun</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>penury</td>\n",
       "      <td>20.6</td>\n",
       "      <td>0.28</td>\n",
       "      <td>20.6</td>\n",
       "      <td>0.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25243</th>\n",
       "      <td>kendo</td>\n",
       "      <td>kendo</td>\n",
       "      <td>0.37</td>\n",
       "      <td>Noun</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>kendo</td>\n",
       "      <td>20.5</td>\n",
       "      <td>0.11</td>\n",
       "      <td>20.5</td>\n",
       "      <td>0.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38932</th>\n",
       "      <td>rogation</td>\n",
       "      <td>rogation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>rogation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42089</th>\n",
       "      <td>smilax</td>\n",
       "      <td>smilax</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>smilax</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46368</th>\n",
       "      <td>thulium</td>\n",
       "      <td>thulium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>thulium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50862</th>\n",
       "      <td>wickiup</td>\n",
       "      <td>wickiup</td>\n",
       "      <td>0.27</td>\n",
       "      <td>Noun</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>wickiup</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50941</th>\n",
       "      <td>williwaw</td>\n",
       "      <td>williwaw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>williwaw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51715 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Word Alternative.spelling  Freq_pm Dom_PoS_SUBTLEX  Nletters  \\\n",
       "14878   eisteddfod           eisteddfod      NaN             NaN        10   \n",
       "2084    architrave           architrave     0.04            Noun        10   \n",
       "6274   calceolaria          calceolaria     0.02            Noun        11   \n",
       "32931       penury               penury     0.02            Noun         6   \n",
       "25243        kendo                kendo     0.37            Noun         5   \n",
       "...            ...                  ...      ...             ...       ...   \n",
       "38932     rogation             rogation      NaN             NaN         8   \n",
       "42089       smilax               smilax      NaN             NaN         6   \n",
       "46368      thulium              thulium      NaN             NaN         7   \n",
       "50862      wickiup              wickiup     0.27            Noun         7   \n",
       "50941     williwaw             williwaw      NaN             NaN         8   \n",
       "\n",
       "       Nphon  Nsyll Lemma_highest_PoS  AoA_Kup  Perc_known  AoA_Kup_lem  \\\n",
       "14878      8      3        eisteddfod     25.0        0.05         25.0   \n",
       "2084       8      3        architrave     21.0        0.05         21.0   \n",
       "6274      11      6       calceolaria     21.0        0.11         21.0   \n",
       "32931      7      3            penury     20.6        0.28         20.6   \n",
       "25243      5      2             kendo     20.5        0.11         20.5   \n",
       "...      ...    ...               ...      ...         ...          ...   \n",
       "38932      7      3          rogation      NaN        0.00          NaN   \n",
       "42089      7      2            smilax      NaN        0.00          NaN   \n",
       "46368      6      3           thulium      NaN        0.00          NaN   \n",
       "50862      6      3           wickiup      NaN        0.00          NaN   \n",
       "50941      6      3          williwaw      NaN        0.00          NaN   \n",
       "\n",
       "       Perc_known_lem  AoA_Bird_lem  AoA_Bristol_lem  AoA_Cort_lem  AoA_Schock  \n",
       "14878            0.05           NaN              NaN           NaN         NaN  \n",
       "2084             0.05           NaN              NaN           NaN         NaN  \n",
       "6274             0.11           NaN              NaN           NaN         NaN  \n",
       "32931            0.28           NaN              NaN           NaN         NaN  \n",
       "25243            0.11           NaN              NaN           NaN         NaN  \n",
       "...               ...           ...              ...           ...         ...  \n",
       "38932            0.00           NaN              NaN           NaN         NaN  \n",
       "42089            0.00           NaN              NaN           NaN         NaN  \n",
       "46368            0.00           NaN              NaN           NaN         NaN  \n",
       "50862            0.00           NaN              NaN           NaN         NaN  \n",
       "50941            0.00           NaN              NaN           NaN         NaN  \n",
       "\n",
       "[51715 rows x 16 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AoA.sort_values(['AoA_Kup_lem'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(AoA[AoA['AoA_Kup_lem'].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Alternative.spelling</th>\n",
       "      <th>Freq_pm</th>\n",
       "      <th>Dom_PoS_SUBTLEX</th>\n",
       "      <th>Nletters</th>\n",
       "      <th>Nphon</th>\n",
       "      <th>Nsyll</th>\n",
       "      <th>Lemma_highest_PoS</th>\n",
       "      <th>AoA_Kup</th>\n",
       "      <th>Perc_known</th>\n",
       "      <th>AoA_Kup_lem</th>\n",
       "      <th>Perc_known_lem</th>\n",
       "      <th>AoA_Bird_lem</th>\n",
       "      <th>AoA_Bristol_lem</th>\n",
       "      <th>AoA_Cort_lem</th>\n",
       "      <th>AoA_Schock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>actinium</td>\n",
       "      <td>actinium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>actinium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322</th>\n",
       "      <td>ambuscade</td>\n",
       "      <td>ambuscade</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>ambuscade</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2306</th>\n",
       "      <td>ashlar</td>\n",
       "      <td>ashlar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>ashlar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5095</th>\n",
       "      <td>bosky</td>\n",
       "      <td>bosky</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>bosky</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6404</th>\n",
       "      <td>canaille</td>\n",
       "      <td>canaille</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>canaille</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9004</th>\n",
       "      <td>compeer</td>\n",
       "      <td>compeer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>compeer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9005</th>\n",
       "      <td>compeers</td>\n",
       "      <td>compeers</td>\n",
       "      <td>0.02</td>\n",
       "      <td>Noun</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>compeer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16000</th>\n",
       "      <td>europium</td>\n",
       "      <td>europium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>europium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19065</th>\n",
       "      <td>gallimaufry</td>\n",
       "      <td>gallimaufry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>gallimaufry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22498</th>\n",
       "      <td>hutment</td>\n",
       "      <td>hutment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>hutment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25196</th>\n",
       "      <td>karakul</td>\n",
       "      <td>karakul</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>karakul</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25219</th>\n",
       "      <td>kedge</td>\n",
       "      <td>kedge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>kedge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25575</th>\n",
       "      <td>kyat</td>\n",
       "      <td>kyat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>kyat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32754</th>\n",
       "      <td>peculation</td>\n",
       "      <td>peculation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>peculation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34588</th>\n",
       "      <td>pother</td>\n",
       "      <td>pother</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>pother</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38932</th>\n",
       "      <td>rogation</td>\n",
       "      <td>rogation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>rogation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42089</th>\n",
       "      <td>smilax</td>\n",
       "      <td>smilax</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>smilax</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46368</th>\n",
       "      <td>thulium</td>\n",
       "      <td>thulium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>thulium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50862</th>\n",
       "      <td>wickiup</td>\n",
       "      <td>wickiup</td>\n",
       "      <td>0.27</td>\n",
       "      <td>Noun</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>wickiup</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50941</th>\n",
       "      <td>williwaw</td>\n",
       "      <td>williwaw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>williwaw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Word Alternative.spelling  Freq_pm Dom_PoS_SUBTLEX  Nletters  \\\n",
       "442       actinium             actinium      NaN             NaN         8   \n",
       "1322     ambuscade            ambuscade      NaN             NaN         9   \n",
       "2306        ashlar               ashlar      NaN             NaN         6   \n",
       "5095         bosky                bosky      NaN             NaN         5   \n",
       "6404      canaille             canaille      NaN             NaN         8   \n",
       "9004       compeer              compeer      NaN             NaN         7   \n",
       "9005      compeers             compeers     0.02            Noun         8   \n",
       "16000     europium             europium      NaN             NaN         8   \n",
       "19065  gallimaufry          gallimaufry      NaN             NaN        11   \n",
       "22498      hutment              hutment      NaN             NaN         7   \n",
       "25196      karakul              karakul      NaN             NaN         7   \n",
       "25219        kedge                kedge      NaN             NaN         5   \n",
       "25575         kyat                 kyat      NaN             NaN         4   \n",
       "32754   peculation           peculation      NaN             NaN        10   \n",
       "34588       pother               pother      NaN             NaN         6   \n",
       "38932     rogation             rogation      NaN             NaN         8   \n",
       "42089       smilax               smilax      NaN             NaN         6   \n",
       "46368      thulium              thulium      NaN             NaN         7   \n",
       "50862      wickiup              wickiup     0.27            Noun         7   \n",
       "50941     williwaw             williwaw      NaN             NaN         8   \n",
       "\n",
       "       Nphon  Nsyll Lemma_highest_PoS  AoA_Kup  Perc_known  AoA_Kup_lem  \\\n",
       "442        8      4          actinium      NaN         0.0          NaN   \n",
       "1322       8      3         ambuscade      NaN         0.0          NaN   \n",
       "2306       5      2            ashlar      NaN         0.0          NaN   \n",
       "5095       4      2             bosky      NaN         0.0          NaN   \n",
       "6404       5      2          canaille      NaN         0.0          NaN   \n",
       "9004       6      3           compeer      NaN         0.0          NaN   \n",
       "9005       7      3           compeer      NaN         NaN          NaN   \n",
       "16000      8      4          europium      NaN         0.0          NaN   \n",
       "19065      9      4       gallimaufry      NaN         0.0          NaN   \n",
       "22498      7      2           hutment      NaN         0.0          NaN   \n",
       "25196      7      3           karakul      NaN         0.0          NaN   \n",
       "25219      3      1             kedge      NaN         0.0          NaN   \n",
       "25575      4      2              kyat      NaN         0.0          NaN   \n",
       "32754     10      4        peculation      NaN         0.0          NaN   \n",
       "34588      5      2            pother      NaN         0.0          NaN   \n",
       "38932      7      3          rogation      NaN         0.0          NaN   \n",
       "42089      7      2            smilax      NaN         0.0          NaN   \n",
       "46368      6      3           thulium      NaN         0.0          NaN   \n",
       "50862      6      3           wickiup      NaN         0.0          NaN   \n",
       "50941      6      3          williwaw      NaN         0.0          NaN   \n",
       "\n",
       "       Perc_known_lem  AoA_Bird_lem  AoA_Bristol_lem  AoA_Cort_lem  AoA_Schock  \n",
       "442               0.0           NaN              NaN           NaN         NaN  \n",
       "1322              0.0           NaN              NaN           NaN         NaN  \n",
       "2306              0.0           NaN              NaN           NaN         NaN  \n",
       "5095              0.0           NaN              NaN           NaN         NaN  \n",
       "6404              0.0           NaN              NaN           NaN         NaN  \n",
       "9004              0.0           NaN              NaN           NaN         NaN  \n",
       "9005              0.0           NaN              NaN           NaN         NaN  \n",
       "16000             0.0           NaN              NaN           NaN         NaN  \n",
       "19065             0.0           NaN              NaN           NaN         NaN  \n",
       "22498             0.0           NaN              NaN           NaN         NaN  \n",
       "25196             0.0           NaN              NaN           NaN         NaN  \n",
       "25219             0.0           NaN              NaN           NaN         NaN  \n",
       "25575             0.0           NaN              NaN           NaN         NaN  \n",
       "32754             0.0           NaN              NaN           NaN         NaN  \n",
       "34588             0.0           NaN              NaN           NaN         NaN  \n",
       "38932             0.0           NaN              NaN           NaN         NaN  \n",
       "42089             0.0           NaN              NaN           NaN         NaN  \n",
       "46368             0.0           NaN              NaN           NaN         NaN  \n",
       "50862             0.0           NaN              NaN           NaN         NaN  \n",
       "50941             0.0           NaN              NaN           NaN         NaN  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AoA[AoA['AoA_Kup_lem'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to impute all Nan values in AoA_Kup_lem as the max AoA value 25, as they appear to be hard words.\n",
    "AoA['AoA_Kup_lem'].fillna(value=AoA['AoA_Kup_lem'].max(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Alternative.spelling</th>\n",
       "      <th>Freq_pm</th>\n",
       "      <th>Dom_PoS_SUBTLEX</th>\n",
       "      <th>Nletters</th>\n",
       "      <th>Nphon</th>\n",
       "      <th>Nsyll</th>\n",
       "      <th>Lemma_highest_PoS</th>\n",
       "      <th>AoA_Kup</th>\n",
       "      <th>Perc_known</th>\n",
       "      <th>AoA_Kup_lem</th>\n",
       "      <th>Perc_known_lem</th>\n",
       "      <th>AoA_Bird_lem</th>\n",
       "      <th>AoA_Bristol_lem</th>\n",
       "      <th>AoA_Cort_lem</th>\n",
       "      <th>AoA_Schock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2306</th>\n",
       "      <td>ashlar</td>\n",
       "      <td>ashlar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>ashlar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38932</th>\n",
       "      <td>rogation</td>\n",
       "      <td>rogation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>rogation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46368</th>\n",
       "      <td>thulium</td>\n",
       "      <td>thulium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>thulium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14878</th>\n",
       "      <td>eisteddfod</td>\n",
       "      <td>eisteddfod</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>eisteddfod</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5095</th>\n",
       "      <td>bosky</td>\n",
       "      <td>bosky</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>bosky</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27395</th>\n",
       "      <td>mamma</td>\n",
       "      <td>mamma</td>\n",
       "      <td>3.02</td>\n",
       "      <td>Noun</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>mama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27393</th>\n",
       "      <td>mamas</td>\n",
       "      <td>mamas</td>\n",
       "      <td>0.71</td>\n",
       "      <td>Noun</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>mama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27392</th>\n",
       "      <td>mama</td>\n",
       "      <td>mama</td>\n",
       "      <td>103.71</td>\n",
       "      <td>Noun</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>mama</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29050</th>\n",
       "      <td>mommas</td>\n",
       "      <td>mommas</td>\n",
       "      <td>0.10</td>\n",
       "      <td>Noun</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>momma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29049</th>\n",
       "      <td>momma</td>\n",
       "      <td>momma</td>\n",
       "      <td>8.08</td>\n",
       "      <td>Noun</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>momma</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51715 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Word Alternative.spelling  Freq_pm Dom_PoS_SUBTLEX  Nletters  \\\n",
       "2306       ashlar               ashlar      NaN             NaN         6   \n",
       "38932    rogation             rogation      NaN             NaN         8   \n",
       "46368     thulium              thulium      NaN             NaN         7   \n",
       "14878  eisteddfod           eisteddfod      NaN             NaN        10   \n",
       "5095        bosky                bosky      NaN             NaN         5   \n",
       "...           ...                  ...      ...             ...       ...   \n",
       "27395       mamma                mamma     3.02            Noun         5   \n",
       "27393       mamas                mamas     0.71            Noun         5   \n",
       "27392        mama                 mama   103.71            Noun         4   \n",
       "29050      mommas               mommas     0.10            Noun         6   \n",
       "29049       momma                momma     8.08            Noun         5   \n",
       "\n",
       "       Nphon  Nsyll Lemma_highest_PoS  AoA_Kup  Perc_known  AoA_Kup_lem  \\\n",
       "2306       5      2            ashlar      NaN        0.00        25.00   \n",
       "38932      7      3          rogation      NaN        0.00        25.00   \n",
       "46368      6      3           thulium      NaN        0.00        25.00   \n",
       "14878      8      3        eisteddfod    25.00        0.05        25.00   \n",
       "5095       4      2             bosky      NaN        0.00        25.00   \n",
       "...      ...    ...               ...      ...         ...          ...   \n",
       "27395      4      2              mama      NaN         NaN         1.89   \n",
       "27393      5      2              mama      NaN         NaN         1.89   \n",
       "27392      4      2              mama     1.89        1.00         1.89   \n",
       "29050      5      2             momma      NaN         NaN         1.58   \n",
       "29049      4      2             momma     1.58        1.00         1.58   \n",
       "\n",
       "       Perc_known_lem  AoA_Bird_lem  AoA_Bristol_lem  AoA_Cort_lem  AoA_Schock  \n",
       "2306             0.00           NaN              NaN           NaN         NaN  \n",
       "38932            0.00           NaN              NaN           NaN         NaN  \n",
       "46368            0.00           NaN              NaN           NaN         NaN  \n",
       "14878            0.05           NaN              NaN           NaN         NaN  \n",
       "5095             0.00           NaN              NaN           NaN         NaN  \n",
       "...               ...           ...              ...           ...         ...  \n",
       "27395            1.00           NaN              NaN           NaN         NaN  \n",
       "27393            1.00           NaN              NaN           NaN         NaN  \n",
       "27392            1.00           NaN              NaN           NaN         NaN  \n",
       "29050            1.00           NaN              NaN           NaN         NaN  \n",
       "29049            1.00           NaN              NaN           NaN         NaN  \n",
       "\n",
       "[51715 rows x 16 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AoA.sort_values(['AoA_Kup_lem'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AoA values range from 0 - 25, which means the smaller the AoA value, the easier the word is. We could possibly use the AoA value to give easier words less weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_word = set(word_vectors.index_to_key) #around 6k words in the Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5776"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2623"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_word.intersection(concreteset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.6199677 ,  0.3468209 , -0.37597764, -0.84315234,  0.05326695,\n",
       "       -0.74597925, -0.2600026 , -0.9814865 , -0.85832727, -0.8009238 ,\n",
       "       -0.40282986, -0.7274299 , -0.46454006, -0.06327678, -0.6668875 ,\n",
       "        0.68247014, -1.2197053 ,  0.33938536,  0.50376123, -1.0847578 ,\n",
       "        0.24329747, -0.16985822,  0.36326942,  0.16396426, -0.4165022 ,\n",
       "        0.6009113 ,  0.18639898, -0.3841828 , -0.6158585 ,  0.8503197 ,\n",
       "        0.15161711, -0.357656  ,  0.4907954 ,  0.5068166 , -0.46216726,\n",
       "       -0.10496143,  0.40876412,  0.43992898,  0.13667339,  0.13547929,\n",
       "       -0.6998609 ,  0.41898432, -0.06581438,  1.3475554 ,  0.08873701,\n",
       "        0.27507004,  0.5438392 , -2.0921082 ,  0.4102677 ,  0.52933025,\n",
       "        0.45466015, -0.562415  ,  0.36320716,  0.23065574, -0.54838544,\n",
       "        0.3496241 ,  0.3873599 , -0.06940398, -1.3185865 ,  0.21078272,\n",
       "       -0.14478372,  1.3990853 , -0.7048181 , -0.6680918 , -0.6833189 ,\n",
       "       -0.6162195 , -0.32513937, -0.02604951, -0.59235597, -0.26110998,\n",
       "        0.04813253, -0.1921679 ,  0.7412333 , -0.30765235, -0.36599642,\n",
       "       -0.00277252,  0.55416507,  0.06391015, -0.16472207, -0.49990007,\n",
       "        0.55019563,  0.29558071, -0.54138684, -0.64309686, -0.0056091 ,\n",
       "       -0.18736823,  0.5332082 ,  0.01739273, -0.1178661 ,  0.33478612,\n",
       "        0.32538503,  0.04173602, -0.9254497 ,  0.10686918,  0.61844766,\n",
       "        0.18322487, -0.09160172,  0.44687897, -0.34248507, -1.3560922 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors['live']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-74-e7a08ad5c3a7>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['AoA_Kup_lem'][i] = 3\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "word_list = []\n",
    "for word in model_word: \n",
    "    word_list.append((word,lemmatizer.lemmatize(word.lower())))\n",
    "df = pd.DataFrame(word_list,columns=['Original','word'])\n",
    "df = df.merge(AoA,left_on='word',right_on='Word',how='left')\n",
    "df = df[['Original','word','Perc_known','AoA_Kup_lem']]\n",
    "word_not_matched = set(df[df['Perc_known'].isnull()].word.values)\n",
    "\n",
    "for i in range(len(df)):   \n",
    "    if df['word'][i][0] in set(('0','1','2','3','4','5','6','7','8','9')) or len(df['word'][i])==1:\n",
    "        df['AoA_Kup_lem'][i] = 3\n",
    "mean_value = df['AoA_Kup_lem'].mean()\n",
    "df['AoA_Kup_lem'].fillna(value=mean_value,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original</th>\n",
       "      <th>word</th>\n",
       "      <th>Perc_known</th>\n",
       "      <th>AoA_Kup_lem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3604</th>\n",
       "      <td>troops</td>\n",
       "      <td>troop</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5455</th>\n",
       "      <td>weapon</td>\n",
       "      <td>weapon</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Original    word  Perc_known  AoA_Kup_lem\n",
       "3604   troops   troop         1.0         8.35\n",
       "5455   weapon  weapon         1.0         6.95"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.loc[df['Original']==['troops','weapons']]\n",
    "df[df['Original'].isin(['troops','weapon'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_perc_known(tokenized_text,df):\n",
    "    avg_perc_know=None\n",
    "    perc_know_list=[]\n",
    "    for _ in tokenized_text: \n",
    "        words =[word for word in _ if word in word_vectors.key_to_index]\n",
    "        \n",
    "        if len(words) >0:\n",
    "            avg_perc_know = np.mean(df[df['Original'].isin(words)]['AoA_Kup_lem'])\n",
    "            perc_know_list.append(avg_perc_know)\n",
    "        else: \n",
    "            \n",
    "            perc_know_list.append(0)\n",
    "            \n",
    "    return perc_know_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(X_train_wv)\n",
    "df_train['year'] = generate_perc_known(tokenized_text_train,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(X_test_wv)\n",
    "df_test['year'] = generate_perc_known(tokenized_text_test,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=RANDOM_SEED,max_iter=1000).fit(df_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test,lr.predict(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_bow = DummyClassifier(strategy='uniform',random_state=RANDOM_SEED).fit(X_train_transform,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, dummy_bow.predict(X_test_transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_wv = DummyClassifier(strategy='uniform',random_state=RANDOM_SEED).fit(X_train_wv,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test,dummy_wv.predict(X_test_wv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_bow = LogisticRegression(random_state=RANDOM_SEED,max_iter=1000).fit(X_train_transform,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test,lr_bow.predict(X_test_transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_wv = LogisticRegression(random_state=RANDOM_SEED,max_iter=1000).fit(X_train_wv,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test,lr_wv.predict(X_test_wv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_bow = RandomForestClassifier(n_estimators=500,max_depth=5,random_state=RANDOM_SEED).fit(X_train_transform,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test,rf_bow.predict(X_test_transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_wv = RandomForestClassifier(n_estimators=100,max_depth=5,random_state=RANDOM_SEED).fit(X_train_wv,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test,rf_wv.predict(X_test_wv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Unsupervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2,random_state=RANDOM_SEED).fit(X_train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df = pd.DataFrame({'cluster':kmeans.labels_,'y_label':y_train,'text':X_train})\n",
    "cluster_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
