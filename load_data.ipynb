{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import altair as alt\n",
    "import seaborn as sns\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.18.5'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make sure numpy version is < 1.20\n",
    "np.version.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.18.5 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (1.18.5)\n"
     ]
    }
   ],
   "source": [
    "#Install known version of numpy that works\n",
    "!python -m pip install numpy==1.18.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\mryua\\anaconda3\\lib\\site-packages (4.1.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from gensim) (6.0.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from gensim) (1.5.0)\n",
      "Requirement already satisfied: Cython==0.29.23 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from gensim) (0.29.23)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from gensim) (1.18.5)\n"
     ]
    }
   ],
   "source": [
    "#Install gensim\n",
    "!python -m pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mryua\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mryua\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mryua\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from tqdm.notebook import tqdm\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED=694"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There is manuscript evidence that Austen conti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In a remarkable comparative analysis , Mandaea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Before Persephone was released to Hermes , who...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cogeneration plants are commonly found in dist...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Geneva -LRB- , ; , ; , ; ; -RRB- is the second...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416763</th>\n",
       "      <td>A Duke Nukem 3D version has been sold for Xbox...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416764</th>\n",
       "      <td>However , it is becoming replaced as a method ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416765</th>\n",
       "      <td>There are hand gestures in both Hindu and Budd...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416766</th>\n",
       "      <td>If it is necessary to use colors , try to choo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416767</th>\n",
       "      <td>Calgary Stampeders ,</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>416768 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            original_text  label\n",
       "0       There is manuscript evidence that Austen conti...      1\n",
       "1       In a remarkable comparative analysis , Mandaea...      1\n",
       "2       Before Persephone was released to Hermes , who...      1\n",
       "3       Cogeneration plants are commonly found in dist...      1\n",
       "4       Geneva -LRB- , ; , ; , ; ; -RRB- is the second...      1\n",
       "...                                                   ...    ...\n",
       "416763  A Duke Nukem 3D version has been sold for Xbox...      0\n",
       "416764  However , it is becoming replaced as a method ...      0\n",
       "416765  There are hand gestures in both Hindu and Budd...      0\n",
       "416766  If it is necessary to use colors , try to choo...      0\n",
       "416767                               Calgary Stampeders ,      0\n",
       "\n",
       "[416768 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = 'Data/WikiLarge_Train.csv'\n",
    "df = pd.read_csv(train_path, skiprows=0, skipfooter=0, engine='python')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['label']==1])/len(df) # the dataset label is well balanced "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'He studied in Armenia and Istanbul , then at Wisconsin University which he finished in 1915 .'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[50]['original_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117.921906192414"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['original_text'].apply(lambda x: len(x)).mean()\n",
    "# This means all texts are considered short text, which allows us to use dense representations, \n",
    "# as dense representations work well with short text.\n",
    "# Gensim.KeyedVectors.load('assets/wikipedia.100.word-vecs.kv')??? How to generate and use this???\n",
    "# Maybe we should train word2vec model on the entire corpus. Just training data? TOP 100 word-vectors(features)\n",
    "# Alternatively we could use bag-of-words model, which is term-document matrix representation, having much more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['original_text']\n",
    "y = df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>original_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-2011</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-2011</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-2000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-1997</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.636</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119087</th>\n",
       "      <td>119087</td>\n",
       "      <td>#NAME?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119088</th>\n",
       "      <td>119088</td>\n",
       "      <td>#NAME?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119089</th>\n",
       "      <td>119089</td>\n",
       "      <td>#NAME?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119090</th>\n",
       "      <td>119090</td>\n",
       "      <td>#NAME?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119091</th>\n",
       "      <td>119091</td>\n",
       "      <td>#NAME?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119092 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id original_text  label\n",
       "0            0         -2011    NaN\n",
       "1            1         -2011    NaN\n",
       "2            2         -2000    NaN\n",
       "3            3         -1997    NaN\n",
       "4            4         1.636    NaN\n",
       "...        ...           ...    ...\n",
       "119087  119087        #NAME?    NaN\n",
       "119088  119088        #NAME?    NaN\n",
       "119089  119089        #NAME?    NaN\n",
       "119090  119090        #NAME?    NaN\n",
       "119091  119091        #NAME?    NaN\n",
       "\n",
       "[119092 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_path = 'Data/WikiLarge_Test.csv'\n",
    "test_df = pd.read_csv(test_path, skiprows=0, skipfooter=0, engine='python')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                           10000\n",
       "original_text    An atheist would say that this argument proves...\n",
       "label                                                          NaN\n",
       "Name: 10000, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.iloc[10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119087</th>\n",
       "      <td>119087</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119088</th>\n",
       "      <td>119088</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119089</th>\n",
       "      <td>119089</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119090</th>\n",
       "      <td>119090</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119091</th>\n",
       "      <td>119091</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119092 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  label\n",
       "0            0      0\n",
       "1            1      0\n",
       "2            2      1\n",
       "3            3      1\n",
       "4            4      0\n",
       "...        ...    ...\n",
       "119087  119087      0\n",
       "119088  119088      1\n",
       "119089  119089      1\n",
       "119090  119090      1\n",
       "119091  119091      1\n",
       "\n",
       "[119092 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samplesubmission_path = 'Data/sampleSubmission.csv'\n",
    "samplesubmission_df = pd.read_csv(samplesubmission_path, skiprows=0, skipfooter=0, engine='python')\n",
    "samplesubmission_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conclude, the dataframes we are working with are:\n",
    "\n",
    "dalechall_df, concreteness_df, aoawords_df, train_df, test_df, samplesubmission_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=10,stop_words='english',ngram_range=(1,2))\n",
    "X_train_transform = vectorizer.fit_transform(X_train)\n",
    "X_test_transform  = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<333414x57773 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4071111 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(stopwords.words('english')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "== dale_chall.txt ==\n",
    "\n",
    "This is the Dale Chall 3000 Word List, which is one definition of words that are considered \"basic\" English.\n",
    "\n",
    "A summary is at https://www.readabilityformulas.com/articles/dale-chall-readability-word-list.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic english words\n",
    "dalechall_path = 'Data/dale_chall.txt'\n",
    "dale_chall = pd.read_csv(dalechall_path,delimiter='\\t',header=None,names=['word'])\n",
    "dale = set(dale_chall['word'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2946"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The 2946 words in dale can be combined with the nltk stopwords.\n",
    "### We could maybe assign an arbitrary score to each dale_chall word. - for reference only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will use a geo dataset to add city and country names to the stopwords library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datapackage in c:\\users\\mryua\\anaconda3\\lib\\site-packages (1.15.2)\n",
      "Requirement already satisfied: jsonpointer>=1.10 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from datapackage) (2.3)\n",
      "Requirement already satisfied: jsonschema>=2.5 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from datapackage) (3.2.0)\n",
      "Requirement already satisfied: requests>=2.8 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from datapackage) (2.24.0)\n",
      "Requirement already satisfied: chardet>=3.0 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from datapackage) (3.0.4)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from datapackage) (1.15.0)\n",
      "Requirement already satisfied: tableschema>=1.12.1 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from datapackage) (1.20.2)\n",
      "Requirement already satisfied: click>=6.7 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from datapackage) (7.1.2)\n",
      "Requirement already satisfied: unicodecsv>=0.14 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from datapackage) (0.14.1)\n",
      "Requirement already satisfied: tabulator>=1.29 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from datapackage) (1.53.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from jsonschema>=2.5->datapackage) (49.2.0.post20200714)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from jsonschema>=2.5->datapackage) (19.3.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from jsonschema>=2.5->datapackage) (0.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from requests>=2.8->datapackage) (2021.5.30)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from requests>=2.8->datapackage) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from requests>=2.8->datapackage) (2.10)\n",
      "Requirement already satisfied: rfc3986>=1.1.0 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from tableschema>=1.12.1->datapackage) (2.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.4 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from tableschema>=1.12.1->datapackage) (2.8.1)\n",
      "Requirement already satisfied: cached-property>=1.5 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from tableschema>=1.12.1->datapackage) (1.5.2)\n",
      "Requirement already satisfied: isodate>=0.5.4 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from tableschema>=1.12.1->datapackage) (0.6.1)\n",
      "Requirement already satisfied: ijson>=3.0.3 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from tabulator>=1.29->datapackage) (3.1.4)\n",
      "Requirement already satisfied: linear-tsv>=1.0 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from tabulator>=1.29->datapackage) (1.1.0)\n",
      "Requirement already satisfied: sqlalchemy>=0.9.6 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from tabulator>=1.29->datapackage) (1.3.18)\n",
      "Requirement already satisfied: openpyxl>=2.6 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from tabulator>=1.29->datapackage) (3.0.4)\n",
      "Requirement already satisfied: jsonlines>=1.1 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from tabulator>=1.29->datapackage) (3.0.0)\n",
      "Requirement already satisfied: xlrd>=1.0 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from tabulator>=1.29->datapackage) (1.2.0)\n",
      "Requirement already satisfied: boto3>=1.9 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from tabulator>=1.29->datapackage) (1.23.0)\n",
      "Requirement already satisfied: jdcal in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from openpyxl>=2.6->tabulator>=1.29->datapackage) (1.4.1)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from openpyxl>=2.6->tabulator>=1.29->datapackage) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from boto3>=1.9->tabulator>=1.29->datapackage) (0.5.2)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from boto3>=1.9->tabulator>=1.29->datapackage) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.27.0,>=1.26.0 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from boto3>=1.9->tabulator>=1.29->datapackage) (1.26.0)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install datapackage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['validation_report', 'world-cities_csv', 'world-cities_json', 'world-cities_zip', 'world-cities_csv_preview', 'world-cities']\n"
     ]
    }
   ],
   "source": [
    "from datapackage import Package\n",
    "package = Package('https://datahub.io/core/world-cities/datapackage.json')\n",
    "# print list of all resources:\n",
    "print(package.resource_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_cities = []\n",
    "for resource in package.resources:\n",
    "    if resource.descriptor['datahub']['type'] == 'derived/csv':\n",
    "        world_cities = resource.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23018"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(world_cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['les Escaldes', 'Andorra', 'Escaldes-Engordany', 3040051],\n",
       " ['Andorra la Vella', 'Andorra', 'Andorra la Vella', 3041563],\n",
       " ['Umm al Qaywayn', 'United Arab Emirates', 'Umm al Qaywayn', 290594],\n",
       " ['Ras al-Khaimah', 'United Arab Emirates', 'Raʼs al Khaymah', 291074],\n",
       " ['Khawr Fakkān', 'United Arab Emirates', 'Ash Shāriqah', 291696],\n",
       " ['Dubai', 'United Arab Emirates', 'Dubai', 292223],\n",
       " ['Dibba Al-Fujairah', 'United Arab Emirates', 'Al Fujayrah', 292231],\n",
       " ['Dibba Al-Hisn', 'United Arab Emirates', 'Al Fujayrah', 292239],\n",
       " ['Sharjah', 'United Arab Emirates', 'Ash Shāriqah', 292672],\n",
       " ['Ar Ruways', 'United Arab Emirates', 'Abu Dhabi', 292688]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world_cities[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_cities_df = pd.DataFrame(world_cities, columns=['name', 'country', 'subcountry', 'geonameid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>subcountry</th>\n",
       "      <th>geonameid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>les Escaldes</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>Escaldes-Engordany</td>\n",
       "      <td>3040051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>3041563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Umm al Qaywayn</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>Umm al Qaywayn</td>\n",
       "      <td>290594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ras al-Khaimah</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>Raʼs al Khaymah</td>\n",
       "      <td>291074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Khawr Fakkān</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>Ash Shāriqah</td>\n",
       "      <td>291696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23013</th>\n",
       "      <td>Bulawayo</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Bulawayo</td>\n",
       "      <td>894701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23014</th>\n",
       "      <td>Bindura</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Mashonaland Central</td>\n",
       "      <td>895061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23015</th>\n",
       "      <td>Beitbridge</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Matabeleland South</td>\n",
       "      <td>895269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23016</th>\n",
       "      <td>Epworth</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Harare</td>\n",
       "      <td>1085510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23017</th>\n",
       "      <td>Chitungwiza</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Harare</td>\n",
       "      <td>1106542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23018 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name               country           subcountry  geonameid\n",
       "0          les Escaldes               Andorra   Escaldes-Engordany    3040051\n",
       "1      Andorra la Vella               Andorra     Andorra la Vella    3041563\n",
       "2        Umm al Qaywayn  United Arab Emirates       Umm al Qaywayn     290594\n",
       "3        Ras al-Khaimah  United Arab Emirates      Raʼs al Khaymah     291074\n",
       "4          Khawr Fakkān  United Arab Emirates         Ash Shāriqah     291696\n",
       "...                 ...                   ...                  ...        ...\n",
       "23013          Bulawayo              Zimbabwe             Bulawayo     894701\n",
       "23014           Bindura              Zimbabwe  Mashonaland Central     895061\n",
       "23015        Beitbridge              Zimbabwe   Matabeleland South     895269\n",
       "23016           Epworth              Zimbabwe               Harare    1085510\n",
       "23017       Chitungwiza              Zimbabwe               Harare    1106542\n",
       "\n",
       "[23018 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world_cities_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_cities_df = world_cities_df.applymap(lambda s:s.lower() if type(s) == str else s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>subcountry</th>\n",
       "      <th>geonameid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6633</th>\n",
       "      <td>yerres</td>\n",
       "      <td>france</td>\n",
       "      <td>île-de-france</td>\n",
       "      <td>2967245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6634</th>\n",
       "      <td>wittenheim</td>\n",
       "      <td>france</td>\n",
       "      <td>alsace-champagne-ardenne-lorraine</td>\n",
       "      <td>2967318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6635</th>\n",
       "      <td>wattrelos</td>\n",
       "      <td>france</td>\n",
       "      <td>nord-pas-de-calais-picardie</td>\n",
       "      <td>2967421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6636</th>\n",
       "      <td>wasquehal</td>\n",
       "      <td>france</td>\n",
       "      <td>nord-pas-de-calais-picardie</td>\n",
       "      <td>2967438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6637</th>\n",
       "      <td>voiron</td>\n",
       "      <td>france</td>\n",
       "      <td>auvergne-rhône-alpes</td>\n",
       "      <td>2967758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7261</th>\n",
       "      <td>marseille 15</td>\n",
       "      <td>france</td>\n",
       "      <td>provence-alpes-côte d'azur</td>\n",
       "      <td>7284896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7262</th>\n",
       "      <td>marseille 16</td>\n",
       "      <td>france</td>\n",
       "      <td>provence-alpes-côte d'azur</td>\n",
       "      <td>7284897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7263</th>\n",
       "      <td>la defense</td>\n",
       "      <td>france</td>\n",
       "      <td>île-de-france</td>\n",
       "      <td>8504417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7264</th>\n",
       "      <td>saint-quentin-en-yvelines</td>\n",
       "      <td>france</td>\n",
       "      <td>île-de-france</td>\n",
       "      <td>8533870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7265</th>\n",
       "      <td>cergy-pontoise</td>\n",
       "      <td>france</td>\n",
       "      <td>île-de-france</td>\n",
       "      <td>8555643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>633 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name country                         subcountry  \\\n",
       "6633                     yerres  france                      île-de-france   \n",
       "6634                 wittenheim  france  alsace-champagne-ardenne-lorraine   \n",
       "6635                  wattrelos  france        nord-pas-de-calais-picardie   \n",
       "6636                  wasquehal  france        nord-pas-de-calais-picardie   \n",
       "6637                     voiron  france               auvergne-rhône-alpes   \n",
       "...                         ...     ...                                ...   \n",
       "7261               marseille 15  france         provence-alpes-côte d'azur   \n",
       "7262               marseille 16  france         provence-alpes-côte d'azur   \n",
       "7263                 la defense  france                      île-de-france   \n",
       "7264  saint-quentin-en-yvelines  france                      île-de-france   \n",
       "7265             cergy-pontoise  france                      île-de-france   \n",
       "\n",
       "      geonameid  \n",
       "6633    2967245  \n",
       "6634    2967318  \n",
       "6635    2967421  \n",
       "6636    2967438  \n",
       "6637    2967758  \n",
       "...         ...  \n",
       "7261    7284896  \n",
       "7262    7284897  \n",
       "7263    8504417  \n",
       "7264    8533870  \n",
       "7265    8555643  \n",
       "\n",
       "[633 rows x 4 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world_cities_df[world_cities_df['country']=='france']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = set(world_cities_df['name'].unique())\n",
    "countries = set(world_cities_df['country'].unique())\n",
    "subcountries = set(world_cities_df['subcountry'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will add this to stopwords\n",
    "geo_data = cities | countries | subcountries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21940"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "244"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2594"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subcountries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23803"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(geo_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['validation_report', 'language-codes_csv', 'language-codes-3b2_csv', 'language-codes-full_csv', 'ietf-language-tags_csv', 'language-codes_json', 'language-codes-3b2_json', 'language-codes-full_json', 'ietf-language-tags_json', 'language-codes_zip', 'language-codes', 'language-codes-3b2', 'language-codes-full', 'ietf-language-tags']\n"
     ]
    }
   ],
   "source": [
    "language_package = Package('https://datahub.io/core/language-codes/datapackage.json')\n",
    "\n",
    "# print list of all resources:\n",
    "print(language_package.resource_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print processed tabular data (if exists any)\n",
    "languages_data = []\n",
    "#for resource in language_package.resources:\n",
    "#    if resource.descriptor['datahub']['derivedFrom']=='language-codes':\n",
    "#        print(resource.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages_data = language_package.resources[1].read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha2</th>\n",
       "      <th>english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aa</td>\n",
       "      <td>afar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ab</td>\n",
       "      <td>abkhazian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ae</td>\n",
       "      <td>avestan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>af</td>\n",
       "      <td>afrikaans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ak</td>\n",
       "      <td>akan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>yi</td>\n",
       "      <td>yiddish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>yo</td>\n",
       "      <td>yoruba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>za</td>\n",
       "      <td>zhuang; chuang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>zh</td>\n",
       "      <td>chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>zu</td>\n",
       "      <td>zulu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>184 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    alpha2         english\n",
       "0       aa            afar\n",
       "1       ab       abkhazian\n",
       "2       ae         avestan\n",
       "3       af       afrikaans\n",
       "4       ak            akan\n",
       "..     ...             ...\n",
       "179     yi         yiddish\n",
       "180     yo          yoruba\n",
       "181     za  zhuang; chuang\n",
       "182     zh         chinese\n",
       "183     zu            zulu\n",
       "\n",
       "[184 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages_df = pd.DataFrame(languages_data, columns=['alpha2', 'english'])\n",
    "languages_df = languages_df.applymap(lambda s:s.lower() if type(s) == str else s)\n",
    "languages_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = set(languages_df['english'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nationality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>afghan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>albanian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>algerian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>andorran</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>wallisian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>welsh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>yemeni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>zambian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>zimbabwean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nationality\n",
       "0        afghan\n",
       "1      albanian\n",
       "2      algerian\n",
       "3      american\n",
       "4      andorran\n",
       "..          ...\n",
       "220   wallisian\n",
       "221       welsh\n",
       "222      yemeni\n",
       "223     zambian\n",
       "224  zimbabwean\n",
       "\n",
       "[225 rows x 1 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nationality_path = 'Data/CH_Nationality_List_20171130_v1.csv'\n",
    "nationality_df = pd.read_csv(nationality_path, skiprows=0, skipfooter=0, engine='python')\n",
    "nationality_df = nationality_df.applymap(lambda s:s.lower() if type(s) == str else s)\n",
    "nationality_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nationalities = set(nationality_df['Nationality'].unique())\n",
    "len(nationalities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>country_id</th>\n",
       "      <th>country_code</th>\n",
       "      <th>country_name</th>\n",
       "      <th>state_code</th>\n",
       "      <th>type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3901</td>\n",
       "      <td>badakhshan</td>\n",
       "      <td>1</td>\n",
       "      <td>af</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td>bds</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.734772</td>\n",
       "      <td>70.811995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3871</td>\n",
       "      <td>badghis</td>\n",
       "      <td>1</td>\n",
       "      <td>af</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td>bdg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.167134</td>\n",
       "      <td>63.769538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3875</td>\n",
       "      <td>baghlan</td>\n",
       "      <td>1</td>\n",
       "      <td>af</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td>bgl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.178903</td>\n",
       "      <td>68.745306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3884</td>\n",
       "      <td>balkh</td>\n",
       "      <td>1</td>\n",
       "      <td>af</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td>bal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.755060</td>\n",
       "      <td>66.897537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3872</td>\n",
       "      <td>bamyan</td>\n",
       "      <td>1</td>\n",
       "      <td>af</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td>bam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.810007</td>\n",
       "      <td>67.821210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4974</th>\n",
       "      <td>1953</td>\n",
       "      <td>mashonaland west province</td>\n",
       "      <td>247</td>\n",
       "      <td>zw</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>mw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-17.485103</td>\n",
       "      <td>29.788925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4975</th>\n",
       "      <td>1960</td>\n",
       "      <td>masvingo province</td>\n",
       "      <td>247</td>\n",
       "      <td>zw</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>mv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-20.624151</td>\n",
       "      <td>31.262637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4976</th>\n",
       "      <td>1954</td>\n",
       "      <td>matabeleland north province</td>\n",
       "      <td>247</td>\n",
       "      <td>zw</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>mn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-18.533157</td>\n",
       "      <td>27.549585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4977</th>\n",
       "      <td>1952</td>\n",
       "      <td>matabeleland south province</td>\n",
       "      <td>247</td>\n",
       "      <td>zw</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>ms</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21.052337</td>\n",
       "      <td>29.045993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4978</th>\n",
       "      <td>1957</td>\n",
       "      <td>midlands province</td>\n",
       "      <td>247</td>\n",
       "      <td>zw</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>mi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-19.055201</td>\n",
       "      <td>29.603549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4979 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                         name  country_id country_code country_name  \\\n",
       "0     3901                   badakhshan           1           af  afghanistan   \n",
       "1     3871                      badghis           1           af  afghanistan   \n",
       "2     3875                      baghlan           1           af  afghanistan   \n",
       "3     3884                        balkh           1           af  afghanistan   \n",
       "4     3872                       bamyan           1           af  afghanistan   \n",
       "...    ...                          ...         ...          ...          ...   \n",
       "4974  1953    mashonaland west province         247           zw     zimbabwe   \n",
       "4975  1960            masvingo province         247           zw     zimbabwe   \n",
       "4976  1954  matabeleland north province         247           zw     zimbabwe   \n",
       "4977  1952  matabeleland south province         247           zw     zimbabwe   \n",
       "4978  1957            midlands province         247           zw     zimbabwe   \n",
       "\n",
       "     state_code type   latitude  longitude  \n",
       "0           bds  NaN  36.734772  70.811995  \n",
       "1           bdg  NaN  35.167134  63.769538  \n",
       "2           bgl  NaN  36.178903  68.745306  \n",
       "3           bal  NaN  36.755060  66.897537  \n",
       "4           bam  NaN  34.810007  67.821210  \n",
       "...         ...  ...        ...        ...  \n",
       "4974         mw  NaN -17.485103  29.788925  \n",
       "4975         mv  NaN -20.624151  31.262637  \n",
       "4976         mn  NaN -18.533157  27.549585  \n",
       "4977         ms  NaN -21.052337  29.045993  \n",
       "4978         mi  NaN -19.055201  29.603549  \n",
       "\n",
       "[4979 rows x 9 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_path = 'Data/states.csv'\n",
    "states_df = pd.read_csv(states_path, skiprows=0, skipfooter=0, engine='python')\n",
    "states_df = states_df.applymap(lambda s:s.lower() if type(s) == str else s)\n",
    "states_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4896"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = set(states_df['name'].unique())\n",
    "len(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ï»¿name</th>\n",
       "      <th>alpha-2</th>\n",
       "      <th>alpha-3</th>\n",
       "      <th>country-code</th>\n",
       "      <th>iso_3166-2</th>\n",
       "      <th>region</th>\n",
       "      <th>sub-region</th>\n",
       "      <th>intermediate-region</th>\n",
       "      <th>region-code</th>\n",
       "      <th>sub-region-code</th>\n",
       "      <th>intermediate-region-code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>afghanistan</td>\n",
       "      <td>af</td>\n",
       "      <td>afg</td>\n",
       "      <td>4</td>\n",
       "      <td>iso 3166-2:af</td>\n",
       "      <td>asia</td>\n",
       "      <td>southern asia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>142.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ã…land islands</td>\n",
       "      <td>ax</td>\n",
       "      <td>ala</td>\n",
       "      <td>248</td>\n",
       "      <td>iso 3166-2:ax</td>\n",
       "      <td>europe</td>\n",
       "      <td>northern europe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>albania</td>\n",
       "      <td>al</td>\n",
       "      <td>alb</td>\n",
       "      <td>8</td>\n",
       "      <td>iso 3166-2:al</td>\n",
       "      <td>europe</td>\n",
       "      <td>southern europe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>algeria</td>\n",
       "      <td>dz</td>\n",
       "      <td>dza</td>\n",
       "      <td>12</td>\n",
       "      <td>iso 3166-2:dz</td>\n",
       "      <td>africa</td>\n",
       "      <td>northern africa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>american samoa</td>\n",
       "      <td>as</td>\n",
       "      <td>asm</td>\n",
       "      <td>16</td>\n",
       "      <td>iso 3166-2:as</td>\n",
       "      <td>oceania</td>\n",
       "      <td>polynesia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>wallis and futuna</td>\n",
       "      <td>wf</td>\n",
       "      <td>wlf</td>\n",
       "      <td>876</td>\n",
       "      <td>iso 3166-2:wf</td>\n",
       "      <td>oceania</td>\n",
       "      <td>polynesia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>western sahara</td>\n",
       "      <td>eh</td>\n",
       "      <td>esh</td>\n",
       "      <td>732</td>\n",
       "      <td>iso 3166-2:eh</td>\n",
       "      <td>africa</td>\n",
       "      <td>northern africa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>yemen</td>\n",
       "      <td>ye</td>\n",
       "      <td>yem</td>\n",
       "      <td>887</td>\n",
       "      <td>iso 3166-2:ye</td>\n",
       "      <td>asia</td>\n",
       "      <td>western asia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>142.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>zambia</td>\n",
       "      <td>zm</td>\n",
       "      <td>zmb</td>\n",
       "      <td>894</td>\n",
       "      <td>iso 3166-2:zm</td>\n",
       "      <td>africa</td>\n",
       "      <td>sub-saharan africa</td>\n",
       "      <td>eastern africa</td>\n",
       "      <td>2.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>zw</td>\n",
       "      <td>zwe</td>\n",
       "      <td>716</td>\n",
       "      <td>iso 3166-2:zw</td>\n",
       "      <td>africa</td>\n",
       "      <td>sub-saharan africa</td>\n",
       "      <td>eastern africa</td>\n",
       "      <td>2.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>249 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ï»¿name alpha-2 alpha-3  country-code     iso_3166-2   region  \\\n",
       "0          afghanistan      af     afg             4  iso 3166-2:af     asia   \n",
       "1       ã…land islands      ax     ala           248  iso 3166-2:ax   europe   \n",
       "2              albania      al     alb             8  iso 3166-2:al   europe   \n",
       "3              algeria      dz     dza            12  iso 3166-2:dz   africa   \n",
       "4       american samoa      as     asm            16  iso 3166-2:as  oceania   \n",
       "..                 ...     ...     ...           ...            ...      ...   \n",
       "244  wallis and futuna      wf     wlf           876  iso 3166-2:wf  oceania   \n",
       "245     western sahara      eh     esh           732  iso 3166-2:eh   africa   \n",
       "246              yemen      ye     yem           887  iso 3166-2:ye     asia   \n",
       "247             zambia      zm     zmb           894  iso 3166-2:zm   africa   \n",
       "248           zimbabwe      zw     zwe           716  iso 3166-2:zw   africa   \n",
       "\n",
       "             sub-region intermediate-region  region-code  sub-region-code  \\\n",
       "0         southern asia                 NaN        142.0             34.0   \n",
       "1       northern europe                 NaN        150.0            154.0   \n",
       "2       southern europe                 NaN        150.0             39.0   \n",
       "3       northern africa                 NaN          2.0             15.0   \n",
       "4             polynesia                 NaN          9.0             61.0   \n",
       "..                  ...                 ...          ...              ...   \n",
       "244           polynesia                 NaN          9.0             61.0   \n",
       "245     northern africa                 NaN          2.0             15.0   \n",
       "246        western asia                 NaN        142.0            145.0   \n",
       "247  sub-saharan africa      eastern africa          2.0            202.0   \n",
       "248  sub-saharan africa      eastern africa          2.0            202.0   \n",
       "\n",
       "     intermediate-region-code  \n",
       "0                         NaN  \n",
       "1                         NaN  \n",
       "2                         NaN  \n",
       "3                         NaN  \n",
       "4                         NaN  \n",
       "..                        ...  \n",
       "244                       NaN  \n",
       "245                       NaN  \n",
       "246                       NaN  \n",
       "247                      14.0  \n",
       "248                      14.0  \n",
       "\n",
       "[249 rows x 11 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continents_path = 'Data/continents2.csv'\n",
    "continents_df = pd.read_csv(continents_path, skiprows=0, skipfooter=0, engine='python')\n",
    "continents_df = continents_df.applymap(lambda s:s.lower() if type(s) == str else s)\n",
    "continents_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continents = set(continents_df['region'].unique())\n",
    "len(continents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>newPerct2013</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>michael</td>\n",
       "      <td>0.011577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>james</td>\n",
       "      <td>0.010218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>john</td>\n",
       "      <td>0.009675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>robert</td>\n",
       "      <td>0.009493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>david</td>\n",
       "      <td>0.008943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>christina</td>\n",
       "      <td>0.001435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>julie</td>\n",
       "      <td>0.001418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>jordan</td>\n",
       "      <td>0.001416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>kyle</td>\n",
       "      <td>0.001413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>anna</td>\n",
       "      <td>0.001400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0       name  newPerct2013\n",
       "0            1    michael      0.011577\n",
       "1            2      james      0.010218\n",
       "2            3       john      0.009675\n",
       "3            4     robert      0.009493\n",
       "4            5      david      0.008943\n",
       "..         ...        ...           ...\n",
       "95          96  christina      0.001435\n",
       "96          97      julie      0.001418\n",
       "97          98     jordan      0.001416\n",
       "98          99       kyle      0.001413\n",
       "99         100       anna      0.001400\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstname_path = 'Data/new-top-firstNames.csv'\n",
    "firstname_df = pd.read_csv(firstname_path, skiprows=0, skipfooter=0, engine='python')\n",
    "firstname_df = firstname_df.applymap(lambda s:s.lower() if type(s) == str else s)\n",
    "firstname_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstnames = set(firstname_df['name'].unique())\n",
    "len(firstnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>john</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>william</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>james</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>charles</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>george</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6777</th>\n",
       "      <td>laylah</td>\n",
       "      <td>girl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6778</th>\n",
       "      <td>carleigh</td>\n",
       "      <td>girl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6779</th>\n",
       "      <td>kenley</td>\n",
       "      <td>girl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6780</th>\n",
       "      <td>sloane</td>\n",
       "      <td>girl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6781</th>\n",
       "      <td>elianna</td>\n",
       "      <td>girl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6782 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0     1\n",
       "0         john   boy\n",
       "1      william   boy\n",
       "2        james   boy\n",
       "3      charles   boy\n",
       "4       george   boy\n",
       "...        ...   ...\n",
       "6777    laylah  girl\n",
       "6778  carleigh  girl\n",
       "6779    kenley  girl\n",
       "6780    sloane  girl\n",
       "6781   elianna  girl\n",
       "\n",
       "[6782 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstname_path2 = 'Data/babynames-clean.csv'\n",
    "firstname_df2 = pd.read_csv(firstname_path2, header= None, skiprows=0, skipfooter=0, engine='python')\n",
    "firstname_df2 = firstname_df2.applymap(lambda s:s.lower() if type(s) == str else s)\n",
    "firstname_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6782"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstnames2 = set(firstname_df2[0].unique())\n",
    "len(firstnames2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6782"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstnames = firstnames | firstnames2\n",
    "len(firstnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>perct2013</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>smith</td>\n",
       "      <td>0.007999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>johnson</td>\n",
       "      <td>0.006346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>williams</td>\n",
       "      <td>0.005330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>brown</td>\n",
       "      <td>0.004724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>jones</td>\n",
       "      <td>0.004676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>vasquez</td>\n",
       "      <td>0.000760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>sanders</td>\n",
       "      <td>0.000753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>jimenez</td>\n",
       "      <td>0.000751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>long</td>\n",
       "      <td>0.000747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>foster</td>\n",
       "      <td>0.000746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0      name  perct2013\n",
       "0            1     smith   0.007999\n",
       "1            2   johnson   0.006346\n",
       "2            3  williams   0.005330\n",
       "3            4     brown   0.004724\n",
       "4            5     jones   0.004676\n",
       "..         ...       ...        ...\n",
       "95          96   vasquez   0.000760\n",
       "96          97   sanders   0.000753\n",
       "97          98   jimenez   0.000751\n",
       "98          99      long   0.000747\n",
       "99         100    foster   0.000746\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surname_path = 'Data/new-top-surnames.csv'\n",
    "surname_df = pd.read_csv(surname_path, skiprows=0, skipfooter=0, engine='python')\n",
    "surname_df = surname_df.applymap(lambda s:s.lower() if type(s) == str else s)\n",
    "surname_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surnames = set(surname_df['name'].unique())\n",
    "len(surnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "days=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']\n",
    "months=['January','February','March', 'April','May','June','July','August','September','October','November','December']\n",
    "calendar = days.copy()\n",
    "calendar.extend(months)\n",
    "calendar = set([w.lower() for w in calendar])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'april',\n",
       " 'august',\n",
       " 'december',\n",
       " 'february',\n",
       " 'friday',\n",
       " 'january',\n",
       " 'july',\n",
       " 'june',\n",
       " 'march',\n",
       " 'may',\n",
       " 'monday',\n",
       " 'november',\n",
       " 'october',\n",
       " 'saturday',\n",
       " 'september',\n",
       " 'sunday',\n",
       " 'thursday',\n",
       " 'tuesday',\n",
       " 'wednesday'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "304501    1979-80 Buffalo Sabres NHL 32 1880 74 1 4 2.36...\n",
       "162313    Diseases Lentils in culture Lentils are mentio...\n",
       "336845    Railroads , like the Lehigh Valley Railroad , ...\n",
       "150625    An example of this would be an individual anim...\n",
       "40240     Both the Matanuska and Susitna Rivers have maj...\n",
       "                                ...                        \n",
       "259178    After the Germans invaded Norway in April 1940...\n",
       "365838    July 28 - Henry Bennet , 1st Earl of Arlington...\n",
       "131932    Pancake restaurants are popular family restaur...\n",
       "146867                                 A cycling domestique\n",
       "121958    David Boreanaz 's first paid acting appearance...\n",
       "Name: original_text, Length: 333414, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1979-80 Buffalo Sabres NHL 32 1880 74 1 4 2.36 20 8 4 0 0.000'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[304501]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['buffalo', 'sabres', 'nhl']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim.utils.simple_preprocess(X_train[304501])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gensim.parsing.preprocessing.STOPWORDS\n",
    "#stopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text_train=[]\n",
    "tokenized_text_test=[]\n",
    "stopWords = set(stopwords.words('english')) | dale | geo_data | languages | nationalities | states | continents | firstnames | surnames | calendar\n",
    "# This cell will run 4 minutes\n",
    "import gensim\n",
    "from nltk.stem.porter import *\n",
    "def lemmatize_stemming(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    #Un-hash next line to use stemming\n",
    "    #return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "    #Un-hash next line to NOT use stemming\n",
    "    return WordNetLemmatizer().lemmatize(text, pos='v')\n",
    "\n",
    "# Tokenize and lemmatize\n",
    "def preprocess(text):\n",
    "    result=[]\n",
    "    for token in gensim.utils.simple_preprocess(text) :\n",
    "        if token not in stopWords and len(token) > 3:\n",
    "            #Un-hash next line to use lemmatization/stemming\n",
    "            result.append(lemmatize_stemming(token))\n",
    "            #Un-hash next line to NOT use lemmatization/stemming\n",
    "            #result.append(token)\n",
    "            \n",
    "    return result\n",
    "\n",
    "tokenized_text_train = [preprocess(text) for text in X_train]\n",
    "tokenized_text_test=[preprocess(text) for text in X_test]\n",
    "\n",
    "#for text in tqdm(X_train):\n",
    "#    tokens_in_text = word_tokenize(text)\n",
    "#    tokens_in_text = [word for word in tokens_in_text if word.lower() not in stopWords]\n",
    "#    tokenized_text_train.append(tokens_in_text)\n",
    "    \n",
    "#for text in tqdm(X_test):\n",
    "#    tokens_in_text = word_tokenize(text)\n",
    "#    tokens_in_text = [word for word in tokens_in_text if word.lower() not in stopWords]\n",
    "#    tokenized_text_test.append(tokens_in_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36872"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenized_text_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5798971, 9373610)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Word2Vec(vector_size=100,window=2,min_count=100,seed= RANDOM_SEED,workers=4)\n",
    "model.build_vocab(tokenized_text_train)\n",
    "model.train(tokenized_text_train,total_examples=model.corpus_count,epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_vectors.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = word_vectors.key_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unite': 0,\n",
       " 'department': 1,\n",
       " 'state': 2,\n",
       " 'region': 3,\n",
       " 'commune': 4,\n",
       " 'include': 5,\n",
       " 'call': 6,\n",
       " 'play': 7,\n",
       " 'national': 8,\n",
       " 'district': 9,\n",
       " 'release': 10,\n",
       " 'years': 11,\n",
       " 'name': 12,\n",
       " 'locate': 13,\n",
       " 'area': 14,\n",
       " 'former': 15,\n",
       " 'series': 16,\n",
       " 'later': 17,\n",
       " 'album': 18,\n",
       " 'league': 19,\n",
       " 'system': 20,\n",
       " 'work': 21,\n",
       " 'century': 22,\n",
       " 'base': 23,\n",
       " 'award': 24,\n",
       " 'population': 25,\n",
       " 'refer': 26,\n",
       " 'largest': 27,\n",
       " 'province': 28,\n",
       " 'start': 29,\n",
       " 'record': 30,\n",
       " 'form': 31,\n",
       " 'ndash': 32,\n",
       " 'create': 33,\n",
       " 'main': 34,\n",
       " 'usually': 35,\n",
       " 'president': 36,\n",
       " 'international': 37,\n",
       " 'force': 38,\n",
       " 'produce': 39,\n",
       " 'type': 40,\n",
       " 'television': 41,\n",
       " 'use': 42,\n",
       " 'species': 43,\n",
       " 'game': 44,\n",
       " 'common': 45,\n",
       " 'feature': 46,\n",
       " 'publish': 47,\n",
       " 'professional': 48,\n",
       " 'found': 49,\n",
       " 'municipality': 50,\n",
       " 'although': 51,\n",
       " 'currently': 52,\n",
       " 'character': 53,\n",
       " 'championship': 54,\n",
       " 'modern': 55,\n",
       " 'famous': 56,\n",
       " 'develop': 57,\n",
       " 'members': 58,\n",
       " 'popular': 59,\n",
       " 'video': 60,\n",
       " 'tropical': 61,\n",
       " 'time': 62,\n",
       " 'serve': 63,\n",
       " 'republic': 64,\n",
       " 'show': 65,\n",
       " 'hurricane': 66,\n",
       " 'within': 67,\n",
       " 'period': 68,\n",
       " 'consider': 69,\n",
       " 'official': 70,\n",
       " 'change': 71,\n",
       " 'contain': 72,\n",
       " 'design': 73,\n",
       " 'example': 74,\n",
       " 'move': 75,\n",
       " 'countries': 76,\n",
       " 'result': 77,\n",
       " 'reference': 78,\n",
       " 'original': 79,\n",
       " 'program': 80,\n",
       " 'european': 81,\n",
       " 'total': 82,\n",
       " 'appear': 83,\n",
       " 'accord': 84,\n",
       " 'career': 85,\n",
       " 'minister': 86,\n",
       " 'control': 87,\n",
       " 'support': 88,\n",
       " 'basse': 89,\n",
       " 'allow': 90,\n",
       " 'perform': 91,\n",
       " 'current': 92,\n",
       " 'hockey': 93,\n",
       " 'article': 94,\n",
       " 'commonly': 95,\n",
       " 'border': 96,\n",
       " 'islands': 97,\n",
       " 'footballer': 98,\n",
       " 'local': 99,\n",
       " 'empire': 100,\n",
       " 'wrestle': 101,\n",
       " 'star': 102,\n",
       " 'division': 103,\n",
       " 'establish': 104,\n",
       " 'range': 105,\n",
       " 'open': 106,\n",
       " 'actor': 107,\n",
       " 'study': 108,\n",
       " 'originally': 109,\n",
       " 'join': 110,\n",
       " 'part': 111,\n",
       " 'cause': 112,\n",
       " 'remain': 113,\n",
       " 'role': 114,\n",
       " 'continue': 115,\n",
       " 'political': 116,\n",
       " 'receive': 117,\n",
       " 'consist': 118,\n",
       " 'version': 119,\n",
       " 'human': 120,\n",
       " 'similar': 121,\n",
       " 'days': 122,\n",
       " 'emperor': 123,\n",
       " 'mean': 124,\n",
       " 'provide': 125,\n",
       " 'areas': 126,\n",
       " 'process': 127,\n",
       " 'final': 128,\n",
       " 'network': 129,\n",
       " 'pay': 130,\n",
       " 'science': 131,\n",
       " 'source': 132,\n",
       " 'book': 133,\n",
       " 'describe': 134,\n",
       " 'association': 135,\n",
       " 'operate': 136,\n",
       " 'ancient': 137,\n",
       " 'style': 138,\n",
       " 'military': 139,\n",
       " 'place': 140,\n",
       " 'computer': 141,\n",
       " 'event': 142,\n",
       " 'position': 143,\n",
       " 'events': 144,\n",
       " 'energy': 145,\n",
       " 'complete': 146,\n",
       " 'various': 147,\n",
       " 'picardie': 148,\n",
       " 'sign': 149,\n",
       " 'languages': 150,\n",
       " 'natural': 151,\n",
       " 'replace': 152,\n",
       " 'prime': 153,\n",
       " 'aquitaine': 154,\n",
       " 'generally': 155,\n",
       " 'atlantic': 156,\n",
       " 'discover': 157,\n",
       " 'development': 158,\n",
       " 'reach': 159,\n",
       " 'formula': 160,\n",
       " 'census': 161,\n",
       " 'exist': 162,\n",
       " 'director': 163,\n",
       " 'relate': 164,\n",
       " 'represent': 165,\n",
       " 'orchestra': 166,\n",
       " 'parliament': 167,\n",
       " 'writer': 168,\n",
       " 'team': 169,\n",
       " 'project': 170,\n",
       " 'site': 171,\n",
       " 'race': 172,\n",
       " 'songs': 173,\n",
       " 'model': 174,\n",
       " 'special': 175,\n",
       " 'occur': 176,\n",
       " 'systems': 177,\n",
       " 'film': 178,\n",
       " 'plant': 179,\n",
       " 'sport': 180,\n",
       " 'information': 181,\n",
       " 'image': 182,\n",
       " 'others': 183,\n",
       " 'port': 184,\n",
       " 'follow': 185,\n",
       " 'chemical': 186,\n",
       " 'number': 187,\n",
       " 'rule': 188,\n",
       " 'software': 189,\n",
       " 'win': 190,\n",
       " 'object': 191,\n",
       " 'group': 192,\n",
       " 'theory': 193,\n",
       " 'highest': 194,\n",
       " 'cities': 195,\n",
       " 'cover': 196,\n",
       " 'organization': 197,\n",
       " 'actress': 198,\n",
       " 'tour': 199,\n",
       " 'train': 200,\n",
       " 'almost': 201,\n",
       " 'lead': 202,\n",
       " 'movement': 203,\n",
       " 'across': 204,\n",
       " 'elect': 205,\n",
       " 'speak': 206,\n",
       " 'stadium': 207,\n",
       " 'return': 208,\n",
       " 'increase': 209,\n",
       " 'composer': 210,\n",
       " 'opera': 211,\n",
       " 'research': 212,\n",
       " 'novel': 213,\n",
       " 'culture': 214,\n",
       " 'live': 215,\n",
       " 'studio': 216,\n",
       " 'divide': 217,\n",
       " 'influence': 218,\n",
       " 'independent': 219,\n",
       " 'debut': 220,\n",
       " 'officially': 221,\n",
       " 'entertainment': 222,\n",
       " 'players': 223,\n",
       " 'community': 224,\n",
       " 'structure': 225,\n",
       " 'claim': 226,\n",
       " 'lower': 227,\n",
       " 'simply': 228,\n",
       " 'introduce': 229,\n",
       " 'end': 230,\n",
       " 'social': 231,\n",
       " 'issue': 232,\n",
       " 'involve': 233,\n",
       " 'pass': 234,\n",
       " 'catholic': 235,\n",
       " 'animals': 236,\n",
       " 'especially': 237,\n",
       " 'northwestern': 238,\n",
       " 'disney': 239,\n",
       " 'genus': 240,\n",
       " 'throughout': 241,\n",
       " 'retire': 242,\n",
       " 'guitar': 243,\n",
       " 'soviet': 244,\n",
       " 'act': 245,\n",
       " 'brand': 246,\n",
       " 'territory': 247,\n",
       " 'traditional': 248,\n",
       " 'mass': 249,\n",
       " 'add': 250,\n",
       " 'britain': 251,\n",
       " 'grow': 252,\n",
       " 'word': 253,\n",
       " 'airport': 254,\n",
       " 'production': 255,\n",
       " 'travel': 256,\n",
       " 'wikipedia': 257,\n",
       " 'approximately': 258,\n",
       " 'native': 259,\n",
       " 'announce': 260,\n",
       " 'effect': 261,\n",
       " 'politician': 262,\n",
       " 'unit': 263,\n",
       " 'defeat': 264,\n",
       " 'come': 265,\n",
       " 'standard': 266,\n",
       " 'civil': 267,\n",
       " 'oldest': 268,\n",
       " 'define': 269,\n",
       " 'units': 270,\n",
       " 'available': 271,\n",
       " 'data': 272,\n",
       " 'society': 273,\n",
       " 'direct': 274,\n",
       " 'point': 275,\n",
       " 'successful': 276,\n",
       " 'associate': 277,\n",
       " 'channel': 278,\n",
       " 'musical': 279,\n",
       " 'distance': 280,\n",
       " 'rank': 281,\n",
       " 'action': 282,\n",
       " 'academy': 283,\n",
       " 'limit': 284,\n",
       " 'report': 285,\n",
       " 'help': 286,\n",
       " 'service': 287,\n",
       " 'pacific': 288,\n",
       " 'super': 289,\n",
       " 'orbit': 290,\n",
       " 'average': 291,\n",
       " 'require': 292,\n",
       " 'instrument': 293,\n",
       " 'episode': 294,\n",
       " 'page': 295,\n",
       " 'education': 296,\n",
       " 'websites': 297,\n",
       " 'term': 298,\n",
       " 'smaller': 299,\n",
       " 'windows': 300,\n",
       " 'section': 301,\n",
       " 'premier': 302,\n",
       " 'secretary': 303,\n",
       " 'turn': 304,\n",
       " 'date': 305,\n",
       " 'mainly': 306,\n",
       " 'dynasty': 307,\n",
       " 'attempt': 308,\n",
       " 'larger': 309,\n",
       " 'function': 310,\n",
       " 'estimate': 311,\n",
       " 'note': 312,\n",
       " 'mountains': 313,\n",
       " 'make': 314,\n",
       " 'arts': 315,\n",
       " 'line': 316,\n",
       " 'label': 317,\n",
       " 'compose': 318,\n",
       " 'scale': 319,\n",
       " 'cathedral': 320,\n",
       " 'nintendo': 321,\n",
       " 'festival': 322,\n",
       " 'performance': 323,\n",
       " 'thus': 324,\n",
       " 'administrative': 325,\n",
       " 'say': 326,\n",
       " 'albums': 327,\n",
       " 'fiction': 328,\n",
       " 'metropolitan': 329,\n",
       " 'students': 330,\n",
       " 'nations': 331,\n",
       " 'alpes': 332,\n",
       " 'partement': 333,\n",
       " 'nuclear': 334,\n",
       " 'producer': 335,\n",
       " 'success': 336,\n",
       " 'display': 337,\n",
       " 'months': 338,\n",
       " 'typically': 339,\n",
       " 'become': 340,\n",
       " 'surround': 341,\n",
       " 'link': 342,\n",
       " 'female': 343,\n",
       " 'own': 344,\n",
       " 'recognize': 345,\n",
       " 'material': 346,\n",
       " 'nobel': 347,\n",
       " 'addition': 348,\n",
       " 'want': 349,\n",
       " 'conduct': 350,\n",
       " 'list': 351,\n",
       " 'decide': 352,\n",
       " 'african': 353,\n",
       " 'believe': 354,\n",
       " 'arm': 355,\n",
       " 'right': 356,\n",
       " 'title': 357,\n",
       " 'derive': 358,\n",
       " 'school': 359,\n",
       " 'museum': 360,\n",
       " 'text': 361,\n",
       " 'finish': 362,\n",
       " 'things': 363,\n",
       " 'greater': 364,\n",
       " 'concert': 365,\n",
       " 'suggest': 366,\n",
       " 'religious': 367,\n",
       " 'widely': 368,\n",
       " 'cells': 369,\n",
       " 'pope': 370,\n",
       " 'election': 371,\n",
       " 'attack': 372,\n",
       " 'edition': 373,\n",
       " 'take': 374,\n",
       " 'institute': 375,\n",
       " 'physical': 376,\n",
       " 'compound': 377,\n",
       " 'pressure': 378,\n",
       " 'purpose': 379,\n",
       " 'higher': 380,\n",
       " 'eventually': 381,\n",
       " 'single': 382,\n",
       " 'picardy': 383,\n",
       " 'practice': 384,\n",
       " 'primary': 385,\n",
       " 'lie': 386,\n",
       " 'borough': 387,\n",
       " 'condition': 388,\n",
       " 'combine': 389,\n",
       " 'private': 390,\n",
       " 'plan': 391,\n",
       " 'extend': 392,\n",
       " 'guitarist': 393,\n",
       " 'musician': 394,\n",
       " 'enter': 395,\n",
       " 'code': 396,\n",
       " 'treaty': 397,\n",
       " 'symbol': 398,\n",
       " 'situate': 399,\n",
       " 'category': 400,\n",
       " 'house': 401,\n",
       " 'professor': 402,\n",
       " 'comedy': 403,\n",
       " 'towns': 404,\n",
       " 'survive': 405,\n",
       " 'share': 406,\n",
       " 'website': 407,\n",
       " 'engineer': 408,\n",
       " 'songwriter': 409,\n",
       " 'regard': 410,\n",
       " 'build': 411,\n",
       " 'season': 412,\n",
       " 'declare': 413,\n",
       " 'worldwide': 414,\n",
       " 'particularly': 415,\n",
       " 'nature': 416,\n",
       " 'connect': 417,\n",
       " 'status': 418,\n",
       " 'host': 419,\n",
       " 'active': 420,\n",
       " 'air': 421,\n",
       " 'regions': 422,\n",
       " 'internet': 423,\n",
       " 'historical': 424,\n",
       " 'economic': 425,\n",
       " 'formerly': 426,\n",
       " 'location': 427,\n",
       " 'humans': 428,\n",
       " 'copy': 429,\n",
       " 'apply': 430,\n",
       " 'animate': 431,\n",
       " 'nickname': 432,\n",
       " 'temperature': 433,\n",
       " 'classical': 434,\n",
       " 'destroy': 435,\n",
       " 'democratic': 436,\n",
       " 'multiple': 437,\n",
       " 'elements': 438,\n",
       " 'alternative': 439,\n",
       " 'planet': 440,\n",
       " 'particular': 441,\n",
       " 'bass': 442,\n",
       " 'industry': 443,\n",
       " 'revolution': 444,\n",
       " 'olympic': 445,\n",
       " 'appoint': 446,\n",
       " 'fall': 447,\n",
       " 'nation': 448,\n",
       " 'draft': 449,\n",
       " 'jewish': 450,\n",
       " 'primarily': 451,\n",
       " 'experience': 452,\n",
       " 'future': 453,\n",
       " 'hold': 454,\n",
       " 'access': 455,\n",
       " 'launch': 456,\n",
       " 'foreign': 457,\n",
       " 'parent': 458,\n",
       " 'adopt': 459,\n",
       " 'individual': 460,\n",
       " 'rat': 461,\n",
       " 'prix': 462,\n",
       " 'chess': 463,\n",
       " 'recent': 464,\n",
       " 'regular': 465,\n",
       " 'statistics': 466,\n",
       " 'korea': 467,\n",
       " 'older': 468,\n",
       " 'advance': 469,\n",
       " 'depression': 470,\n",
       " 'literature': 471,\n",
       " 'capture': 472,\n",
       " 'graduate': 473,\n",
       " 'disease': 474,\n",
       " 'zone': 475,\n",
       " 'need': 476,\n",
       " 'founder': 477,\n",
       " 'flower': 478,\n",
       " 'complex': 479,\n",
       " 'account': 480,\n",
       " 'power': 481,\n",
       " 'inhabitants': 482,\n",
       " 'southeast': 483,\n",
       " 'peninsula': 484,\n",
       " 'earlier': 485,\n",
       " 'ask': 486,\n",
       " 'commercial': 487,\n",
       " 'vote': 488,\n",
       " 'medical': 489,\n",
       " 'greatest': 490,\n",
       " 'basketball': 491,\n",
       " 'user': 492,\n",
       " 'poet': 493,\n",
       " 'despite': 494,\n",
       " 'conference': 495,\n",
       " 'license': 496,\n",
       " 'age': 497,\n",
       " 'stand': 498,\n",
       " 'southeastern': 499,\n",
       " 'previously': 500,\n",
       " 'fame': 501,\n",
       " 'solar': 502,\n",
       " 'degree': 503,\n",
       " 'southwestern': 504,\n",
       " 'wind': 505,\n",
       " 'succeed': 506,\n",
       " 'hours': 507,\n",
       " 'directly': 508,\n",
       " 'collection': 509,\n",
       " 'principal': 510,\n",
       " 'variety': 511,\n",
       " 'brothers': 512,\n",
       " 'probably': 513,\n",
       " 'digital': 514,\n",
       " 'discovery': 515,\n",
       " 'previous': 516,\n",
       " 'construction': 517,\n",
       " 'carry': 518,\n",
       " 'notable': 519,\n",
       " 'accept': 520,\n",
       " 'friends': 521,\n",
       " 'theme': 522,\n",
       " 'competition': 523,\n",
       " 'personal': 524,\n",
       " 'war': 525,\n",
       " 'look': 526,\n",
       " 'longer': 527,\n",
       " 'drama': 528,\n",
       " 'vocals': 529,\n",
       " 'reduce': 530,\n",
       " 'focus': 531,\n",
       " 'comprise': 532,\n",
       " 'campaign': 533,\n",
       " 'attend': 534,\n",
       " 'biggest': 535,\n",
       " 'challenge': 536,\n",
       " 'interest': 537,\n",
       " 'circuit': 538,\n",
       " 'paint': 539,\n",
       " 'rename': 540,\n",
       " 'organize': 541,\n",
       " 'saturn': 542,\n",
       " 'counties': 543,\n",
       " 'entire': 544,\n",
       " 'compete': 545,\n",
       " 'foundation': 546,\n",
       " 'band': 547,\n",
       " 'annual': 548,\n",
       " 'problems': 549,\n",
       " 'cultural': 550,\n",
       " 'leave': 551,\n",
       " 'security': 552,\n",
       " 'belong': 553,\n",
       " 'transfer': 554,\n",
       " 'bomb': 555,\n",
       " 'online': 556,\n",
       " 'element': 557,\n",
       " 'offer': 558,\n",
       " 'cycle': 559,\n",
       " 'score': 560,\n",
       " 'edit': 561,\n",
       " 'examples': 562,\n",
       " 'raise': 563,\n",
       " 'station': 564,\n",
       " 'acid': 565,\n",
       " 'appearance': 566,\n",
       " 'symphony': 567,\n",
       " 'technology': 568,\n",
       " 'recently': 569,\n",
       " 'mix': 570,\n",
       " 'fictional': 571,\n",
       " 'commission': 572,\n",
       " 'head': 573,\n",
       " 'majority': 574,\n",
       " 'olympics': 575,\n",
       " 'merge': 576,\n",
       " 'architecture': 577,\n",
       " 'distribution': 578,\n",
       " 'significant': 579,\n",
       " 'transport': 580,\n",
       " 'document': 581,\n",
       " 'reign': 582,\n",
       " 'express': 583,\n",
       " 'gain': 584,\n",
       " 'cyclone': 585,\n",
       " 'begin': 586,\n",
       " 'picture': 587,\n",
       " 'identify': 588,\n",
       " 'users': 589,\n",
       " 'scientific': 590,\n",
       " 'soccer': 591,\n",
       " 'order': 592,\n",
       " 'mythology': 593,\n",
       " 'occupy': 594,\n",
       " 'maintain': 595,\n",
       " 'sell': 596,\n",
       " 'translate': 597,\n",
       " 'separate': 598,\n",
       " 'present': 599,\n",
       " 'artists': 600,\n",
       " 'bird': 601,\n",
       " 'specific': 602,\n",
       " 'format': 603,\n",
       " 'fight': 604,\n",
       " 'run': 605,\n",
       " 'device': 606,\n",
       " 'headquarter': 607,\n",
       " 'give': 608,\n",
       " 'weeks': 609,\n",
       " 'close': 610,\n",
       " 'asteroid': 611,\n",
       " 'muslim': 612,\n",
       " 'adventure': 613,\n",
       " 'command': 614,\n",
       " 'flow': 615,\n",
       " 'products': 616,\n",
       " 'core': 617,\n",
       " 'roles': 618,\n",
       " 'climate': 619,\n",
       " 'content': 620,\n",
       " 'committee': 621,\n",
       " 'initially': 622,\n",
       " 'satellite': 623,\n",
       " 'philosophy': 624,\n",
       " 'color': 625,\n",
       " 'achieve': 626,\n",
       " 'origin': 627,\n",
       " 'contest': 628,\n",
       " 'ship': 629,\n",
       " 'actually': 630,\n",
       " 'congress': 631,\n",
       " 'hand': 632,\n",
       " 'constitution': 633,\n",
       " 'anti': 634,\n",
       " 'method': 635,\n",
       " 'nazi': 636,\n",
       " 'provence': 637,\n",
       " 'highly': 638,\n",
       " 'angle': 639,\n",
       " 'determine': 640,\n",
       " 'land': 641,\n",
       " 'affect': 642,\n",
       " 'commonwealth': 643,\n",
       " 'isbn': 644,\n",
       " 'overall': 645,\n",
       " 'count': 646,\n",
       " 'diameter': 647,\n",
       " 'celebrate': 648,\n",
       " 'signal': 649,\n",
       " 'vary': 650,\n",
       " 'happen': 651,\n",
       " 'linux': 652,\n",
       " 'cancer': 653,\n",
       " 'solo': 654,\n",
       " 'agree': 655,\n",
       " 'executive': 656,\n",
       " 'younger': 657,\n",
       " 'volume': 658,\n",
       " 'relationship': 659,\n",
       " 'mention': 660,\n",
       " 'store': 661,\n",
       " 'numerous': 662,\n",
       " 'credit': 663,\n",
       " 'corporation': 664,\n",
       " 'evidence': 665,\n",
       " 'originate': 666,\n",
       " 'tree': 667,\n",
       " 'physics': 668,\n",
       " 'regional': 669,\n",
       " 'industrial': 670,\n",
       " 'underground': 671,\n",
       " 'earn': 672,\n",
       " 'provinces': 673,\n",
       " 'versions': 674,\n",
       " 'labor': 675,\n",
       " 'environment': 676,\n",
       " 'growth': 677,\n",
       " 'earliest': 678,\n",
       " 'student': 679,\n",
       " 'case': 680,\n",
       " 'breed': 681,\n",
       " 'product': 682,\n",
       " 'religion': 683,\n",
       " 'cast': 684,\n",
       " 'islamic': 685,\n",
       " 'longest': 686,\n",
       " 'measure': 687,\n",
       " 'administration': 688,\n",
       " 'basic': 689,\n",
       " 'strike': 690,\n",
       " 'mathematics': 691,\n",
       " 'therefore': 692,\n",
       " 'kill': 693,\n",
       " 'tell': 694,\n",
       " 'promote': 695,\n",
       " 'track': 696,\n",
       " 'triple': 697,\n",
       " 'contract': 698,\n",
       " 'letter': 699,\n",
       " 'drug': 700,\n",
       " 'troop': 701,\n",
       " 'ways': 702,\n",
       " 'last': 703,\n",
       " 'compare': 704,\n",
       " 'punk': 705,\n",
       " 'company': 706,\n",
       " 'level': 707,\n",
       " 'shape': 708,\n",
       " 'prior': 709,\n",
       " 'policy': 710,\n",
       " 'indicate': 711,\n",
       " 'visit': 712,\n",
       " 'khan': 713,\n",
       " 'sit': 714,\n",
       " 'adult': 715,\n",
       " 'match': 716,\n",
       " 'pronounce': 717,\n",
       " 'invent': 718,\n",
       " 'operation': 719,\n",
       " 'normally': 720,\n",
       " 'wrestler': 721,\n",
       " 'responsible': 722,\n",
       " 'whether': 723,\n",
       " 'approach': 724,\n",
       " 'materials': 725,\n",
       " 'blue': 726,\n",
       " 'incorporate': 727,\n",
       " 'federation': 728,\n",
       " 'concern': 729,\n",
       " 'medal': 730,\n",
       " 'microsoft': 731,\n",
       " 'unlike': 732,\n",
       " 'expand': 733,\n",
       " 'creation': 734,\n",
       " 'supply': 735,\n",
       " 'address': 736,\n",
       " 'fantasy': 737,\n",
       " 'hill': 738,\n",
       " 'manage': 739,\n",
       " 'authority': 740,\n",
       " 'legal': 741,\n",
       " 'console': 742,\n",
       " 'centuries': 743,\n",
       " 'fail': 744,\n",
       " 'field': 745,\n",
       " 'bury': 746,\n",
       " 'rhine': 747,\n",
       " 'construct': 748,\n",
       " 'propose': 749,\n",
       " 'nominate': 750,\n",
       " 'detail': 751,\n",
       " 'teach': 752,\n",
       " 'church': 753,\n",
       " 'distinguish': 754,\n",
       " 'relatively': 755,\n",
       " 'secondary': 756,\n",
       " 'select': 757,\n",
       " 'goals': 758,\n",
       " 'billion': 759,\n",
       " 'historic': 760,\n",
       " 'electronic': 761,\n",
       " 'universe': 762,\n",
       " 'remove': 763,\n",
       " 'alone': 764,\n",
       " 'kilometres': 765,\n",
       " 'aircraft': 766,\n",
       " 'medieval': 767,\n",
       " 'evolution': 768,\n",
       " 'view': 769,\n",
       " 'management': 770,\n",
       " 'generation': 771,\n",
       " 'print': 772,\n",
       " 'families': 773,\n",
       " 'novels': 774,\n",
       " 'mine': 775,\n",
       " 'trade': 776,\n",
       " 'layer': 777,\n",
       " 'classic': 778,\n",
       " 'vice': 779,\n",
       " 'prevent': 780,\n",
       " 'staff': 781,\n",
       " 'deaths': 782,\n",
       " 'meter': 783,\n",
       " 'concept': 784,\n",
       " 'completely': 785,\n",
       " 'try': 786,\n",
       " 'entry': 787,\n",
       " 'classify': 788,\n",
       " 'sexual': 789,\n",
       " 'piece': 790,\n",
       " 'dictionary': 791,\n",
       " 'density': 792,\n",
       " 'ability': 793,\n",
       " 'kong': 794,\n",
       " 'activity': 795,\n",
       " 'reserve': 796,\n",
       " 'motion': 797,\n",
       " 'lack': 798,\n",
       " 'tradition': 799,\n",
       " 'biography': 800,\n",
       " 'assembly': 801,\n",
       " 'reform': 802,\n",
       " 'depend': 803,\n",
       " 'chamber': 804,\n",
       " 'territories': 805,\n",
       " 'weight': 806,\n",
       " 'frequently': 807,\n",
       " 'orthodox': 808,\n",
       " 'minutes': 809,\n",
       " 'heritage': 810,\n",
       " 'carbon': 811,\n",
       " 'conservative': 812,\n",
       " 'theatre': 813,\n",
       " 'ally': 814,\n",
       " 'spell': 815,\n",
       " 'azur': 816,\n",
       " 'municipalities': 817,\n",
       " 'water': 818,\n",
       " 'manufacture': 819,\n",
       " 'roll': 820,\n",
       " 'rural': 821,\n",
       " 'landfall': 822,\n",
       " 'agreement': 823,\n",
       " 'parallel': 824,\n",
       " 'cars': 825,\n",
       " 'portion': 826,\n",
       " 'ministry': 827,\n",
       " 'championships': 828,\n",
       " 'outer': 829,\n",
       " 'trophy': 830,\n",
       " 'soldier': 831,\n",
       " 'roughly': 832,\n",
       " 'find': 833,\n",
       " 'strength': 834,\n",
       " 'reveal': 835,\n",
       " 'shortly': 836,\n",
       " 'mark': 837,\n",
       " 'tube': 838,\n",
       " 'experiment': 839,\n",
       " 'gregorian': 840,\n",
       " 'pattern': 841,\n",
       " 'sing': 842,\n",
       " 'largely': 843,\n",
       " 'fund': 844,\n",
       " 'convert': 845,\n",
       " 'closely': 846,\n",
       " 'laws': 847,\n",
       " 'side': 848,\n",
       " 'tribe': 849,\n",
       " 'definition': 850,\n",
       " 'applications': 851,\n",
       " 'opposite': 852,\n",
       " 'writers': 853,\n",
       " 'episodes': 854,\n",
       " 'agency': 855,\n",
       " 'traditionally': 856,\n",
       " 'cents': 857,\n",
       " 'latter': 858,\n",
       " 'boys': 859,\n",
       " 'observe': 860,\n",
       " 'chart': 861,\n",
       " 'activities': 862,\n",
       " 'draw': 863,\n",
       " 'govern': 864,\n",
       " 'sons': 865,\n",
       " 'market': 866,\n",
       " 'sequel': 867,\n",
       " 'economy': 868,\n",
       " 'marine': 869,\n",
       " 'designate': 870,\n",
       " 'traffic': 871,\n",
       " 'ideas': 872,\n",
       " 'jazz': 873,\n",
       " 'reason': 874,\n",
       " 'drop': 875,\n",
       " 'difficult': 876,\n",
       " 'asian': 877,\n",
       " 'external': 878,\n",
       " 'multi': 879,\n",
       " 'inspire': 880,\n",
       " 'problem': 881,\n",
       " 'distinct': 882,\n",
       " 'engines': 883,\n",
       " 'script': 884,\n",
       " 'distribute': 885,\n",
       " 'scene': 886,\n",
       " 'studios': 887,\n",
       " 'temple': 888,\n",
       " 'additional': 889,\n",
       " 'couple': 890,\n",
       " 'philosopher': 891,\n",
       " 'meet': 892,\n",
       " 'folk': 893,\n",
       " 'impact': 894,\n",
       " 'metres': 895,\n",
       " 'mediterranean': 896,\n",
       " 'interstate': 897,\n",
       " 'formal': 898,\n",
       " 'ardãƒ': 899,\n",
       " 'girls': 900,\n",
       " 'semi': 901,\n",
       " 'bureau': 902,\n",
       " 'respectively': 903,\n",
       " 'affairs': 904,\n",
       " 'arrest': 905,\n",
       " 'musicians': 906,\n",
       " 'disk': 907,\n",
       " 'slightly': 908,\n",
       " 'caribbean': 909,\n",
       " 'senior': 910,\n",
       " 'burn': 911,\n",
       " 'charge': 912,\n",
       " 'christmas': 913,\n",
       " 'suffer': 914,\n",
       " 'prominent': 915,\n",
       " 'alphabet': 916,\n",
       " 'lyric': 917,\n",
       " 'club': 918,\n",
       " 'sciences': 919,\n",
       " 'pioneer': 920,\n",
       " 'avoid': 921,\n",
       " 'eye': 922,\n",
       " 'memory': 923,\n",
       " 'write': 924,\n",
       " 'intend': 925,\n",
       " 'target': 926,\n",
       " 'legend': 927,\n",
       " 'hit': 928,\n",
       " 'egg': 929,\n",
       " 'tehsil': 930,\n",
       " 'computers': 931,\n",
       " 'colony': 932,\n",
       " 'drum': 933,\n",
       " 'socialist': 934,\n",
       " 'factor': 935,\n",
       " 'contact': 936,\n",
       " 'tournament': 937,\n",
       " 'global': 938,\n",
       " 'midfielder': 939,\n",
       " 'workers': 940,\n",
       " 'smackdown': 941,\n",
       " 'universities': 942,\n",
       " 'interview': 943,\n",
       " 'organizations': 944,\n",
       " 'formation': 945,\n",
       " 'extreme': 946,\n",
       " 'councils': 947,\n",
       " 'pilot': 948,\n",
       " 'size': 949,\n",
       " 'abbottabad': 950,\n",
       " 'bond': 951,\n",
       " 'grammy': 952,\n",
       " 'knight': 953,\n",
       " 'fan': 954,\n",
       " 'yorkshire': 955,\n",
       " 'communist': 956,\n",
       " 'request': 957,\n",
       " 'collect': 958,\n",
       " 'span': 959,\n",
       " 'basis': 960,\n",
       " 'conflict': 961,\n",
       " 'bear': 962,\n",
       " 'plot': 963,\n",
       " 'franchise': 964,\n",
       " 'supreme': 965,\n",
       " 'voice': 966,\n",
       " 'purchase': 967,\n",
       " 'editor': 968,\n",
       " 'behavior': 969,\n",
       " 'property': 970,\n",
       " 'initial': 971,\n",
       " 'kinds': 972,\n",
       " 'earthquake': 973,\n",
       " 'grant': 974,\n",
       " 'journal': 975,\n",
       " 'chairman': 976,\n",
       " 'stay': 977,\n",
       " 'register': 978,\n",
       " 'johann': 979,\n",
       " 'atomic': 980,\n",
       " 'designation': 981,\n",
       " 'individuals': 982,\n",
       " 'continental': 983,\n",
       " 'oppose': 984,\n",
       " 'test': 985,\n",
       " 'immediately': 986,\n",
       " 'classification': 987,\n",
       " 'flavor': 988,\n",
       " 'permanent': 989,\n",
       " 'wing': 990,\n",
       " 'internal': 991,\n",
       " 'capacity': 992,\n",
       " 'biology': 993,\n",
       " 'confirm': 994,\n",
       " 'convention': 995,\n",
       " 'montreal': 996,\n",
       " 'hong': 997,\n",
       " 'hitler': 998,\n",
       " 'virgin': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors[0] == word_vectors['unite']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2875"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_in_vector = word_vectors.index_to_key\n",
    "len(words_in_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word's Difficulty Considered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "== Concreteness_ratings_Brysbaert_et_al_BRM.txt ==\n",
    "\n",
    "This file contains concreteness ratings for 40 thousand English lemma words gathered via Amazon Mechanical Turk. The ratings come from a larger list of 63 thousand words and represent all English words known to 85% of the raters.\n",
    "\n",
    "The file contains eight columns:\n",
    "1. The word\n",
    "2. Whether it is a single word or a two-word expression \n",
    "3. The mean concreteness rating\n",
    "4. The standard deviation of the concreteness ratings\n",
    "5. The number of persons indicating they did not know the word\n",
    "6. The total number of persons who rated the word\n",
    "7. Percentage participants who knew the word\n",
    "8. The SUBTLEX-US frequency count (on a total of 51 million; Brysbaert & New, 2009) \n",
    "9. The dominant part-of-speech usage\n",
    "\n",
    "Original source: http://crr.ugent.be/archives/1330\n",
    "\n",
    "Brysbaert, M., Warriner, A.B., & Kuperman, V. (2014). Concreteness ratings for 40 thousand generally known English word lemmas. Behavior Research Methods, 46, 904-911.\n",
    "http://crr.ugent.be/papers/Brysbaert_Warriner_Kuperman_BRM_Concreteness_ratings.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concreteness rating - the higher Conc.M, the easier the word is.\n",
    "concreteness_path = 'Data/Concreteness_ratings_Brysbaert_et_al_BRM.txt'\n",
    "concrete_df = pd.read_csv(concreteness_path,delimiter='\\t', keep_default_na=False)\n",
    "concreteset=(concrete_df['Word'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Bigram</th>\n",
       "      <th>Conc.M</th>\n",
       "      <th>Conc.SD</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent_known</th>\n",
       "      <th>SUBTLEX</th>\n",
       "      <th>Dom_Pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>roadsweeper</td>\n",
       "      <td>0</td>\n",
       "      <td>4.85</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>traindriver</td>\n",
       "      <td>0</td>\n",
       "      <td>4.54</td>\n",
       "      <td>0.71</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tush</td>\n",
       "      <td>0</td>\n",
       "      <td>4.45</td>\n",
       "      <td>1.01</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>0.88</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hairdress</td>\n",
       "      <td>0</td>\n",
       "      <td>3.93</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pharmaceutics</td>\n",
       "      <td>0</td>\n",
       "      <td>3.77</td>\n",
       "      <td>1.41</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39949</th>\n",
       "      <td>unenvied</td>\n",
       "      <td>0</td>\n",
       "      <td>1.21</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39950</th>\n",
       "      <td>agnostically</td>\n",
       "      <td>0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39951</th>\n",
       "      <td>conceptualistic</td>\n",
       "      <td>0</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.50</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39952</th>\n",
       "      <td>conventionalism</td>\n",
       "      <td>0</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39953</th>\n",
       "      <td>essentialness</td>\n",
       "      <td>0</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39954 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Word  Bigram  Conc.M  Conc.SD  Unknown  Total  \\\n",
       "0          roadsweeper       0    4.85     0.37        1     27   \n",
       "1          traindriver       0    4.54     0.71        3     29   \n",
       "2                 tush       0    4.45     1.01        3     25   \n",
       "3            hairdress       0    3.93     1.28        0     29   \n",
       "4        pharmaceutics       0    3.77     1.41        4     26   \n",
       "...                ...     ...     ...      ...      ...    ...   \n",
       "39949         unenvied       0    1.21     0.62        1     30   \n",
       "39950     agnostically       0    1.20     0.50        2     27   \n",
       "39951  conceptualistic       0    1.18     0.50        4     26   \n",
       "39952  conventionalism       0    1.18     0.48        1     29   \n",
       "39953    essentialness       0    1.04     0.20        2     26   \n",
       "\n",
       "       Percent_known  SUBTLEX Dom_Pos  \n",
       "0               0.96        0       0  \n",
       "1               0.90        0       0  \n",
       "2               0.88       66       0  \n",
       "3               1.00        1       0  \n",
       "4               0.85        0       0  \n",
       "...              ...      ...     ...  \n",
       "39949           0.97        0    #N/A  \n",
       "39950           0.93        0    #N/A  \n",
       "39951           0.85        0    #N/A  \n",
       "39952           0.97        0    #N/A  \n",
       "39953           0.92        0    #N/A  \n",
       "\n",
       "[39954 rows x 9 columns]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    37058\n",
       "1     2896\n",
       "Name: Bigram, dtype: int64"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_df.Bigram.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Bigram</th>\n",
       "      <th>Conc.M</th>\n",
       "      <th>Conc.SD</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent_known</th>\n",
       "      <th>SUBTLEX</th>\n",
       "      <th>Dom_Pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28707</th>\n",
       "      <td>baking soda</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28709</th>\n",
       "      <td>baseball bat</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28710</th>\n",
       "      <td>bath towel</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28711</th>\n",
       "      <td>beach ball</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28712</th>\n",
       "      <td>bed sheet</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39619</th>\n",
       "      <td>tantamount to</td>\n",
       "      <td>1</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.85</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39857</th>\n",
       "      <td>chance on</td>\n",
       "      <td>1</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39871</th>\n",
       "      <td>free rein</td>\n",
       "      <td>1</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0.63</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39899</th>\n",
       "      <td>by chance</td>\n",
       "      <td>1</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39947</th>\n",
       "      <td>in principle</td>\n",
       "      <td>1</td>\n",
       "      <td>1.21</td>\n",
       "      <td>0.41</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2896 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Word  Bigram  Conc.M  Conc.SD  Unknown  Total  Percent_known  \\\n",
       "28707    baking soda       1    5.00     0.00        0     30           1.00   \n",
       "28709   baseball bat       1    5.00     0.00        0     29           1.00   \n",
       "28710     bath towel       1    5.00     0.00        0     29           1.00   \n",
       "28711     beach ball       1    5.00     0.00        0     28           1.00   \n",
       "28712      bed sheet       1    5.00     0.00        0     28           1.00   \n",
       "...              ...     ...     ...      ...      ...    ...            ...   \n",
       "39619  tantamount to       1    1.52     0.85        4     27           0.85   \n",
       "39857      chance on       1    1.38     0.75        2     28           0.93   \n",
       "39871      free rein       1    1.37     0.63        2     29           0.93   \n",
       "39899      by chance       1    1.34     0.72        1     30           0.97   \n",
       "39947   in principle       1    1.21     0.41        4     28           0.86   \n",
       "\n",
       "       SUBTLEX Dom_Pos  \n",
       "28707        0    #N/A  \n",
       "28709        0    #N/A  \n",
       "28710        0    #N/A  \n",
       "28711        0    #N/A  \n",
       "28712        0    #N/A  \n",
       "...        ...     ...  \n",
       "39619        0    #N/A  \n",
       "39857        0    #N/A  \n",
       "39871        0    #N/A  \n",
       "39899        0    #N/A  \n",
       "39947        0    #N/A  \n",
       "\n",
       "[2896 rows x 9 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_df[concrete_df.Bigram==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Bigram</th>\n",
       "      <th>Conc.M</th>\n",
       "      <th>Conc.SD</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent_known</th>\n",
       "      <th>SUBTLEX</th>\n",
       "      <th>Dom_Pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Word, Bigram, Conc.M, Conc.SD, Unknown, Total, Percent_known, SUBTLEX, Dom_Pos]\n",
       "Index: []"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#There is no Nan value in Conc.M column\n",
    "concrete_df[concrete_df['Conc.M'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are we gonna consider bigrams in this dataset, given it's only a small fraction ~ 8% in size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.04"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(concrete_df['Conc.M'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(concrete_df['Conc.M'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concreteness values range from 1 - 5, we could possible use the inverse value of concreteness to scale it to a 0-1 range and give easier words less weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_words = list(concrete_df['Word'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39954"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(concrete_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_complement = [word for word in words_in_vector if word not in concrete_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "550"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(concrete_complement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['years',\n",
       " 'largest',\n",
       " 'ndash',\n",
       " 'members',\n",
       " 'countries',\n",
       " 'european',\n",
       " 'basse',\n",
       " 'islands',\n",
       " 'areas',\n",
       " 'events',\n",
       " 'picardie',\n",
       " 'languages',\n",
       " 'aquitaine',\n",
       " 'songs',\n",
       " 'systems',\n",
       " 'others',\n",
       " 'cities',\n",
       " 'players',\n",
       " 'animals',\n",
       " 'disney',\n",
       " 'britain',\n",
       " 'oldest',\n",
       " 'units',\n",
       " 'websites',\n",
       " 'windows',\n",
       " 'larger',\n",
       " 'mountains',\n",
       " 'albums',\n",
       " 'students',\n",
       " 'nations',\n",
       " 'alpes',\n",
       " 'partement',\n",
       " 'months',\n",
       " 'nobel',\n",
       " 'african',\n",
       " 'things',\n",
       " 'cells',\n",
       " 'picardy',\n",
       " 'towns',\n",
       " 'regions',\n",
       " 'humans',\n",
       " 'elements',\n",
       " 'prix',\n",
       " 'korea',\n",
       " 'inhabitants',\n",
       " 'earlier',\n",
       " 'greatest',\n",
       " 'hours',\n",
       " 'brothers',\n",
       " 'friends',\n",
       " 'vocals',\n",
       " 'saturn',\n",
       " 'counties',\n",
       " 'problems',\n",
       " 'examples',\n",
       " 'users',\n",
       " 'artists',\n",
       " 'weeks',\n",
       " 'products',\n",
       " 'roles',\n",
       " 'nazi',\n",
       " 'provence',\n",
       " 'isbn',\n",
       " 'linux',\n",
       " 'provinces',\n",
       " 'versions',\n",
       " 'earliest',\n",
       " 'longest',\n",
       " 'khan',\n",
       " 'materials',\n",
       " 'microsoft',\n",
       " 'centuries',\n",
       " 'rhine',\n",
       " 'goals',\n",
       " 'kilometres',\n",
       " 'families',\n",
       " 'novels',\n",
       " 'deaths',\n",
       " 'kong',\n",
       " 'territories',\n",
       " 'minutes',\n",
       " 'theatre',\n",
       " 'azur',\n",
       " 'municipalities',\n",
       " 'cars',\n",
       " 'championships',\n",
       " 'gregorian',\n",
       " 'laws',\n",
       " 'applications',\n",
       " 'writers',\n",
       " 'episodes',\n",
       " 'cents',\n",
       " 'boys',\n",
       " 'activities',\n",
       " 'ideas',\n",
       " 'asian',\n",
       " 'engines',\n",
       " 'studios',\n",
       " 'metres',\n",
       " 'ardãƒ',\n",
       " 'girls',\n",
       " 'affairs',\n",
       " 'musicians',\n",
       " 'caribbean',\n",
       " 'sciences',\n",
       " 'tehsil',\n",
       " 'computers',\n",
       " 'workers',\n",
       " 'smackdown',\n",
       " 'universities',\n",
       " 'organizations',\n",
       " 'councils',\n",
       " 'abbottabad',\n",
       " 'grammy',\n",
       " 'yorkshire',\n",
       " 'kinds',\n",
       " 'johann',\n",
       " 'individuals',\n",
       " 'montreal',\n",
       " 'hong',\n",
       " 'hitler',\n",
       " 'organisms',\n",
       " 'jews',\n",
       " 'tribes',\n",
       " 'gods',\n",
       " 'muslims',\n",
       " 'ones',\n",
       " 'smallest',\n",
       " 'pokãƒ',\n",
       " 'mammals',\n",
       " 'relations',\n",
       " 'villages',\n",
       " 'fifa',\n",
       " 'youngest',\n",
       " 'operations',\n",
       " 'kilometers',\n",
       " 'kings',\n",
       " 'weapons',\n",
       " 'arab',\n",
       " 'neptune',\n",
       " 'methods',\n",
       " 'decades',\n",
       " 'leaders',\n",
       " 'colour',\n",
       " 'puerto',\n",
       " 'devices',\n",
       " 'properties',\n",
       " 'communities',\n",
       " 'westphalia',\n",
       " 'asteroids',\n",
       " 'rout',\n",
       " 'friedrich',\n",
       " 'thousands',\n",
       " 'particles',\n",
       " 'bros',\n",
       " 'vendãƒ',\n",
       " 'differences',\n",
       " 'scientists',\n",
       " 'temperatures',\n",
       " 'tallest',\n",
       " 'males',\n",
       " 'degrees',\n",
       " 'prefecture',\n",
       " 'drivers',\n",
       " 'sisters',\n",
       " 'mar',\n",
       " 'appearances',\n",
       " 'beatles',\n",
       " 'wrestlemania',\n",
       " 'composers',\n",
       " 'critics',\n",
       " 'females',\n",
       " 'residents',\n",
       " 'items',\n",
       " 'legs',\n",
       " 'performances',\n",
       " 'ardã',\n",
       " 'elections',\n",
       " 'christians',\n",
       " 'institutions',\n",
       " 'airlines',\n",
       " 'viii',\n",
       " 'saxe',\n",
       " 'romans',\n",
       " 'americans',\n",
       " 'authorities',\n",
       " 'indo',\n",
       " 'representatives',\n",
       " 'planets',\n",
       " 'byzantine',\n",
       " 'governments',\n",
       " 'rangers',\n",
       " 'anglo',\n",
       " 'duchy',\n",
       " 'orton',\n",
       " 'bach',\n",
       " 'colonies',\n",
       " 'divisions',\n",
       " 'homo',\n",
       " 'standards',\n",
       " 'hundreds',\n",
       " 'poems',\n",
       " 'uranus',\n",
       " 'origins',\n",
       " 'actors',\n",
       " 'roads',\n",
       " 'uefa',\n",
       " 'techniques',\n",
       " 'scholars',\n",
       " 'tram',\n",
       " 'contributions',\n",
       " 'citizens',\n",
       " 'offices',\n",
       " 'wagner',\n",
       " 'prussia',\n",
       " 'cyclones',\n",
       " 'populations',\n",
       " 'departments',\n",
       " 'texts',\n",
       " 'boundaries',\n",
       " 'vehicles',\n",
       " 'winners',\n",
       " 'adults',\n",
       " 'productions',\n",
       " 'officials',\n",
       " 'britannica',\n",
       " 'resources',\n",
       " 'shakespeare',\n",
       " 'movements',\n",
       " 'instructions',\n",
       " 'efforts',\n",
       " 'labour',\n",
       " 'closest',\n",
       " 'molecules',\n",
       " 'passengers',\n",
       " 'persons',\n",
       " 'zeus',\n",
       " 'insects',\n",
       " 'electrons',\n",
       " 'serie',\n",
       " 'hurricanes',\n",
       " 'ecliptic',\n",
       " 'atlantiques',\n",
       " 'genera',\n",
       " 'canadiens',\n",
       " 'bengal',\n",
       " 'colleges',\n",
       " 'forbes',\n",
       " 'lowest',\n",
       " 'batista',\n",
       " 'pokã',\n",
       " 'bits',\n",
       " 'foods',\n",
       " 'fossils',\n",
       " 'components',\n",
       " 'beliefs',\n",
       " 'brabant',\n",
       " 'norse',\n",
       " 'operas',\n",
       " 'frankfurt',\n",
       " 'josã',\n",
       " 'maritimes',\n",
       " 'editors',\n",
       " 'communications',\n",
       " 'shah',\n",
       " 'mosques',\n",
       " 'mcmahon',\n",
       " 'whedon',\n",
       " 'theorem',\n",
       " 'shire',\n",
       " 'baptist',\n",
       " 'instal',\n",
       " 'neighbour',\n",
       " 'worlds',\n",
       " 'newspapers',\n",
       " 'aspects',\n",
       " 'visitors',\n",
       " 'bouches',\n",
       " 'societies',\n",
       " 'symbols',\n",
       " 'oceans',\n",
       " 'dollars',\n",
       " 'traditions',\n",
       " 'symptoms',\n",
       " 'videos',\n",
       " 'renault',\n",
       " 'leonese',\n",
       " 'indus',\n",
       " 'nasa',\n",
       " 'locomotives',\n",
       " 'sony',\n",
       " 'daughters',\n",
       " 'variations',\n",
       " 'slavic',\n",
       " 'reich',\n",
       " 'mccartney',\n",
       " 'atoms',\n",
       " 'janeiro',\n",
       " 'finals',\n",
       " 'generations',\n",
       " 'centre',\n",
       " 'fastest',\n",
       " 'michaels',\n",
       " 'mozart',\n",
       " 'rulers',\n",
       " 'nuremberg',\n",
       " 'observations',\n",
       " 'categories',\n",
       " 'historians',\n",
       " 'costa',\n",
       " 'railways',\n",
       " 'pyrã',\n",
       " 'arabia',\n",
       " 'simpsons',\n",
       " 'singers',\n",
       " 'predators',\n",
       " 'diseases',\n",
       " 'strongest',\n",
       " 'antarctica',\n",
       " 'scenes',\n",
       " 'newfoundland',\n",
       " 'knowles',\n",
       " 'buenos',\n",
       " 'khyber',\n",
       " 'castile',\n",
       " 'persia',\n",
       " 'unesco',\n",
       " 'vendã',\n",
       " 'thames',\n",
       " 'anglican',\n",
       " 'armies',\n",
       " 'harvard',\n",
       " 'honour',\n",
       " 'organs',\n",
       " 'programme',\n",
       " 'amazon',\n",
       " 'alps',\n",
       " 'petersburg',\n",
       " 'saudi',\n",
       " 'winger',\n",
       " 'vector',\n",
       " 'organise',\n",
       " 'georg',\n",
       " 'restaurants',\n",
       " 'apollo',\n",
       " 'relatives',\n",
       " 'teau',\n",
       " 'laureate',\n",
       " 'households',\n",
       " 'plat',\n",
       " 'flemish',\n",
       " 'wider',\n",
       " 'policies',\n",
       " 'nazis',\n",
       " 'locations',\n",
       " 'extratropical',\n",
       " 'crimes',\n",
       " 'heinrich',\n",
       " 'josãƒ',\n",
       " 'producers',\n",
       " 'ubuntu',\n",
       " 'pakhtunkhwa',\n",
       " 'kingdoms',\n",
       " 'prisoners',\n",
       " 'minerals',\n",
       " 'bundesliga',\n",
       " 'glands',\n",
       " 'relationships',\n",
       " 'harbour',\n",
       " 'chakwal',\n",
       " 'industries',\n",
       " 'sussex',\n",
       " 'religions',\n",
       " 'editions',\n",
       " 'soundgarden',\n",
       " 'yugoslavia',\n",
       " 'blackhawks',\n",
       " 'ferrari',\n",
       " 'emirates',\n",
       " 'victims',\n",
       " 'saxon',\n",
       " 'hume',\n",
       " 'prussian',\n",
       " 'platforms',\n",
       " 'chãƒ',\n",
       " 'skills',\n",
       " 'theories',\n",
       " 'debian',\n",
       " 'dinosaurs',\n",
       " 'lanka',\n",
       " 'emperors',\n",
       " 'volkswagen',\n",
       " 'doors',\n",
       " 'giants',\n",
       " 'basilica',\n",
       " 'ussr',\n",
       " 'wiki',\n",
       " 'supporters',\n",
       " 'duties',\n",
       " 'jurassic',\n",
       " 'varieties',\n",
       " 'substances',\n",
       " 'creatures',\n",
       " 'tehsils',\n",
       " 'empress',\n",
       " 'readers',\n",
       " 'baltic',\n",
       " 'unions',\n",
       " 'sainte',\n",
       " 'reactions',\n",
       " 'facto',\n",
       " 'descendants',\n",
       " 'sega',\n",
       " 'astronomers',\n",
       " 'arabian',\n",
       " 'settlers',\n",
       " 'wolfgang',\n",
       " 'viewers',\n",
       " 'medici',\n",
       " 'candidates',\n",
       " 'collections',\n",
       " 'victorian',\n",
       " 'athletes',\n",
       " 'arrondissement',\n",
       " 'tibet',\n",
       " 'boroughs',\n",
       " 'vegas',\n",
       " 'grande',\n",
       " 'germanic',\n",
       " 'pradesh',\n",
       " 'trials',\n",
       " 'europeans',\n",
       " 'environments',\n",
       " 'directors',\n",
       " 'burma',\n",
       " 'enemies',\n",
       " 'cardinals',\n",
       " 'continents',\n",
       " 'competitions',\n",
       " 'germans',\n",
       " 'georges',\n",
       " 'antilles',\n",
       " 'businesses',\n",
       " 'canton',\n",
       " 'fischer',\n",
       " 'stronger',\n",
       " 'owners',\n",
       " 'employees',\n",
       " 'proteins',\n",
       " 'tourists',\n",
       " 'fewer',\n",
       " 'tournaments',\n",
       " 'bruins',\n",
       " 'broadway',\n",
       " 'teachers',\n",
       " 'ions',\n",
       " 'seas',\n",
       " 'pluto',\n",
       " 'subfamily',\n",
       " 'acids',\n",
       " 'silva',\n",
       " 'conductors',\n",
       " 'tico',\n",
       " 'agents',\n",
       " 'settlements',\n",
       " 'monuments',\n",
       " 'extant',\n",
       " 'indians',\n",
       " 'bishops',\n",
       " 'volcanoes',\n",
       " 'nixon',\n",
       " 'nascar',\n",
       " 'compositions',\n",
       " 'ncaa',\n",
       " 'presidents',\n",
       " 'photos',\n",
       " 'airways',\n",
       " 'organisation',\n",
       " 'lessons',\n",
       " 'medals',\n",
       " 'hindenburg',\n",
       " 'theaters',\n",
       " 'fibers',\n",
       " 'keynes',\n",
       " 'wrestlers',\n",
       " 'valleys',\n",
       " 'kreis',\n",
       " 'mecklenburg',\n",
       " 'beyoncã',\n",
       " 'boeing',\n",
       " 'greeks',\n",
       " 'genes',\n",
       " 'chevrolet',\n",
       " 'slower',\n",
       " 'ville',\n",
       " 'scala',\n",
       " 'magazines',\n",
       " 'heights',\n",
       " 'buddha',\n",
       " 'pichilemu',\n",
       " 'lions',\n",
       " 'warriors',\n",
       " 'rica',\n",
       " 'cyrillic',\n",
       " 'genres',\n",
       " 'patients',\n",
       " 'busiest',\n",
       " 'denominations',\n",
       " 'publications',\n",
       " 'developers',\n",
       " 'topics',\n",
       " 'nato',\n",
       " 'dialects',\n",
       " 'followers',\n",
       " 'aang',\n",
       " 'gettysburg',\n",
       " 'ants',\n",
       " 'prayers',\n",
       " 'vertebrates',\n",
       " 'ming',\n",
       " 'poets',\n",
       " 'sunderland',\n",
       " 'mongol',\n",
       " 'oblast',\n",
       " 'ears',\n",
       " 'rttemberg',\n",
       " 'dolphins',\n",
       " 'researchers',\n",
       " 'bavarian',\n",
       " 'trojan',\n",
       " 'translations',\n",
       " 'agencies',\n",
       " 'haute',\n",
       " 'benoit',\n",
       " 'grameen',\n",
       " 'specimens',\n",
       " 'rhode',\n",
       " 'disambiguation',\n",
       " 'recipes',\n",
       " 'stallone',\n",
       " 'defence',\n",
       " 'vegetables',\n",
       " 'czechoslovakia',\n",
       " 'ipswich',\n",
       " 'catholics',\n",
       " 'earthquakes',\n",
       " 'congo',\n",
       " 'immigrants',\n",
       " 'amadeus',\n",
       " 'terminus']"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_complement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_intersect = [word for word in words_in_vector if word in concrete_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2325"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(concrete_intersect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unite',\n",
       " 'department',\n",
       " 'state',\n",
       " 'region',\n",
       " 'commune',\n",
       " 'include',\n",
       " 'call',\n",
       " 'play',\n",
       " 'national',\n",
       " 'district',\n",
       " 'release',\n",
       " 'name',\n",
       " 'locate',\n",
       " 'area',\n",
       " 'former',\n",
       " 'series',\n",
       " 'later',\n",
       " 'album',\n",
       " 'league',\n",
       " 'system',\n",
       " 'work',\n",
       " 'century',\n",
       " 'base',\n",
       " 'award',\n",
       " 'population',\n",
       " 'refer',\n",
       " 'province',\n",
       " 'start',\n",
       " 'record',\n",
       " 'form',\n",
       " 'create',\n",
       " 'main',\n",
       " 'usually',\n",
       " 'president',\n",
       " 'international',\n",
       " 'force',\n",
       " 'produce',\n",
       " 'type',\n",
       " 'television',\n",
       " 'use',\n",
       " 'species',\n",
       " 'game',\n",
       " 'common',\n",
       " 'feature',\n",
       " 'publish',\n",
       " 'professional',\n",
       " 'found',\n",
       " 'municipality',\n",
       " 'although',\n",
       " 'currently',\n",
       " 'character',\n",
       " 'championship',\n",
       " 'modern',\n",
       " 'famous',\n",
       " 'develop',\n",
       " 'popular',\n",
       " 'video',\n",
       " 'tropical',\n",
       " 'time',\n",
       " 'serve',\n",
       " 'republic',\n",
       " 'show',\n",
       " 'hurricane',\n",
       " 'within',\n",
       " 'period',\n",
       " 'consider',\n",
       " 'official',\n",
       " 'change',\n",
       " 'contain',\n",
       " 'design',\n",
       " 'example',\n",
       " 'move',\n",
       " 'result',\n",
       " 'reference',\n",
       " 'original',\n",
       " 'program',\n",
       " 'total',\n",
       " 'appear',\n",
       " 'accord',\n",
       " 'career',\n",
       " 'minister',\n",
       " 'control',\n",
       " 'support',\n",
       " 'allow',\n",
       " 'perform',\n",
       " 'current',\n",
       " 'hockey',\n",
       " 'article',\n",
       " 'commonly',\n",
       " 'border',\n",
       " 'footballer',\n",
       " 'local',\n",
       " 'empire',\n",
       " 'wrestle',\n",
       " 'star',\n",
       " 'division',\n",
       " 'establish',\n",
       " 'range',\n",
       " 'open',\n",
       " 'actor',\n",
       " 'study',\n",
       " 'originally',\n",
       " 'join',\n",
       " 'part',\n",
       " 'cause',\n",
       " 'remain',\n",
       " 'role',\n",
       " 'continue',\n",
       " 'political',\n",
       " 'receive',\n",
       " 'consist',\n",
       " 'version',\n",
       " 'human',\n",
       " 'similar',\n",
       " 'days',\n",
       " 'emperor',\n",
       " 'mean',\n",
       " 'provide',\n",
       " 'process',\n",
       " 'final',\n",
       " 'network',\n",
       " 'pay',\n",
       " 'science',\n",
       " 'source',\n",
       " 'book',\n",
       " 'describe',\n",
       " 'association',\n",
       " 'operate',\n",
       " 'ancient',\n",
       " 'style',\n",
       " 'military',\n",
       " 'place',\n",
       " 'computer',\n",
       " 'event',\n",
       " 'position',\n",
       " 'energy',\n",
       " 'complete',\n",
       " 'various',\n",
       " 'sign',\n",
       " 'natural',\n",
       " 'replace',\n",
       " 'prime',\n",
       " 'generally',\n",
       " 'atlantic',\n",
       " 'discover',\n",
       " 'development',\n",
       " 'reach',\n",
       " 'formula',\n",
       " 'census',\n",
       " 'exist',\n",
       " 'director',\n",
       " 'relate',\n",
       " 'represent',\n",
       " 'orchestra',\n",
       " 'parliament',\n",
       " 'writer',\n",
       " 'team',\n",
       " 'project',\n",
       " 'site',\n",
       " 'race',\n",
       " 'model',\n",
       " 'special',\n",
       " 'occur',\n",
       " 'film',\n",
       " 'plant',\n",
       " 'sport',\n",
       " 'information',\n",
       " 'image',\n",
       " 'port',\n",
       " 'follow',\n",
       " 'chemical',\n",
       " 'number',\n",
       " 'rule',\n",
       " 'software',\n",
       " 'win',\n",
       " 'object',\n",
       " 'group',\n",
       " 'theory',\n",
       " 'highest',\n",
       " 'cover',\n",
       " 'organization',\n",
       " 'actress',\n",
       " 'tour',\n",
       " 'train',\n",
       " 'almost',\n",
       " 'lead',\n",
       " 'movement',\n",
       " 'across',\n",
       " 'elect',\n",
       " 'speak',\n",
       " 'stadium',\n",
       " 'return',\n",
       " 'increase',\n",
       " 'composer',\n",
       " 'opera',\n",
       " 'research',\n",
       " 'novel',\n",
       " 'culture',\n",
       " 'live',\n",
       " 'studio',\n",
       " 'divide',\n",
       " 'influence',\n",
       " 'independent',\n",
       " 'debut',\n",
       " 'officially',\n",
       " 'entertainment',\n",
       " 'community',\n",
       " 'structure',\n",
       " 'claim',\n",
       " 'lower',\n",
       " 'simply',\n",
       " 'introduce',\n",
       " 'end',\n",
       " 'social',\n",
       " 'issue',\n",
       " 'involve',\n",
       " 'pass',\n",
       " 'catholic',\n",
       " 'especially',\n",
       " 'northwestern',\n",
       " 'genus',\n",
       " 'throughout',\n",
       " 'retire',\n",
       " 'guitar',\n",
       " 'soviet',\n",
       " 'act',\n",
       " 'brand',\n",
       " 'territory',\n",
       " 'traditional',\n",
       " 'mass',\n",
       " 'add',\n",
       " 'grow',\n",
       " 'word',\n",
       " 'airport',\n",
       " 'production',\n",
       " 'travel',\n",
       " 'wikipedia',\n",
       " 'approximately',\n",
       " 'native',\n",
       " 'announce',\n",
       " 'effect',\n",
       " 'politician',\n",
       " 'unit',\n",
       " 'defeat',\n",
       " 'come',\n",
       " 'standard',\n",
       " 'civil',\n",
       " 'define',\n",
       " 'available',\n",
       " 'data',\n",
       " 'society',\n",
       " 'direct',\n",
       " 'point',\n",
       " 'successful',\n",
       " 'associate',\n",
       " 'channel',\n",
       " 'musical',\n",
       " 'distance',\n",
       " 'rank',\n",
       " 'action',\n",
       " 'academy',\n",
       " 'limit',\n",
       " 'report',\n",
       " 'help',\n",
       " 'service',\n",
       " 'pacific',\n",
       " 'super',\n",
       " 'orbit',\n",
       " 'average',\n",
       " 'require',\n",
       " 'instrument',\n",
       " 'episode',\n",
       " 'page',\n",
       " 'education',\n",
       " 'term',\n",
       " 'smaller',\n",
       " 'section',\n",
       " 'premier',\n",
       " 'secretary',\n",
       " 'turn',\n",
       " 'date',\n",
       " 'mainly',\n",
       " 'dynasty',\n",
       " 'attempt',\n",
       " 'function',\n",
       " 'estimate',\n",
       " 'note',\n",
       " 'make',\n",
       " 'arts',\n",
       " 'line',\n",
       " 'label',\n",
       " 'compose',\n",
       " 'scale',\n",
       " 'cathedral',\n",
       " 'nintendo',\n",
       " 'festival',\n",
       " 'performance',\n",
       " 'thus',\n",
       " 'administrative',\n",
       " 'say',\n",
       " 'fiction',\n",
       " 'metropolitan',\n",
       " 'nuclear',\n",
       " 'producer',\n",
       " 'success',\n",
       " 'display',\n",
       " 'typically',\n",
       " 'become',\n",
       " 'surround',\n",
       " 'link',\n",
       " 'female',\n",
       " 'own',\n",
       " 'recognize',\n",
       " 'material',\n",
       " 'addition',\n",
       " 'want',\n",
       " 'conduct',\n",
       " 'list',\n",
       " 'decide',\n",
       " 'believe',\n",
       " 'arm',\n",
       " 'right',\n",
       " 'title',\n",
       " 'derive',\n",
       " 'school',\n",
       " 'museum',\n",
       " 'text',\n",
       " 'finish',\n",
       " 'greater',\n",
       " 'concert',\n",
       " 'suggest',\n",
       " 'religious',\n",
       " 'widely',\n",
       " 'pope',\n",
       " 'election',\n",
       " 'attack',\n",
       " 'edition',\n",
       " 'take',\n",
       " 'institute',\n",
       " 'physical',\n",
       " 'compound',\n",
       " 'pressure',\n",
       " 'purpose',\n",
       " 'higher',\n",
       " 'eventually',\n",
       " 'single',\n",
       " 'practice',\n",
       " 'primary',\n",
       " 'lie',\n",
       " 'borough',\n",
       " 'condition',\n",
       " 'combine',\n",
       " 'private',\n",
       " 'plan',\n",
       " 'extend',\n",
       " 'guitarist',\n",
       " 'musician',\n",
       " 'enter',\n",
       " 'code',\n",
       " 'treaty',\n",
       " 'symbol',\n",
       " 'situate',\n",
       " 'category',\n",
       " 'house',\n",
       " 'professor',\n",
       " 'comedy',\n",
       " 'survive',\n",
       " 'share',\n",
       " 'website',\n",
       " 'engineer',\n",
       " 'songwriter',\n",
       " 'regard',\n",
       " 'build',\n",
       " 'season',\n",
       " 'declare',\n",
       " 'worldwide',\n",
       " 'particularly',\n",
       " 'nature',\n",
       " 'connect',\n",
       " 'status',\n",
       " 'host',\n",
       " 'active',\n",
       " 'air',\n",
       " 'internet',\n",
       " 'historical',\n",
       " 'economic',\n",
       " 'formerly',\n",
       " 'location',\n",
       " 'copy',\n",
       " 'apply',\n",
       " 'animate',\n",
       " 'nickname',\n",
       " 'temperature',\n",
       " 'classical',\n",
       " 'destroy',\n",
       " 'democratic',\n",
       " 'multiple',\n",
       " 'alternative',\n",
       " 'planet',\n",
       " 'particular',\n",
       " 'bass',\n",
       " 'industry',\n",
       " 'revolution',\n",
       " 'olympic',\n",
       " 'appoint',\n",
       " 'fall',\n",
       " 'nation',\n",
       " 'draft',\n",
       " 'jewish',\n",
       " 'primarily',\n",
       " 'experience',\n",
       " 'future',\n",
       " 'hold',\n",
       " 'access',\n",
       " 'launch',\n",
       " 'foreign',\n",
       " 'parent',\n",
       " 'adopt',\n",
       " 'individual',\n",
       " 'rat',\n",
       " 'chess',\n",
       " 'recent',\n",
       " 'regular',\n",
       " 'statistics',\n",
       " 'older',\n",
       " 'advance',\n",
       " 'depression',\n",
       " 'literature',\n",
       " 'capture',\n",
       " 'graduate',\n",
       " 'disease',\n",
       " 'zone',\n",
       " 'need',\n",
       " 'founder',\n",
       " 'flower',\n",
       " 'complex',\n",
       " 'account',\n",
       " 'power',\n",
       " 'southeast',\n",
       " 'peninsula',\n",
       " 'ask',\n",
       " 'commercial',\n",
       " 'vote',\n",
       " 'medical',\n",
       " 'basketball',\n",
       " 'user',\n",
       " 'poet',\n",
       " 'despite',\n",
       " 'conference',\n",
       " 'license',\n",
       " 'age',\n",
       " 'stand',\n",
       " 'southeastern',\n",
       " 'previously',\n",
       " 'fame',\n",
       " 'solar',\n",
       " 'degree',\n",
       " 'southwestern',\n",
       " 'wind',\n",
       " 'succeed',\n",
       " 'directly',\n",
       " 'collection',\n",
       " 'principal',\n",
       " 'variety',\n",
       " 'probably',\n",
       " 'digital',\n",
       " 'discovery',\n",
       " 'previous',\n",
       " 'construction',\n",
       " 'carry',\n",
       " 'notable',\n",
       " 'accept',\n",
       " 'theme',\n",
       " 'competition',\n",
       " 'personal',\n",
       " 'war',\n",
       " 'look',\n",
       " 'longer',\n",
       " 'drama',\n",
       " 'reduce',\n",
       " 'focus',\n",
       " 'comprise',\n",
       " 'campaign',\n",
       " 'attend',\n",
       " 'biggest',\n",
       " 'challenge',\n",
       " 'interest',\n",
       " 'circuit',\n",
       " 'paint',\n",
       " 'rename',\n",
       " 'organize',\n",
       " 'entire',\n",
       " 'compete',\n",
       " 'foundation',\n",
       " 'band',\n",
       " 'annual',\n",
       " 'cultural',\n",
       " 'leave',\n",
       " 'security',\n",
       " 'belong',\n",
       " 'transfer',\n",
       " 'bomb',\n",
       " 'online',\n",
       " 'element',\n",
       " 'offer',\n",
       " 'cycle',\n",
       " 'score',\n",
       " 'edit',\n",
       " 'raise',\n",
       " 'station',\n",
       " 'acid',\n",
       " 'appearance',\n",
       " 'symphony',\n",
       " 'technology',\n",
       " 'recently',\n",
       " 'mix',\n",
       " 'fictional',\n",
       " 'commission',\n",
       " 'head',\n",
       " 'majority',\n",
       " 'olympics',\n",
       " 'merge',\n",
       " 'architecture',\n",
       " 'distribution',\n",
       " 'significant',\n",
       " 'transport',\n",
       " 'document',\n",
       " 'reign',\n",
       " 'express',\n",
       " 'gain',\n",
       " 'cyclone',\n",
       " 'begin',\n",
       " 'picture',\n",
       " 'identify',\n",
       " 'scientific',\n",
       " 'soccer',\n",
       " 'order',\n",
       " 'mythology',\n",
       " 'occupy',\n",
       " 'maintain',\n",
       " 'sell',\n",
       " 'translate',\n",
       " 'separate',\n",
       " 'present',\n",
       " 'bird',\n",
       " 'specific',\n",
       " 'format',\n",
       " 'fight',\n",
       " 'run',\n",
       " 'device',\n",
       " 'headquarter',\n",
       " 'give',\n",
       " 'close',\n",
       " 'asteroid',\n",
       " 'muslim',\n",
       " 'adventure',\n",
       " 'command',\n",
       " 'flow',\n",
       " 'core',\n",
       " 'climate',\n",
       " 'content',\n",
       " 'committee',\n",
       " 'initially',\n",
       " 'satellite',\n",
       " 'philosophy',\n",
       " 'color',\n",
       " 'achieve',\n",
       " 'origin',\n",
       " 'contest',\n",
       " 'ship',\n",
       " 'actually',\n",
       " 'congress',\n",
       " 'hand',\n",
       " 'constitution',\n",
       " 'anti',\n",
       " 'method',\n",
       " 'highly',\n",
       " 'angle',\n",
       " 'determine',\n",
       " 'land',\n",
       " 'affect',\n",
       " 'commonwealth',\n",
       " 'overall',\n",
       " 'count',\n",
       " 'diameter',\n",
       " 'celebrate',\n",
       " 'signal',\n",
       " 'vary',\n",
       " 'happen',\n",
       " 'cancer',\n",
       " 'solo',\n",
       " 'agree',\n",
       " 'executive',\n",
       " 'younger',\n",
       " 'volume',\n",
       " 'relationship',\n",
       " 'mention',\n",
       " 'store',\n",
       " 'numerous',\n",
       " 'credit',\n",
       " 'corporation',\n",
       " 'evidence',\n",
       " 'originate',\n",
       " 'tree',\n",
       " 'physics',\n",
       " 'regional',\n",
       " 'industrial',\n",
       " 'underground',\n",
       " 'earn',\n",
       " 'labor',\n",
       " 'environment',\n",
       " 'growth',\n",
       " 'student',\n",
       " 'case',\n",
       " 'breed',\n",
       " 'product',\n",
       " 'religion',\n",
       " 'cast',\n",
       " 'islamic',\n",
       " 'measure',\n",
       " 'administration',\n",
       " 'basic',\n",
       " 'strike',\n",
       " 'mathematics',\n",
       " 'therefore',\n",
       " 'kill',\n",
       " 'tell',\n",
       " 'promote',\n",
       " 'track',\n",
       " 'triple',\n",
       " 'contract',\n",
       " 'letter',\n",
       " 'drug',\n",
       " 'troop',\n",
       " 'ways',\n",
       " 'last',\n",
       " 'compare',\n",
       " 'punk',\n",
       " 'company',\n",
       " 'level',\n",
       " 'shape',\n",
       " 'prior',\n",
       " 'policy',\n",
       " 'indicate',\n",
       " 'visit',\n",
       " 'sit',\n",
       " 'adult',\n",
       " 'match',\n",
       " 'pronounce',\n",
       " 'invent',\n",
       " 'operation',\n",
       " 'normally',\n",
       " 'wrestler',\n",
       " 'responsible',\n",
       " 'whether',\n",
       " 'approach',\n",
       " 'blue',\n",
       " 'incorporate',\n",
       " 'federation',\n",
       " 'concern',\n",
       " 'medal',\n",
       " 'unlike',\n",
       " 'expand',\n",
       " 'creation',\n",
       " 'supply',\n",
       " 'address',\n",
       " 'fantasy',\n",
       " 'hill',\n",
       " 'manage',\n",
       " 'authority',\n",
       " 'legal',\n",
       " 'console',\n",
       " 'fail',\n",
       " 'field',\n",
       " 'bury',\n",
       " 'construct',\n",
       " 'propose',\n",
       " 'nominate',\n",
       " 'detail',\n",
       " 'teach',\n",
       " 'church',\n",
       " 'distinguish',\n",
       " 'relatively',\n",
       " 'secondary',\n",
       " 'select',\n",
       " 'billion',\n",
       " 'historic',\n",
       " 'electronic',\n",
       " 'universe',\n",
       " 'remove',\n",
       " 'alone',\n",
       " 'aircraft',\n",
       " 'medieval',\n",
       " 'evolution',\n",
       " 'view',\n",
       " 'management',\n",
       " 'generation',\n",
       " 'print',\n",
       " 'mine',\n",
       " 'trade',\n",
       " 'layer',\n",
       " 'classic',\n",
       " 'vice',\n",
       " 'prevent',\n",
       " 'staff',\n",
       " 'meter',\n",
       " 'concept',\n",
       " 'completely',\n",
       " 'try',\n",
       " 'entry',\n",
       " 'classify',\n",
       " 'sexual',\n",
       " 'piece',\n",
       " 'dictionary',\n",
       " 'density',\n",
       " 'ability',\n",
       " 'activity',\n",
       " 'reserve',\n",
       " 'motion',\n",
       " 'lack',\n",
       " 'tradition',\n",
       " 'biography',\n",
       " 'assembly',\n",
       " 'reform',\n",
       " 'depend',\n",
       " 'chamber',\n",
       " 'weight',\n",
       " 'frequently',\n",
       " 'orthodox',\n",
       " 'heritage',\n",
       " 'carbon',\n",
       " 'conservative',\n",
       " 'ally',\n",
       " 'spell',\n",
       " 'water',\n",
       " 'manufacture',\n",
       " 'roll',\n",
       " 'rural',\n",
       " 'landfall',\n",
       " 'agreement',\n",
       " 'parallel',\n",
       " 'portion',\n",
       " 'ministry',\n",
       " 'outer',\n",
       " 'trophy',\n",
       " 'soldier',\n",
       " 'roughly',\n",
       " 'find',\n",
       " 'strength',\n",
       " 'reveal',\n",
       " 'shortly',\n",
       " 'mark',\n",
       " 'tube',\n",
       " 'experiment',\n",
       " 'pattern',\n",
       " 'sing',\n",
       " 'largely',\n",
       " 'fund',\n",
       " 'convert',\n",
       " 'closely',\n",
       " 'side',\n",
       " 'tribe',\n",
       " 'definition',\n",
       " 'opposite',\n",
       " 'agency',\n",
       " 'traditionally',\n",
       " 'latter',\n",
       " 'observe',\n",
       " 'chart',\n",
       " 'draw',\n",
       " 'govern',\n",
       " 'sons',\n",
       " 'market',\n",
       " 'sequel',\n",
       " 'economy',\n",
       " 'marine',\n",
       " 'designate',\n",
       " 'traffic',\n",
       " 'jazz',\n",
       " 'reason',\n",
       " 'drop',\n",
       " 'difficult',\n",
       " 'external',\n",
       " 'multi',\n",
       " 'inspire',\n",
       " 'problem',\n",
       " 'distinct',\n",
       " 'script',\n",
       " 'distribute',\n",
       " 'scene',\n",
       " 'temple',\n",
       " 'additional',\n",
       " 'couple',\n",
       " 'philosopher',\n",
       " 'meet',\n",
       " 'folk',\n",
       " 'impact',\n",
       " 'mediterranean',\n",
       " 'interstate',\n",
       " 'formal',\n",
       " 'semi',\n",
       " 'bureau',\n",
       " 'respectively',\n",
       " 'arrest',\n",
       " 'disk',\n",
       " 'slightly',\n",
       " 'senior',\n",
       " 'burn',\n",
       " 'charge',\n",
       " 'christmas',\n",
       " 'suffer',\n",
       " 'prominent',\n",
       " 'alphabet',\n",
       " 'lyric',\n",
       " 'club',\n",
       " 'pioneer',\n",
       " 'avoid',\n",
       " 'eye',\n",
       " 'memory',\n",
       " 'write',\n",
       " 'intend',\n",
       " 'target',\n",
       " 'legend',\n",
       " 'hit',\n",
       " 'egg',\n",
       " 'colony',\n",
       " 'drum',\n",
       " 'socialist',\n",
       " 'factor',\n",
       " 'contact',\n",
       " 'tournament',\n",
       " 'global',\n",
       " 'midfielder',\n",
       " 'interview',\n",
       " 'formation',\n",
       " 'extreme',\n",
       " 'pilot',\n",
       " 'size',\n",
       " 'bond',\n",
       " 'knight',\n",
       " 'fan',\n",
       " 'communist',\n",
       " 'request',\n",
       " 'collect',\n",
       " 'span',\n",
       " 'basis',\n",
       " 'conflict',\n",
       " 'bear',\n",
       " 'plot',\n",
       " 'franchise',\n",
       " 'supreme',\n",
       " 'voice',\n",
       " 'purchase',\n",
       " 'editor',\n",
       " 'behavior',\n",
       " 'property',\n",
       " 'initial',\n",
       " 'earthquake',\n",
       " 'grant',\n",
       " 'journal',\n",
       " 'chairman',\n",
       " 'stay',\n",
       " 'register',\n",
       " 'atomic',\n",
       " 'designation',\n",
       " 'continental',\n",
       " 'oppose',\n",
       " 'test',\n",
       " 'immediately',\n",
       " 'classification',\n",
       " 'flavor',\n",
       " 'permanent',\n",
       " 'wing',\n",
       " 'internal',\n",
       " 'capacity',\n",
       " 'biology',\n",
       " 'confirm',\n",
       " 'convention',\n",
       " 'virgin',\n",
       " 'peak',\n",
       " 'translation',\n",
       " 'contemporary',\n",
       " 'abbreviate',\n",
       " 'explorer',\n",
       " 'solid',\n",
       " 'evolve',\n",
       " 'medium',\n",
       " 'memorial',\n",
       " 'attach',\n",
       " 'drive',\n",
       " 'politics',\n",
       " 'generate',\n",
       " 'subsequently',\n",
       " 'party',\n",
       " 'demand',\n",
       " 'champion',\n",
       " 'combination',\n",
       " 'wall',\n",
       " 'execute',\n",
       " 'wave',\n",
       " 'senate',\n",
       " 'preserve',\n",
       " 'invasion',\n",
       " 'understand',\n",
       " 'chancellor',\n",
       " 'contrast',\n",
       " 'specifically',\n",
       " 'talk',\n",
       " 'survivor',\n",
       " 'potter',\n",
       " 'presidential',\n",
       " 'expansion',\n",
       " 'dedicate',\n",
       " 'defender',\n",
       " 'dog',\n",
       " 'dispute',\n",
       " 'financial',\n",
       " 'storm',\n",
       " 'frontier',\n",
       " 'block',\n",
       " 'plastic',\n",
       " 'universal',\n",
       " 'mathematician',\n",
       " 'encyclopedia',\n",
       " 'islam',\n",
       " 'center',\n",
       " 'rare',\n",
       " 'learn',\n",
       " 'get',\n",
       " 'heavyweight',\n",
       " 'protect',\n",
       " 'opposition',\n",
       " 'possibly',\n",
       " 'playstation',\n",
       " 'easily',\n",
       " 'commander',\n",
       " 'chemistry',\n",
       " 'participate',\n",
       " 'subtropical',\n",
       " 'drummer',\n",
       " 'intelligence',\n",
       " 'obtain',\n",
       " 'notably',\n",
       " 'striker',\n",
       " 'visible',\n",
       " 'comedian',\n",
       " 'expect',\n",
       " 'sales',\n",
       " 'christianity',\n",
       " 'rock',\n",
       " 'selection',\n",
       " 'usage',\n",
       " 'retain',\n",
       " 'mosque',\n",
       " 'moon',\n",
       " 'figure',\n",
       " 'coastal',\n",
       " 'existence',\n",
       " 'mainland',\n",
       " 'typical',\n",
       " 'relative',\n",
       " 'phrase',\n",
       " 'literally',\n",
       " 'mechanical',\n",
       " 'parish',\n",
       " 'quality',\n",
       " 'assume',\n",
       " 'value',\n",
       " 'liquid',\n",
       " 'protection',\n",
       " 'positive',\n",
       " 'retrieve',\n",
       " 'pianist',\n",
       " 'acquire',\n",
       " 'broadcast',\n",
       " 'branch',\n",
       " 'damage',\n",
       " 'protestant',\n",
       " 'violin',\n",
       " 'prove',\n",
       " 'chapel',\n",
       " 'influential',\n",
       " 'park',\n",
       " 'stag',\n",
       " 'garden',\n",
       " 'municipal',\n",
       " 'root',\n",
       " 'warn',\n",
       " 'review',\n",
       " 'class',\n",
       " 'employ',\n",
       " 'domestic',\n",
       " 'mission',\n",
       " 'flood',\n",
       " 'colonial',\n",
       " 'fill',\n",
       " 'republican',\n",
       " 'collapse',\n",
       " 'critical',\n",
       " 'historically',\n",
       " ...]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_intersect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unite'"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_intersect[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.7801074 , -0.39743483,  0.33151   , -0.42535198, -0.31678352,\n",
       "       -0.12494306, -1.0003312 ,  0.30804688,  0.09399007, -0.4421056 ,\n",
       "        1.1328658 , -0.41188908,  0.2421638 , -0.9570693 , -0.6196538 ,\n",
       "       -0.08834325,  0.2479033 , -0.7989512 , -1.092673  , -0.19335406,\n",
       "        0.18697774, -0.14205298, -0.38506132, -0.85547936, -0.16819596,\n",
       "        0.339418  ,  0.22533469,  0.0850617 , -0.6015083 , -0.9227408 ,\n",
       "        0.649183  ,  0.2831538 ,  0.08499917,  0.43151474,  0.18259144,\n",
       "       -1.3428677 ,  0.2823986 ,  0.23954643,  0.12896317, -0.37075236,\n",
       "       -0.15888508, -0.948024  , -0.19588557, -0.91594225,  0.564731  ,\n",
       "       -1.1667819 , -0.21770501, -0.57910943,  0.9150283 , -0.34880003,\n",
       "       -0.37580523, -0.71430224, -0.05618142, -0.36738282,  0.28864875,\n",
       "        0.29770705,  0.66635185,  0.64129317, -0.17470375, -0.33624524,\n",
       "        0.20392656,  0.26327574, -0.5132786 ,  0.09495102, -0.53185385,\n",
       "       -0.320495  , -0.4341125 ,  1.1091578 , -0.4819226 ,  0.6022063 ,\n",
       "       -0.8568386 ,  0.51142275, -0.626579  ,  0.44029298,  0.86500907,\n",
       "       -1.4252523 ,  0.18938884, -0.17977554,  0.55464876,  1.2583567 ,\n",
       "        0.21873645, -0.68087065, -0.70339864, -0.1681996 , -0.66108096,\n",
       "       -0.0282214 ,  0.73659146,  0.36599526, -0.10388531,  0.13581987,\n",
       "       -0.6657157 , -0.01056981,  0.21829662, -1.3176495 , -0.79909843,\n",
       "        0.2910644 ,  0.7670251 ,  0.16996291, -0.03479747, -0.37629378],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.52])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_df[concrete_df['Word']=='state']['Conc.M'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in concrete_intersect:\n",
    "    word_vectors[word] = word_vectors[word] * 1/concrete_df[concrete_df['Word']==word]['Conc.M'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "== AoA_51715_words.csv ==\n",
    "\n",
    "This file contains \"Age of Acquisition\" (AoA) estimates for about 51k English words, which refers to the approximate age (in years) when a word was learned. Early words, being more basic, have lower average AoA.\n",
    "\n",
    "The main columns you will be interested in are \"Word\" and \"AoA_Kup_lem\". But the others may be useful too.\n",
    "\n",
    "The file contains these columns:\n",
    "\n",
    "Word :: The word in question\n",
    "Alternative.spelling :: if the Word may be spelled frequently in another form\t\n",
    "Freq_pm\t:: Freq of the Word in general English (larger -> more common)\n",
    "Dom_PoS_SUBTLEX\t:: Dominant part of speech in general usage\n",
    "Nletters :: number of letters \n",
    "Nphon :: number of phonemes\n",
    "Nsyll :: number of syllables\n",
    "Lemma_highest_PoS :: the \"lemmatized\" or \"root\" form of the word (in the dominant part of speech. e.g. The root form of the verb \"abates\" is \"abate\".\n",
    "AoA_Kup\t:: The AoA from a previous study by Kuperman et al.\n",
    "Perc_known :: Percent of people who knew the word in the Kuperman et al. study\n",
    "AoA_Kup_lem :: Estimated AoA based on Kuperman et al. study lemmatized words. THIS IS THE MAIN COLUMN OF INTEREST.\n",
    "Perc_known_lem\t:: Estimated percentage of people who would know this form of the word in the Kuperman study.\n",
    "AoA_Bird_lem :: AoA reported in previous study by Bird (2001) \n",
    "AoA_Bristol_lem\t:: AoA reported in previous study from Bristol Univ. (2006)\n",
    "AoA_Cort_lem :: AoA reported in previous study by Cortese & Khanna (2008)\n",
    "AoA_Schock :: AoA reported in previous study by Schock (2012)\n",
    "\n",
    "Original source : http://crr.ugent.be/archives/806"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Alternative.spelling</th>\n",
       "      <th>Freq_pm</th>\n",
       "      <th>Dom_PoS_SUBTLEX</th>\n",
       "      <th>Nletters</th>\n",
       "      <th>Nphon</th>\n",
       "      <th>Nsyll</th>\n",
       "      <th>Lemma_highest_PoS</th>\n",
       "      <th>AoA_Kup</th>\n",
       "      <th>Perc_known</th>\n",
       "      <th>AoA_Kup_lem</th>\n",
       "      <th>Perc_known_lem</th>\n",
       "      <th>AoA_Bird_lem</th>\n",
       "      <th>AoA_Bristol_lem</th>\n",
       "      <th>AoA_Cort_lem</th>\n",
       "      <th>AoA_Schock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>20415.27</td>\n",
       "      <td>Article</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>2.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aardvark</td>\n",
       "      <td>aardvark</td>\n",
       "      <td>0.41</td>\n",
       "      <td>Noun</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>aardvark</td>\n",
       "      <td>9.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abacus</td>\n",
       "      <td>abacus</td>\n",
       "      <td>0.24</td>\n",
       "      <td>Noun</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>abacus</td>\n",
       "      <td>8.69</td>\n",
       "      <td>0.65</td>\n",
       "      <td>8.69</td>\n",
       "      <td>0.65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abacuses</td>\n",
       "      <td>abacuses</td>\n",
       "      <td>0.02</td>\n",
       "      <td>Noun</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>abacus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.69</td>\n",
       "      <td>0.65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abalone</td>\n",
       "      <td>abalone</td>\n",
       "      <td>0.51</td>\n",
       "      <td>Verb</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>abalone</td>\n",
       "      <td>12.23</td>\n",
       "      <td>0.72</td>\n",
       "      <td>12.23</td>\n",
       "      <td>0.72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word Alternative.spelling   Freq_pm Dom_PoS_SUBTLEX  Nletters  Nphon  \\\n",
       "0         a                    a  20415.27         Article         1      1   \n",
       "1  aardvark             aardvark      0.41            Noun         8      7   \n",
       "2    abacus               abacus      0.24            Noun         6      6   \n",
       "3  abacuses             abacuses      0.02            Noun         8      9   \n",
       "4   abalone              abalone      0.51            Verb         7      7   \n",
       "\n",
       "   Nsyll Lemma_highest_PoS  AoA_Kup  Perc_known  AoA_Kup_lem  Perc_known_lem  \\\n",
       "0      1                 a     2.89        1.00         2.89            1.00   \n",
       "1      2          aardvark     9.89        1.00         9.89            1.00   \n",
       "2      3            abacus     8.69        0.65         8.69            0.65   \n",
       "3      4            abacus      NaN         NaN         8.69            0.65   \n",
       "4      4           abalone    12.23        0.72        12.23            0.72   \n",
       "\n",
       "   AoA_Bird_lem  AoA_Bristol_lem  AoA_Cort_lem  AoA_Schock  \n",
       "0          3.16              NaN           NaN         NaN  \n",
       "1           NaN              NaN           NaN         NaN  \n",
       "2           NaN              NaN           NaN         NaN  \n",
       "3           NaN              NaN           NaN         NaN  \n",
       "4           NaN              NaN           NaN         NaN  "
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AoA\n",
    "#Perc_known_lem, AoA_Kup_lem\n",
    "aoawords_path = 'Data/AoA_51715_words.csv'\n",
    "AoA = pd.read_csv(aoawords_path,encoding = 'unicode_escape')\n",
    "AoA_set = set(AoA['Word'].values)\n",
    "AoA.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51715"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(AoA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.58"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AoA.AoA_Kup_lem.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.0"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AoA.AoA_Kup_lem.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Alternative.spelling</th>\n",
       "      <th>Freq_pm</th>\n",
       "      <th>Dom_PoS_SUBTLEX</th>\n",
       "      <th>Nletters</th>\n",
       "      <th>Nphon</th>\n",
       "      <th>Nsyll</th>\n",
       "      <th>Lemma_highest_PoS</th>\n",
       "      <th>AoA_Kup</th>\n",
       "      <th>Perc_known</th>\n",
       "      <th>AoA_Kup_lem</th>\n",
       "      <th>Perc_known_lem</th>\n",
       "      <th>AoA_Bird_lem</th>\n",
       "      <th>AoA_Bristol_lem</th>\n",
       "      <th>AoA_Cort_lem</th>\n",
       "      <th>AoA_Schock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14878</th>\n",
       "      <td>eisteddfod</td>\n",
       "      <td>eisteddfod</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>eisteddfod</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2084</th>\n",
       "      <td>architrave</td>\n",
       "      <td>architrave</td>\n",
       "      <td>0.04</td>\n",
       "      <td>Noun</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>architrave</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6274</th>\n",
       "      <td>calceolaria</td>\n",
       "      <td>calceolaria</td>\n",
       "      <td>0.02</td>\n",
       "      <td>Noun</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>calceolaria</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32931</th>\n",
       "      <td>penury</td>\n",
       "      <td>penury</td>\n",
       "      <td>0.02</td>\n",
       "      <td>Noun</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>penury</td>\n",
       "      <td>20.6</td>\n",
       "      <td>0.28</td>\n",
       "      <td>20.6</td>\n",
       "      <td>0.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25243</th>\n",
       "      <td>kendo</td>\n",
       "      <td>kendo</td>\n",
       "      <td>0.37</td>\n",
       "      <td>Noun</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>kendo</td>\n",
       "      <td>20.5</td>\n",
       "      <td>0.11</td>\n",
       "      <td>20.5</td>\n",
       "      <td>0.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38932</th>\n",
       "      <td>rogation</td>\n",
       "      <td>rogation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>rogation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42089</th>\n",
       "      <td>smilax</td>\n",
       "      <td>smilax</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>smilax</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46368</th>\n",
       "      <td>thulium</td>\n",
       "      <td>thulium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>thulium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50862</th>\n",
       "      <td>wickiup</td>\n",
       "      <td>wickiup</td>\n",
       "      <td>0.27</td>\n",
       "      <td>Noun</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>wickiup</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50941</th>\n",
       "      <td>williwaw</td>\n",
       "      <td>williwaw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>williwaw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51715 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Word Alternative.spelling  Freq_pm Dom_PoS_SUBTLEX  Nletters  \\\n",
       "14878   eisteddfod           eisteddfod      NaN             NaN        10   \n",
       "2084    architrave           architrave     0.04            Noun        10   \n",
       "6274   calceolaria          calceolaria     0.02            Noun        11   \n",
       "32931       penury               penury     0.02            Noun         6   \n",
       "25243        kendo                kendo     0.37            Noun         5   \n",
       "...            ...                  ...      ...             ...       ...   \n",
       "38932     rogation             rogation      NaN             NaN         8   \n",
       "42089       smilax               smilax      NaN             NaN         6   \n",
       "46368      thulium              thulium      NaN             NaN         7   \n",
       "50862      wickiup              wickiup     0.27            Noun         7   \n",
       "50941     williwaw             williwaw      NaN             NaN         8   \n",
       "\n",
       "       Nphon  Nsyll Lemma_highest_PoS  AoA_Kup  Perc_known  AoA_Kup_lem  \\\n",
       "14878      8      3        eisteddfod     25.0        0.05         25.0   \n",
       "2084       8      3        architrave     21.0        0.05         21.0   \n",
       "6274      11      6       calceolaria     21.0        0.11         21.0   \n",
       "32931      7      3            penury     20.6        0.28         20.6   \n",
       "25243      5      2             kendo     20.5        0.11         20.5   \n",
       "...      ...    ...               ...      ...         ...          ...   \n",
       "38932      7      3          rogation      NaN        0.00          NaN   \n",
       "42089      7      2            smilax      NaN        0.00          NaN   \n",
       "46368      6      3           thulium      NaN        0.00          NaN   \n",
       "50862      6      3           wickiup      NaN        0.00          NaN   \n",
       "50941      6      3          williwaw      NaN        0.00          NaN   \n",
       "\n",
       "       Perc_known_lem  AoA_Bird_lem  AoA_Bristol_lem  AoA_Cort_lem  AoA_Schock  \n",
       "14878            0.05           NaN              NaN           NaN         NaN  \n",
       "2084             0.05           NaN              NaN           NaN         NaN  \n",
       "6274             0.11           NaN              NaN           NaN         NaN  \n",
       "32931            0.28           NaN              NaN           NaN         NaN  \n",
       "25243            0.11           NaN              NaN           NaN         NaN  \n",
       "...               ...           ...              ...           ...         ...  \n",
       "38932            0.00           NaN              NaN           NaN         NaN  \n",
       "42089            0.00           NaN              NaN           NaN         NaN  \n",
       "46368            0.00           NaN              NaN           NaN         NaN  \n",
       "50862            0.00           NaN              NaN           NaN         NaN  \n",
       "50941            0.00           NaN              NaN           NaN         NaN  \n",
       "\n",
       "[51715 rows x 16 columns]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AoA.sort_values(['AoA_Kup_lem'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(AoA[AoA['AoA_Kup_lem'].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Alternative.spelling</th>\n",
       "      <th>Freq_pm</th>\n",
       "      <th>Dom_PoS_SUBTLEX</th>\n",
       "      <th>Nletters</th>\n",
       "      <th>Nphon</th>\n",
       "      <th>Nsyll</th>\n",
       "      <th>Lemma_highest_PoS</th>\n",
       "      <th>AoA_Kup</th>\n",
       "      <th>Perc_known</th>\n",
       "      <th>AoA_Kup_lem</th>\n",
       "      <th>Perc_known_lem</th>\n",
       "      <th>AoA_Bird_lem</th>\n",
       "      <th>AoA_Bristol_lem</th>\n",
       "      <th>AoA_Cort_lem</th>\n",
       "      <th>AoA_Schock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>actinium</td>\n",
       "      <td>actinium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>actinium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322</th>\n",
       "      <td>ambuscade</td>\n",
       "      <td>ambuscade</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>ambuscade</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2306</th>\n",
       "      <td>ashlar</td>\n",
       "      <td>ashlar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>ashlar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5095</th>\n",
       "      <td>bosky</td>\n",
       "      <td>bosky</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>bosky</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6404</th>\n",
       "      <td>canaille</td>\n",
       "      <td>canaille</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>canaille</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9004</th>\n",
       "      <td>compeer</td>\n",
       "      <td>compeer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>compeer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9005</th>\n",
       "      <td>compeers</td>\n",
       "      <td>compeers</td>\n",
       "      <td>0.02</td>\n",
       "      <td>Noun</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>compeer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16000</th>\n",
       "      <td>europium</td>\n",
       "      <td>europium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>europium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19065</th>\n",
       "      <td>gallimaufry</td>\n",
       "      <td>gallimaufry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>gallimaufry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22498</th>\n",
       "      <td>hutment</td>\n",
       "      <td>hutment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>hutment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25196</th>\n",
       "      <td>karakul</td>\n",
       "      <td>karakul</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>karakul</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25219</th>\n",
       "      <td>kedge</td>\n",
       "      <td>kedge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>kedge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25575</th>\n",
       "      <td>kyat</td>\n",
       "      <td>kyat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>kyat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32754</th>\n",
       "      <td>peculation</td>\n",
       "      <td>peculation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>peculation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34588</th>\n",
       "      <td>pother</td>\n",
       "      <td>pother</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>pother</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38932</th>\n",
       "      <td>rogation</td>\n",
       "      <td>rogation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>rogation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42089</th>\n",
       "      <td>smilax</td>\n",
       "      <td>smilax</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>smilax</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46368</th>\n",
       "      <td>thulium</td>\n",
       "      <td>thulium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>thulium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50862</th>\n",
       "      <td>wickiup</td>\n",
       "      <td>wickiup</td>\n",
       "      <td>0.27</td>\n",
       "      <td>Noun</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>wickiup</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50941</th>\n",
       "      <td>williwaw</td>\n",
       "      <td>williwaw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>williwaw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Word Alternative.spelling  Freq_pm Dom_PoS_SUBTLEX  Nletters  \\\n",
       "442       actinium             actinium      NaN             NaN         8   \n",
       "1322     ambuscade            ambuscade      NaN             NaN         9   \n",
       "2306        ashlar               ashlar      NaN             NaN         6   \n",
       "5095         bosky                bosky      NaN             NaN         5   \n",
       "6404      canaille             canaille      NaN             NaN         8   \n",
       "9004       compeer              compeer      NaN             NaN         7   \n",
       "9005      compeers             compeers     0.02            Noun         8   \n",
       "16000     europium             europium      NaN             NaN         8   \n",
       "19065  gallimaufry          gallimaufry      NaN             NaN        11   \n",
       "22498      hutment              hutment      NaN             NaN         7   \n",
       "25196      karakul              karakul      NaN             NaN         7   \n",
       "25219        kedge                kedge      NaN             NaN         5   \n",
       "25575         kyat                 kyat      NaN             NaN         4   \n",
       "32754   peculation           peculation      NaN             NaN        10   \n",
       "34588       pother               pother      NaN             NaN         6   \n",
       "38932     rogation             rogation      NaN             NaN         8   \n",
       "42089       smilax               smilax      NaN             NaN         6   \n",
       "46368      thulium              thulium      NaN             NaN         7   \n",
       "50862      wickiup              wickiup     0.27            Noun         7   \n",
       "50941     williwaw             williwaw      NaN             NaN         8   \n",
       "\n",
       "       Nphon  Nsyll Lemma_highest_PoS  AoA_Kup  Perc_known  AoA_Kup_lem  \\\n",
       "442        8      4          actinium      NaN         0.0          NaN   \n",
       "1322       8      3         ambuscade      NaN         0.0          NaN   \n",
       "2306       5      2            ashlar      NaN         0.0          NaN   \n",
       "5095       4      2             bosky      NaN         0.0          NaN   \n",
       "6404       5      2          canaille      NaN         0.0          NaN   \n",
       "9004       6      3           compeer      NaN         0.0          NaN   \n",
       "9005       7      3           compeer      NaN         NaN          NaN   \n",
       "16000      8      4          europium      NaN         0.0          NaN   \n",
       "19065      9      4       gallimaufry      NaN         0.0          NaN   \n",
       "22498      7      2           hutment      NaN         0.0          NaN   \n",
       "25196      7      3           karakul      NaN         0.0          NaN   \n",
       "25219      3      1             kedge      NaN         0.0          NaN   \n",
       "25575      4      2              kyat      NaN         0.0          NaN   \n",
       "32754     10      4        peculation      NaN         0.0          NaN   \n",
       "34588      5      2            pother      NaN         0.0          NaN   \n",
       "38932      7      3          rogation      NaN         0.0          NaN   \n",
       "42089      7      2            smilax      NaN         0.0          NaN   \n",
       "46368      6      3           thulium      NaN         0.0          NaN   \n",
       "50862      6      3           wickiup      NaN         0.0          NaN   \n",
       "50941      6      3          williwaw      NaN         0.0          NaN   \n",
       "\n",
       "       Perc_known_lem  AoA_Bird_lem  AoA_Bristol_lem  AoA_Cort_lem  AoA_Schock  \n",
       "442               0.0           NaN              NaN           NaN         NaN  \n",
       "1322              0.0           NaN              NaN           NaN         NaN  \n",
       "2306              0.0           NaN              NaN           NaN         NaN  \n",
       "5095              0.0           NaN              NaN           NaN         NaN  \n",
       "6404              0.0           NaN              NaN           NaN         NaN  \n",
       "9004              0.0           NaN              NaN           NaN         NaN  \n",
       "9005              0.0           NaN              NaN           NaN         NaN  \n",
       "16000             0.0           NaN              NaN           NaN         NaN  \n",
       "19065             0.0           NaN              NaN           NaN         NaN  \n",
       "22498             0.0           NaN              NaN           NaN         NaN  \n",
       "25196             0.0           NaN              NaN           NaN         NaN  \n",
       "25219             0.0           NaN              NaN           NaN         NaN  \n",
       "25575             0.0           NaN              NaN           NaN         NaN  \n",
       "32754             0.0           NaN              NaN           NaN         NaN  \n",
       "34588             0.0           NaN              NaN           NaN         NaN  \n",
       "38932             0.0           NaN              NaN           NaN         NaN  \n",
       "42089             0.0           NaN              NaN           NaN         NaN  \n",
       "46368             0.0           NaN              NaN           NaN         NaN  \n",
       "50862             0.0           NaN              NaN           NaN         NaN  \n",
       "50941             0.0           NaN              NaN           NaN         NaN  "
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AoA[AoA['AoA_Kup_lem'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to impute all Nan values in AoA_Kup_lem as the max AoA value 25, as they appear to be hard words.\n",
    "AoA['AoA_Kup_lem'].fillna(value=AoA['AoA_Kup_lem'].max(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Alternative.spelling</th>\n",
       "      <th>Freq_pm</th>\n",
       "      <th>Dom_PoS_SUBTLEX</th>\n",
       "      <th>Nletters</th>\n",
       "      <th>Nphon</th>\n",
       "      <th>Nsyll</th>\n",
       "      <th>Lemma_highest_PoS</th>\n",
       "      <th>AoA_Kup</th>\n",
       "      <th>Perc_known</th>\n",
       "      <th>AoA_Kup_lem</th>\n",
       "      <th>Perc_known_lem</th>\n",
       "      <th>AoA_Bird_lem</th>\n",
       "      <th>AoA_Bristol_lem</th>\n",
       "      <th>AoA_Cort_lem</th>\n",
       "      <th>AoA_Schock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2306</th>\n",
       "      <td>ashlar</td>\n",
       "      <td>ashlar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>ashlar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38932</th>\n",
       "      <td>rogation</td>\n",
       "      <td>rogation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>rogation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46368</th>\n",
       "      <td>thulium</td>\n",
       "      <td>thulium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>thulium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14878</th>\n",
       "      <td>eisteddfod</td>\n",
       "      <td>eisteddfod</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>eisteddfod</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5095</th>\n",
       "      <td>bosky</td>\n",
       "      <td>bosky</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>bosky</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27395</th>\n",
       "      <td>mamma</td>\n",
       "      <td>mamma</td>\n",
       "      <td>3.02</td>\n",
       "      <td>Noun</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>mama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27393</th>\n",
       "      <td>mamas</td>\n",
       "      <td>mamas</td>\n",
       "      <td>0.71</td>\n",
       "      <td>Noun</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>mama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27392</th>\n",
       "      <td>mama</td>\n",
       "      <td>mama</td>\n",
       "      <td>103.71</td>\n",
       "      <td>Noun</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>mama</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29050</th>\n",
       "      <td>mommas</td>\n",
       "      <td>mommas</td>\n",
       "      <td>0.10</td>\n",
       "      <td>Noun</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>momma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29049</th>\n",
       "      <td>momma</td>\n",
       "      <td>momma</td>\n",
       "      <td>8.08</td>\n",
       "      <td>Noun</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>momma</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51715 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Word Alternative.spelling  Freq_pm Dom_PoS_SUBTLEX  Nletters  \\\n",
       "2306       ashlar               ashlar      NaN             NaN         6   \n",
       "38932    rogation             rogation      NaN             NaN         8   \n",
       "46368     thulium              thulium      NaN             NaN         7   \n",
       "14878  eisteddfod           eisteddfod      NaN             NaN        10   \n",
       "5095        bosky                bosky      NaN             NaN         5   \n",
       "...           ...                  ...      ...             ...       ...   \n",
       "27395       mamma                mamma     3.02            Noun         5   \n",
       "27393       mamas                mamas     0.71            Noun         5   \n",
       "27392        mama                 mama   103.71            Noun         4   \n",
       "29050      mommas               mommas     0.10            Noun         6   \n",
       "29049       momma                momma     8.08            Noun         5   \n",
       "\n",
       "       Nphon  Nsyll Lemma_highest_PoS  AoA_Kup  Perc_known  AoA_Kup_lem  \\\n",
       "2306       5      2            ashlar      NaN        0.00        25.00   \n",
       "38932      7      3          rogation      NaN        0.00        25.00   \n",
       "46368      6      3           thulium      NaN        0.00        25.00   \n",
       "14878      8      3        eisteddfod    25.00        0.05        25.00   \n",
       "5095       4      2             bosky      NaN        0.00        25.00   \n",
       "...      ...    ...               ...      ...         ...          ...   \n",
       "27395      4      2              mama      NaN         NaN         1.89   \n",
       "27393      5      2              mama      NaN         NaN         1.89   \n",
       "27392      4      2              mama     1.89        1.00         1.89   \n",
       "29050      5      2             momma      NaN         NaN         1.58   \n",
       "29049      4      2             momma     1.58        1.00         1.58   \n",
       "\n",
       "       Perc_known_lem  AoA_Bird_lem  AoA_Bristol_lem  AoA_Cort_lem  AoA_Schock  \n",
       "2306             0.00           NaN              NaN           NaN         NaN  \n",
       "38932            0.00           NaN              NaN           NaN         NaN  \n",
       "46368            0.00           NaN              NaN           NaN         NaN  \n",
       "14878            0.05           NaN              NaN           NaN         NaN  \n",
       "5095             0.00           NaN              NaN           NaN         NaN  \n",
       "...               ...           ...              ...           ...         ...  \n",
       "27395            1.00           NaN              NaN           NaN         NaN  \n",
       "27393            1.00           NaN              NaN           NaN         NaN  \n",
       "27392            1.00           NaN              NaN           NaN         NaN  \n",
       "29050            1.00           NaN              NaN           NaN         NaN  \n",
       "29049            1.00           NaN              NaN           NaN         NaN  \n",
       "\n",
       "[51715 rows x 16 columns]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AoA.sort_values(['AoA_Kup_lem'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AoA values range from 0 - 25, which means the smaller the AoA value, the easier the word is. We could possibly use the AoA value to give easier words less weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoa_words = list(AoA['Word'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51715"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aoa_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoa_complement = [word for word in words_in_vector if word not in aoa_words]\n",
    "aoa_intersect = [word for word in words_in_vector if word in aoa_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "322"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aoa_complement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ndash',\n",
       " 'usually',\n",
       " 'european',\n",
       " 'basse',\n",
       " 'commonly',\n",
       " 'picardie',\n",
       " 'aquitaine',\n",
       " 'generally',\n",
       " 'atlantic',\n",
       " 'officially',\n",
       " 'lower',\n",
       " 'especially',\n",
       " 'disney',\n",
       " 'throughout',\n",
       " 'britain',\n",
       " 'wikipedia',\n",
       " 'approximately',\n",
       " 'pacific',\n",
       " 'mainly',\n",
       " 'nintendo',\n",
       " 'alpes',\n",
       " 'partement',\n",
       " 'typically',\n",
       " 'nobel',\n",
       " 'african',\n",
       " 'widely',\n",
       " 'picardy',\n",
       " 'particularly',\n",
       " 'formerly',\n",
       " 'olympic',\n",
       " 'jewish',\n",
       " 'prix',\n",
       " 'korea',\n",
       " 'previously',\n",
       " 'directly',\n",
       " 'probably',\n",
       " 'saturn',\n",
       " 'online',\n",
       " 'recently',\n",
       " 'nazi',\n",
       " 'provence',\n",
       " 'highly',\n",
       " 'isbn',\n",
       " 'linux',\n",
       " 'islamic',\n",
       " 'microsoft',\n",
       " 'unlike',\n",
       " 'rhine',\n",
       " 'relatively',\n",
       " 'kilometres',\n",
       " 'completely',\n",
       " 'kong',\n",
       " 'frequently',\n",
       " 'azur',\n",
       " 'municipalities',\n",
       " 'shortly',\n",
       " 'gregorian',\n",
       " 'largely',\n",
       " 'closely',\n",
       " 'traditionally',\n",
       " 'asian',\n",
       " 'metres',\n",
       " 'ardãƒ',\n",
       " 'respectively',\n",
       " 'caribbean',\n",
       " 'tehsil',\n",
       " 'smackdown',\n",
       " 'abbottabad',\n",
       " 'grammy',\n",
       " 'yorkshire',\n",
       " 'johann',\n",
       " 'montreal',\n",
       " 'hong',\n",
       " 'hitler',\n",
       " 'jews',\n",
       " 'subsequently',\n",
       " 'muslims',\n",
       " 'specifically',\n",
       " 'islam',\n",
       " 'pokãƒ',\n",
       " 'possibly',\n",
       " 'playstation',\n",
       " 'easily',\n",
       " 'fifa',\n",
       " 'subtropical',\n",
       " 'notably',\n",
       " 'christianity',\n",
       " 'arab',\n",
       " 'neptune',\n",
       " 'historically',\n",
       " 'colour',\n",
       " 'puerto',\n",
       " 'onto',\n",
       " 'newly',\n",
       " 'westphalia',\n",
       " 'extremely',\n",
       " 'friedrich',\n",
       " 'vendãƒ',\n",
       " 'entirely',\n",
       " 'alongside',\n",
       " 'voyager',\n",
       " 'beatles',\n",
       " 'wrestlemania',\n",
       " 'xbox',\n",
       " 'ardã',\n",
       " 'christians',\n",
       " 'formally',\n",
       " 'gaelic',\n",
       " 'viii',\n",
       " 'saxe',\n",
       " 'romans',\n",
       " 'americans',\n",
       " 'indo',\n",
       " 'anglo',\n",
       " 'orton',\n",
       " 'bach',\n",
       " 'google',\n",
       " 'uranus',\n",
       " 'uefa',\n",
       " 'wagner',\n",
       " 'prussia',\n",
       " 'celtic',\n",
       " 'heavily',\n",
       " 'annually',\n",
       " 'britannica',\n",
       " 'shakespeare',\n",
       " 'hindu',\n",
       " 'labour',\n",
       " 'zeus',\n",
       " 'serie',\n",
       " 'ecliptic',\n",
       " 'atlantiques',\n",
       " 'canadiens',\n",
       " 'bengal',\n",
       " 'forbes',\n",
       " 'batista',\n",
       " 'pokã',\n",
       " 'brabant',\n",
       " 'commons',\n",
       " 'norse',\n",
       " 'operas',\n",
       " 'frankfurt',\n",
       " 'overseas',\n",
       " 'josã',\n",
       " 'maritimes',\n",
       " 'greatly',\n",
       " 'shah',\n",
       " 'mcmahon',\n",
       " 'whedon',\n",
       " 'gradually',\n",
       " 'briefly',\n",
       " 'baptist',\n",
       " 'fairly',\n",
       " 'instal',\n",
       " 'neighbour',\n",
       " 'bouches',\n",
       " 'renault',\n",
       " 'leonese',\n",
       " 'indus',\n",
       " 'nasa',\n",
       " 'sony',\n",
       " 'slavic',\n",
       " 'reich',\n",
       " 'mccartney',\n",
       " 'janeiro',\n",
       " 'michaels',\n",
       " 'mozart',\n",
       " 'nuremberg',\n",
       " 'costa',\n",
       " 'pyrã',\n",
       " 'arabia',\n",
       " 'simpsons',\n",
       " 'antarctica',\n",
       " 'buddhism',\n",
       " 'newfoundland',\n",
       " 'strongly',\n",
       " 'knowles',\n",
       " 'internationally',\n",
       " 'inland',\n",
       " 'buenos',\n",
       " 'khyber',\n",
       " 'successfully',\n",
       " 'castile',\n",
       " 'persia',\n",
       " 'unesco',\n",
       " 'vendã',\n",
       " 'thames',\n",
       " 'orient',\n",
       " 'anglican',\n",
       " 'somewhat',\n",
       " 'subspecies',\n",
       " 'harvard',\n",
       " 'honour',\n",
       " 'programme',\n",
       " 'amazon',\n",
       " 'alps',\n",
       " 'petersburg',\n",
       " 'saudi',\n",
       " 'organise',\n",
       " 'georg',\n",
       " 'antarctic',\n",
       " 'apollo',\n",
       " 'teau',\n",
       " 'exclusively',\n",
       " 'flemish',\n",
       " 'nazis',\n",
       " 'publicly',\n",
       " 'extratropical',\n",
       " 'similarly',\n",
       " 'heinrich',\n",
       " 'josãƒ',\n",
       " 'ubuntu',\n",
       " 'pakhtunkhwa',\n",
       " 'significantly',\n",
       " 'bundesliga',\n",
       " 'harbour',\n",
       " 'chakwal',\n",
       " 'sussex',\n",
       " 'soundgarden',\n",
       " 'yugoslavia',\n",
       " 'blackhawks',\n",
       " 'ferrari',\n",
       " 'emirates',\n",
       " 'saxon',\n",
       " 'hume',\n",
       " 'prussian',\n",
       " 'chãƒ',\n",
       " 'debian',\n",
       " 'lanka',\n",
       " 'volkswagen',\n",
       " 'twentieth',\n",
       " 'ussr',\n",
       " 'loosely',\n",
       " 'jurassic',\n",
       " 'tehsils',\n",
       " 'increasingly',\n",
       " 'baltic',\n",
       " 'sainte',\n",
       " 'facto',\n",
       " 'sega',\n",
       " 'necessarily',\n",
       " 'partially',\n",
       " 'arabian',\n",
       " 'wolfgang',\n",
       " 'medici',\n",
       " 'victorian',\n",
       " 'arrondissement',\n",
       " 'tibet',\n",
       " 'vegas',\n",
       " 'grande',\n",
       " 'germanic',\n",
       " 'pradesh',\n",
       " 'independently',\n",
       " 'europeans',\n",
       " 'burma',\n",
       " 'germans',\n",
       " 'georges',\n",
       " 'commercially',\n",
       " 'antilles',\n",
       " 'canton',\n",
       " 'fischer',\n",
       " 'bruins',\n",
       " 'broadway',\n",
       " 'pluto',\n",
       " 'subfamily',\n",
       " 'silva',\n",
       " 'tico',\n",
       " 'forever',\n",
       " 'indians',\n",
       " 'nixon',\n",
       " 'nascar',\n",
       " 'ncaa',\n",
       " 'organisation',\n",
       " 'simultaneously',\n",
       " 'legally',\n",
       " 'hindenburg',\n",
       " 'properly',\n",
       " 'keynes',\n",
       " 'apparently',\n",
       " 'kreis',\n",
       " 'mecklenburg',\n",
       " 'beyoncã',\n",
       " 'boeing',\n",
       " 'greeks',\n",
       " 'thereafter',\n",
       " 'chevrolet',\n",
       " 'additionally',\n",
       " 'ville',\n",
       " 'scala',\n",
       " 'buddha',\n",
       " 'pichilemu',\n",
       " 'rica',\n",
       " 'cyrillic',\n",
       " 'nato',\n",
       " 'aang',\n",
       " 'gettysburg',\n",
       " 'yearly',\n",
       " 'ming',\n",
       " 'sunderland',\n",
       " 'mongol',\n",
       " 'extensively',\n",
       " 'oblast',\n",
       " 'rttemberg',\n",
       " 'nineteenth',\n",
       " 'bavarian',\n",
       " 'trojan',\n",
       " 'haute',\n",
       " 'predominantly',\n",
       " 'benoit',\n",
       " 'grameen',\n",
       " 'rhode',\n",
       " 'unitary',\n",
       " 'disambiguation',\n",
       " 'stallone',\n",
       " 'czechoslovakia',\n",
       " 'eleventh',\n",
       " 'meanwhile',\n",
       " 'sexually',\n",
       " 'ipswich',\n",
       " 'catholics',\n",
       " 'congo',\n",
       " 'amadeus']"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aoa_complement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2553"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aoa_intersect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unite',\n",
       " 'department',\n",
       " 'state',\n",
       " 'region',\n",
       " 'commune',\n",
       " 'include',\n",
       " 'call',\n",
       " 'play',\n",
       " 'national',\n",
       " 'district',\n",
       " 'release',\n",
       " 'years',\n",
       " 'name',\n",
       " 'locate',\n",
       " 'area',\n",
       " 'former',\n",
       " 'series',\n",
       " 'later',\n",
       " 'album',\n",
       " 'league']"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aoa_intersect[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2225"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([word for word in aoa_intersect if word in concrete_intersect])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in aoa_intersect:\n",
    "    word_vectors[word] = word_vectors[word] * AoA[AoA['Word']==word]['AoA_Kup_lem'].values/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05664643, -0.02885919,  0.02407215, -0.03088635, -0.0230028 ,\n",
       "       -0.00907257, -0.07263768,  0.02236841,  0.00682496, -0.03210289,\n",
       "        0.0822615 , -0.02990876,  0.01758439, -0.06949628, -0.04499532,\n",
       "       -0.00641492,  0.01800116, -0.05801475, -0.07934295, -0.01404014,\n",
       "        0.01357713, -0.01031498, -0.0279607 , -0.06211947, -0.01221332,\n",
       "        0.02464637,  0.01636237,  0.00617664, -0.04367771, -0.06700356,\n",
       "        0.04713954,  0.02056083,  0.0061721 ,  0.03133386,  0.01325863,\n",
       "       -0.09751051,  0.02050599,  0.01739434,  0.00936448, -0.02692168,\n",
       "       -0.01153722, -0.06883947, -0.01422396, -0.0665099 ,  0.04100717,\n",
       "       -0.08472428, -0.01580835, -0.04205124,  0.06644353, -0.02532764,\n",
       "       -0.02728858, -0.05186808, -0.00407954, -0.026677  ,  0.02095984,\n",
       "        0.02161759,  0.04838623,  0.04656663, -0.01268587, -0.02441599,\n",
       "        0.01480785,  0.01911741, -0.03727103,  0.00689474, -0.03861984,\n",
       "       -0.02327231, -0.03152249,  0.08053998, -0.03499415,  0.04372839,\n",
       "       -0.06221816,  0.03713626, -0.04549818,  0.03197128,  0.06281146,\n",
       "       -0.10349276,  0.01375221, -0.01305415,  0.04027506,  0.09137386,\n",
       "        0.01588325, -0.04944049, -0.05107633, -0.01221358, -0.04800349,\n",
       "       -0.00204926,  0.05348659,  0.02657625, -0.00754349,  0.00986237,\n",
       "       -0.04834004, -0.00076751,  0.01585131, -0.09567932, -0.05802544,\n",
       "        0.02113525,  0.05569648,  0.01234163, -0.00252677, -0.02732406],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dense_features(tokenized_text,word_vectors):\n",
    "    dense_list=[]\n",
    "    words=[]\n",
    "    for _ in tokenized_text: \n",
    "        words =[word for word in _ if word in word_vectors.key_to_index]\n",
    "        \n",
    "        if len(words) >0:\n",
    "            dense_list.append(np.mean(word_vectors[words],axis=0))\n",
    "            \n",
    "        else: \n",
    "            dense_list.append(np.zeros(word_vectors.vector_size))\n",
    "            \n",
    "    return np.array(dense_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_wv = generate_dense_features(tokenized_text_train,word_vectors)\n",
    "X_test_wv = generate_dense_features(tokenized_text_test,word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(333414, 100)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_wv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_wv = LogisticRegression(random_state=RANDOM_SEED,max_iter=1000).fit(X_train_wv,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5819276819348802"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,lr_wv.predict(X_test_wv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_fun(doc):\n",
    "    return doc\n",
    "vectorizer = TfidfVectorizer(analyzer='word',tokenizer=dummy_fun, preprocessor=dummy_fun, token_pattern=r'(?u)\\b\\w\\w+__\\([\\w\\s]*\\)')\n",
    "X_train_transform = vectorizer.fit_transform(tokenized_text_train)\n",
    "X_test_transform  = vectorizer.transform(tokenized_text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103167"
      ]
     },
     "execution_count": 671,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a_nx',\n",
       " 'aabout',\n",
       " 'aabye',\n",
       " 'aach',\n",
       " 'aafc',\n",
       " 'aage',\n",
       " 'aaiil',\n",
       " 'aaliyahs',\n",
       " 'aall',\n",
       " 'aalto',\n",
       " 'aames',\n",
       " 'aamir',\n",
       " 'aang',\n",
       " 'aangã',\n",
       " 'aapep',\n",
       " 'aarberg',\n",
       " 'aarburg',\n",
       " 'aarc',\n",
       " 'aarde',\n",
       " 'aardman',\n",
       " 'aardsma',\n",
       " 'aardvark',\n",
       " 'aardvarks',\n",
       " 'aare',\n",
       " 'aargauer',\n",
       " 'aarhus',\n",
       " 'aaroni',\n",
       " 'aarons',\n",
       " 'aarre',\n",
       " 'aarseth',\n",
       " 'aartselaar',\n",
       " 'aarwangen',\n",
       " 'aasen',\n",
       " 'aashurah',\n",
       " 'aast',\n",
       " 'aastana',\n",
       " 'aave',\n",
       " 'ababa',\n",
       " 'ababba',\n",
       " 'ababda',\n",
       " 'abac',\n",
       " 'abacada',\n",
       " 'abaci',\n",
       " 'aback',\n",
       " 'abacus',\n",
       " 'abacuses',\n",
       " 'abad',\n",
       " 'abagnale',\n",
       " 'abahutu',\n",
       " 'abaj',\n",
       " 'abajo',\n",
       " 'abakanskoye',\n",
       " 'abal',\n",
       " 'abalo',\n",
       " 'abalone',\n",
       " 'abando',\n",
       " 'abandon',\n",
       " 'abandonded',\n",
       " 'abandonment',\n",
       " 'abarat',\n",
       " 'abassi',\n",
       " 'abate',\n",
       " 'abattoirs',\n",
       " 'abatutsi',\n",
       " 'abauzit',\n",
       " 'abavo',\n",
       " 'abazhou',\n",
       " 'abaãºj',\n",
       " 'abba',\n",
       " 'abbado',\n",
       " 'abbadon',\n",
       " 'abbados',\n",
       " 'abbandando',\n",
       " 'abbas',\n",
       " 'abbasi',\n",
       " 'abbasid',\n",
       " 'abbasids',\n",
       " 'abbasies',\n",
       " 'abbass',\n",
       " 'abbassid',\n",
       " 'abbay',\n",
       " 'abbaye',\n",
       " 'abbe',\n",
       " 'abbeydale',\n",
       " 'abbeys',\n",
       " 'abbiamo',\n",
       " 'abbiati',\n",
       " 'abbiss',\n",
       " 'abbondancieri',\n",
       " 'abbondanzieri',\n",
       " 'abbondio',\n",
       " 'abbot',\n",
       " 'abbotsinch',\n",
       " 'abbottabad',\n",
       " 'abbotts',\n",
       " 'abbr',\n",
       " 'abbrev',\n",
       " 'abbreviate',\n",
       " 'abbreviation',\n",
       " 'abbreviations',\n",
       " 'abbruzzese',\n",
       " 'abbs',\n",
       " 'abbud',\n",
       " 'abbã',\n",
       " 'abbãƒ',\n",
       " 'abcd',\n",
       " 'abcs',\n",
       " 'abdacom',\n",
       " 'abdal',\n",
       " 'abdallah',\n",
       " 'abdel',\n",
       " 'abdelazar',\n",
       " 'abdelhafid',\n",
       " 'abdeljalil',\n",
       " 'abdelwahab',\n",
       " 'abdera',\n",
       " 'abderathe',\n",
       " 'abdest',\n",
       " 'abdi',\n",
       " 'abdicate',\n",
       " 'abdicatio',\n",
       " 'abdication',\n",
       " 'abdirashid',\n",
       " 'abdolah',\n",
       " 'abdollah',\n",
       " 'abdomen',\n",
       " 'abdomens',\n",
       " 'abdominal',\n",
       " 'abdominis',\n",
       " 'abdou',\n",
       " 'abdoulaye',\n",
       " 'abdu',\n",
       " 'abduct',\n",
       " 'abduction',\n",
       " 'abdulahi',\n",
       " 'abdulaziz',\n",
       " 'abdullaziz',\n",
       " 'abdun',\n",
       " 'abdurrahman',\n",
       " 'abdus',\n",
       " 'abeba',\n",
       " 'abela',\n",
       " 'abelard',\n",
       " 'abele',\n",
       " 'abelian',\n",
       " 'abelisaurid',\n",
       " 'abella',\n",
       " 'abells',\n",
       " 'abelmoschus',\n",
       " 'abelshauser',\n",
       " 'abelson',\n",
       " 'abendroth',\n",
       " 'abenobashi',\n",
       " 'abenon',\n",
       " 'abenteuer',\n",
       " 'aber',\n",
       " 'abercrombie',\n",
       " 'abercromby',\n",
       " 'aberdeenshire',\n",
       " 'aberdeenshires',\n",
       " 'aberdour',\n",
       " 'aberdovey',\n",
       " 'aberdyfi',\n",
       " 'aberfan',\n",
       " 'aberford',\n",
       " 'aberfoyle',\n",
       " 'abergavenny',\n",
       " 'abergement',\n",
       " 'abergynolwyn',\n",
       " 'aberlin',\n",
       " 'aberrant',\n",
       " 'aberration',\n",
       " 'aberrations',\n",
       " 'aberson',\n",
       " 'abert',\n",
       " 'abertay',\n",
       " 'aberystwyththe',\n",
       " 'abet',\n",
       " 'abeyie',\n",
       " 'abgar',\n",
       " 'abgebrã',\n",
       " 'abgrenzung',\n",
       " 'abhainn',\n",
       " 'abhanga',\n",
       " 'abhangas',\n",
       " 'abhinav',\n",
       " 'abhiras',\n",
       " 'abhor',\n",
       " 'abhorrã',\n",
       " 'abid',\n",
       " 'abidal',\n",
       " 'abide',\n",
       " 'abidine',\n",
       " 'abidos',\n",
       " 'abierta',\n",
       " 'abilities',\n",
       " 'ability',\n",
       " 'abimael',\n",
       " 'abin',\n",
       " 'abio',\n",
       " 'abiogenesis',\n",
       " 'abiotic',\n",
       " 'abiotically',\n",
       " 'abire',\n",
       " 'abisalovich',\n",
       " 'abispa',\n",
       " 'abitur',\n",
       " 'abiword',\n",
       " 'abjadi',\n",
       " 'abjads',\n",
       " 'abjuration',\n",
       " 'abkai',\n",
       " 'abkco',\n",
       " 'abkhaz',\n",
       " 'ablanedo',\n",
       " 'ablation',\n",
       " 'ablative',\n",
       " 'ablaze',\n",
       " 'abled',\n",
       " 'ablest',\n",
       " 'ablon',\n",
       " 'abloy',\n",
       " 'ablutions',\n",
       " 'abma',\n",
       " 'abney',\n",
       " 'abnicum',\n",
       " 'abnormal',\n",
       " 'abnormalities',\n",
       " 'abnormality',\n",
       " 'abnormally',\n",
       " 'abobrãƒ',\n",
       " 'abol',\n",
       " 'abolish',\n",
       " 'abolishment',\n",
       " 'abolition',\n",
       " 'abolitionism',\n",
       " 'abolitionist',\n",
       " 'abolitionists',\n",
       " 'abominations',\n",
       " 'abong',\n",
       " 'aboolian',\n",
       " 'aboot',\n",
       " 'aboriginal',\n",
       " 'aboriginals',\n",
       " 'aborigine',\n",
       " 'aborigines',\n",
       " 'abort',\n",
       " 'abortifacient',\n",
       " 'abortion',\n",
       " 'abortions',\n",
       " 'abortive',\n",
       " 'abou',\n",
       " 'abound',\n",
       " 'aboutus',\n",
       " 'aboveground',\n",
       " 'abra',\n",
       " 'abracadabra',\n",
       " 'abrahamic',\n",
       " 'abrahams',\n",
       " 'abramczik',\n",
       " 'abramovich',\n",
       " 'abrams',\n",
       " 'abrantes',\n",
       " 'abrasion',\n",
       " 'abrasions',\n",
       " 'abraxas',\n",
       " 'abraãƒ',\n",
       " 'abreaction',\n",
       " 'abreu',\n",
       " 'abrictosaurus',\n",
       " 'abridge',\n",
       " 'abridgment',\n",
       " 'abroad',\n",
       " 'abrogant',\n",
       " 'abrogate',\n",
       " 'abronia',\n",
       " 'abrowse',\n",
       " 'abrsm',\n",
       " 'abrupt',\n",
       " 'abruptly',\n",
       " 'abruzzi',\n",
       " 'abrã',\n",
       " 'abscess',\n",
       " 'abscesses',\n",
       " 'abscissa',\n",
       " 'abscond',\n",
       " 'absecon',\n",
       " 'absence',\n",
       " 'absences',\n",
       " 'absent',\n",
       " 'absentee',\n",
       " 'absentia',\n",
       " 'absentpelagic',\n",
       " 'absinth',\n",
       " 'absinthe',\n",
       " 'absinthes',\n",
       " 'absinthium',\n",
       " 'absolut',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absolutepunk',\n",
       " 'absolution',\n",
       " 'absolutist',\n",
       " 'absolutive',\n",
       " 'absolve',\n",
       " 'absorb',\n",
       " 'absorbance',\n",
       " 'absorbances',\n",
       " 'absorbent',\n",
       " 'absorber',\n",
       " 'absorbers',\n",
       " 'absorption',\n",
       " 'absorptive',\n",
       " 'abstain',\n",
       " 'abstention',\n",
       " 'abstentionism',\n",
       " 'abstinence',\n",
       " 'abstract',\n",
       " 'abstraction',\n",
       " 'abstractionists',\n",
       " 'abstractions',\n",
       " 'absurd',\n",
       " 'absurde',\n",
       " 'absurdism',\n",
       " 'absurdist',\n",
       " 'absurdity',\n",
       " 'abtwil',\n",
       " 'abub',\n",
       " 'abubakari',\n",
       " 'abugida',\n",
       " 'abugidas',\n",
       " 'abukuma',\n",
       " 'abul',\n",
       " 'abuladze',\n",
       " 'abulkhair',\n",
       " 'abulm',\n",
       " 'abuls',\n",
       " 'abulã',\n",
       " 'abundance',\n",
       " 'abundant',\n",
       " 'abundantly',\n",
       " 'aburish',\n",
       " 'abuse',\n",
       " 'abusive',\n",
       " 'abusively',\n",
       " 'abut',\n",
       " 'abutere',\n",
       " 'abutments',\n",
       " 'aby',\n",
       " 'abydos',\n",
       " 'abyssal',\n",
       " 'abzekh',\n",
       " 'abãƒ',\n",
       " 'acacia',\n",
       " 'acacias',\n",
       " 'acad',\n",
       " 'acadamias',\n",
       " 'academe',\n",
       " 'academia',\n",
       " 'academic',\n",
       " 'academical',\n",
       " 'academically',\n",
       " 'academician',\n",
       " 'academics',\n",
       " 'academie',\n",
       " 'academies',\n",
       " 'academkniga',\n",
       " 'academy',\n",
       " 'acadia',\n",
       " 'acadians',\n",
       " 'acadã',\n",
       " 'acadãƒ',\n",
       " 'acamprosate',\n",
       " 'acanthaceae',\n",
       " 'acanthaclisinae',\n",
       " 'acanthocephala',\n",
       " 'acanthodii',\n",
       " 'acanthomintha',\n",
       " 'acanthomyops',\n",
       " 'acanthophis',\n",
       " 'acanthophylla',\n",
       " 'acanthostega',\n",
       " 'acapulco',\n",
       " 'acari',\n",
       " 'acarology',\n",
       " 'acaso',\n",
       " 'acasta',\n",
       " 'acca',\n",
       " 'accademia',\n",
       " 'accadian',\n",
       " 'accede',\n",
       " 'accelerate',\n",
       " 'accelerateur',\n",
       " 'acceleration',\n",
       " 'accelerations',\n",
       " 'accelerator',\n",
       " 'accelerators',\n",
       " 'acceleratorsã',\n",
       " 'accelerometer',\n",
       " 'accelerometers',\n",
       " 'accends',\n",
       " 'accent',\n",
       " 'accentschurmann',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'acceptably',\n",
       " 'acceptance',\n",
       " 'acceptor',\n",
       " 'access',\n",
       " 'accessibility',\n",
       " 'accessible',\n",
       " 'accession',\n",
       " 'accessories',\n",
       " 'accessory',\n",
       " 'acchieved',\n",
       " 'acchouhouri',\n",
       " 'acciaiuoli',\n",
       " 'acciarito',\n",
       " 'accident',\n",
       " 'accidental',\n",
       " 'accidentally',\n",
       " 'accidentals',\n",
       " 'accidents',\n",
       " 'accidie',\n",
       " 'accies',\n",
       " 'acciona',\n",
       " 'accipiter',\n",
       " 'accipitridae',\n",
       " 'acciã³n',\n",
       " 'acciãƒ',\n",
       " 'acclaim',\n",
       " 'acclamation',\n",
       " 'acclamations',\n",
       " 'acclimatation',\n",
       " 'acclimate',\n",
       " 'acclimatisation',\n",
       " 'accolade',\n",
       " 'accolades',\n",
       " 'accomack',\n",
       " 'accommodate',\n",
       " 'accommodation',\n",
       " 'accommodations',\n",
       " 'accommodative',\n",
       " 'accompaniment',\n",
       " 'accompanist',\n",
       " 'accompany',\n",
       " 'accomping',\n",
       " 'accomplice',\n",
       " 'accomplices',\n",
       " 'accomplish',\n",
       " 'accomplishers',\n",
       " 'accomplishment',\n",
       " 'accomplishments',\n",
       " 'accomptant',\n",
       " 'accons',\n",
       " 'accord',\n",
       " 'accordance',\n",
       " 'accordingly',\n",
       " 'accordion',\n",
       " 'accordionist',\n",
       " 'accordo',\n",
       " 'accost',\n",
       " 'accouchement',\n",
       " 'account',\n",
       " 'accountability',\n",
       " 'accountable',\n",
       " 'accountancy',\n",
       " 'accountant',\n",
       " 'accountants',\n",
       " 'accountn',\n",
       " 'accountsare',\n",
       " 'accous',\n",
       " 'accouterments',\n",
       " 'accoutrement',\n",
       " 'accoyer',\n",
       " 'accredit',\n",
       " 'accreditation',\n",
       " 'accreditor',\n",
       " 'accreta',\n",
       " 'accrete',\n",
       " 'accretion',\n",
       " 'accross',\n",
       " 'accrue',\n",
       " 'acculturate',\n",
       " 'accumbens',\n",
       " 'accumulate',\n",
       " 'accumulation',\n",
       " 'accumulations',\n",
       " 'accuracy',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'accusamus',\n",
       " 'accusantium',\n",
       " 'accusation',\n",
       " 'accusations',\n",
       " 'accuse',\n",
       " 'accustom',\n",
       " 'ace',\n",
       " 'acedia',\n",
       " 'aceldama',\n",
       " 'aceman',\n",
       " 'acephala',\n",
       " 'acequia',\n",
       " 'acer',\n",
       " 'aceraceae',\n",
       " 'aceramic',\n",
       " 'acerbic',\n",
       " 'acerbo',\n",
       " 'acetaldehyde',\n",
       " 'acetaminophen',\n",
       " 'acetate',\n",
       " 'acetic',\n",
       " 'acetobacter',\n",
       " 'acetone',\n",
       " 'acetyl',\n",
       " 'acetylate',\n",
       " 'acetylation',\n",
       " 'acetylcholine',\n",
       " 'acetylene',\n",
       " 'acetylide',\n",
       " 'acetylsalicylic',\n",
       " 'acevedo',\n",
       " 'achab',\n",
       " 'achaea',\n",
       " 'achaemenid',\n",
       " 'achaius',\n",
       " 'achard',\n",
       " 'acharya',\n",
       " 'achawãƒ',\n",
       " 'ache',\n",
       " 'achebe',\n",
       " 'achelate',\n",
       " 'acheloos',\n",
       " 'achelous',\n",
       " 'achenbach',\n",
       " 'achenes',\n",
       " 'acheron',\n",
       " 'acherontia',\n",
       " 'achery',\n",
       " 'acheulean',\n",
       " 'achhim',\n",
       " 'achi',\n",
       " 'achicourt',\n",
       " 'achiet',\n",
       " 'achievable',\n",
       " 'achieve',\n",
       " 'achievement',\n",
       " 'achievements',\n",
       " 'achila',\n",
       " 'achiles',\n",
       " 'achille',\n",
       " 'achillea',\n",
       " 'achilles',\n",
       " 'achillobator',\n",
       " 'achiote',\n",
       " 'achiral',\n",
       " 'achlorhydria',\n",
       " 'achmad',\n",
       " 'achmed',\n",
       " 'achna',\n",
       " 'achoholic',\n",
       " 'acholi',\n",
       " 'achondrite',\n",
       " 'achondroplasia',\n",
       " 'achondroplastic',\n",
       " 'achonry',\n",
       " 'achromasia',\n",
       " 'achromatopsia',\n",
       " 'achromatosis',\n",
       " 'achromia',\n",
       " 'achterhoek',\n",
       " 'achtice',\n",
       " 'achtung',\n",
       " 'achy',\n",
       " 'achzarit',\n",
       " 'achã',\n",
       " 'achãƒ',\n",
       " 'acib',\n",
       " 'acid',\n",
       " 'acidic',\n",
       " 'acidification',\n",
       " 'acidify',\n",
       " 'acidity',\n",
       " 'acidosis',\n",
       " 'acids',\n",
       " 'acinar',\n",
       " 'acis',\n",
       " 'ackerman',\n",
       " 'ackery',\n",
       " 'ackley',\n",
       " 'acklins',\n",
       " 'acknowledge',\n",
       " 'acknowledgement',\n",
       " 'acknowledgment',\n",
       " 'acknowledgments',\n",
       " 'ackworth',\n",
       " 'acland',\n",
       " 'aclare',\n",
       " 'acme',\n",
       " 'acmi',\n",
       " 'acne',\n",
       " 'acnielsen',\n",
       " 'acolyte',\n",
       " 'acolytes',\n",
       " 'acomyinae',\n",
       " 'acomys',\n",
       " 'aconcagua',\n",
       " 'aconite',\n",
       " 'aconitum',\n",
       " 'acorah',\n",
       " 'acorn',\n",
       " 'acorns',\n",
       " 'acosta',\n",
       " 'acou',\n",
       " 'acoustic',\n",
       " 'acoustical',\n",
       " 'acoustically',\n",
       " 'acoustician',\n",
       " 'acousticly',\n",
       " 'acoustics',\n",
       " 'acpb',\n",
       " 'acquaint',\n",
       " 'acquaintance',\n",
       " 'acquaintances',\n",
       " 'acquarossa',\n",
       " 'acqueville',\n",
       " 'acquiesce',\n",
       " 'acquieses',\n",
       " 'acquin',\n",
       " 'acquire',\n",
       " 'acquisition',\n",
       " 'acquisitions',\n",
       " 'acquit',\n",
       " 'acquittal',\n",
       " 'acrea',\n",
       " 'acrelãƒ',\n",
       " 'acres',\n",
       " 'acrisius',\n",
       " 'acritarch',\n",
       " 'acritarchs',\n",
       " 'acrobat',\n",
       " 'acrobates',\n",
       " 'acrobatic',\n",
       " 'acrobatics',\n",
       " 'acrobaticã',\n",
       " 'acrobats',\n",
       " 'acron',\n",
       " 'acronis',\n",
       " 'acronym',\n",
       " 'acronymic',\n",
       " 'acronymous',\n",
       " 'acronyms',\n",
       " 'acropolis',\n",
       " 'across',\n",
       " 'acrossmanhattan',\n",
       " 'acrylic',\n",
       " 'acrymia',\n",
       " 'acst',\n",
       " 'act',\n",
       " 'acta',\n",
       " 'acte',\n",
       " 'actias',\n",
       " 'actin',\n",
       " 'actinide',\n",
       " 'actinides',\n",
       " 'actinidia',\n",
       " 'actinium',\n",
       " 'actinobacteria',\n",
       " 'actinoid',\n",
       " 'actinolite',\n",
       " 'actinomorphic',\n",
       " 'actinomycetes',\n",
       " 'actinopterygii',\n",
       " 'actinopterygius',\n",
       " 'actinosporea',\n",
       " 'actinotrocha',\n",
       " 'action',\n",
       " 'actionscript',\n",
       " 'actium',\n",
       " 'actius',\n",
       " 'activate',\n",
       " 'activation',\n",
       " 'activator',\n",
       " 'active',\n",
       " 'activebass',\n",
       " 'actively',\n",
       " 'actives',\n",
       " 'activestats',\n",
       " 'activeworlds',\n",
       " 'activex',\n",
       " 'activision',\n",
       " 'activism',\n",
       " 'activist',\n",
       " 'activists',\n",
       " 'activities',\n",
       " 'activitist',\n",
       " 'activitiy',\n",
       " 'activity',\n",
       " 'activitã',\n",
       " 'actor',\n",
       " 'actors',\n",
       " 'actress',\n",
       " 'actresses',\n",
       " 'actual',\n",
       " 'actuality',\n",
       " 'actualitã',\n",
       " 'actually',\n",
       " 'actuaries',\n",
       " 'actuate',\n",
       " 'actuations',\n",
       " 'actus',\n",
       " 'acuatic',\n",
       " 'acuca',\n",
       " 'acuity',\n",
       " 'aculeata',\n",
       " 'aculeatus',\n",
       " 'acupressure',\n",
       " 'acupuncture',\n",
       " 'acura',\n",
       " 'acute',\n",
       " 'acutely',\n",
       " 'acuteness',\n",
       " 'acutus',\n",
       " 'acyclic',\n",
       " 'acyl',\n",
       " 'adachi',\n",
       " 'adad',\n",
       " 'adage',\n",
       " 'adages',\n",
       " 'adagh',\n",
       " 'adagio',\n",
       " 'adair',\n",
       " 'adairville',\n",
       " 'adak',\n",
       " 'adal',\n",
       " 'adalbert',\n",
       " 'adama',\n",
       " 'adamantine',\n",
       " 'adamantium',\n",
       " 'adamey',\n",
       " 'adaminaby',\n",
       " 'adamite',\n",
       " 'adamkus',\n",
       " 'adamlarina',\n",
       " 'adamle',\n",
       " 'adamski',\n",
       " 'adamson',\n",
       " 'adamsville',\n",
       " 'adapiformes',\n",
       " 'adapt',\n",
       " 'adaptability',\n",
       " 'adaptable',\n",
       " 'adaptation',\n",
       " 'adaptations',\n",
       " 'adapter',\n",
       " 'adapters',\n",
       " 'adaption',\n",
       " 'adaptions',\n",
       " 'adaptive',\n",
       " 'adaptively',\n",
       " 'adaptor',\n",
       " 'adas',\n",
       " 'adasaurus',\n",
       " 'adashim',\n",
       " 'adastra',\n",
       " 'adav',\n",
       " 'add',\n",
       " 'addai',\n",
       " 'addakhil',\n",
       " 'addams',\n",
       " 'addax',\n",
       " 'addenbrooke',\n",
       " 'addendum',\n",
       " 'adder',\n",
       " 'adderley',\n",
       " 'adders',\n",
       " 'addicks',\n",
       " 'addict',\n",
       " 'addiction',\n",
       " 'addictions',\n",
       " 'addictive',\n",
       " 'addington',\n",
       " 'addis',\n",
       " 'addiscombe',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'additionally',\n",
       " 'additionals',\n",
       " 'additions',\n",
       " 'additive',\n",
       " 'additively',\n",
       " 'additives',\n",
       " 'addon',\n",
       " 'address',\n",
       " 'addressability',\n",
       " 'addressable',\n",
       " 'adegboyega',\n",
       " 'adegem',\n",
       " 'adelante',\n",
       " 'adelboden',\n",
       " 'adelekan',\n",
       " 'adelheid',\n",
       " 'adelir',\n",
       " 'adelomyrmex',\n",
       " 'adelong',\n",
       " 'adelphotheos',\n",
       " 'adelsheim',\n",
       " 'ademar',\n",
       " 'ademir',\n",
       " 'ademola',\n",
       " 'adenauer',\n",
       " 'adenine',\n",
       " 'adenoidectomy',\n",
       " 'adenoids',\n",
       " 'adenoma',\n",
       " 'adenosine',\n",
       " 'adephaga',\n",
       " 'adept',\n",
       " 'adequality',\n",
       " 'adequate',\n",
       " 'adequately',\n",
       " 'aderbal',\n",
       " 'ades',\n",
       " 'adesa',\n",
       " 'adetokunbo',\n",
       " 'adeus',\n",
       " 'adha',\n",
       " 'adhaerens',\n",
       " 'adhan',\n",
       " 'adhana',\n",
       " 'adhd',\n",
       " 'adhemar',\n",
       " 'adhere',\n",
       " 'adherence',\n",
       " 'adherent',\n",
       " 'adherents',\n",
       " 'adhesion',\n",
       " 'adhesions',\n",
       " 'adhesive',\n",
       " 'adhesives',\n",
       " 'adhlaka',\n",
       " 'adhur',\n",
       " 'adiabatic',\n",
       " 'adiabene',\n",
       " 'adibuddha',\n",
       " 'adic',\n",
       " 'adichie',\n",
       " 'adidas',\n",
       " 'adiel',\n",
       " 'adieu',\n",
       " 'adige',\n",
       " 'adikalar',\n",
       " 'adil',\n",
       " 'adinath',\n",
       " 'adine',\n",
       " 'adinfer',\n",
       " 'adingaheim',\n",
       " 'adiperukku',\n",
       " 'adipisci',\n",
       " 'adipocytes',\n",
       " 'adipose',\n",
       " 'adiposity',\n",
       " 'adipperukku',\n",
       " 'adiri',\n",
       " 'adirondack',\n",
       " 'adit',\n",
       " 'adits',\n",
       " 'adiyiah',\n",
       " 'adjacent',\n",
       " 'adjacã',\n",
       " 'adjacãƒ',\n",
       " 'adjascent',\n",
       " 'adjectival',\n",
       " 'adjectivally',\n",
       " 'adjective',\n",
       " 'adjectives',\n",
       " 'adjei',\n",
       " 'adjemian',\n",
       " 'adjoin',\n",
       " 'adjudge',\n",
       " 'adjudicate',\n",
       " 'adjudication',\n",
       " 'adjudicator',\n",
       " 'adjudicators',\n",
       " 'adjunct',\n",
       " 'adjunctive',\n",
       " 'adjuncts',\n",
       " 'adjuration',\n",
       " 'adjust',\n",
       " 'adjustable',\n",
       " 'adjustment',\n",
       " 'adjustments',\n",
       " 'adjutant',\n",
       " 'adjutants',\n",
       " 'adjuvants',\n",
       " 'adkins',\n",
       " 'adlaka',\n",
       " 'adleman',\n",
       " 'adlon',\n",
       " 'admin',\n",
       " 'adminer',\n",
       " 'administer',\n",
       " 'administeriet',\n",
       " 'administraciã³n',\n",
       " 'administraciãƒ',\n",
       " 'administrate',\n",
       " 'administration',\n",
       " 'administrations',\n",
       " 'administrative',\n",
       " 'administrator',\n",
       " 'administrators',\n",
       " 'admins',\n",
       " 'adminship',\n",
       " 'admira',\n",
       " 'admirable',\n",
       " 'admirably',\n",
       " 'admirals',\n",
       " 'admiralspalast',\n",
       " 'admiralty',\n",
       " 'admiration',\n",
       " 'admire',\n",
       " 'admirer',\n",
       " 'admirers',\n",
       " 'admiringly',\n",
       " 'admission',\n",
       " 'admissions',\n",
       " 'admit',\n",
       " 'admittance',\n",
       " 'admittedly',\n",
       " 'admixture',\n",
       " 'admixtures',\n",
       " 'admonition',\n",
       " 'admont',\n",
       " 'adna',\n",
       " 'adnan',\n",
       " 'adnos',\n",
       " 'adobe',\n",
       " 'adobes',\n",
       " 'adolescence',\n",
       " 'adolescent',\n",
       " 'adolescente',\n",
       " 'adolescents',\n",
       " 'adolphe',\n",
       " 'adom',\n",
       " 'adomnãƒ',\n",
       " 'adonai',\n",
       " 'adopt',\n",
       " 'adoptable',\n",
       " 'adoption',\n",
       " 'adoptionism',\n",
       " 'adoptions',\n",
       " 'adoptive',\n",
       " 'adorable',\n",
       " 'adoration',\n",
       " 'adore',\n",
       " 'adorn',\n",
       " 'adornments',\n",
       " 'adorno',\n",
       " 'adoroam',\n",
       " 'adrastea',\n",
       " 'adrenal',\n",
       " 'adrenalin',\n",
       " 'adrenaline',\n",
       " 'adrenalize',\n",
       " 'adriaan',\n",
       " 'adriaen',\n",
       " 'adriaenszoon',\n",
       " 'adriano',\n",
       " 'adrianopole',\n",
       " 'adrianov',\n",
       " 'adrianus',\n",
       " 'adriatic',\n",
       " 'adriatica',\n",
       " 'adriatico',\n",
       " 'adriã',\n",
       " 'adriãƒ',\n",
       " 'adroam',\n",
       " 'adroguãƒ',\n",
       " 'adsit',\n",
       " 'adso',\n",
       " 'adsorption',\n",
       " 'adsur',\n",
       " 'adtranz',\n",
       " 'adua',\n",
       " 'adug',\n",
       " 'aduki',\n",
       " 'adula',\n",
       " 'adulate',\n",
       " 'adulation',\n",
       " 'adult',\n",
       " 'adultera',\n",
       " 'adulterate',\n",
       " 'adulteration',\n",
       " 'adulterators',\n",
       " 'adulterer',\n",
       " 'adulterers',\n",
       " 'adulterous',\n",
       " 'adultery',\n",
       " 'adulthood',\n",
       " 'adultos',\n",
       " ...]"
      ]
     },
     "execution_count": 672,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<333414x106068 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1944434 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_bow = LogisticRegression(random_state=RANDOM_SEED,max_iter=1000).fit(X_train_transform,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6466876214698755"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,lr_bow.predict(X_test_transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_word = set(word_vectors.index_to_key) #around 6k words in the Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model_word.intersection(concreteset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors['live']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "word_list = []\n",
    "for word in model_word: \n",
    "    word_list.append((word,lemmatizer.lemmatize(word.lower())))\n",
    "df = pd.DataFrame(word_list,columns=['Original','word'])\n",
    "df = df.merge(AoA,left_on='word',right_on='Word',how='left')\n",
    "df = df[['Original','word','Perc_known','AoA_Kup_lem']]\n",
    "word_not_matched = set(df[df['Perc_known'].isnull()].word.values)\n",
    "\n",
    "for i in range(len(df)):   \n",
    "    if df['word'][i][0] in set(('0','1','2','3','4','5','6','7','8','9')) or len(df['word'][i])==1:\n",
    "        df['AoA_Kup_lem'][i] = 3\n",
    "mean_value = df['AoA_Kup_lem'].mean()\n",
    "df['AoA_Kup_lem'].fillna(value=mean_value,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.loc[df['Original']==['troops','weapons']]\n",
    "df[df['Original'].isin(['troops','weapon'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_perc_known(tokenized_text,df):\n",
    "    avg_perc_know=None\n",
    "    perc_know_list=[]\n",
    "    for _ in tokenized_text: \n",
    "        words =[word for word in _ if word in word_vectors.key_to_index]\n",
    "        \n",
    "        if len(words) >0:\n",
    "            avg_perc_know = np.mean(df[df['Original'].isin(words)]['AoA_Kup_lem'])\n",
    "            perc_know_list.append(avg_perc_know)\n",
    "        else: \n",
    "            \n",
    "            perc_know_list.append(0)\n",
    "            \n",
    "    return perc_know_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(X_train_wv)\n",
    "#df_train['year'] = generate_perc_known(tokenized_text_train,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(X_test_wv)\n",
    "#df_test['year'] = generate_perc_known(tokenized_text_test,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.163066</td>\n",
       "      <td>0.066503</td>\n",
       "      <td>0.007967</td>\n",
       "      <td>-0.368197</td>\n",
       "      <td>-0.475971</td>\n",
       "      <td>0.174799</td>\n",
       "      <td>-0.226500</td>\n",
       "      <td>0.288741</td>\n",
       "      <td>-0.101118</td>\n",
       "      <td>0.251682</td>\n",
       "      <td>...</td>\n",
       "      <td>0.343301</td>\n",
       "      <td>0.449110</td>\n",
       "      <td>-0.301583</td>\n",
       "      <td>-0.318929</td>\n",
       "      <td>-0.027628</td>\n",
       "      <td>-0.003120</td>\n",
       "      <td>0.640888</td>\n",
       "      <td>0.395134</td>\n",
       "      <td>-0.211103</td>\n",
       "      <td>7.319698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.098105</td>\n",
       "      <td>-0.697004</td>\n",
       "      <td>-0.067849</td>\n",
       "      <td>0.073167</td>\n",
       "      <td>0.001977</td>\n",
       "      <td>-0.519177</td>\n",
       "      <td>-0.064798</td>\n",
       "      <td>-0.384014</td>\n",
       "      <td>0.359658</td>\n",
       "      <td>-0.080730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100243</td>\n",
       "      <td>-0.152842</td>\n",
       "      <td>0.018108</td>\n",
       "      <td>-0.616458</td>\n",
       "      <td>0.208961</td>\n",
       "      <td>0.239500</td>\n",
       "      <td>-0.078117</td>\n",
       "      <td>0.907243</td>\n",
       "      <td>0.644744</td>\n",
       "      <td>8.900953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.608009</td>\n",
       "      <td>-0.270855</td>\n",
       "      <td>-0.351858</td>\n",
       "      <td>-1.324698</td>\n",
       "      <td>0.509448</td>\n",
       "      <td>0.466696</td>\n",
       "      <td>-0.869674</td>\n",
       "      <td>0.316894</td>\n",
       "      <td>-0.832663</td>\n",
       "      <td>0.482958</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.804097</td>\n",
       "      <td>-1.260673</td>\n",
       "      <td>-0.484280</td>\n",
       "      <td>-1.026836</td>\n",
       "      <td>-0.381989</td>\n",
       "      <td>0.006748</td>\n",
       "      <td>0.651532</td>\n",
       "      <td>0.502151</td>\n",
       "      <td>-1.543706</td>\n",
       "      <td>7.385000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.231419</td>\n",
       "      <td>-0.460309</td>\n",
       "      <td>-0.321846</td>\n",
       "      <td>-0.401228</td>\n",
       "      <td>-1.299778</td>\n",
       "      <td>-0.461486</td>\n",
       "      <td>0.002258</td>\n",
       "      <td>-0.175611</td>\n",
       "      <td>0.296010</td>\n",
       "      <td>0.373852</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068769</td>\n",
       "      <td>0.134842</td>\n",
       "      <td>0.026607</td>\n",
       "      <td>0.200088</td>\n",
       "      <td>0.376173</td>\n",
       "      <td>0.175164</td>\n",
       "      <td>-0.239718</td>\n",
       "      <td>0.463941</td>\n",
       "      <td>-0.541556</td>\n",
       "      <td>8.971588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.155188</td>\n",
       "      <td>0.110082</td>\n",
       "      <td>0.749716</td>\n",
       "      <td>-0.211680</td>\n",
       "      <td>-0.294006</td>\n",
       "      <td>-0.928232</td>\n",
       "      <td>0.095029</td>\n",
       "      <td>0.326077</td>\n",
       "      <td>0.020296</td>\n",
       "      <td>0.458989</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.496064</td>\n",
       "      <td>0.562254</td>\n",
       "      <td>-0.161042</td>\n",
       "      <td>-0.556670</td>\n",
       "      <td>-0.152797</td>\n",
       "      <td>0.216482</td>\n",
       "      <td>-0.109737</td>\n",
       "      <td>1.134926</td>\n",
       "      <td>-0.073294</td>\n",
       "      <td>7.939948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83349</th>\n",
       "      <td>-0.212178</td>\n",
       "      <td>-0.577913</td>\n",
       "      <td>0.233901</td>\n",
       "      <td>-0.283749</td>\n",
       "      <td>-0.250686</td>\n",
       "      <td>-0.740940</td>\n",
       "      <td>-0.073741</td>\n",
       "      <td>0.163121</td>\n",
       "      <td>-0.268991</td>\n",
       "      <td>0.569778</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062439</td>\n",
       "      <td>0.181861</td>\n",
       "      <td>-0.294118</td>\n",
       "      <td>0.674152</td>\n",
       "      <td>-0.312687</td>\n",
       "      <td>-0.416863</td>\n",
       "      <td>0.006465</td>\n",
       "      <td>0.296494</td>\n",
       "      <td>0.144787</td>\n",
       "      <td>7.846061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83350</th>\n",
       "      <td>0.083994</td>\n",
       "      <td>-0.119798</td>\n",
       "      <td>0.014636</td>\n",
       "      <td>-0.046240</td>\n",
       "      <td>-0.176528</td>\n",
       "      <td>-0.371178</td>\n",
       "      <td>-0.049741</td>\n",
       "      <td>-0.063575</td>\n",
       "      <td>0.069346</td>\n",
       "      <td>0.097987</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.106163</td>\n",
       "      <td>0.598239</td>\n",
       "      <td>-0.423099</td>\n",
       "      <td>-0.277646</td>\n",
       "      <td>0.249423</td>\n",
       "      <td>0.238795</td>\n",
       "      <td>-0.084238</td>\n",
       "      <td>0.325800</td>\n",
       "      <td>-0.371009</td>\n",
       "      <td>7.653076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83351</th>\n",
       "      <td>-0.027579</td>\n",
       "      <td>-0.583053</td>\n",
       "      <td>-0.212853</td>\n",
       "      <td>0.064448</td>\n",
       "      <td>-0.001676</td>\n",
       "      <td>-0.386104</td>\n",
       "      <td>-0.194504</td>\n",
       "      <td>0.125628</td>\n",
       "      <td>0.087920</td>\n",
       "      <td>0.013556</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087076</td>\n",
       "      <td>0.200042</td>\n",
       "      <td>0.022237</td>\n",
       "      <td>0.865286</td>\n",
       "      <td>0.345294</td>\n",
       "      <td>0.206362</td>\n",
       "      <td>-0.050420</td>\n",
       "      <td>0.287032</td>\n",
       "      <td>-0.024188</td>\n",
       "      <td>6.618984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83352</th>\n",
       "      <td>0.150752</td>\n",
       "      <td>-0.344787</td>\n",
       "      <td>0.016055</td>\n",
       "      <td>-0.438976</td>\n",
       "      <td>0.105028</td>\n",
       "      <td>-0.072180</td>\n",
       "      <td>-0.229091</td>\n",
       "      <td>0.010541</td>\n",
       "      <td>-0.065317</td>\n",
       "      <td>0.162644</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090400</td>\n",
       "      <td>-0.352687</td>\n",
       "      <td>-0.262663</td>\n",
       "      <td>-0.028436</td>\n",
       "      <td>0.180446</td>\n",
       "      <td>-0.053098</td>\n",
       "      <td>0.068634</td>\n",
       "      <td>-0.034959</td>\n",
       "      <td>0.074879</td>\n",
       "      <td>7.009195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83353</th>\n",
       "      <td>0.798341</td>\n",
       "      <td>-0.436330</td>\n",
       "      <td>-0.095135</td>\n",
       "      <td>-0.875586</td>\n",
       "      <td>-0.725843</td>\n",
       "      <td>-0.983312</td>\n",
       "      <td>-0.478156</td>\n",
       "      <td>0.076523</td>\n",
       "      <td>-0.534273</td>\n",
       "      <td>0.518388</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020779</td>\n",
       "      <td>0.168365</td>\n",
       "      <td>-0.001870</td>\n",
       "      <td>-0.459175</td>\n",
       "      <td>-1.014081</td>\n",
       "      <td>-0.339258</td>\n",
       "      <td>0.264108</td>\n",
       "      <td>0.849447</td>\n",
       "      <td>-0.063408</td>\n",
       "      <td>8.322109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83354 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      0.163066  0.066503  0.007967 -0.368197 -0.475971  0.174799 -0.226500   \n",
       "1      0.098105 -0.697004 -0.067849  0.073167  0.001977 -0.519177 -0.064798   \n",
       "2      0.608009 -0.270855 -0.351858 -1.324698  0.509448  0.466696 -0.869674   \n",
       "3     -0.231419 -0.460309 -0.321846 -0.401228 -1.299778 -0.461486  0.002258   \n",
       "4     -0.155188  0.110082  0.749716 -0.211680 -0.294006 -0.928232  0.095029   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "83349 -0.212178 -0.577913  0.233901 -0.283749 -0.250686 -0.740940 -0.073741   \n",
       "83350  0.083994 -0.119798  0.014636 -0.046240 -0.176528 -0.371178 -0.049741   \n",
       "83351 -0.027579 -0.583053 -0.212853  0.064448 -0.001676 -0.386104 -0.194504   \n",
       "83352  0.150752 -0.344787  0.016055 -0.438976  0.105028 -0.072180 -0.229091   \n",
       "83353  0.798341 -0.436330 -0.095135 -0.875586 -0.725843 -0.983312 -0.478156   \n",
       "\n",
       "              7         8         9  ...        91        92        93  \\\n",
       "0      0.288741 -0.101118  0.251682  ...  0.343301  0.449110 -0.301583   \n",
       "1     -0.384014  0.359658 -0.080730  ...  0.100243 -0.152842  0.018108   \n",
       "2      0.316894 -0.832663  0.482958  ... -0.804097 -1.260673 -0.484280   \n",
       "3     -0.175611  0.296010  0.373852  ... -0.068769  0.134842  0.026607   \n",
       "4      0.326077  0.020296  0.458989  ... -0.496064  0.562254 -0.161042   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "83349  0.163121 -0.268991  0.569778  ... -0.062439  0.181861 -0.294118   \n",
       "83350 -0.063575  0.069346  0.097987  ... -0.106163  0.598239 -0.423099   \n",
       "83351  0.125628  0.087920  0.013556  ... -0.087076  0.200042  0.022237   \n",
       "83352  0.010541 -0.065317  0.162644  ... -0.090400 -0.352687 -0.262663   \n",
       "83353  0.076523 -0.534273  0.518388  ... -0.020779  0.168365 -0.001870   \n",
       "\n",
       "             94        95        96        97        98        99      year  \n",
       "0     -0.318929 -0.027628 -0.003120  0.640888  0.395134 -0.211103  7.319698  \n",
       "1     -0.616458  0.208961  0.239500 -0.078117  0.907243  0.644744  8.900953  \n",
       "2     -1.026836 -0.381989  0.006748  0.651532  0.502151 -1.543706  7.385000  \n",
       "3      0.200088  0.376173  0.175164 -0.239718  0.463941 -0.541556  8.971588  \n",
       "4     -0.556670 -0.152797  0.216482 -0.109737  1.134926 -0.073294  7.939948  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "83349  0.674152 -0.312687 -0.416863  0.006465  0.296494  0.144787  7.846061  \n",
       "83350 -0.277646  0.249423  0.238795 -0.084238  0.325800 -0.371009  7.653076  \n",
       "83351  0.865286  0.345294  0.206362 -0.050420  0.287032 -0.024188  6.618984  \n",
       "83352 -0.028436  0.180446 -0.053098  0.068634 -0.034959  0.074879  7.009195  \n",
       "83353 -0.459175 -1.014081 -0.339258  0.264108  0.849447 -0.063408  8.322109  \n",
       "\n",
       "[83354 rows x 101 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=RANDOM_SEED,max_iter=1000).fit(df_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58372723564556"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,lr.predict(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmatrix_lr_wv=metrics.confusion_matrix(y_test, lr_wv.predict(X_test_wv))\n",
    "\n",
    "ax = sns.heatmap(cmatrix_lr_wv, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['False','True'])\n",
    "ax.yaxis.set_ticklabels(['False','True'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_bow = DummyClassifier(strategy='uniform',random_state=RANDOM_SEED).fit(X_train_transform,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5011277203253593"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, dummy_bow.predict(X_test_transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_wv = DummyClassifier(strategy='uniform',random_state=RANDOM_SEED).fit(X_train_wv,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5011277203253593"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,dummy_wv.predict(X_test_wv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_bow = LogisticRegression(random_state=RANDOM_SEED,max_iter=1000).fit(X_train_transform,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6465916452719725"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,lr_bow.predict(X_test_transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_wv = LogisticRegression(random_state=RANDOM_SEED,max_iter=1000).fit(X_train_wv,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5640041269765098"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,lr_wv.predict(X_test_wv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_bow = RandomForestClassifier(n_estimators=500,max_depth=5,random_state=RANDOM_SEED).fit(X_train_transform,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6416968591789236"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,rf_bow.predict(X_test_transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_wv = RandomForestClassifier(n_estimators=100,max_depth=5,random_state=RANDOM_SEED).fit(X_train_wv,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test,rf_wv.predict(X_test_wv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Unsupervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2,random_state=RANDOM_SEED).fit(X_train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df = pd.DataFrame({'cluster':kmeans.labels_,'y_label':y_train,'text':X_train})\n",
    "cluster_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA Topic Modeling - Consider NMF to create a document-topic matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from nltk.stem.porter import *\n",
    "def lemmatize_stemming(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    #Un-hash next line to use stemming\n",
    "    #return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "    #Un-hash next line to NOT use stemming\n",
    "    return WordNetLemmatizer().lemmatize(text, pos='v')\n",
    "# Tokenize and lemmatize\n",
    "def preprocess(text):\n",
    "    result=[]\n",
    "    for token in gensim.utils.simple_preprocess(text) :\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            #Un-hash next line to use stemming\n",
    "            result.append(lemmatize_stemming(token))\n",
    "            #Un-hash next line to NOT use stemming\n",
    "            #result.append(token)\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"There is manuscript evidence that Austen continued to work on these pieces as late as the period 1809 Ã¢ '' 11 , and that her niece and nephew , Anna and James Edward Austen , made further additions as late as 1814 .\""
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['original_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['manuscript',\n",
       " 'evidence',\n",
       " 'austen',\n",
       " 'continue',\n",
       " 'work',\n",
       " 'piece',\n",
       " 'late',\n",
       " 'period',\n",
       " 'niece',\n",
       " 'nephew',\n",
       " 'anna',\n",
       " 'jam',\n",
       " 'edward',\n",
       " 'austen',\n",
       " 'additions',\n",
       " 'late']"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(df['original_text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell will run about 2 minutes\n",
    "processed_docs = [preprocess(text) for text in df['original_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.corpora.dictionary.Dictionary at 0x1567b848520>"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "#bow_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "416768"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bow_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell will run 10 minutes\n",
    "#lda_model =  gensim.models.LdaMulticore(bow_corpus, \n",
    "#                                   num_topics = 8, \n",
    "#                                   id2word = dictionary,                                    \n",
    "#                                   passes = 10,\n",
    "#                                   workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for idx, topic in lda_model.print_topics(-1):\n",
    "#    print(\"Topic: {} \\nWords: {}\".format(idx, topic ))\n",
    "#    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
