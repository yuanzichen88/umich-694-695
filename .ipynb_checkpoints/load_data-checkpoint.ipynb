{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import altair as alt\n",
    "import seaborn as sns\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.18.5'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make sure numpy version is < 1.20\n",
    "np.version.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.18.5 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (1.18.5)\n"
     ]
    }
   ],
   "source": [
    "#Install known version of numpy that works\n",
    "!python -m pip install numpy==1.18.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\mryua\\anaconda3\\lib\\site-packages (4.1.2)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from gensim) (1.5.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from gensim) (6.0.0)\n",
      "Requirement already satisfied: Cython==0.29.23 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from gensim) (0.29.23)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from gensim) (1.18.5)\n"
     ]
    }
   ],
   "source": [
    "#Install gensim\n",
    "!python -m pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mryua\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mryua\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from tqdm.notebook import tqdm\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED=694"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There is manuscript evidence that Austen conti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In a remarkable comparative analysis , Mandaea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Before Persephone was released to Hermes , who...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cogeneration plants are commonly found in dist...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Geneva -LRB- , ; , ; , ; ; -RRB- is the second...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416763</th>\n",
       "      <td>A Duke Nukem 3D version has been sold for Xbox...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416764</th>\n",
       "      <td>However , it is becoming replaced as a method ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416765</th>\n",
       "      <td>There are hand gestures in both Hindu and Budd...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416766</th>\n",
       "      <td>If it is necessary to use colors , try to choo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416767</th>\n",
       "      <td>Calgary Stampeders ,</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>416768 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            original_text  label\n",
       "0       There is manuscript evidence that Austen conti...      1\n",
       "1       In a remarkable comparative analysis , Mandaea...      1\n",
       "2       Before Persephone was released to Hermes , who...      1\n",
       "3       Cogeneration plants are commonly found in dist...      1\n",
       "4       Geneva -LRB- , ; , ; , ; ; -RRB- is the second...      1\n",
       "...                                                   ...    ...\n",
       "416763  A Duke Nukem 3D version has been sold for Xbox...      0\n",
       "416764  However , it is becoming replaced as a method ...      0\n",
       "416765  There are hand gestures in both Hindu and Budd...      0\n",
       "416766  If it is necessary to use colors , try to choo...      0\n",
       "416767                               Calgary Stampeders ,      0\n",
       "\n",
       "[416768 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = 'Data/WikiLarge_Train.csv'\n",
    "df = pd.read_csv(train_path, skiprows=0, skipfooter=0, engine='python')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['label']==1])/len(df) # the dataset label is well balanced "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coastal lagoons , marshes , and deltas'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[410006]['original_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[410000]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.18195254914005"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['label']==0]['original_text'].apply(lambda x: len(x)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.581304744802495"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['label']==0]['original_text'].apply(lambda x: len(x)).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "591"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['label']==0]['original_text'].apply(lambda x: len(x)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['label']==0]['original_text'].apply(lambda x: len(x)).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137.66185983568795"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['label']==1]['original_text'].apply(lambda x: len(x)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.87716383067678"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['label']==1]['original_text'].apply(lambda x: len(x)).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "577"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['label']==1]['original_text'].apply(lambda x: len(x)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['label']==1]['original_text'].apply(lambda x: len(x)).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_length'] = df['original_text'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'He has subsequently written a further nine plays .'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['label']==1) & (df['text_length']==50)].loc[27]['original_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>208709</th>\n",
       "      <td>Pages</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208988</th>\n",
       "      <td>Plain</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209004</th>\n",
       "      <td>Drama</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209374</th>\n",
       "      <td>Child</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209606</th>\n",
       "      <td>equal</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415970</th>\n",
       "      <td>Sabre</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416078</th>\n",
       "      <td>Poems</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416108</th>\n",
       "      <td>Rumba</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416144</th>\n",
       "      <td>Notes</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416553</th>\n",
       "      <td>Titus</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>977 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       original_text  label  text_length\n",
       "208709         Pages      0            5\n",
       "208988         Plain      0            5\n",
       "209004         Drama      0            5\n",
       "209374         Child      0            5\n",
       "209606         equal      0            5\n",
       "...              ...    ...          ...\n",
       "415970         Sabre      0            5\n",
       "416078         Poems      0            5\n",
       "416108         Rumba      0            5\n",
       "416144         Notes      0            5\n",
       "416553         Titus      0            5\n",
       "\n",
       "[977 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['label']==0) & (df['text_length']==5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There is manuscript evidence that Austen conti...</td>\n",
       "      <td>1</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In a remarkable comparative analysis , Mandaea...</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Before Persephone was released to Hermes , who...</td>\n",
       "      <td>1</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cogeneration plants are commonly found in dist...</td>\n",
       "      <td>1</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Geneva -LRB- , ; , ; , ; ; -RRB- is the second...</td>\n",
       "      <td>1</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416763</th>\n",
       "      <td>A Duke Nukem 3D version has been sold for Xbox...</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416764</th>\n",
       "      <td>However , it is becoming replaced as a method ...</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416765</th>\n",
       "      <td>There are hand gestures in both Hindu and Budd...</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416766</th>\n",
       "      <td>If it is necessary to use colors , try to choo...</td>\n",
       "      <td>0</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416767</th>\n",
       "      <td>Calgary Stampeders ,</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>416768 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            original_text  label  text_length\n",
       "0       There is manuscript evidence that Austen conti...      1          216\n",
       "1       In a remarkable comparative analysis , Mandaea...      1          156\n",
       "2       Before Persephone was released to Hermes , who...      1          248\n",
       "3       Cogeneration plants are commonly found in dist...      1          246\n",
       "4       Geneva -LRB- , ; , ; , ; ; -RRB- is the second...      1          202\n",
       "...                                                   ...    ...          ...\n",
       "416763  A Duke Nukem 3D version has been sold for Xbox...      0           79\n",
       "416764  However , it is becoming replaced as a method ...      0          111\n",
       "416765  There are hand gestures in both Hindu and Budd...      0           64\n",
       "416766  If it is necessary to use colors , try to choo...      0          216\n",
       "416767                               Calgary Stampeders ,      0           20\n",
       "\n",
       "[416768 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117.921906192414"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['original_text'].apply(lambda x: len(x)).mean()\n",
    "# This means all texts are considered short text, which allows us to use dense representations, \n",
    "# as dense representations work well with short text.\n",
    "# Gensim.KeyedVectors.load('assets/wikipedia.100.word-vecs.kv')??? How to generate and use this???\n",
    "# Maybe we should train word2vec model on the entire corpus. Just training data? TOP 100 word-vectors(features)\n",
    "# Alternatively we could use bag-of-words model, which is term-document matrix representation, having much more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['original_text']\n",
    "y = df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>original_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-2011</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-2011</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-2000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-1997</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.636</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119087</th>\n",
       "      <td>119087</td>\n",
       "      <td>#NAME?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119088</th>\n",
       "      <td>119088</td>\n",
       "      <td>#NAME?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119089</th>\n",
       "      <td>119089</td>\n",
       "      <td>#NAME?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119090</th>\n",
       "      <td>119090</td>\n",
       "      <td>#NAME?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119091</th>\n",
       "      <td>119091</td>\n",
       "      <td>#NAME?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119092 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id original_text  label\n",
       "0            0         -2011    NaN\n",
       "1            1         -2011    NaN\n",
       "2            2         -2000    NaN\n",
       "3            3         -1997    NaN\n",
       "4            4         1.636    NaN\n",
       "...        ...           ...    ...\n",
       "119087  119087        #NAME?    NaN\n",
       "119088  119088        #NAME?    NaN\n",
       "119089  119089        #NAME?    NaN\n",
       "119090  119090        #NAME?    NaN\n",
       "119091  119091        #NAME?    NaN\n",
       "\n",
       "[119092 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_path = 'Data/WikiLarge_Test.csv'\n",
    "test_df = pd.read_csv(test_path, skiprows=0, skipfooter=0, engine='python')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                           10000\n",
       "original_text    An atheist would say that this argument proves...\n",
       "label                                                          NaN\n",
       "Name: 10000, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.iloc[10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119087</th>\n",
       "      <td>119087</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119088</th>\n",
       "      <td>119088</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119089</th>\n",
       "      <td>119089</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119090</th>\n",
       "      <td>119090</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119091</th>\n",
       "      <td>119091</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119092 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  label\n",
       "0            0      0\n",
       "1            1      0\n",
       "2            2      1\n",
       "3            3      1\n",
       "4            4      0\n",
       "...        ...    ...\n",
       "119087  119087      0\n",
       "119088  119088      1\n",
       "119089  119089      1\n",
       "119090  119090      1\n",
       "119091  119091      1\n",
       "\n",
       "[119092 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samplesubmission_path = 'Data/sampleSubmission.csv'\n",
    "samplesubmission_df = pd.read_csv(samplesubmission_path, skiprows=0, skipfooter=0, engine='python')\n",
    "samplesubmission_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conclude, the dataframes we are working with are:\n",
    "\n",
    "dalechall_df, concreteness_df, aoawords_df, train_df, test_df, samplesubmission_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=10,stop_words='english',ngram_range=(1,2))\n",
    "X_train_transform = vectorizer.fit_transform(X_train)\n",
    "X_test_transform  = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<333414x57773 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4071111 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(stopwords.words('english')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "== dale_chall.txt ==\n",
    "\n",
    "This is the Dale Chall 3000 Word List, which is one definition of words that are considered \"basic\" English.\n",
    "\n",
    "A summary is at https://www.readabilityformulas.com/articles/dale-chall-readability-word-list.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic english words\n",
    "dalechall_path = 'Data/dale_chall.txt'\n",
    "dale_chall = pd.read_csv(dalechall_path,delimiter='\\t',header=None,names=['word'])\n",
    "dale = set(dale_chall['word'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2946"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The 2946 words in dale can be combined with the nltk stopwords.\n",
    "### We could maybe assign an arbitrary score to each dale_chall word. - for reference only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will use a geo dataset to add city and country names to the stopwords library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datapackage in c:\\users\\mryua\\anaconda3\\lib\\site-packages (1.15.2)\n",
      "Requirement already satisfied: click>=6.7 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from datapackage) (7.1.2)\n",
      "Requirement already satisfied: jsonpointer>=1.10 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from datapackage) (2.3)\n",
      "Requirement already satisfied: tabulator>=1.29 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from datapackage) (1.53.5)\n",
      "Requirement already satisfied: unicodecsv>=0.14 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from datapackage) (0.14.1)\n",
      "Requirement already satisfied: requests>=2.8 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from datapackage) (2.24.0)\n",
      "Requirement already satisfied: tableschema>=1.12.1 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from datapackage) (1.20.2)\n",
      "Requirement already satisfied: chardet>=3.0 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from datapackage) (3.0.4)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from datapackage) (1.15.0)\n",
      "Requirement already satisfied: jsonschema>=2.5 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from datapackage) (3.2.0)\n",
      "Requirement already satisfied: jsonlines>=1.1 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from tabulator>=1.29->datapackage) (3.0.0)\n",
      "Requirement already satisfied: openpyxl>=2.6 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from tabulator>=1.29->datapackage) (3.0.4)\n",
      "Requirement already satisfied: ijson>=3.0.3 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from tabulator>=1.29->datapackage) (3.1.4)\n",
      "Requirement already satisfied: sqlalchemy>=0.9.6 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from tabulator>=1.29->datapackage) (1.3.18)\n",
      "Requirement already satisfied: boto3>=1.9 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from tabulator>=1.29->datapackage) (1.23.0)\n",
      "Requirement already satisfied: linear-tsv>=1.0 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from tabulator>=1.29->datapackage) (1.1.0)\n",
      "Requirement already satisfied: xlrd>=1.0 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from tabulator>=1.29->datapackage) (1.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from requests>=2.8->datapackage) (2021.5.30)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from requests>=2.8->datapackage) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from requests>=2.8->datapackage) (2.10)\n",
      "Requirement already satisfied: python-dateutil>=2.4 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from tableschema>=1.12.1->datapackage) (2.8.1)\n",
      "Requirement already satisfied: rfc3986>=1.1.0 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from tableschema>=1.12.1->datapackage) (2.0.0)\n",
      "Requirement already satisfied: isodate>=0.5.4 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from tableschema>=1.12.1->datapackage) (0.6.1)\n",
      "Requirement already satisfied: cached-property>=1.5 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from tableschema>=1.12.1->datapackage) (1.5.2)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from jsonschema>=2.5->datapackage) (19.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from jsonschema>=2.5->datapackage) (49.2.0.post20200714)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from jsonschema>=2.5->datapackage) (0.16.0)\n",
      "Requirement already satisfied: jdcal in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from openpyxl>=2.6->tabulator>=1.29->datapackage) (1.4.1)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from openpyxl>=2.6->tabulator>=1.29->datapackage) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from boto3>=1.9->tabulator>=1.29->datapackage) (0.5.2)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from boto3>=1.9->tabulator>=1.29->datapackage) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.27.0,>=1.26.0 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from boto3>=1.9->tabulator>=1.29->datapackage) (1.26.0)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install datapackage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['validation_report', 'world-cities_csv', 'world-cities_json', 'world-cities_zip', 'world-cities_csv_preview', 'world-cities']\n"
     ]
    }
   ],
   "source": [
    "from datapackage import Package\n",
    "package = Package('https://datahub.io/core/world-cities/datapackage.json')\n",
    "# print list of all resources:\n",
    "print(package.resource_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_cities = []\n",
    "for resource in package.resources:\n",
    "    if resource.descriptor['datahub']['type'] == 'derived/csv':\n",
    "        world_cities = resource.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23018"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(world_cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['les Escaldes', 'Andorra', 'Escaldes-Engordany', 3040051],\n",
       " ['Andorra la Vella', 'Andorra', 'Andorra la Vella', 3041563],\n",
       " ['Umm al Qaywayn', 'United Arab Emirates', 'Umm al Qaywayn', 290594],\n",
       " ['Ras al-Khaimah', 'United Arab Emirates', 'Raʼs al Khaymah', 291074],\n",
       " ['Khawr Fakkān', 'United Arab Emirates', 'Ash Shāriqah', 291696],\n",
       " ['Dubai', 'United Arab Emirates', 'Dubai', 292223],\n",
       " ['Dibba Al-Fujairah', 'United Arab Emirates', 'Al Fujayrah', 292231],\n",
       " ['Dibba Al-Hisn', 'United Arab Emirates', 'Al Fujayrah', 292239],\n",
       " ['Sharjah', 'United Arab Emirates', 'Ash Shāriqah', 292672],\n",
       " ['Ar Ruways', 'United Arab Emirates', 'Abu Dhabi', 292688]]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world_cities[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_cities_df = pd.DataFrame(world_cities, columns=['name', 'country', 'subcountry', 'geonameid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>subcountry</th>\n",
       "      <th>geonameid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>les Escaldes</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>Escaldes-Engordany</td>\n",
       "      <td>3040051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>3041563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Umm al Qaywayn</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>Umm al Qaywayn</td>\n",
       "      <td>290594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ras al-Khaimah</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>Raʼs al Khaymah</td>\n",
       "      <td>291074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Khawr Fakkān</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>Ash Shāriqah</td>\n",
       "      <td>291696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23013</th>\n",
       "      <td>Bulawayo</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Bulawayo</td>\n",
       "      <td>894701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23014</th>\n",
       "      <td>Bindura</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Mashonaland Central</td>\n",
       "      <td>895061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23015</th>\n",
       "      <td>Beitbridge</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Matabeleland South</td>\n",
       "      <td>895269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23016</th>\n",
       "      <td>Epworth</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Harare</td>\n",
       "      <td>1085510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23017</th>\n",
       "      <td>Chitungwiza</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Harare</td>\n",
       "      <td>1106542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23018 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name               country           subcountry  geonameid\n",
       "0          les Escaldes               Andorra   Escaldes-Engordany    3040051\n",
       "1      Andorra la Vella               Andorra     Andorra la Vella    3041563\n",
       "2        Umm al Qaywayn  United Arab Emirates       Umm al Qaywayn     290594\n",
       "3        Ras al-Khaimah  United Arab Emirates      Raʼs al Khaymah     291074\n",
       "4          Khawr Fakkān  United Arab Emirates         Ash Shāriqah     291696\n",
       "...                 ...                   ...                  ...        ...\n",
       "23013          Bulawayo              Zimbabwe             Bulawayo     894701\n",
       "23014           Bindura              Zimbabwe  Mashonaland Central     895061\n",
       "23015        Beitbridge              Zimbabwe   Matabeleland South     895269\n",
       "23016           Epworth              Zimbabwe               Harare    1085510\n",
       "23017       Chitungwiza              Zimbabwe               Harare    1106542\n",
       "\n",
       "[23018 rows x 4 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world_cities_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_cities_df = world_cities_df.applymap(lambda s:s.lower() if type(s) == str else s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>subcountry</th>\n",
       "      <th>geonameid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6633</th>\n",
       "      <td>yerres</td>\n",
       "      <td>france</td>\n",
       "      <td>île-de-france</td>\n",
       "      <td>2967245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6634</th>\n",
       "      <td>wittenheim</td>\n",
       "      <td>france</td>\n",
       "      <td>alsace-champagne-ardenne-lorraine</td>\n",
       "      <td>2967318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6635</th>\n",
       "      <td>wattrelos</td>\n",
       "      <td>france</td>\n",
       "      <td>nord-pas-de-calais-picardie</td>\n",
       "      <td>2967421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6636</th>\n",
       "      <td>wasquehal</td>\n",
       "      <td>france</td>\n",
       "      <td>nord-pas-de-calais-picardie</td>\n",
       "      <td>2967438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6637</th>\n",
       "      <td>voiron</td>\n",
       "      <td>france</td>\n",
       "      <td>auvergne-rhône-alpes</td>\n",
       "      <td>2967758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7261</th>\n",
       "      <td>marseille 15</td>\n",
       "      <td>france</td>\n",
       "      <td>provence-alpes-côte d'azur</td>\n",
       "      <td>7284896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7262</th>\n",
       "      <td>marseille 16</td>\n",
       "      <td>france</td>\n",
       "      <td>provence-alpes-côte d'azur</td>\n",
       "      <td>7284897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7263</th>\n",
       "      <td>la defense</td>\n",
       "      <td>france</td>\n",
       "      <td>île-de-france</td>\n",
       "      <td>8504417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7264</th>\n",
       "      <td>saint-quentin-en-yvelines</td>\n",
       "      <td>france</td>\n",
       "      <td>île-de-france</td>\n",
       "      <td>8533870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7265</th>\n",
       "      <td>cergy-pontoise</td>\n",
       "      <td>france</td>\n",
       "      <td>île-de-france</td>\n",
       "      <td>8555643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>633 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name country                         subcountry  \\\n",
       "6633                     yerres  france                      île-de-france   \n",
       "6634                 wittenheim  france  alsace-champagne-ardenne-lorraine   \n",
       "6635                  wattrelos  france        nord-pas-de-calais-picardie   \n",
       "6636                  wasquehal  france        nord-pas-de-calais-picardie   \n",
       "6637                     voiron  france               auvergne-rhône-alpes   \n",
       "...                         ...     ...                                ...   \n",
       "7261               marseille 15  france         provence-alpes-côte d'azur   \n",
       "7262               marseille 16  france         provence-alpes-côte d'azur   \n",
       "7263                 la defense  france                      île-de-france   \n",
       "7264  saint-quentin-en-yvelines  france                      île-de-france   \n",
       "7265             cergy-pontoise  france                      île-de-france   \n",
       "\n",
       "      geonameid  \n",
       "6633    2967245  \n",
       "6634    2967318  \n",
       "6635    2967421  \n",
       "6636    2967438  \n",
       "6637    2967758  \n",
       "...         ...  \n",
       "7261    7284896  \n",
       "7262    7284897  \n",
       "7263    8504417  \n",
       "7264    8533870  \n",
       "7265    8555643  \n",
       "\n",
       "[633 rows x 4 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world_cities_df[world_cities_df['country']=='france']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = set(world_cities_df['name'].unique())\n",
    "countries = set(world_cities_df['country'].unique())\n",
    "subcountries = set(world_cities_df['subcountry'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will add this to stopwords\n",
    "geo_data = cities | countries | subcountries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21940"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "244"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2594"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subcountries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23803"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(geo_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['validation_report', 'language-codes_csv', 'language-codes-3b2_csv', 'language-codes-full_csv', 'ietf-language-tags_csv', 'language-codes_json', 'language-codes-3b2_json', 'language-codes-full_json', 'ietf-language-tags_json', 'language-codes_zip', 'language-codes', 'language-codes-3b2', 'language-codes-full', 'ietf-language-tags']\n"
     ]
    }
   ],
   "source": [
    "language_package = Package('https://datahub.io/core/language-codes/datapackage.json')\n",
    "\n",
    "# print list of all resources:\n",
    "print(language_package.resource_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print processed tabular data (if exists any)\n",
    "languages_data = []\n",
    "#for resource in language_package.resources:\n",
    "#    if resource.descriptor['datahub']['derivedFrom']=='language-codes':\n",
    "#        print(resource.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages_data = language_package.resources[1].read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha2</th>\n",
       "      <th>english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aa</td>\n",
       "      <td>afar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ab</td>\n",
       "      <td>abkhazian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ae</td>\n",
       "      <td>avestan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>af</td>\n",
       "      <td>afrikaans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ak</td>\n",
       "      <td>akan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>yi</td>\n",
       "      <td>yiddish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>yo</td>\n",
       "      <td>yoruba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>za</td>\n",
       "      <td>zhuang; chuang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>zh</td>\n",
       "      <td>chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>zu</td>\n",
       "      <td>zulu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>184 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    alpha2         english\n",
       "0       aa            afar\n",
       "1       ab       abkhazian\n",
       "2       ae         avestan\n",
       "3       af       afrikaans\n",
       "4       ak            akan\n",
       "..     ...             ...\n",
       "179     yi         yiddish\n",
       "180     yo          yoruba\n",
       "181     za  zhuang; chuang\n",
       "182     zh         chinese\n",
       "183     zu            zulu\n",
       "\n",
       "[184 rows x 2 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages_df = pd.DataFrame(languages_data, columns=['alpha2', 'english'])\n",
    "languages_df = languages_df.applymap(lambda s:s.lower() if type(s) == str else s)\n",
    "languages_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = set(languages_df['english'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nationality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>afghan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>albanian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>algerian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>andorran</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>wallisian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>welsh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>yemeni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>zambian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>zimbabwean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nationality\n",
       "0        afghan\n",
       "1      albanian\n",
       "2      algerian\n",
       "3      american\n",
       "4      andorran\n",
       "..          ...\n",
       "220   wallisian\n",
       "221       welsh\n",
       "222      yemeni\n",
       "223     zambian\n",
       "224  zimbabwean\n",
       "\n",
       "[225 rows x 1 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nationality_path = 'Data/CH_Nationality_List_20171130_v1.csv'\n",
    "nationality_df = pd.read_csv(nationality_path, skiprows=0, skipfooter=0, engine='python')\n",
    "nationality_df = nationality_df.applymap(lambda s:s.lower() if type(s) == str else s)\n",
    "nationality_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nationalities = set(nationality_df['Nationality'].unique())\n",
    "len(nationalities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>country_id</th>\n",
       "      <th>country_code</th>\n",
       "      <th>country_name</th>\n",
       "      <th>state_code</th>\n",
       "      <th>type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3901</td>\n",
       "      <td>badakhshan</td>\n",
       "      <td>1</td>\n",
       "      <td>af</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td>bds</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.734772</td>\n",
       "      <td>70.811995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3871</td>\n",
       "      <td>badghis</td>\n",
       "      <td>1</td>\n",
       "      <td>af</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td>bdg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.167134</td>\n",
       "      <td>63.769538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3875</td>\n",
       "      <td>baghlan</td>\n",
       "      <td>1</td>\n",
       "      <td>af</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td>bgl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.178903</td>\n",
       "      <td>68.745306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3884</td>\n",
       "      <td>balkh</td>\n",
       "      <td>1</td>\n",
       "      <td>af</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td>bal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.755060</td>\n",
       "      <td>66.897537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3872</td>\n",
       "      <td>bamyan</td>\n",
       "      <td>1</td>\n",
       "      <td>af</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td>bam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.810007</td>\n",
       "      <td>67.821210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4974</th>\n",
       "      <td>1953</td>\n",
       "      <td>mashonaland west province</td>\n",
       "      <td>247</td>\n",
       "      <td>zw</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>mw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-17.485103</td>\n",
       "      <td>29.788925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4975</th>\n",
       "      <td>1960</td>\n",
       "      <td>masvingo province</td>\n",
       "      <td>247</td>\n",
       "      <td>zw</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>mv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-20.624151</td>\n",
       "      <td>31.262637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4976</th>\n",
       "      <td>1954</td>\n",
       "      <td>matabeleland north province</td>\n",
       "      <td>247</td>\n",
       "      <td>zw</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>mn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-18.533157</td>\n",
       "      <td>27.549585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4977</th>\n",
       "      <td>1952</td>\n",
       "      <td>matabeleland south province</td>\n",
       "      <td>247</td>\n",
       "      <td>zw</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>ms</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21.052337</td>\n",
       "      <td>29.045993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4978</th>\n",
       "      <td>1957</td>\n",
       "      <td>midlands province</td>\n",
       "      <td>247</td>\n",
       "      <td>zw</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>mi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-19.055201</td>\n",
       "      <td>29.603549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4979 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                         name  country_id country_code country_name  \\\n",
       "0     3901                   badakhshan           1           af  afghanistan   \n",
       "1     3871                      badghis           1           af  afghanistan   \n",
       "2     3875                      baghlan           1           af  afghanistan   \n",
       "3     3884                        balkh           1           af  afghanistan   \n",
       "4     3872                       bamyan           1           af  afghanistan   \n",
       "...    ...                          ...         ...          ...          ...   \n",
       "4974  1953    mashonaland west province         247           zw     zimbabwe   \n",
       "4975  1960            masvingo province         247           zw     zimbabwe   \n",
       "4976  1954  matabeleland north province         247           zw     zimbabwe   \n",
       "4977  1952  matabeleland south province         247           zw     zimbabwe   \n",
       "4978  1957            midlands province         247           zw     zimbabwe   \n",
       "\n",
       "     state_code type   latitude  longitude  \n",
       "0           bds  NaN  36.734772  70.811995  \n",
       "1           bdg  NaN  35.167134  63.769538  \n",
       "2           bgl  NaN  36.178903  68.745306  \n",
       "3           bal  NaN  36.755060  66.897537  \n",
       "4           bam  NaN  34.810007  67.821210  \n",
       "...         ...  ...        ...        ...  \n",
       "4974         mw  NaN -17.485103  29.788925  \n",
       "4975         mv  NaN -20.624151  31.262637  \n",
       "4976         mn  NaN -18.533157  27.549585  \n",
       "4977         ms  NaN -21.052337  29.045993  \n",
       "4978         mi  NaN -19.055201  29.603549  \n",
       "\n",
       "[4979 rows x 9 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_path = 'Data/states.csv'\n",
    "states_df = pd.read_csv(states_path, skiprows=0, skipfooter=0, engine='python')\n",
    "states_df = states_df.applymap(lambda s:s.lower() if type(s) == str else s)\n",
    "states_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4896"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = set(states_df['name'].unique())\n",
    "len(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ï»¿name</th>\n",
       "      <th>alpha-2</th>\n",
       "      <th>alpha-3</th>\n",
       "      <th>country-code</th>\n",
       "      <th>iso_3166-2</th>\n",
       "      <th>region</th>\n",
       "      <th>sub-region</th>\n",
       "      <th>intermediate-region</th>\n",
       "      <th>region-code</th>\n",
       "      <th>sub-region-code</th>\n",
       "      <th>intermediate-region-code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>afghanistan</td>\n",
       "      <td>af</td>\n",
       "      <td>afg</td>\n",
       "      <td>4</td>\n",
       "      <td>iso 3166-2:af</td>\n",
       "      <td>asia</td>\n",
       "      <td>southern asia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>142.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ã…land islands</td>\n",
       "      <td>ax</td>\n",
       "      <td>ala</td>\n",
       "      <td>248</td>\n",
       "      <td>iso 3166-2:ax</td>\n",
       "      <td>europe</td>\n",
       "      <td>northern europe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>albania</td>\n",
       "      <td>al</td>\n",
       "      <td>alb</td>\n",
       "      <td>8</td>\n",
       "      <td>iso 3166-2:al</td>\n",
       "      <td>europe</td>\n",
       "      <td>southern europe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>algeria</td>\n",
       "      <td>dz</td>\n",
       "      <td>dza</td>\n",
       "      <td>12</td>\n",
       "      <td>iso 3166-2:dz</td>\n",
       "      <td>africa</td>\n",
       "      <td>northern africa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>american samoa</td>\n",
       "      <td>as</td>\n",
       "      <td>asm</td>\n",
       "      <td>16</td>\n",
       "      <td>iso 3166-2:as</td>\n",
       "      <td>oceania</td>\n",
       "      <td>polynesia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>wallis and futuna</td>\n",
       "      <td>wf</td>\n",
       "      <td>wlf</td>\n",
       "      <td>876</td>\n",
       "      <td>iso 3166-2:wf</td>\n",
       "      <td>oceania</td>\n",
       "      <td>polynesia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>western sahara</td>\n",
       "      <td>eh</td>\n",
       "      <td>esh</td>\n",
       "      <td>732</td>\n",
       "      <td>iso 3166-2:eh</td>\n",
       "      <td>africa</td>\n",
       "      <td>northern africa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>yemen</td>\n",
       "      <td>ye</td>\n",
       "      <td>yem</td>\n",
       "      <td>887</td>\n",
       "      <td>iso 3166-2:ye</td>\n",
       "      <td>asia</td>\n",
       "      <td>western asia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>142.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>zambia</td>\n",
       "      <td>zm</td>\n",
       "      <td>zmb</td>\n",
       "      <td>894</td>\n",
       "      <td>iso 3166-2:zm</td>\n",
       "      <td>africa</td>\n",
       "      <td>sub-saharan africa</td>\n",
       "      <td>eastern africa</td>\n",
       "      <td>2.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>zw</td>\n",
       "      <td>zwe</td>\n",
       "      <td>716</td>\n",
       "      <td>iso 3166-2:zw</td>\n",
       "      <td>africa</td>\n",
       "      <td>sub-saharan africa</td>\n",
       "      <td>eastern africa</td>\n",
       "      <td>2.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>249 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ï»¿name alpha-2 alpha-3  country-code     iso_3166-2   region  \\\n",
       "0          afghanistan      af     afg             4  iso 3166-2:af     asia   \n",
       "1       ã…land islands      ax     ala           248  iso 3166-2:ax   europe   \n",
       "2              albania      al     alb             8  iso 3166-2:al   europe   \n",
       "3              algeria      dz     dza            12  iso 3166-2:dz   africa   \n",
       "4       american samoa      as     asm            16  iso 3166-2:as  oceania   \n",
       "..                 ...     ...     ...           ...            ...      ...   \n",
       "244  wallis and futuna      wf     wlf           876  iso 3166-2:wf  oceania   \n",
       "245     western sahara      eh     esh           732  iso 3166-2:eh   africa   \n",
       "246              yemen      ye     yem           887  iso 3166-2:ye     asia   \n",
       "247             zambia      zm     zmb           894  iso 3166-2:zm   africa   \n",
       "248           zimbabwe      zw     zwe           716  iso 3166-2:zw   africa   \n",
       "\n",
       "             sub-region intermediate-region  region-code  sub-region-code  \\\n",
       "0         southern asia                 NaN        142.0             34.0   \n",
       "1       northern europe                 NaN        150.0            154.0   \n",
       "2       southern europe                 NaN        150.0             39.0   \n",
       "3       northern africa                 NaN          2.0             15.0   \n",
       "4             polynesia                 NaN          9.0             61.0   \n",
       "..                  ...                 ...          ...              ...   \n",
       "244           polynesia                 NaN          9.0             61.0   \n",
       "245     northern africa                 NaN          2.0             15.0   \n",
       "246        western asia                 NaN        142.0            145.0   \n",
       "247  sub-saharan africa      eastern africa          2.0            202.0   \n",
       "248  sub-saharan africa      eastern africa          2.0            202.0   \n",
       "\n",
       "     intermediate-region-code  \n",
       "0                         NaN  \n",
       "1                         NaN  \n",
       "2                         NaN  \n",
       "3                         NaN  \n",
       "4                         NaN  \n",
       "..                        ...  \n",
       "244                       NaN  \n",
       "245                       NaN  \n",
       "246                       NaN  \n",
       "247                      14.0  \n",
       "248                      14.0  \n",
       "\n",
       "[249 rows x 11 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continents_path = 'Data/continents2.csv'\n",
    "continents_df = pd.read_csv(continents_path, skiprows=0, skipfooter=0, engine='python')\n",
    "continents_df = continents_df.applymap(lambda s:s.lower() if type(s) == str else s)\n",
    "continents_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continents = set(continents_df['region'].unique())\n",
    "len(continents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>newPerct2013</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>michael</td>\n",
       "      <td>0.011577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>james</td>\n",
       "      <td>0.010218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>john</td>\n",
       "      <td>0.009675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>robert</td>\n",
       "      <td>0.009493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>david</td>\n",
       "      <td>0.008943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>christina</td>\n",
       "      <td>0.001435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>julie</td>\n",
       "      <td>0.001418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>jordan</td>\n",
       "      <td>0.001416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>kyle</td>\n",
       "      <td>0.001413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>anna</td>\n",
       "      <td>0.001400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0       name  newPerct2013\n",
       "0            1    michael      0.011577\n",
       "1            2      james      0.010218\n",
       "2            3       john      0.009675\n",
       "3            4     robert      0.009493\n",
       "4            5      david      0.008943\n",
       "..         ...        ...           ...\n",
       "95          96  christina      0.001435\n",
       "96          97      julie      0.001418\n",
       "97          98     jordan      0.001416\n",
       "98          99       kyle      0.001413\n",
       "99         100       anna      0.001400\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstname_path = 'Data/new-top-firstNames.csv'\n",
    "firstname_df = pd.read_csv(firstname_path, skiprows=0, skipfooter=0, engine='python')\n",
    "firstname_df = firstname_df.applymap(lambda s:s.lower() if type(s) == str else s)\n",
    "firstname_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstnames = set(firstname_df['name'].unique())\n",
    "len(firstnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>john</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>william</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>james</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>charles</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>george</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6777</th>\n",
       "      <td>laylah</td>\n",
       "      <td>girl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6778</th>\n",
       "      <td>carleigh</td>\n",
       "      <td>girl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6779</th>\n",
       "      <td>kenley</td>\n",
       "      <td>girl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6780</th>\n",
       "      <td>sloane</td>\n",
       "      <td>girl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6781</th>\n",
       "      <td>elianna</td>\n",
       "      <td>girl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6782 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0     1\n",
       "0         john   boy\n",
       "1      william   boy\n",
       "2        james   boy\n",
       "3      charles   boy\n",
       "4       george   boy\n",
       "...        ...   ...\n",
       "6777    laylah  girl\n",
       "6778  carleigh  girl\n",
       "6779    kenley  girl\n",
       "6780    sloane  girl\n",
       "6781   elianna  girl\n",
       "\n",
       "[6782 rows x 2 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstname_path2 = 'Data/babynames-clean.csv'\n",
    "firstname_df2 = pd.read_csv(firstname_path2, header= None, skiprows=0, skipfooter=0, engine='python')\n",
    "firstname_df2 = firstname_df2.applymap(lambda s:s.lower() if type(s) == str else s)\n",
    "firstname_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6782"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstnames2 = set(firstname_df2[0].unique())\n",
    "len(firstnames2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6782"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstnames = firstnames | firstnames2\n",
    "len(firstnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>perct2013</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>smith</td>\n",
       "      <td>0.007999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>johnson</td>\n",
       "      <td>0.006346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>williams</td>\n",
       "      <td>0.005330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>brown</td>\n",
       "      <td>0.004724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>jones</td>\n",
       "      <td>0.004676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>vasquez</td>\n",
       "      <td>0.000760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>sanders</td>\n",
       "      <td>0.000753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>jimenez</td>\n",
       "      <td>0.000751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>long</td>\n",
       "      <td>0.000747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>foster</td>\n",
       "      <td>0.000746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0      name  perct2013\n",
       "0            1     smith   0.007999\n",
       "1            2   johnson   0.006346\n",
       "2            3  williams   0.005330\n",
       "3            4     brown   0.004724\n",
       "4            5     jones   0.004676\n",
       "..         ...       ...        ...\n",
       "95          96   vasquez   0.000760\n",
       "96          97   sanders   0.000753\n",
       "97          98   jimenez   0.000751\n",
       "98          99      long   0.000747\n",
       "99         100    foster   0.000746\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surname_path = 'Data/new-top-surnames.csv'\n",
    "surname_df = pd.read_csv(surname_path, skiprows=0, skipfooter=0, engine='python')\n",
    "surname_df = surname_df.applymap(lambda s:s.lower() if type(s) == str else s)\n",
    "surname_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surnames = set(surname_df['name'].unique())\n",
    "len(surnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "days=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']\n",
    "months=['January','February','March', 'April','May','June','July','August','September','October','November','December']\n",
    "calendar = days.copy()\n",
    "calendar.extend(months)\n",
    "calendar = set([w.lower() for w in calendar])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'april',\n",
       " 'august',\n",
       " 'december',\n",
       " 'february',\n",
       " 'friday',\n",
       " 'january',\n",
       " 'july',\n",
       " 'june',\n",
       " 'march',\n",
       " 'may',\n",
       " 'monday',\n",
       " 'november',\n",
       " 'october',\n",
       " 'saturday',\n",
       " 'september',\n",
       " 'sunday',\n",
       " 'thursday',\n",
       " 'tuesday',\n",
       " 'wednesday'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "304501    1979-80 Buffalo Sabres NHL 32 1880 74 1 4 2.36...\n",
       "162313    Diseases Lentils in culture Lentils are mentio...\n",
       "336845    Railroads , like the Lehigh Valley Railroad , ...\n",
       "150625    An example of this would be an individual anim...\n",
       "40240     Both the Matanuska and Susitna Rivers have maj...\n",
       "                                ...                        \n",
       "259178    After the Germans invaded Norway in April 1940...\n",
       "365838    July 28 - Henry Bennet , 1st Earl of Arlington...\n",
       "131932    Pancake restaurants are popular family restaur...\n",
       "146867                                 A cycling domestique\n",
       "121958    David Boreanaz 's first paid acting appearance...\n",
       "Name: original_text, Length: 333414, dtype: object"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1979-80 Buffalo Sabres NHL 32 1880 74 1 4 2.36 20 8 4 0 0.000'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[304501]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['buffalo', 'sabres', 'nhl']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim.utils.simple_preprocess(X_train[304501])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gensim.parsing.preprocessing.STOPWORDS\n",
    "#stopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text_train=[]\n",
    "tokenized_text_test=[]\n",
    "stopWords = set(stopwords.words('english')) | dale | geo_data | languages | nationalities | states | continents | firstnames | surnames | calendar\n",
    "# This cell will run 4 minutes\n",
    "import gensim\n",
    "from nltk.stem.porter import *\n",
    "def lemmatize_stemming(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    #Un-hash next line to use stemming\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "    #Un-hash next line to NOT use stemming\n",
    "    #return WordNetLemmatizer().lemmatize(text, pos='v')\n",
    "\n",
    "# Tokenize and lemmatize\n",
    "def preprocess(text):\n",
    "    result=[]\n",
    "    for token in gensim.utils.simple_preprocess(text) :\n",
    "        if token not in stopWords and len(token) > 3:\n",
    "            #Un-hash next line to use lemmatization/stemming\n",
    "            result.append(lemmatize_stemming(token))\n",
    "            #Un-hash next line to NOT use lemmatization/stemming\n",
    "            #result.append(token)\n",
    "            \n",
    "    return result\n",
    "\n",
    "tokenized_text_train = [preprocess(text) for text in X_train]\n",
    "tokenized_text_test=[preprocess(text) for text in X_test]\n",
    "\n",
    "#for text in tqdm(X_train):\n",
    "#    tokens_in_text = word_tokenize(text)\n",
    "#    tokens_in_text = [word for word in tokens_in_text if word.lower() not in stopWords]\n",
    "#    tokenized_text_train.append(tokens_in_text)\n",
    "    \n",
    "#for text in tqdm(X_test):\n",
    "#    tokens_in_text = word_tokenize(text)\n",
    "#    tokens_in_text = [word for word in tokens_in_text if word.lower() not in stopWords]\n",
    "#    tokenized_text_test.append(tokens_in_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2986"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenized_text_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8116155, 11762330)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Word2Vec(vector_size=100,window=2,min_count=100,seed= RANDOM_SEED,workers=4)\n",
    "model.build_vocab(tokenized_text_train)\n",
    "model.train(tokenized_text_train,total_examples=model.corpus_count,epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_vectors.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = word_vectors.key_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'franc': 0,\n",
       " 'unit': 1,\n",
       " 'commun': 2,\n",
       " 'depart': 3,\n",
       " 'region': 4,\n",
       " 'state': 5,\n",
       " 'american': 6,\n",
       " 'includ': 7,\n",
       " 'call': 8,\n",
       " 'nation': 9,\n",
       " 'play': 10,\n",
       " 'area': 11,\n",
       " 'locat': 12,\n",
       " 'univers': 13,\n",
       " 'district': 14,\n",
       " 'releas': 15,\n",
       " 'year': 16,\n",
       " 'refer': 17,\n",
       " 'name': 18,\n",
       " 'english': 19,\n",
       " 'album': 20,\n",
       " 'system': 21,\n",
       " 'seri': 22,\n",
       " 'former': 23,\n",
       " 'origin': 24,\n",
       " 'later': 25,\n",
       " 'german': 26,\n",
       " 'septemb': 27,\n",
       " 'british': 28,\n",
       " 'januari': 29,\n",
       " 'calai': 30,\n",
       " 'current': 31,\n",
       " 'juli': 32,\n",
       " 'octob': 33,\n",
       " 'august': 34,\n",
       " 'centuri': 35,\n",
       " 'popul': 36,\n",
       " 'leagu': 37,\n",
       " 'june': 38,\n",
       " 'decemb': 39,\n",
       " 'provinc': 40,\n",
       " 'april': 41,\n",
       " 'novemb': 42,\n",
       " 'england': 43,\n",
       " 'produc': 44,\n",
       " 'work': 45,\n",
       " 'februari': 46,\n",
       " 'develop': 47,\n",
       " 'base': 48,\n",
       " 'award': 49,\n",
       " 'intern': 50,\n",
       " 'london': 51,\n",
       " 'french': 52,\n",
       " 'presid': 53,\n",
       " 'john': 54,\n",
       " 'largest': 55,\n",
       " 'record': 56,\n",
       " 'start': 57,\n",
       " 'form': 58,\n",
       " 'ndash': 59,\n",
       " 'creat': 60,\n",
       " 'main': 61,\n",
       " 'usual': 62,\n",
       " 'central': 63,\n",
       " 'offici': 64,\n",
       " 'germani': 65,\n",
       " 'municip': 66,\n",
       " 'japanes': 67,\n",
       " 'forc': 68,\n",
       " 'organ': 69,\n",
       " 'design': 70,\n",
       " 'common': 71,\n",
       " 'perform': 72,\n",
       " 'televis': 73,\n",
       " 'use': 74,\n",
       " 'type': 75,\n",
       " 'publish': 76,\n",
       " 'speci': 77,\n",
       " 'york': 78,\n",
       " 'game': 79,\n",
       " 'profession': 80,\n",
       " 'championship': 81,\n",
       " 'event': 82,\n",
       " 'featur': 83,\n",
       " 'appear': 84,\n",
       " 'popular': 85,\n",
       " 'found': 86,\n",
       " 'period': 87,\n",
       " 'union': 88,\n",
       " 'although': 89,\n",
       " 'oper': 90,\n",
       " 'exampl': 91,\n",
       " 'america': 92,\n",
       " 'roman': 93,\n",
       " 'gener': 94,\n",
       " 'charact': 95,\n",
       " 'bass': 96,\n",
       " 'video': 97,\n",
       " 'australia': 98,\n",
       " 'associ': 99,\n",
       " 'human': 100,\n",
       " 'modern': 101,\n",
       " 'hurrican': 102,\n",
       " 'japan': 103,\n",
       " 'famou': 104,\n",
       " 'tropic': 105,\n",
       " 'member': 106,\n",
       " 'anim': 107,\n",
       " 'success': 108,\n",
       " 'republ': 109,\n",
       " 'nord': 110,\n",
       " 'italian': 111,\n",
       " 'natur': 112,\n",
       " 'time': 113,\n",
       " 'compos': 114,\n",
       " 'serv': 115,\n",
       " 'product': 116,\n",
       " 'william': 117,\n",
       " 'show': 118,\n",
       " 'along': 119,\n",
       " 'contain': 120,\n",
       " 'council': 121,\n",
       " 'within': 122,\n",
       " 'elect': 123,\n",
       " 'aisn': 124,\n",
       " 'europ': 125,\n",
       " 'role': 126,\n",
       " 'chang': 127,\n",
       " 'comput': 128,\n",
       " 'consid': 129,\n",
       " 'picardi': 130,\n",
       " 'pakistan': 131,\n",
       " 'greek': 132,\n",
       " 'european': 133,\n",
       " 'support': 134,\n",
       " 'countri': 135,\n",
       " 'version': 136,\n",
       " 'result': 137,\n",
       " 'move': 138,\n",
       " 'georg': 139,\n",
       " 'spanish': 140,\n",
       " 'christian': 141,\n",
       " 'control': 142,\n",
       " 'polit': 143,\n",
       " 'jam': 144,\n",
       " 'independ': 145,\n",
       " 'tradit': 146,\n",
       " 'program': 147,\n",
       " 'continu': 148,\n",
       " 'normandi': 149,\n",
       " 'local': 150,\n",
       " 'accord': 151,\n",
       " 'india': 152,\n",
       " 'divis': 153,\n",
       " 'total': 154,\n",
       " 'calvado': 155,\n",
       " 'establish': 156,\n",
       " 'actor': 157,\n",
       " 'complet': 158,\n",
       " 'california': 159,\n",
       " 'career': 160,\n",
       " 'minist': 161,\n",
       " 'scienc': 162,\n",
       " 'allow': 163,\n",
       " 'empir': 164,\n",
       " 'switzerland': 165,\n",
       " 'final': 166,\n",
       " 'island': 167,\n",
       " 'hockey': 168,\n",
       " 'northwest': 169,\n",
       " 'cultur': 170,\n",
       " 'canton': 171,\n",
       " 'consist': 172,\n",
       " 'posit': 173,\n",
       " 'articl': 174,\n",
       " 'footbal': 175,\n",
       " 'provid': 176,\n",
       " 'relat': 177,\n",
       " 'commonli': 178,\n",
       " 'repres': 179,\n",
       " 'canada': 180,\n",
       " 'border': 181,\n",
       " 'similar': 182,\n",
       " 'wrestl': 183,\n",
       " 'emperor': 184,\n",
       " 'open': 185,\n",
       " 'star': 186,\n",
       " 'link': 187,\n",
       " 'receiv': 188,\n",
       " 'rang': 189,\n",
       " 'activ': 190,\n",
       " 'studi': 191,\n",
       " 'part': 192,\n",
       " 'join': 193,\n",
       " 'caus': 194,\n",
       " 'remain': 195,\n",
       " 'writer': 196,\n",
       " 'feder': 197,\n",
       " 'exist': 198,\n",
       " 'charl': 199,\n",
       " 'websit': 200,\n",
       " 'novel': 201,\n",
       " 'australian': 202,\n",
       " 'special': 203,\n",
       " 'administr': 204,\n",
       " 'day': 205,\n",
       " 'process': 206,\n",
       " 'territori': 207,\n",
       " 'mean': 208,\n",
       " 'itali': 209,\n",
       " 'network': 210,\n",
       " 'henri': 211,\n",
       " 'inform': 212,\n",
       " 'studio': 213,\n",
       " 'pay': 214,\n",
       " 'replac': 215,\n",
       " 'edit': 216,\n",
       " 'loir': 217,\n",
       " 'sourc': 218,\n",
       " 'book': 219,\n",
       " 'describ': 220,\n",
       " 'ancient': 221,\n",
       " 'histor': 222,\n",
       " 'style': 223,\n",
       " 'militari': 224,\n",
       " 'director': 225,\n",
       " 'mile': 226,\n",
       " 'addit': 227,\n",
       " 'fiction': 228,\n",
       " 'canadian': 229,\n",
       " 'place': 230,\n",
       " 'scotland': 231,\n",
       " 'girond': 232,\n",
       " 'educ': 233,\n",
       " 'energi': 234,\n",
       " 'mari': 235,\n",
       " 'institut': 236,\n",
       " 'chemic': 237,\n",
       " 'robert': 238,\n",
       " 'movement': 239,\n",
       " 'collect': 240,\n",
       " 'ireland': 241,\n",
       " 'variou': 242,\n",
       " 'africa': 243,\n",
       " 'physic': 244,\n",
       " 'industri': 245,\n",
       " 'sign': 246,\n",
       " 'paul': 247,\n",
       " 'opera': 248,\n",
       " 'languag': 249,\n",
       " 'student': 250,\n",
       " 'follow': 251,\n",
       " 'formula': 252,\n",
       " 'theori': 253,\n",
       " 'orchestra': 254,\n",
       " 'project': 255,\n",
       " 'latin': 256,\n",
       " 'episod': 257,\n",
       " 'florida': 258,\n",
       " 'brazilian': 259,\n",
       " 'prime': 260,\n",
       " 'aquitain': 261,\n",
       " 'object': 262,\n",
       " 'atlant': 263,\n",
       " 'civil': 264,\n",
       " 'tour': 265,\n",
       " 'materi': 266,\n",
       " 'discov': 267,\n",
       " 'censu': 268,\n",
       " 'reach': 269,\n",
       " 'david': 270,\n",
       " 'russian': 271,\n",
       " 'structur': 272,\n",
       " 'element': 273,\n",
       " 'standard': 274,\n",
       " 'research': 275,\n",
       " 'parliament': 276,\n",
       " 'effect': 277,\n",
       " 'indian': 278,\n",
       " 'classic': 279,\n",
       " 'chines': 280,\n",
       " 'entertain': 281,\n",
       " 'plant': 282,\n",
       " 'team': 283,\n",
       " 'site': 284,\n",
       " 'race': 285,\n",
       " 'model': 286,\n",
       " 'song': 287,\n",
       " 'occur': 288,\n",
       " 'film': 289,\n",
       " 'michael': 290,\n",
       " 'olymp': 291,\n",
       " 'asia': 292,\n",
       " 'sport': 293,\n",
       " 'pari': 294,\n",
       " 'recent': 295,\n",
       " 'imag': 296,\n",
       " 'actress': 297,\n",
       " 'other': 298,\n",
       " 'port': 299,\n",
       " 'southwest': 300,\n",
       " 'citi': 301,\n",
       " 'retir': 302,\n",
       " 'number': 303,\n",
       " 'rule': 304,\n",
       " 'softwar': 305,\n",
       " 'win': 306,\n",
       " 'group': 307,\n",
       " 'stadium': 308,\n",
       " 'social': 309,\n",
       " 'user': 310,\n",
       " 'cathol': 311,\n",
       " 'richard': 312,\n",
       " 'involv': 313,\n",
       " 'highest': 314,\n",
       " 'cover': 315,\n",
       " 'berlin': 316,\n",
       " 'train': 317,\n",
       " 'combin': 318,\n",
       " 'almost': 319,\n",
       " 'lead': 320,\n",
       " 'minor': 321,\n",
       " 'across': 322,\n",
       " 'scottish': 323,\n",
       " 'speak': 324,\n",
       " 'return': 325,\n",
       " 'increas': 326,\n",
       " 'typic': 327,\n",
       " 'divid': 328,\n",
       " 'approxim': 329,\n",
       " 'societi': 330,\n",
       " 'dutch': 331,\n",
       " 'live': 332,\n",
       " 'person': 333,\n",
       " 'influenc': 334,\n",
       " 'guitar': 335,\n",
       " 'announc': 336,\n",
       " 'debut': 337,\n",
       " 'engin': 338,\n",
       " 'critic': 339,\n",
       " 'symbol': 340,\n",
       " 'initi': 341,\n",
       " 'execut': 342,\n",
       " 'musician': 343,\n",
       " 'player': 344,\n",
       " 'duke': 345,\n",
       " 'construct': 346,\n",
       " 'orbit': 347,\n",
       " 'femal': 348,\n",
       " 'instrument': 349,\n",
       " 'claim': 350,\n",
       " 'direct': 351,\n",
       " 'end': 352,\n",
       " 'lower': 353,\n",
       " 'travel': 354,\n",
       " 'simpli': 355,\n",
       " 'introduc': 356,\n",
       " 'spain': 357,\n",
       " 'connect': 358,\n",
       " 'issu': 359,\n",
       " 'airport': 360,\n",
       " 'translat': 361,\n",
       " 'pass': 362,\n",
       " 'soviet': 363,\n",
       " 'iowa': 364,\n",
       " 'peter': 365,\n",
       " 'experi': 366,\n",
       " 'author': 367,\n",
       " 'especi': 368,\n",
       " 'politician': 369,\n",
       " 'disney': 370,\n",
       " 'governor': 371,\n",
       " 'northwestern': 372,\n",
       " 'situat': 373,\n",
       " 'altern': 374,\n",
       " 'individu': 375,\n",
       " 'genu': 376,\n",
       " 'throughout': 377,\n",
       " 'report': 378,\n",
       " 'manag': 379,\n",
       " 'thoma': 380,\n",
       " 'rel': 381,\n",
       " 'function': 382,\n",
       " 'premier': 383,\n",
       " 'requir': 384,\n",
       " 'mountain': 385,\n",
       " 'act': 386,\n",
       " 'wale': 387,\n",
       " 'nativ': 388,\n",
       " 'edward': 389,\n",
       " 'text': 390,\n",
       " 'brand': 391,\n",
       " 'britain': 392,\n",
       " 'mass': 393,\n",
       " 'distribut': 394,\n",
       " 'electron': 395,\n",
       " 'music': 396,\n",
       " 'add': 397,\n",
       " 'alp': 398,\n",
       " 'econom': 399,\n",
       " 'grow': 400,\n",
       " 'wikipedia': 401,\n",
       " 'avail': 402,\n",
       " 'word': 403,\n",
       " 'angel': 404,\n",
       " 'practic': 405,\n",
       " 'loui': 406,\n",
       " 'festiv': 407,\n",
       " 'point': 408,\n",
       " 'defeat': 409,\n",
       " 'command': 410,\n",
       " 'notabl': 411,\n",
       " 'problem': 412,\n",
       " 'come': 413,\n",
       " 'mexico': 414,\n",
       " 'temperatur': 415,\n",
       " 'limit': 416,\n",
       " 'defin': 417,\n",
       " 'format': 418,\n",
       " 'oldest': 419,\n",
       " 'specif': 420,\n",
       " 'data': 421,\n",
       " 'statist': 422,\n",
       " 'academi': 423,\n",
       " 'normal': 424,\n",
       " 'cathedr': 425,\n",
       " 'coloni': 426,\n",
       " 'respons': 427,\n",
       " 'dynasti': 428,\n",
       " 'channel': 429,\n",
       " 'celebr': 430,\n",
       " 'distanc': 431,\n",
       " 'washington': 432,\n",
       " 'close': 433,\n",
       " 'rank': 434,\n",
       " 'action': 435,\n",
       " 'pacif': 436,\n",
       " 'martin': 437,\n",
       " 'servic': 438,\n",
       " 'deriv': 439,\n",
       " 'help': 440,\n",
       " 'super': 441,\n",
       " 'virginia': 442,\n",
       " 'planet': 443,\n",
       " 'present': 444,\n",
       " 'averag': 445,\n",
       " 'declar': 446,\n",
       " 'degre': 447,\n",
       " 'secretari': 448,\n",
       " 'democrat': 449,\n",
       " 'page': 450,\n",
       " 'categori': 451,\n",
       " 'section': 452,\n",
       " 'term': 453,\n",
       " 'window': 454,\n",
       " 'smaller': 455,\n",
       " 'chicago': 456,\n",
       " 'secur': 457,\n",
       " 'art': 458,\n",
       " 'mainli': 459,\n",
       " 'estim': 460,\n",
       " 'turn': 461,\n",
       " 'date': 462,\n",
       " 'russia': 463,\n",
       " 'resid': 464,\n",
       " 'larger': 465,\n",
       " 'attempt': 466,\n",
       " 'borough': 467,\n",
       " 'suggest': 468,\n",
       " 'constitut': 469,\n",
       " 'museum': 470,\n",
       " 'texa': 471,\n",
       " 'conduct': 472,\n",
       " 'note': 473,\n",
       " 'entir': 474,\n",
       " 'statu': 475,\n",
       " 'make': 476,\n",
       " 'inhabit': 477,\n",
       " 'label': 478,\n",
       " 'promot': 479,\n",
       " 'partement': 480,\n",
       " 'select': 481,\n",
       " 'muslim': 482,\n",
       " 'line': 483,\n",
       " 'nintendo': 484,\n",
       " 'commerci': 485,\n",
       " 'scale': 486,\n",
       " 'victoria': 487,\n",
       " 'metropolitan': 488,\n",
       " 'believ': 489,\n",
       " 'thu': 490,\n",
       " 'say': 491,\n",
       " 'method': 492,\n",
       " 'privat': 493,\n",
       " 'irish': 494,\n",
       " 'nuclear': 495,\n",
       " 'competit': 496,\n",
       " 'attack': 497,\n",
       " 'display': 498,\n",
       " 'month': 499,\n",
       " 'annual': 500,\n",
       " 'express': 501,\n",
       " 'asteroid': 502,\n",
       " 'devic': 503,\n",
       " 'becom': 504,\n",
       " 'islam': 505,\n",
       " 'surround': 506,\n",
       " 'memori': 507,\n",
       " 'cell': 508,\n",
       " 'centr': 509,\n",
       " 'pope': 510,\n",
       " 'harri': 511,\n",
       " 'diseas': 512,\n",
       " 'finish': 513,\n",
       " 'own': 514,\n",
       " 'recogn': 515,\n",
       " 'eventu': 516,\n",
       " 'observ': 517,\n",
       " 'surviv': 518,\n",
       " 'african': 519,\n",
       " 'right': 520,\n",
       " 'princip': 521,\n",
       " 'nobel': 522,\n",
       " 'decid': 523,\n",
       " 'want': 524,\n",
       " 'vocal': 525,\n",
       " 'austria': 526,\n",
       " 'list': 527,\n",
       " 'access': 528,\n",
       " 'actual': 529,\n",
       " 'season': 530,\n",
       " 'cyclon': 531,\n",
       " 'arm': 532,\n",
       " 'religi': 533,\n",
       " 'titl': 534,\n",
       " 'school': 535,\n",
       " 'brazil': 536,\n",
       " 'probabl': 537,\n",
       " 'guitarist': 538,\n",
       " 'thing': 539,\n",
       " 'greater': 540,\n",
       " 'netherland': 541,\n",
       " 'concert': 542,\n",
       " 'pressur': 543,\n",
       " 'wide': 544,\n",
       " 'condit': 545,\n",
       " 'transport': 546,\n",
       " 'digit': 547,\n",
       " 'appoint': 548,\n",
       " 'songwrit': 549,\n",
       " 'purpos': 550,\n",
       " 'take': 551,\n",
       " 'treati': 552,\n",
       " 'belgian': 553,\n",
       " 'multipl': 554,\n",
       " 'compound': 555,\n",
       " 'separ': 556,\n",
       " 'higher': 557,\n",
       " 'mechan': 558,\n",
       " 'primari': 559,\n",
       " 'oklahoma': 560,\n",
       " 'acid': 561,\n",
       " 'mathemat': 562,\n",
       " 'opposit': 563,\n",
       " 'adopt': 564,\n",
       " 'varieti': 565,\n",
       " 'mario': 566,\n",
       " 'professor': 567,\n",
       " 'singl': 568,\n",
       " 'artist': 569,\n",
       " 'press': 570,\n",
       " 'nomin': 571,\n",
       " 'zealand': 572,\n",
       " 'respect': 573,\n",
       " 'arab': 574,\n",
       " 'lie': 575,\n",
       " 'applic': 576,\n",
       " 'tribe': 577,\n",
       " 'poet': 578,\n",
       " 'jupit': 579,\n",
       " 'media': 580,\n",
       " 'extend': 581,\n",
       " 'comedi': 582,\n",
       " 'plan': 583,\n",
       " 'romania': 584,\n",
       " 'enter': 585,\n",
       " 'complex': 586,\n",
       " 'measur': 587,\n",
       " 'joseph': 588,\n",
       " 'atom': 589,\n",
       " 'code': 590,\n",
       " 'town': 591,\n",
       " 'distinct': 592,\n",
       " 'achiev': 593,\n",
       " 'hous': 594,\n",
       " 'accept': 595,\n",
       " 'confer': 596,\n",
       " 'numer': 597,\n",
       " 'air': 598,\n",
       " 'technolog': 599,\n",
       " 'sarth': 600,\n",
       " 'depress': 601,\n",
       " 'share': 602,\n",
       " 'explor': 603,\n",
       " 'illinoi': 604,\n",
       " 'regard': 605,\n",
       " 'revolut': 606,\n",
       " 'build': 607,\n",
       " 'armenian': 608,\n",
       " 'extrem': 609,\n",
       " 'graduat': 610,\n",
       " 'discoveri': 611,\n",
       " 'particularli': 612,\n",
       " 'worldwid': 613,\n",
       " 'attend': 614,\n",
       " 'foreign': 615,\n",
       " 'protect': 616,\n",
       " 'host': 617,\n",
       " 'govern': 618,\n",
       " 'adult': 619,\n",
       " 'internet': 620,\n",
       " 'medic': 621,\n",
       " 'urban': 622,\n",
       " 'conserv': 623,\n",
       " 'formerli': 624,\n",
       " 'parent': 625,\n",
       " 'austrian': 626,\n",
       " 'corpor': 627,\n",
       " 'copi': 628,\n",
       " 'destroy': 629,\n",
       " 'appli': 630,\n",
       " 'fame': 631,\n",
       " 'architectur': 632,\n",
       " 'extens': 633,\n",
       " 'advanc': 634,\n",
       " 'drama': 635,\n",
       " 'formal': 636,\n",
       " 'account': 637,\n",
       " 'particular': 638,\n",
       " 'foundat': 639,\n",
       " 'futur': 640,\n",
       " 'nicknam': 641,\n",
       " 'nazi': 642,\n",
       " 'manchest': 643,\n",
       " 'signific': 644,\n",
       " 'carolina': 645,\n",
       " 'regular': 646,\n",
       " 'poland': 647,\n",
       " 'jesu': 648,\n",
       " 'fall': 649,\n",
       " 'draft': 650,\n",
       " 'adam': 651,\n",
       " 'jewish': 652,\n",
       " 'relationship': 653,\n",
       " 'convent': 654,\n",
       " 'contest': 655,\n",
       " 'primarili': 656,\n",
       " 'senat': 657,\n",
       " 'launch': 658,\n",
       " 'korea': 659,\n",
       " 'properti': 660,\n",
       " 'hold': 661,\n",
       " 'elizabeth': 662,\n",
       " 'rat': 663,\n",
       " 'prix': 664,\n",
       " 'literatur': 665,\n",
       " 'manufactur': 666,\n",
       " 'chess': 667,\n",
       " 'peninsula': 668,\n",
       " 'older': 669,\n",
       " 'power': 670,\n",
       " 'carri': 671,\n",
       " 'religion': 672,\n",
       " 'captur': 673,\n",
       " 'zone': 674,\n",
       " 'need': 675,\n",
       " 'founder': 676,\n",
       " 'depend': 677,\n",
       " 'flower': 678,\n",
       " 'ask': 679,\n",
       " 'southeast': 680,\n",
       " 'adapt': 681,\n",
       " 'environ': 682,\n",
       " 'earlier': 683,\n",
       " 'basketbal': 684,\n",
       " 'vote': 685,\n",
       " 'polici': 686,\n",
       " 'philosoph': 687,\n",
       " 'greatest': 688,\n",
       " 'differ': 689,\n",
       " 'despit': 690,\n",
       " 'licens': 691,\n",
       " 'age': 692,\n",
       " 'protest': 693,\n",
       " 'korean': 694,\n",
       " 'egypt': 695,\n",
       " 'stand': 696,\n",
       " 'solar': 697,\n",
       " 'climat': 698,\n",
       " 'mytholog': 699,\n",
       " 'southeastern': 700,\n",
       " 'document': 701,\n",
       " 'previous': 702,\n",
       " 'rome': 703,\n",
       " 'southwestern': 704,\n",
       " 'volum': 705,\n",
       " 'wind': 706,\n",
       " 'compar': 707,\n",
       " 'assist': 708,\n",
       " 'symphoni': 709,\n",
       " 'hour': 710,\n",
       " 'legal': 711,\n",
       " 'succeed': 712,\n",
       " 'directli': 713,\n",
       " 'swedish': 714,\n",
       " 'color': 715,\n",
       " 'subsequ': 716,\n",
       " 'brother': 717,\n",
       " 'challeng': 718,\n",
       " 'major': 719,\n",
       " 'contribut': 720,\n",
       " 'invent': 721,\n",
       " 'previou': 722,\n",
       " 'alexand': 723,\n",
       " 'friend': 724,\n",
       " 'santa': 725,\n",
       " 'saturn': 726,\n",
       " 'theme': 727,\n",
       " 'war': 728,\n",
       " 'campaign': 729,\n",
       " 'mark': 730,\n",
       " 'scott': 731,\n",
       " 'look': 732,\n",
       " 'defend': 733,\n",
       " 'longer': 734,\n",
       " 'attract': 735,\n",
       " 'carbon': 736,\n",
       " 'decad': 737,\n",
       " 'compet': 738,\n",
       " 'grant': 739,\n",
       " 'persian': 740,\n",
       " 'begin': 741,\n",
       " 'reduc': 742,\n",
       " 'concept': 743,\n",
       " 'wrestler': 744,\n",
       " 'medal': 745,\n",
       " 'focu': 746,\n",
       " 'compris': 747,\n",
       " 'interest': 748,\n",
       " 'circuit': 749,\n",
       " 'biggest': 750,\n",
       " 'renam': 751,\n",
       " 'paint': 752,\n",
       " 'counti': 753,\n",
       " 'rare': 754,\n",
       " 'biolog': 755,\n",
       " 'definit': 756,\n",
       " 'band': 757,\n",
       " 'mix': 758,\n",
       " 'identifi': 759,\n",
       " 'leav': 760,\n",
       " 'transfer': 761,\n",
       " 'oxford': 762,\n",
       " 'jersey': 763,\n",
       " 'bomb': 764,\n",
       " 'propos': 765,\n",
       " 'station': 766,\n",
       " 'belong': 767,\n",
       " 'onlin': 768,\n",
       " 'emerg': 769,\n",
       " 'sexual': 770,\n",
       " 'athlet': 771,\n",
       " 'andrew': 772,\n",
       " 'offer': 773,\n",
       " 'cycl': 774,\n",
       " 'determin': 775,\n",
       " 'score': 776,\n",
       " 'rais': 777,\n",
       " 'jean': 778,\n",
       " 'indic': 779,\n",
       " 'sweden': 780,\n",
       " 'frequent': 781,\n",
       " 'reform': 782,\n",
       " 'northeast': 783,\n",
       " 'georgia': 784,\n",
       " 'scientif': 785,\n",
       " 'river': 786,\n",
       " 'head': 787,\n",
       " 'ohio': 788,\n",
       " 'maria': 789,\n",
       " 'commiss': 790,\n",
       " 'adventur': 791,\n",
       " 'scene': 792,\n",
       " 'merg': 793,\n",
       " 'editor': 794,\n",
       " 'scientist': 795,\n",
       " 'pictur': 796,\n",
       " 'gain': 797,\n",
       " 'reign': 798,\n",
       " 'sell': 799,\n",
       " 'occupi': 800,\n",
       " 'evid': 801,\n",
       " 'basic': 802,\n",
       " 'smith': 803,\n",
       " 'field': 804,\n",
       " 'vienna': 805,\n",
       " 'order': 806,\n",
       " 'soccer': 807,\n",
       " 'affect': 808,\n",
       " 'maintain': 809,\n",
       " 'melbourn': 810,\n",
       " 'split': 811,\n",
       " 'remov': 812,\n",
       " 'content': 813,\n",
       " 'philosophi': 814,\n",
       " 'promin': 815,\n",
       " 'marin': 816,\n",
       " 'committe': 817,\n",
       " 'cancer': 818,\n",
       " 'daniel': 819,\n",
       " 'bird': 820,\n",
       " 'contract': 821,\n",
       " 'domin': 822,\n",
       " 'run': 823,\n",
       " 'diamet': 824,\n",
       " 'fight': 825,\n",
       " 'composit': 826,\n",
       " 'headquart': 827,\n",
       " 'ford': 828,\n",
       " 'give': 829,\n",
       " 'week': 830,\n",
       " 'kentucki': 831,\n",
       " 'particip': 832,\n",
       " 'abil': 833,\n",
       " 'assembl': 834,\n",
       " 'land': 835,\n",
       " 'ontario': 836,\n",
       " 'congress': 837,\n",
       " 'flow': 838,\n",
       " 'core': 839,\n",
       " 'portugues': 840,\n",
       " 'inspir': 841,\n",
       " 'unlik': 842,\n",
       " 'satellit': 843,\n",
       " 'ceremoni': 844,\n",
       " 'imperi': 845,\n",
       " 'liber': 846,\n",
       " 'francisco': 847,\n",
       " 'instruct': 848,\n",
       " 'agenc': 849,\n",
       " 'vehicl': 850,\n",
       " 'mosqu': 851,\n",
       " 'hand': 852,\n",
       " 'ship': 853,\n",
       " 'provenc': 854,\n",
       " 'shape': 855,\n",
       " 'highli': 856,\n",
       " 'anti': 857,\n",
       " 'bishop': 858,\n",
       " 'pennsylvania': 859,\n",
       " 'angl': 860,\n",
       " 'commonwealth': 861,\n",
       " 'tehsil': 862,\n",
       " 'overal': 863,\n",
       " 'labor': 864,\n",
       " 'columbia': 865,\n",
       " 'isbn': 866,\n",
       " 'count': 867,\n",
       " 'signal': 868,\n",
       " 'vari': 869,\n",
       " 'chri': 870,\n",
       " 'linux': 871,\n",
       " 'happen': 872,\n",
       " 'cast': 873,\n",
       " 'mention': 874,\n",
       " 'solo': 875,\n",
       " 'justic': 876,\n",
       " 'agre': 877,\n",
       " 'arthur': 878,\n",
       " 'younger': 879,\n",
       " 'michigan': 880,\n",
       " 'store': 881,\n",
       " 'techniqu': 882,\n",
       " 'credit': 883,\n",
       " 'boston': 884,\n",
       " 'tree': 885,\n",
       " 'instal': 886,\n",
       " 'underground': 887,\n",
       " 'kilometr': 888,\n",
       " 'sequel': 889,\n",
       " 'tournament': 890,\n",
       " 'entri': 891,\n",
       " 'earn': 892,\n",
       " 'growth': 893,\n",
       " 'creation': 894,\n",
       " 'incorpor': 895,\n",
       " 'fossil': 896,\n",
       " 'boundari': 897,\n",
       " 'affair': 898,\n",
       " 'tell': 899,\n",
       " 'earliest': 900,\n",
       " 'case': 901,\n",
       " 'breed': 902,\n",
       " 'metr': 903,\n",
       " 'parallel': 904,\n",
       " 'astronom': 905,\n",
       " 'longest': 906,\n",
       " 'therefor': 907,\n",
       " 'khan': 908,\n",
       " 'strike': 909,\n",
       " 'track': 910,\n",
       " 'abbrevi': 911,\n",
       " 'kill': 912,\n",
       " 'concentr': 913,\n",
       " 'lyric': 914,\n",
       " 'oxid': 915,\n",
       " 'tripl': 916,\n",
       " 'hungari': 917,\n",
       " 'prevent': 918,\n",
       " 'letter': 919,\n",
       " 'genet': 920,\n",
       " 'drug': 921,\n",
       " 'level': 922,\n",
       " 'sydney': 923,\n",
       " 'prior': 924,\n",
       " 'troop': 925,\n",
       " 'punk': 926,\n",
       " 'mayenn': 927,\n",
       " 'way': 928,\n",
       " 'last': 929,\n",
       " 'particl': 930,\n",
       " 'billion': 931,\n",
       " 'compani': 932,\n",
       " 'burn': 933,\n",
       " 'pronounc': 934,\n",
       " 'visit': 935,\n",
       " 'sit': 936,\n",
       " 'massachusett': 937,\n",
       " 'offic': 938,\n",
       " 'iran': 939,\n",
       " 'airlin': 940,\n",
       " 'match': 941,\n",
       " 'microsoft': 942,\n",
       " 'equat': 943,\n",
       " 'whether': 944,\n",
       " 'templ': 945,\n",
       " 'approach': 946,\n",
       " 'expand': 947,\n",
       " 'blue': 948,\n",
       " 'geograph': 949,\n",
       " 'concern': 950,\n",
       " 'journal': 951,\n",
       " 'earl': 952,\n",
       " 'employ': 953,\n",
       " 'trophi': 954,\n",
       " 'earthquak': 955,\n",
       " 'address': 956,\n",
       " 'distinguish': 957,\n",
       " 'johann': 958,\n",
       " 'hill': 959,\n",
       " 'suppli': 960,\n",
       " 'reserv': 961,\n",
       " 'dictionari': 962,\n",
       " 'ministri': 963,\n",
       " 'albert': 964,\n",
       " 'fantasi': 965,\n",
       " 'mammal': 966,\n",
       " 'agreement': 967,\n",
       " 'alli': 968,\n",
       " 'infect': 969,\n",
       " 'possibl': 970,\n",
       " 'immedi': 971,\n",
       " 'fail': 972,\n",
       " 'agricultur': 973,\n",
       " 'consol': 974,\n",
       " 'classifi': 975,\n",
       " 'famili': 976,\n",
       " 'buri': 977,\n",
       " 'abbey': 978,\n",
       " 'behavior': 979,\n",
       " 'rhine': 980,\n",
       " 'punjab': 981,\n",
       " 'reason': 982,\n",
       " 'biographi': 983,\n",
       " 'detail': 984,\n",
       " 'household': 985,\n",
       " 'belgium': 986,\n",
       " 'legend': 987,\n",
       " 'teach': 988,\n",
       " 'ann': 989,\n",
       " 'frederick': 990,\n",
       " 'kelli': 991,\n",
       " 'stanley': 992,\n",
       " 'church': 993,\n",
       " 'secondari': 994,\n",
       " 'czech': 995,\n",
       " 'turkish': 996,\n",
       " 'aircraft': 997,\n",
       " 'goal': 998,\n",
       " 'densiti': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'unite' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-193-018b4f527078>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mword_vectors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mword_vectors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'unite'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key_or_keys)\u001b[0m\n\u001b[0;32m    393\u001b[0m         \"\"\"\n\u001b[0;32m    394\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_KEY_TYPES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 395\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkey_or_keys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[1;34m(self, key, norm)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \"\"\"\n\u001b[1;32m--> 438\u001b[1;33m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill_norms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mget_index\u001b[1;34m(self, key, default)\u001b[0m\n\u001b[0;32m    410\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 412\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Key '{key}' not present\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Key 'unite' not present\""
     ]
    }
   ],
   "source": [
    "word_vectors[0] == word_vectors['unite']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3473"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_in_vector = word_vectors.index_to_key\n",
    "len(words_in_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word's Difficulty Considered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "== Concreteness_ratings_Brysbaert_et_al_BRM.txt ==\n",
    "\n",
    "This file contains concreteness ratings for 40 thousand English lemma words gathered via Amazon Mechanical Turk. The ratings come from a larger list of 63 thousand words and represent all English words known to 85% of the raters.\n",
    "\n",
    "The file contains eight columns:\n",
    "1. The word\n",
    "2. Whether it is a single word or a two-word expression \n",
    "3. The mean concreteness rating\n",
    "4. The standard deviation of the concreteness ratings\n",
    "5. The number of persons indicating they did not know the word\n",
    "6. The total number of persons who rated the word\n",
    "7. Percentage participants who knew the word\n",
    "8. The SUBTLEX-US frequency count (on a total of 51 million; Brysbaert & New, 2009) \n",
    "9. The dominant part-of-speech usage\n",
    "\n",
    "Original source: http://crr.ugent.be/archives/1330\n",
    "\n",
    "Brysbaert, M., Warriner, A.B., & Kuperman, V. (2014). Concreteness ratings for 40 thousand generally known English word lemmas. Behavior Research Methods, 46, 904-911.\n",
    "http://crr.ugent.be/papers/Brysbaert_Warriner_Kuperman_BRM_Concreteness_ratings.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concreteness rating - the higher Conc.M, the easier the word is.\n",
    "concreteness_path = 'Data/Concreteness_ratings_Brysbaert_et_al_BRM.txt'\n",
    "concrete_df = pd.read_csv(concreteness_path,delimiter='\\t', keep_default_na=False)\n",
    "concreteset=(concrete_df['Word'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Bigram</th>\n",
       "      <th>Conc.M</th>\n",
       "      <th>Conc.SD</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent_known</th>\n",
       "      <th>SUBTLEX</th>\n",
       "      <th>Dom_Pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>roadsweeper</td>\n",
       "      <td>0</td>\n",
       "      <td>4.85</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>traindriver</td>\n",
       "      <td>0</td>\n",
       "      <td>4.54</td>\n",
       "      <td>0.71</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tush</td>\n",
       "      <td>0</td>\n",
       "      <td>4.45</td>\n",
       "      <td>1.01</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>0.88</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hairdress</td>\n",
       "      <td>0</td>\n",
       "      <td>3.93</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pharmaceutics</td>\n",
       "      <td>0</td>\n",
       "      <td>3.77</td>\n",
       "      <td>1.41</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39949</th>\n",
       "      <td>unenvied</td>\n",
       "      <td>0</td>\n",
       "      <td>1.21</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39950</th>\n",
       "      <td>agnostically</td>\n",
       "      <td>0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39951</th>\n",
       "      <td>conceptualistic</td>\n",
       "      <td>0</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.50</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39952</th>\n",
       "      <td>conventionalism</td>\n",
       "      <td>0</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39953</th>\n",
       "      <td>essentialness</td>\n",
       "      <td>0</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39954 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Word  Bigram  Conc.M  Conc.SD  Unknown  Total  \\\n",
       "0          roadsweeper       0    4.85     0.37        1     27   \n",
       "1          traindriver       0    4.54     0.71        3     29   \n",
       "2                 tush       0    4.45     1.01        3     25   \n",
       "3            hairdress       0    3.93     1.28        0     29   \n",
       "4        pharmaceutics       0    3.77     1.41        4     26   \n",
       "...                ...     ...     ...      ...      ...    ...   \n",
       "39949         unenvied       0    1.21     0.62        1     30   \n",
       "39950     agnostically       0    1.20     0.50        2     27   \n",
       "39951  conceptualistic       0    1.18     0.50        4     26   \n",
       "39952  conventionalism       0    1.18     0.48        1     29   \n",
       "39953    essentialness       0    1.04     0.20        2     26   \n",
       "\n",
       "       Percent_known  SUBTLEX Dom_Pos  \n",
       "0               0.96        0       0  \n",
       "1               0.90        0       0  \n",
       "2               0.88       66       0  \n",
       "3               1.00        1       0  \n",
       "4               0.85        0       0  \n",
       "...              ...      ...     ...  \n",
       "39949           0.97        0    #N/A  \n",
       "39950           0.93        0    #N/A  \n",
       "39951           0.85        0    #N/A  \n",
       "39952           0.97        0    #N/A  \n",
       "39953           0.92        0    #N/A  \n",
       "\n",
       "[39954 rows x 9 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_df['stem'] = concrete_df['Word'].apply(lemmatize_stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Bigram</th>\n",
       "      <th>Conc.M</th>\n",
       "      <th>Conc.SD</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent_known</th>\n",
       "      <th>SUBTLEX</th>\n",
       "      <th>Dom_Pos</th>\n",
       "      <th>stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>roadsweeper</td>\n",
       "      <td>0</td>\n",
       "      <td>4.85</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>roadsweep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>traindriver</td>\n",
       "      <td>0</td>\n",
       "      <td>4.54</td>\n",
       "      <td>0.71</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>traindriv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tush</td>\n",
       "      <td>0</td>\n",
       "      <td>4.45</td>\n",
       "      <td>1.01</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>0.88</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>tush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hairdress</td>\n",
       "      <td>0</td>\n",
       "      <td>3.93</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>hairdress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pharmaceutics</td>\n",
       "      <td>0</td>\n",
       "      <td>3.77</td>\n",
       "      <td>1.41</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pharmaceut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39949</th>\n",
       "      <td>unenvied</td>\n",
       "      <td>0</td>\n",
       "      <td>1.21</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "      <td>unenvi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39950</th>\n",
       "      <td>agnostically</td>\n",
       "      <td>0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "      <td>agnost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39951</th>\n",
       "      <td>conceptualistic</td>\n",
       "      <td>0</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.50</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "      <td>conceptualist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39952</th>\n",
       "      <td>conventionalism</td>\n",
       "      <td>0</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "      <td>convention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39953</th>\n",
       "      <td>essentialness</td>\n",
       "      <td>0</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "      <td>essenti</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39954 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Word  Bigram  Conc.M  Conc.SD  Unknown  Total  \\\n",
       "0          roadsweeper       0    4.85     0.37        1     27   \n",
       "1          traindriver       0    4.54     0.71        3     29   \n",
       "2                 tush       0    4.45     1.01        3     25   \n",
       "3            hairdress       0    3.93     1.28        0     29   \n",
       "4        pharmaceutics       0    3.77     1.41        4     26   \n",
       "...                ...     ...     ...      ...      ...    ...   \n",
       "39949         unenvied       0    1.21     0.62        1     30   \n",
       "39950     agnostically       0    1.20     0.50        2     27   \n",
       "39951  conceptualistic       0    1.18     0.50        4     26   \n",
       "39952  conventionalism       0    1.18     0.48        1     29   \n",
       "39953    essentialness       0    1.04     0.20        2     26   \n",
       "\n",
       "       Percent_known  SUBTLEX Dom_Pos           stem  \n",
       "0               0.96        0       0      roadsweep  \n",
       "1               0.90        0       0      traindriv  \n",
       "2               0.88       66       0           tush  \n",
       "3               1.00        1       0      hairdress  \n",
       "4               0.85        0       0     pharmaceut  \n",
       "...              ...      ...     ...            ...  \n",
       "39949           0.97        0    #N/A         unenvi  \n",
       "39950           0.93        0    #N/A         agnost  \n",
       "39951           0.85        0    #N/A  conceptualist  \n",
       "39952           0.97        0    #N/A     convention  \n",
       "39953           0.92        0    #N/A        essenti  \n",
       "\n",
       "[39954 rows x 10 columns]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    37058\n",
       "1     2896\n",
       "Name: Bigram, dtype: int64"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_df.Bigram.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Bigram</th>\n",
       "      <th>Conc.M</th>\n",
       "      <th>Conc.SD</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent_known</th>\n",
       "      <th>SUBTLEX</th>\n",
       "      <th>Dom_Pos</th>\n",
       "      <th>stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28707</th>\n",
       "      <td>baking soda</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "      <td>baking soda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28709</th>\n",
       "      <td>baseball bat</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "      <td>baseball bat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28710</th>\n",
       "      <td>bath towel</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "      <td>bath towel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28711</th>\n",
       "      <td>beach ball</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "      <td>beach bal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28712</th>\n",
       "      <td>bed sheet</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "      <td>bed sheet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39619</th>\n",
       "      <td>tantamount to</td>\n",
       "      <td>1</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.85</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "      <td>tantamount to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39857</th>\n",
       "      <td>chance on</td>\n",
       "      <td>1</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "      <td>chance on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39871</th>\n",
       "      <td>free rein</td>\n",
       "      <td>1</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0.63</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "      <td>free rein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39899</th>\n",
       "      <td>by chance</td>\n",
       "      <td>1</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "      <td>by chanc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39947</th>\n",
       "      <td>in principle</td>\n",
       "      <td>1</td>\n",
       "      <td>1.21</td>\n",
       "      <td>0.41</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "      <td>in principl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2896 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Word  Bigram  Conc.M  Conc.SD  Unknown  Total  Percent_known  \\\n",
       "28707    baking soda       1    5.00     0.00        0     30           1.00   \n",
       "28709   baseball bat       1    5.00     0.00        0     29           1.00   \n",
       "28710     bath towel       1    5.00     0.00        0     29           1.00   \n",
       "28711     beach ball       1    5.00     0.00        0     28           1.00   \n",
       "28712      bed sheet       1    5.00     0.00        0     28           1.00   \n",
       "...              ...     ...     ...      ...      ...    ...            ...   \n",
       "39619  tantamount to       1    1.52     0.85        4     27           0.85   \n",
       "39857      chance on       1    1.38     0.75        2     28           0.93   \n",
       "39871      free rein       1    1.37     0.63        2     29           0.93   \n",
       "39899      by chance       1    1.34     0.72        1     30           0.97   \n",
       "39947   in principle       1    1.21     0.41        4     28           0.86   \n",
       "\n",
       "       SUBTLEX Dom_Pos           stem  \n",
       "28707        0    #N/A    baking soda  \n",
       "28709        0    #N/A   baseball bat  \n",
       "28710        0    #N/A     bath towel  \n",
       "28711        0    #N/A      beach bal  \n",
       "28712        0    #N/A      bed sheet  \n",
       "...        ...     ...            ...  \n",
       "39619        0    #N/A  tantamount to  \n",
       "39857        0    #N/A      chance on  \n",
       "39871        0    #N/A      free rein  \n",
       "39899        0    #N/A       by chanc  \n",
       "39947        0    #N/A    in principl  \n",
       "\n",
       "[2896 rows x 10 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_df[concrete_df.Bigram==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Bigram</th>\n",
       "      <th>Conc.M</th>\n",
       "      <th>Conc.SD</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent_known</th>\n",
       "      <th>SUBTLEX</th>\n",
       "      <th>Dom_Pos</th>\n",
       "      <th>stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Word, Bigram, Conc.M, Conc.SD, Unknown, Total, Percent_known, SUBTLEX, Dom_Pos, stem]\n",
       "Index: []"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#There is no Nan value in Conc.M column\n",
    "concrete_df[concrete_df['Conc.M'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are we gonna consider bigrams in this dataset, given it's only a small fraction ~ 8% in size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.04"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(concrete_df['Conc.M'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(concrete_df['Conc.M'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concreteness values range from 1 - 5, we could possible use the inverse value of concreteness to scale it to a 0-1 range and give easier words less weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_words = list(concrete_df['Word'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_words = list(concrete_df['stem'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39954"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(concrete_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_complement = [word for word in words_in_vector if word not in concrete_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "870"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(concrete_complement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['franc',\n",
       " 'english',\n",
       " 'german',\n",
       " 'british',\n",
       " 'calai',\n",
       " 'england',\n",
       " 'london',\n",
       " 'french',\n",
       " 'largest',\n",
       " 'ndash',\n",
       " 'germani',\n",
       " 'japanes',\n",
       " 'york',\n",
       " 'america',\n",
       " 'australia',\n",
       " 'nord',\n",
       " 'italian',\n",
       " 'william',\n",
       " 'aisn',\n",
       " 'europ',\n",
       " 'picardi',\n",
       " 'pakistan',\n",
       " 'greek',\n",
       " 'european',\n",
       " 'georg',\n",
       " 'spanish',\n",
       " 'normandi',\n",
       " 'india',\n",
       " 'calvado',\n",
       " 'california',\n",
       " 'switzerland',\n",
       " 'canton',\n",
       " 'canada',\n",
       " 'charl',\n",
       " 'australian',\n",
       " 'itali',\n",
       " 'henri',\n",
       " 'loir',\n",
       " 'canadian',\n",
       " 'scotland',\n",
       " 'girond',\n",
       " 'mari',\n",
       " 'robert',\n",
       " 'ireland',\n",
       " 'africa',\n",
       " 'paul',\n",
       " 'latin',\n",
       " 'florida',\n",
       " 'brazilian',\n",
       " 'aquitain',\n",
       " 'david',\n",
       " 'russian',\n",
       " 'indian',\n",
       " 'chines',\n",
       " 'michael',\n",
       " 'asia',\n",
       " 'pari',\n",
       " 'richard',\n",
       " 'berlin',\n",
       " 'scottish',\n",
       " 'dutch',\n",
       " 'spain',\n",
       " 'iowa',\n",
       " 'disney',\n",
       " 'thoma',\n",
       " 'wale',\n",
       " 'edward',\n",
       " 'britain',\n",
       " 'alp',\n",
       " 'loui',\n",
       " 'mexico',\n",
       " 'oldest',\n",
       " 'washington',\n",
       " 'virginia',\n",
       " 'chicago',\n",
       " 'russia',\n",
       " 'larger',\n",
       " 'texa',\n",
       " 'partement',\n",
       " 'victoria',\n",
       " 'irish',\n",
       " 'centr',\n",
       " 'harri',\n",
       " 'african',\n",
       " 'nobel',\n",
       " 'austria',\n",
       " 'netherland',\n",
       " 'belgian',\n",
       " 'oklahoma',\n",
       " 'mario',\n",
       " 'zealand',\n",
       " 'jupit',\n",
       " 'romania',\n",
       " 'joseph',\n",
       " 'sarth',\n",
       " 'illinoi',\n",
       " 'armenian',\n",
       " 'austrian',\n",
       " 'nazi',\n",
       " 'manchest',\n",
       " 'carolina',\n",
       " 'poland',\n",
       " 'jesu',\n",
       " 'korea',\n",
       " 'elizabeth',\n",
       " 'prix',\n",
       " 'earlier',\n",
       " 'greatest',\n",
       " 'korean',\n",
       " 'egypt',\n",
       " 'rome',\n",
       " 'swedish',\n",
       " 'alexand',\n",
       " 'santa',\n",
       " 'saturn',\n",
       " 'scott',\n",
       " 'persian',\n",
       " 'andrew',\n",
       " 'sweden',\n",
       " 'georgia',\n",
       " 'ohio',\n",
       " 'maria',\n",
       " 'vienna',\n",
       " 'melbourn',\n",
       " 'daniel',\n",
       " 'kentucki',\n",
       " 'ontario',\n",
       " 'portugues',\n",
       " 'francisco',\n",
       " 'provenc',\n",
       " 'pennsylvania',\n",
       " 'tehsil',\n",
       " 'columbia',\n",
       " 'isbn',\n",
       " 'chri',\n",
       " 'linux',\n",
       " 'arthur',\n",
       " 'michigan',\n",
       " 'boston',\n",
       " 'kilometr',\n",
       " 'earliest',\n",
       " 'metr',\n",
       " 'longest',\n",
       " 'khan',\n",
       " 'hungari',\n",
       " 'sydney',\n",
       " 'mayenn',\n",
       " 'massachusett',\n",
       " 'iran',\n",
       " 'microsoft',\n",
       " 'johann',\n",
       " 'albert',\n",
       " 'abbey',\n",
       " 'rhine',\n",
       " 'punjab',\n",
       " 'belgium',\n",
       " 'ann',\n",
       " 'frederick',\n",
       " 'kelli',\n",
       " 'stanley',\n",
       " 'czech',\n",
       " 'turkish',\n",
       " 'alabama',\n",
       " 'mississippi',\n",
       " 'indiana',\n",
       " 'theatr',\n",
       " 'swiss',\n",
       " 'azur',\n",
       " 'toronto',\n",
       " 'israel',\n",
       " 'kashmir',\n",
       " 'kong',\n",
       " 'christoph',\n",
       " 'denmark',\n",
       " 'greec',\n",
       " 'singapor',\n",
       " 'aub',\n",
       " 'jackson',\n",
       " 'saxoni',\n",
       " 'walt',\n",
       " 'alaska',\n",
       " 'julian',\n",
       " 'asian',\n",
       " 'steve',\n",
       " 'cambridg',\n",
       " 'gregorian',\n",
       " 'taylor',\n",
       " 'armenia',\n",
       " 'moscow',\n",
       " 'norway',\n",
       " 'kansa',\n",
       " 'minnesota',\n",
       " 'portug',\n",
       " 'walter',\n",
       " 'simpson',\n",
       " 'pierr',\n",
       " 'hamilton',\n",
       " 'carlo',\n",
       " 'ross',\n",
       " 'ardãƒ',\n",
       " 'argentina',\n",
       " 'caribbean',\n",
       " 'finland',\n",
       " 'robinson',\n",
       " 'colorado',\n",
       " 'munich',\n",
       " 'florenc',\n",
       " 'baden',\n",
       " 'dominican',\n",
       " 'lincoln',\n",
       " 'smackdown',\n",
       " 'grammi',\n",
       " 'davi',\n",
       " 'jane',\n",
       " 'abbottabad',\n",
       " 'yorkshir',\n",
       " 'christ',\n",
       " 'philip',\n",
       " 'aargau',\n",
       " 'wilson',\n",
       " 'hitler',\n",
       " 'franci',\n",
       " 'simon',\n",
       " 'montreal',\n",
       " 'hong',\n",
       " 'stephen',\n",
       " 'jew',\n",
       " 'vietnam',\n",
       " 'hungarian',\n",
       " 'organis',\n",
       " 'benjamin',\n",
       " 'egyptian',\n",
       " 'danish',\n",
       " 'tokyo',\n",
       " 'colour',\n",
       " 'philippin',\n",
       " 'jone',\n",
       " 'karl',\n",
       " 'billi',\n",
       " 'prefectur',\n",
       " 'smallest',\n",
       " 'bavaria',\n",
       " 'pokãƒ',\n",
       " 'matthew',\n",
       " 'johnson',\n",
       " 'fifa',\n",
       " 'hollywood',\n",
       " 'youngest',\n",
       " 'mont',\n",
       " 'milan',\n",
       " 'wilhelm',\n",
       " 'brian',\n",
       " 'argentin',\n",
       " 'afghanistan',\n",
       " 'quebec',\n",
       " 'neptun',\n",
       " 'detroit',\n",
       " 'iraq',\n",
       " 'geneva',\n",
       " 'norwegian',\n",
       " 'samuel',\n",
       " 'madrid',\n",
       " 'harrison',\n",
       " 'missouri',\n",
       " 'taiwan',\n",
       " 'sarah',\n",
       " 'anna',\n",
       " 'mexican',\n",
       " 'arizona',\n",
       " 'paulo',\n",
       " 'maya',\n",
       " 'michel',\n",
       " 'alfr',\n",
       " 'graham',\n",
       " 'chile',\n",
       " 'puerto',\n",
       " 'juan',\n",
       " 'muhammad',\n",
       " 'westphalia',\n",
       " 'warner',\n",
       " 'philadelphia',\n",
       " 'friedrich',\n",
       " 'vancouv',\n",
       " 'vendãƒ',\n",
       " 'birmingham',\n",
       " 'tallest',\n",
       " 'santo',\n",
       " 'carl',\n",
       " 'ferdinand',\n",
       " 'finnish',\n",
       " 'pittsburgh',\n",
       " 'patrick',\n",
       " 'wisconsin',\n",
       " 'caesar',\n",
       " 'beatl',\n",
       " 'ticino',\n",
       " 'bangladesh',\n",
       " 'hawaii',\n",
       " 'vauclus',\n",
       " 'wrestlemania',\n",
       " 'westminst',\n",
       " 'clark',\n",
       " 'bruce',\n",
       " 'jefferson',\n",
       " 'hugh',\n",
       " 'duchi',\n",
       " 'bobbi',\n",
       " 'steven',\n",
       " 'lewi',\n",
       " 'hebrew',\n",
       " 'diego',\n",
       " 'ardã',\n",
       " 'catherin',\n",
       " 'kennedi',\n",
       " 'cuba',\n",
       " 'indonesia',\n",
       " 'jordan',\n",
       " 'arkansa',\n",
       " 'gabriel',\n",
       " 'viii',\n",
       " 'howard',\n",
       " 'anthoni',\n",
       " 'byzantin',\n",
       " 'monro',\n",
       " 'ukrain',\n",
       " 'tennesse',\n",
       " 'walloon',\n",
       " 'idaho',\n",
       " 'welsh',\n",
       " 'iceland',\n",
       " 'liverpool',\n",
       " 'glasgow',\n",
       " 'indo',\n",
       " 'dougla',\n",
       " 'urdu',\n",
       " 'russel',\n",
       " 'eric',\n",
       " 'orton',\n",
       " 'lawrenc',\n",
       " 'anglo',\n",
       " 'bach',\n",
       " 'edinburgh',\n",
       " 'pakistani',\n",
       " 'flander',\n",
       " 'iranian',\n",
       " 'baptist',\n",
       " 'lennon',\n",
       " 'franklin',\n",
       " 'seattl',\n",
       " 'cena',\n",
       " 'atlanta',\n",
       " 'homer',\n",
       " 'homo',\n",
       " 'hess',\n",
       " 'austen',\n",
       " 'andrea',\n",
       " 'jerusalem',\n",
       " 'uranu',\n",
       " 'alic',\n",
       " 'rico',\n",
       " 'kevin',\n",
       " 'antonio',\n",
       " 'wagner',\n",
       " 'louisiana',\n",
       " 'tamil',\n",
       " 'barcelona',\n",
       " 'connecticut',\n",
       " 'jeff',\n",
       " 'uefa',\n",
       " 'bengal',\n",
       " 'tram',\n",
       " 'shakespear',\n",
       " 'theorem',\n",
       " 'prussia',\n",
       " 'britannica',\n",
       " 'haiti',\n",
       " 'labour',\n",
       " 'austin',\n",
       " 'alan',\n",
       " 'clinton',\n",
       " 'hart',\n",
       " 'jacqu',\n",
       " 'perci',\n",
       " 'arnold',\n",
       " 'atlantiqu',\n",
       " 'nichola',\n",
       " 'barri',\n",
       " 'leed',\n",
       " 'hugo',\n",
       " 'allen',\n",
       " 'manhattan',\n",
       " 'giovanni',\n",
       " 'thailand',\n",
       " 'edmund',\n",
       " 'rhode',\n",
       " 'han',\n",
       " 'carter',\n",
       " 'franz',\n",
       " 'emir',\n",
       " 'vector',\n",
       " 'gordon',\n",
       " 'otto',\n",
       " 'romanian',\n",
       " 'shire',\n",
       " 'closest',\n",
       " 'hercul',\n",
       " 'zeu',\n",
       " 'canadien',\n",
       " 'athen',\n",
       " 'miami',\n",
       " 'genera',\n",
       " 'eclipt',\n",
       " 'oscar',\n",
       " 'helen',\n",
       " 'serbia',\n",
       " 'ernst',\n",
       " 'roosevelt',\n",
       " 'margaret',\n",
       " 'cleveland',\n",
       " 'norman',\n",
       " 'theodor',\n",
       " 'eddi',\n",
       " 'amsterdam',\n",
       " 'forb',\n",
       " 'lowest',\n",
       " 'pokã',\n",
       " 'jura',\n",
       " 'bit',\n",
       " 'batista',\n",
       " 'baltimor',\n",
       " 'hampshir',\n",
       " 'solothurn',\n",
       " 'gustav',\n",
       " 'houston',\n",
       " 'jammu',\n",
       " 'jonathan',\n",
       " 'caliph',\n",
       " 'queensland',\n",
       " 'nors',\n",
       " 'syria',\n",
       " 'brabant',\n",
       " 'marco',\n",
       " 'phillip',\n",
       " 'maryland',\n",
       " 'shah',\n",
       " 'madison',\n",
       " 'kurt',\n",
       " 'josã',\n",
       " 'nelson',\n",
       " 'stuart',\n",
       " 'mcmahon',\n",
       " 'brooklyn',\n",
       " 'augustu',\n",
       " 'vega',\n",
       " 'stewart',\n",
       " 'jerri',\n",
       " 'whedon',\n",
       " 'dakota',\n",
       " 'kent',\n",
       " 'malaysia',\n",
       " 'thompson',\n",
       " 'johnni',\n",
       " 'honour',\n",
       " 'sindh',\n",
       " 'peru',\n",
       " 'reich',\n",
       " 'neighbour',\n",
       " 'tuscani',\n",
       " 'herbert',\n",
       " 'holland',\n",
       " 'nasa',\n",
       " 'isra',\n",
       " 'weimar',\n",
       " 'bouch',\n",
       " 'venic',\n",
       " 'ukrainian',\n",
       " 'saxon',\n",
       " 'guerrero',\n",
       " 'louis',\n",
       " 'francesco',\n",
       " 'renault',\n",
       " 'mccartney',\n",
       " 'basilica',\n",
       " 'emmi',\n",
       " 'leones',\n",
       " 'indu',\n",
       " 'slovakia',\n",
       " 'mozart',\n",
       " 'soni',\n",
       " 'amazon',\n",
       " 'lithuania',\n",
       " 'vincent',\n",
       " 'aberdeen',\n",
       " 'lui',\n",
       " 'juliu',\n",
       " 'bernard',\n",
       " 'anglican',\n",
       " 'croatian',\n",
       " 'slavic',\n",
       " 'dave',\n",
       " 'napl',\n",
       " 'janeiro',\n",
       " 'laureat',\n",
       " 'fastest',\n",
       " 'thame',\n",
       " 'utah',\n",
       " 'wright',\n",
       " 'luxembourg',\n",
       " 'nuremberg',\n",
       " 'wayn',\n",
       " 'gregori',\n",
       " 'costa',\n",
       " 'anton',\n",
       " 'pyrã',\n",
       " 'leipzig',\n",
       " 'luke',\n",
       " 'suffolk',\n",
       " 'newfoundland',\n",
       " 'nile',\n",
       " 'arabia',\n",
       " 'oregon',\n",
       " 'constantin',\n",
       " 'nicola',\n",
       " 'charli',\n",
       " 'newton',\n",
       " 'anderson',\n",
       " 'croatia',\n",
       " 'tibetan',\n",
       " 'gilbert',\n",
       " 'strongest',\n",
       " 'terri',\n",
       " 'antarctica',\n",
       " 'luca',\n",
       " 'knowl',\n",
       " 'ivan',\n",
       " 'donald',\n",
       " 'bueno',\n",
       " 'unesco',\n",
       " 'manitoba',\n",
       " 'gari',\n",
       " 'isaac',\n",
       " 'luci',\n",
       " 'willi',\n",
       " 'suceava',\n",
       " 'persia',\n",
       " 'castil',\n",
       " 'cameron',\n",
       " 'ronald',\n",
       " 'khyber',\n",
       " 'leon',\n",
       " 'barbara',\n",
       " 'vendã',\n",
       " 'harvard',\n",
       " 'abraham',\n",
       " 'kirbi',\n",
       " 'winger',\n",
       " 'thuringia',\n",
       " 'petersburg',\n",
       " 'guin',\n",
       " 'salzburg',\n",
       " 'apollo',\n",
       " 'dalla',\n",
       " 'ryan',\n",
       " 'ludwig',\n",
       " 'saudi',\n",
       " 'trojan',\n",
       " 'flora',\n",
       " 'arrondiss',\n",
       " 'mongol',\n",
       " 'franco',\n",
       " 'columbu',\n",
       " 'dublin',\n",
       " 'teau',\n",
       " 'campbel',\n",
       " 'berkeley',\n",
       " 'nevada',\n",
       " 'mali',\n",
       " 'warsaw',\n",
       " 'wider',\n",
       " 'flemish',\n",
       " 'subfamili',\n",
       " 'richmond',\n",
       " 'vike',\n",
       " 'tampa',\n",
       " 'heinrich',\n",
       " 'sheffield',\n",
       " 'ralph',\n",
       " 'volkswagen',\n",
       " 'orlean',\n",
       " 'wiki',\n",
       " 'extratrop',\n",
       " 'brandenburg',\n",
       " 'ubuntu',\n",
       " 'sicili',\n",
       " 'santiago',\n",
       " 'prussian',\n",
       " 'pakhtunkhwa',\n",
       " 'kane',\n",
       " 'stockholm',\n",
       " 'buffi',\n",
       " 'josãƒ',\n",
       " 'murray',\n",
       " 'sebastian',\n",
       " 'bulgaria',\n",
       " 'ernest',\n",
       " 'raymond',\n",
       " 'piper',\n",
       " 'morgan',\n",
       " 'manuel',\n",
       " 'colombia',\n",
       " 'jason',\n",
       " 'bundesliga',\n",
       " 'soundgarden',\n",
       " 'harbour',\n",
       " 'beij',\n",
       " 'chakwal',\n",
       " 'sussex',\n",
       " 'vinc',\n",
       " 'neil',\n",
       " 'alex',\n",
       " 'blackhawk',\n",
       " 'empress',\n",
       " 'tyler',\n",
       " 'ferrari',\n",
       " 'yugoslavia',\n",
       " 'furbi',\n",
       " 'tommi',\n",
       " 'arabian',\n",
       " 'debian',\n",
       " 'tasmania',\n",
       " 'pragu',\n",
       " 'bermuda',\n",
       " 'chãƒ',\n",
       " 'hume',\n",
       " 'lebanon',\n",
       " 'alexandra',\n",
       " 'serbian',\n",
       " 'anastasia',\n",
       " 'alberta',\n",
       " 'hudson',\n",
       " 'jacob',\n",
       " 'lanka',\n",
       " 'craig',\n",
       " 'bristol',\n",
       " 'baltic',\n",
       " 'ussr',\n",
       " 'marcu',\n",
       " 'ottawa',\n",
       " 'jamaica',\n",
       " 'jurass',\n",
       " 'pedro',\n",
       " 'victorian',\n",
       " 'tramway',\n",
       " 'orlando',\n",
       " 'spencer',\n",
       " 'venezuela',\n",
       " 'sega',\n",
       " 'slovak',\n",
       " 'joan',\n",
       " 'dolj',\n",
       " 'parker',\n",
       " 'norfolk',\n",
       " 'facto',\n",
       " 'valencia',\n",
       " 'haut',\n",
       " 'powel',\n",
       " 'susan',\n",
       " 'wolfgang',\n",
       " 'leonard',\n",
       " 'esperanto',\n",
       " 'collin',\n",
       " 'keith',\n",
       " 'surrey',\n",
       " 'alexandria',\n",
       " 'adolf',\n",
       " 'medici',\n",
       " 'andi',\n",
       " 'hermann',\n",
       " 'warren',\n",
       " 'edgar',\n",
       " 'lithuanian',\n",
       " 'tibet',\n",
       " 'windsor',\n",
       " 'avon',\n",
       " 'fernando',\n",
       " 'pradesh',\n",
       " 'burton',\n",
       " 'ethiopia',\n",
       " 'delhi',\n",
       " 'leonardo',\n",
       " 'latvia',\n",
       " 'bryan',\n",
       " 'fischer',\n",
       " 'calvin',\n",
       " 'burma',\n",
       " 'devon',\n",
       " 'isabella',\n",
       " 'chelsea',\n",
       " 'bart',\n",
       " 'thurgau',\n",
       " 'danni',\n",
       " 'antil',\n",
       " 'stronger',\n",
       " 'philipp',\n",
       " 'nigeria',\n",
       " 'bruin',\n",
       " 'claud',\n",
       " 'cyril',\n",
       " 'shawn',\n",
       " 'fewer',\n",
       " 'monaco',\n",
       " 'mauric',\n",
       " 'versail',\n",
       " 'cornel',\n",
       " 'floyd',\n",
       " 'torr',\n",
       " 'greenland',\n",
       " 'perth',\n",
       " 'alban',\n",
       " 'aaron',\n",
       " 'nixon',\n",
       " 'morri',\n",
       " 'brighton',\n",
       " 'cole',\n",
       " 'silva',\n",
       " 'pluto',\n",
       " 'wallac',\n",
       " 'lorenzo',\n",
       " 'inca',\n",
       " 'limburg',\n",
       " 'newcastl',\n",
       " 'sudan',\n",
       " 'tico',\n",
       " 'defenc',\n",
       " 'aragon',\n",
       " 'fred',\n",
       " 'luigi',\n",
       " 'jose',\n",
       " 'harold',\n",
       " 'extant',\n",
       " 'hainaut',\n",
       " 'horton',\n",
       " 'webster',\n",
       " 'estonia',\n",
       " 'canuck',\n",
       " 'stanford',\n",
       " 'nascar',\n",
       " 'ncaa',\n",
       " 'vill',\n",
       " 'somerset',\n",
       " 'buddha',\n",
       " 'waterloo',\n",
       " 'romeo',\n",
       " 'kate',\n",
       " 'malta',\n",
       " 'salvador',\n",
       " 'rick',\n",
       " 'denni',\n",
       " 'evan',\n",
       " 'calgari',\n",
       " 'hindenburg',\n",
       " 'oblast',\n",
       " 'karachi',\n",
       " 'echidna',\n",
       " 'watson',\n",
       " 'nato',\n",
       " 'toyota',\n",
       " 'rudolf',\n",
       " 'antwerp',\n",
       " 'kati',\n",
       " 'livingston',\n",
       " 'colin',\n",
       " 'pete',\n",
       " 'chilean',\n",
       " 'luther',\n",
       " 'scala',\n",
       " 'melina',\n",
       " 'bern',\n",
       " 'pablo',\n",
       " 'domingo',\n",
       " 'maxwel',\n",
       " 'helsinki',\n",
       " 'owen',\n",
       " 'keyn',\n",
       " 'azerbaijan',\n",
       " 'greg',\n",
       " 'slovenia',\n",
       " 'chevrolet',\n",
       " 'rica',\n",
       " 'beyoncã',\n",
       " 'reagan',\n",
       " 'mecklenburg',\n",
       " 'boe',\n",
       " 'krei',\n",
       " 'indonesian',\n",
       " 'jess',\n",
       " 'pichilemu',\n",
       " 'tanzania',\n",
       " 'disambigu',\n",
       " 'antoin',\n",
       " 'cornwal',\n",
       " 'slower',\n",
       " 'regent',\n",
       " 'coburg',\n",
       " 'ruth',\n",
       " 'verd',\n",
       " 'pascal',\n",
       " 'cruz',\n",
       " 'edmonton',\n",
       " 'derbyshir',\n",
       " 'indianapoli',\n",
       " 'osaka',\n",
       " 'scot',\n",
       " 'busiest',\n",
       " 'chad',\n",
       " 'lisa',\n",
       " 'gettysburg',\n",
       " 'sunderland',\n",
       " 'aang',\n",
       " 'dant',\n",
       " 'connor',\n",
       " 'lulu',\n",
       " 'olympiad',\n",
       " 'lancashir',\n",
       " 'princeton',\n",
       " 'thai',\n",
       " 'phil',\n",
       " 'vladimir',\n",
       " 'bavarian',\n",
       " 'ming',\n",
       " 'manga',\n",
       " 'berg',\n",
       " 'oslo',\n",
       " 'fritz',\n",
       " 'rttemberg',\n",
       " 'grameen',\n",
       " 'albani',\n",
       " 'troy',\n",
       " 'lutheran',\n",
       " 'nanci',\n",
       " 'lang',\n",
       " 'benoit',\n",
       " 'gotha',\n",
       " 'socrat',\n",
       " 'hanov',\n",
       " 'amherst',\n",
       " 'bismarck',\n",
       " 'lombardi',\n",
       " 'roberto',\n",
       " 'etymolog',\n",
       " 'malcolm',\n",
       " 'cincinnati',\n",
       " 'czechoslovakia',\n",
       " 'kart',\n",
       " 'stallon',\n",
       " 'sean',\n",
       " 'todd',\n",
       " 'denver',\n",
       " 'baja',\n",
       " 'yokohama',\n",
       " 'ipswich',\n",
       " 'brandon',\n",
       " 'copenhagen',\n",
       " 'amadeu',\n",
       " 'felix',\n",
       " 'memphi',\n",
       " 'terminu',\n",
       " 'congo',\n",
       " 'beethoven',\n",
       " 'montana']"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_complement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_intersect = [word for word in words_in_vector if word in concrete_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2603"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(concrete_intersect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unit',\n",
       " 'commun',\n",
       " 'depart',\n",
       " 'region',\n",
       " 'state',\n",
       " 'american',\n",
       " 'includ',\n",
       " 'call',\n",
       " 'nation',\n",
       " 'play',\n",
       " 'area',\n",
       " 'locat',\n",
       " 'univers',\n",
       " 'district',\n",
       " 'releas',\n",
       " 'year',\n",
       " 'refer',\n",
       " 'name',\n",
       " 'album',\n",
       " 'system',\n",
       " 'seri',\n",
       " 'former',\n",
       " 'origin',\n",
       " 'later',\n",
       " 'septemb',\n",
       " 'januari',\n",
       " 'current',\n",
       " 'juli',\n",
       " 'octob',\n",
       " 'august',\n",
       " 'centuri',\n",
       " 'popul',\n",
       " 'leagu',\n",
       " 'june',\n",
       " 'decemb',\n",
       " 'provinc',\n",
       " 'april',\n",
       " 'novemb',\n",
       " 'produc',\n",
       " 'work',\n",
       " 'februari',\n",
       " 'develop',\n",
       " 'base',\n",
       " 'award',\n",
       " 'intern',\n",
       " 'presid',\n",
       " 'john',\n",
       " 'record',\n",
       " 'start',\n",
       " 'form',\n",
       " 'creat',\n",
       " 'main',\n",
       " 'usual',\n",
       " 'central',\n",
       " 'offici',\n",
       " 'municip',\n",
       " 'forc',\n",
       " 'organ',\n",
       " 'design',\n",
       " 'common',\n",
       " 'perform',\n",
       " 'televis',\n",
       " 'use',\n",
       " 'type',\n",
       " 'publish',\n",
       " 'speci',\n",
       " 'game',\n",
       " 'profession',\n",
       " 'championship',\n",
       " 'event',\n",
       " 'featur',\n",
       " 'appear',\n",
       " 'popular',\n",
       " 'found',\n",
       " 'period',\n",
       " 'union',\n",
       " 'although',\n",
       " 'oper',\n",
       " 'exampl',\n",
       " 'roman',\n",
       " 'gener',\n",
       " 'charact',\n",
       " 'bass',\n",
       " 'video',\n",
       " 'associ',\n",
       " 'human',\n",
       " 'modern',\n",
       " 'hurrican',\n",
       " 'japan',\n",
       " 'famou',\n",
       " 'tropic',\n",
       " 'member',\n",
       " 'anim',\n",
       " 'success',\n",
       " 'republ',\n",
       " 'natur',\n",
       " 'time',\n",
       " 'compos',\n",
       " 'serv',\n",
       " 'product',\n",
       " 'show',\n",
       " 'along',\n",
       " 'contain',\n",
       " 'council',\n",
       " 'within',\n",
       " 'elect',\n",
       " 'role',\n",
       " 'chang',\n",
       " 'comput',\n",
       " 'consid',\n",
       " 'support',\n",
       " 'countri',\n",
       " 'version',\n",
       " 'result',\n",
       " 'move',\n",
       " 'christian',\n",
       " 'control',\n",
       " 'polit',\n",
       " 'jam',\n",
       " 'independ',\n",
       " 'tradit',\n",
       " 'program',\n",
       " 'continu',\n",
       " 'local',\n",
       " 'accord',\n",
       " 'divis',\n",
       " 'total',\n",
       " 'establish',\n",
       " 'actor',\n",
       " 'complet',\n",
       " 'career',\n",
       " 'minist',\n",
       " 'scienc',\n",
       " 'allow',\n",
       " 'empir',\n",
       " 'final',\n",
       " 'island',\n",
       " 'hockey',\n",
       " 'northwest',\n",
       " 'cultur',\n",
       " 'consist',\n",
       " 'posit',\n",
       " 'articl',\n",
       " 'footbal',\n",
       " 'provid',\n",
       " 'relat',\n",
       " 'commonli',\n",
       " 'repres',\n",
       " 'border',\n",
       " 'similar',\n",
       " 'wrestl',\n",
       " 'emperor',\n",
       " 'open',\n",
       " 'star',\n",
       " 'link',\n",
       " 'receiv',\n",
       " 'rang',\n",
       " 'activ',\n",
       " 'studi',\n",
       " 'part',\n",
       " 'join',\n",
       " 'caus',\n",
       " 'remain',\n",
       " 'writer',\n",
       " 'feder',\n",
       " 'exist',\n",
       " 'websit',\n",
       " 'novel',\n",
       " 'special',\n",
       " 'administr',\n",
       " 'day',\n",
       " 'process',\n",
       " 'territori',\n",
       " 'mean',\n",
       " 'network',\n",
       " 'inform',\n",
       " 'studio',\n",
       " 'pay',\n",
       " 'replac',\n",
       " 'edit',\n",
       " 'sourc',\n",
       " 'book',\n",
       " 'describ',\n",
       " 'ancient',\n",
       " 'histor',\n",
       " 'style',\n",
       " 'militari',\n",
       " 'director',\n",
       " 'mile',\n",
       " 'addit',\n",
       " 'fiction',\n",
       " 'place',\n",
       " 'educ',\n",
       " 'energi',\n",
       " 'institut',\n",
       " 'chemic',\n",
       " 'movement',\n",
       " 'collect',\n",
       " 'variou',\n",
       " 'physic',\n",
       " 'industri',\n",
       " 'sign',\n",
       " 'opera',\n",
       " 'languag',\n",
       " 'student',\n",
       " 'follow',\n",
       " 'formula',\n",
       " 'theori',\n",
       " 'orchestra',\n",
       " 'project',\n",
       " 'episod',\n",
       " 'prime',\n",
       " 'object',\n",
       " 'atlant',\n",
       " 'civil',\n",
       " 'tour',\n",
       " 'materi',\n",
       " 'discov',\n",
       " 'censu',\n",
       " 'reach',\n",
       " 'structur',\n",
       " 'element',\n",
       " 'standard',\n",
       " 'research',\n",
       " 'parliament',\n",
       " 'effect',\n",
       " 'classic',\n",
       " 'entertain',\n",
       " 'plant',\n",
       " 'team',\n",
       " 'site',\n",
       " 'race',\n",
       " 'model',\n",
       " 'song',\n",
       " 'occur',\n",
       " 'film',\n",
       " 'olymp',\n",
       " 'sport',\n",
       " 'recent',\n",
       " 'imag',\n",
       " 'actress',\n",
       " 'other',\n",
       " 'port',\n",
       " 'southwest',\n",
       " 'citi',\n",
       " 'retir',\n",
       " 'number',\n",
       " 'rule',\n",
       " 'softwar',\n",
       " 'win',\n",
       " 'group',\n",
       " 'stadium',\n",
       " 'social',\n",
       " 'user',\n",
       " 'cathol',\n",
       " 'involv',\n",
       " 'highest',\n",
       " 'cover',\n",
       " 'train',\n",
       " 'combin',\n",
       " 'almost',\n",
       " 'lead',\n",
       " 'minor',\n",
       " 'across',\n",
       " 'speak',\n",
       " 'return',\n",
       " 'increas',\n",
       " 'typic',\n",
       " 'divid',\n",
       " 'approxim',\n",
       " 'societi',\n",
       " 'live',\n",
       " 'person',\n",
       " 'influenc',\n",
       " 'guitar',\n",
       " 'announc',\n",
       " 'debut',\n",
       " 'engin',\n",
       " 'critic',\n",
       " 'symbol',\n",
       " 'initi',\n",
       " 'execut',\n",
       " 'musician',\n",
       " 'player',\n",
       " 'duke',\n",
       " 'construct',\n",
       " 'orbit',\n",
       " 'femal',\n",
       " 'instrument',\n",
       " 'claim',\n",
       " 'direct',\n",
       " 'end',\n",
       " 'lower',\n",
       " 'travel',\n",
       " 'simpli',\n",
       " 'introduc',\n",
       " 'connect',\n",
       " 'issu',\n",
       " 'airport',\n",
       " 'translat',\n",
       " 'pass',\n",
       " 'soviet',\n",
       " 'peter',\n",
       " 'experi',\n",
       " 'author',\n",
       " 'especi',\n",
       " 'politician',\n",
       " 'governor',\n",
       " 'northwestern',\n",
       " 'situat',\n",
       " 'altern',\n",
       " 'individu',\n",
       " 'genu',\n",
       " 'throughout',\n",
       " 'report',\n",
       " 'manag',\n",
       " 'rel',\n",
       " 'function',\n",
       " 'premier',\n",
       " 'requir',\n",
       " 'mountain',\n",
       " 'act',\n",
       " 'nativ',\n",
       " 'text',\n",
       " 'brand',\n",
       " 'mass',\n",
       " 'distribut',\n",
       " 'electron',\n",
       " 'music',\n",
       " 'add',\n",
       " 'econom',\n",
       " 'grow',\n",
       " 'wikipedia',\n",
       " 'avail',\n",
       " 'word',\n",
       " 'angel',\n",
       " 'practic',\n",
       " 'festiv',\n",
       " 'point',\n",
       " 'defeat',\n",
       " 'command',\n",
       " 'notabl',\n",
       " 'problem',\n",
       " 'come',\n",
       " 'temperatur',\n",
       " 'limit',\n",
       " 'defin',\n",
       " 'format',\n",
       " 'specif',\n",
       " 'data',\n",
       " 'statist',\n",
       " 'academi',\n",
       " 'normal',\n",
       " 'cathedr',\n",
       " 'coloni',\n",
       " 'respons',\n",
       " 'dynasti',\n",
       " 'channel',\n",
       " 'celebr',\n",
       " 'distanc',\n",
       " 'close',\n",
       " 'rank',\n",
       " 'action',\n",
       " 'pacif',\n",
       " 'martin',\n",
       " 'servic',\n",
       " 'deriv',\n",
       " 'help',\n",
       " 'super',\n",
       " 'planet',\n",
       " 'present',\n",
       " 'averag',\n",
       " 'declar',\n",
       " 'degre',\n",
       " 'secretari',\n",
       " 'democrat',\n",
       " 'page',\n",
       " 'categori',\n",
       " 'section',\n",
       " 'term',\n",
       " 'window',\n",
       " 'smaller',\n",
       " 'secur',\n",
       " 'art',\n",
       " 'mainli',\n",
       " 'estim',\n",
       " 'turn',\n",
       " 'date',\n",
       " 'resid',\n",
       " 'attempt',\n",
       " 'borough',\n",
       " 'suggest',\n",
       " 'constitut',\n",
       " 'museum',\n",
       " 'conduct',\n",
       " 'note',\n",
       " 'entir',\n",
       " 'statu',\n",
       " 'make',\n",
       " 'inhabit',\n",
       " 'label',\n",
       " 'promot',\n",
       " 'select',\n",
       " 'muslim',\n",
       " 'line',\n",
       " 'nintendo',\n",
       " 'commerci',\n",
       " 'scale',\n",
       " 'metropolitan',\n",
       " 'believ',\n",
       " 'thu',\n",
       " 'say',\n",
       " 'method',\n",
       " 'privat',\n",
       " 'nuclear',\n",
       " 'competit',\n",
       " 'attack',\n",
       " 'display',\n",
       " 'month',\n",
       " 'annual',\n",
       " 'express',\n",
       " 'asteroid',\n",
       " 'devic',\n",
       " 'becom',\n",
       " 'islam',\n",
       " 'surround',\n",
       " 'memori',\n",
       " 'cell',\n",
       " 'pope',\n",
       " 'diseas',\n",
       " 'finish',\n",
       " 'own',\n",
       " 'recogn',\n",
       " 'eventu',\n",
       " 'observ',\n",
       " 'surviv',\n",
       " 'right',\n",
       " 'princip',\n",
       " 'decid',\n",
       " 'want',\n",
       " 'vocal',\n",
       " 'list',\n",
       " 'access',\n",
       " 'actual',\n",
       " 'season',\n",
       " 'cyclon',\n",
       " 'arm',\n",
       " 'religi',\n",
       " 'titl',\n",
       " 'school',\n",
       " 'brazil',\n",
       " 'probabl',\n",
       " 'guitarist',\n",
       " 'thing',\n",
       " 'greater',\n",
       " 'concert',\n",
       " 'pressur',\n",
       " 'wide',\n",
       " 'condit',\n",
       " 'transport',\n",
       " 'digit',\n",
       " 'appoint',\n",
       " 'songwrit',\n",
       " 'purpos',\n",
       " 'take',\n",
       " 'treati',\n",
       " 'multipl',\n",
       " 'compound',\n",
       " 'separ',\n",
       " 'higher',\n",
       " 'mechan',\n",
       " 'primari',\n",
       " 'acid',\n",
       " 'mathemat',\n",
       " 'opposit',\n",
       " 'adopt',\n",
       " 'varieti',\n",
       " 'professor',\n",
       " 'singl',\n",
       " 'artist',\n",
       " 'press',\n",
       " 'nomin',\n",
       " 'respect',\n",
       " 'arab',\n",
       " 'lie',\n",
       " 'applic',\n",
       " 'tribe',\n",
       " 'poet',\n",
       " 'media',\n",
       " 'extend',\n",
       " 'comedi',\n",
       " 'plan',\n",
       " 'enter',\n",
       " 'complex',\n",
       " 'measur',\n",
       " 'atom',\n",
       " 'code',\n",
       " 'town',\n",
       " 'distinct',\n",
       " 'achiev',\n",
       " 'hous',\n",
       " 'accept',\n",
       " 'confer',\n",
       " 'numer',\n",
       " 'air',\n",
       " 'technolog',\n",
       " 'depress',\n",
       " 'share',\n",
       " 'explor',\n",
       " 'regard',\n",
       " 'revolut',\n",
       " 'build',\n",
       " 'extrem',\n",
       " 'graduat',\n",
       " 'discoveri',\n",
       " 'particularli',\n",
       " 'worldwid',\n",
       " 'attend',\n",
       " 'foreign',\n",
       " 'protect',\n",
       " 'host',\n",
       " 'govern',\n",
       " 'adult',\n",
       " 'internet',\n",
       " 'medic',\n",
       " 'urban',\n",
       " 'conserv',\n",
       " 'formerli',\n",
       " 'parent',\n",
       " 'corpor',\n",
       " 'copi',\n",
       " 'destroy',\n",
       " 'appli',\n",
       " 'fame',\n",
       " 'architectur',\n",
       " 'extens',\n",
       " 'advanc',\n",
       " 'drama',\n",
       " 'formal',\n",
       " 'account',\n",
       " 'particular',\n",
       " 'foundat',\n",
       " 'futur',\n",
       " 'nicknam',\n",
       " 'signific',\n",
       " 'regular',\n",
       " 'fall',\n",
       " 'draft',\n",
       " 'adam',\n",
       " 'jewish',\n",
       " 'relationship',\n",
       " 'convent',\n",
       " 'contest',\n",
       " 'primarili',\n",
       " 'senat',\n",
       " 'launch',\n",
       " 'properti',\n",
       " 'hold',\n",
       " 'rat',\n",
       " 'literatur',\n",
       " 'manufactur',\n",
       " 'chess',\n",
       " 'peninsula',\n",
       " 'older',\n",
       " 'power',\n",
       " 'carri',\n",
       " 'religion',\n",
       " 'captur',\n",
       " 'zone',\n",
       " 'need',\n",
       " 'founder',\n",
       " 'depend',\n",
       " 'flower',\n",
       " 'ask',\n",
       " 'southeast',\n",
       " 'adapt',\n",
       " 'environ',\n",
       " 'basketbal',\n",
       " 'vote',\n",
       " 'polici',\n",
       " 'philosoph',\n",
       " 'differ',\n",
       " 'despit',\n",
       " 'licens',\n",
       " 'age',\n",
       " 'protest',\n",
       " 'stand',\n",
       " 'solar',\n",
       " 'climat',\n",
       " 'mytholog',\n",
       " 'southeastern',\n",
       " 'document',\n",
       " 'previous',\n",
       " 'southwestern',\n",
       " 'volum',\n",
       " 'wind',\n",
       " 'compar',\n",
       " 'assist',\n",
       " 'symphoni',\n",
       " 'hour',\n",
       " 'legal',\n",
       " 'succeed',\n",
       " 'directli',\n",
       " 'color',\n",
       " 'subsequ',\n",
       " 'brother',\n",
       " 'challeng',\n",
       " 'major',\n",
       " 'contribut',\n",
       " 'invent',\n",
       " 'previou',\n",
       " 'friend',\n",
       " 'theme',\n",
       " 'war',\n",
       " 'campaign',\n",
       " 'mark',\n",
       " 'look',\n",
       " 'defend',\n",
       " 'longer',\n",
       " 'attract',\n",
       " 'carbon',\n",
       " 'decad',\n",
       " 'compet',\n",
       " 'grant',\n",
       " 'begin',\n",
       " 'reduc',\n",
       " 'concept',\n",
       " 'wrestler',\n",
       " 'medal',\n",
       " 'focu',\n",
       " 'compris',\n",
       " 'interest',\n",
       " 'circuit',\n",
       " 'biggest',\n",
       " 'renam',\n",
       " 'paint',\n",
       " 'counti',\n",
       " 'rare',\n",
       " 'biolog',\n",
       " 'definit',\n",
       " 'band',\n",
       " 'mix',\n",
       " 'identifi',\n",
       " 'leav',\n",
       " 'transfer',\n",
       " 'oxford',\n",
       " 'jersey',\n",
       " 'bomb',\n",
       " 'propos',\n",
       " 'station',\n",
       " 'belong',\n",
       " 'onlin',\n",
       " 'emerg',\n",
       " 'sexual',\n",
       " 'athlet',\n",
       " 'offer',\n",
       " 'cycl',\n",
       " 'determin',\n",
       " 'score',\n",
       " 'rais',\n",
       " 'jean',\n",
       " 'indic',\n",
       " 'frequent',\n",
       " 'reform',\n",
       " 'northeast',\n",
       " 'scientif',\n",
       " 'river',\n",
       " 'head',\n",
       " 'commiss',\n",
       " 'adventur',\n",
       " 'scene',\n",
       " 'merg',\n",
       " 'editor',\n",
       " 'scientist',\n",
       " 'pictur',\n",
       " 'gain',\n",
       " 'reign',\n",
       " 'sell',\n",
       " 'occupi',\n",
       " 'evid',\n",
       " 'basic',\n",
       " 'smith',\n",
       " 'field',\n",
       " 'order',\n",
       " 'soccer',\n",
       " 'affect',\n",
       " 'maintain',\n",
       " 'split',\n",
       " 'remov',\n",
       " 'content',\n",
       " 'philosophi',\n",
       " 'promin',\n",
       " 'marin',\n",
       " 'committe',\n",
       " 'cancer',\n",
       " 'bird',\n",
       " 'contract',\n",
       " 'domin',\n",
       " 'run',\n",
       " 'diamet',\n",
       " 'fight',\n",
       " 'composit',\n",
       " 'headquart',\n",
       " 'ford',\n",
       " 'give',\n",
       " 'week',\n",
       " 'particip',\n",
       " 'abil',\n",
       " 'assembl',\n",
       " 'land',\n",
       " 'congress',\n",
       " 'flow',\n",
       " 'core',\n",
       " 'inspir',\n",
       " 'unlik',\n",
       " 'satellit',\n",
       " 'ceremoni',\n",
       " 'imperi',\n",
       " 'liber',\n",
       " 'instruct',\n",
       " 'agenc',\n",
       " 'vehicl',\n",
       " 'mosqu',\n",
       " 'hand',\n",
       " 'ship',\n",
       " 'shape',\n",
       " 'highli',\n",
       " 'anti',\n",
       " 'bishop',\n",
       " 'angl',\n",
       " 'commonwealth',\n",
       " 'overal',\n",
       " 'labor',\n",
       " 'count',\n",
       " 'signal',\n",
       " 'vari',\n",
       " 'happen',\n",
       " 'cast',\n",
       " 'mention',\n",
       " 'solo',\n",
       " 'justic',\n",
       " 'agre',\n",
       " 'younger',\n",
       " 'store',\n",
       " 'techniqu',\n",
       " 'credit',\n",
       " 'tree',\n",
       " 'instal',\n",
       " 'underground',\n",
       " 'sequel',\n",
       " 'tournament',\n",
       " 'entri',\n",
       " 'earn',\n",
       " 'growth',\n",
       " 'creation',\n",
       " 'incorpor',\n",
       " 'fossil',\n",
       " 'boundari',\n",
       " 'affair',\n",
       " 'tell',\n",
       " 'case',\n",
       " 'breed',\n",
       " 'parallel',\n",
       " 'astronom',\n",
       " 'therefor',\n",
       " 'strike',\n",
       " 'track',\n",
       " 'abbrevi',\n",
       " 'kill',\n",
       " 'concentr',\n",
       " 'lyric',\n",
       " 'oxid',\n",
       " 'tripl',\n",
       " 'prevent',\n",
       " 'letter',\n",
       " 'genet',\n",
       " 'drug',\n",
       " 'level',\n",
       " 'prior',\n",
       " 'troop',\n",
       " 'punk',\n",
       " 'way',\n",
       " 'last',\n",
       " 'particl',\n",
       " 'billion',\n",
       " 'compani',\n",
       " 'burn',\n",
       " 'pronounc',\n",
       " 'visit',\n",
       " 'sit',\n",
       " 'offic',\n",
       " 'airlin',\n",
       " 'match',\n",
       " 'equat',\n",
       " 'whether',\n",
       " 'templ',\n",
       " 'approach',\n",
       " 'expand',\n",
       " 'blue',\n",
       " 'geograph',\n",
       " 'concern',\n",
       " 'journal',\n",
       " 'earl',\n",
       " 'employ',\n",
       " 'trophi',\n",
       " 'earthquak',\n",
       " 'address',\n",
       " 'distinguish',\n",
       " 'hill',\n",
       " 'suppli',\n",
       " 'reserv',\n",
       " 'dictionari',\n",
       " 'ministri',\n",
       " 'fantasi',\n",
       " 'mammal',\n",
       " 'agreement',\n",
       " 'alli',\n",
       " 'infect',\n",
       " 'possibl',\n",
       " 'immedi',\n",
       " 'fail',\n",
       " 'agricultur',\n",
       " 'consol',\n",
       " 'classifi',\n",
       " 'famili',\n",
       " 'buri',\n",
       " 'behavior',\n",
       " 'reason',\n",
       " 'biographi',\n",
       " 'detail',\n",
       " 'household',\n",
       " 'legend',\n",
       " 'teach',\n",
       " 'church',\n",
       " 'secondari',\n",
       " 'aircraft',\n",
       " 'goal',\n",
       " 'densiti',\n",
       " 'crime',\n",
       " 'intens',\n",
       " 'convert',\n",
       " 'alon',\n",
       " 'domest',\n",
       " 'evolut',\n",
       " 'view',\n",
       " 'arrang',\n",
       " 'mediev',\n",
       " 'print',\n",
       " 'characterist',\n",
       " 'economi',\n",
       " 'mine',\n",
       " 'vice',\n",
       " 'ident',\n",
       " 'voyag',\n",
       " 'trade',\n",
       " 'layer',\n",
       " 'perman',\n",
       " 'roger',\n",
       " 'death',\n",
       " 'transit',\n",
       " 'preserv',\n",
       " 'staff',\n",
       " 'global',\n",
       " 'meter',\n",
       " 'alphabet',\n",
       " 'tri',\n",
       " 'mobil',\n",
       " 'intellig',\n",
       " 'piec',\n",
       " 'frank',\n",
       " 'decis',\n",
       " 'controversi',\n",
       " 'survivor',\n",
       " 'lack',\n",
       " 'motion',\n",
       " 'extinct',\n",
       " 'historian',\n",
       " 'chapel',\n",
       " 'weight',\n",
       " 'chamber',\n",
       " 'liter',\n",
       " 'orthodox',\n",
       " 'minut',\n",
       " 'communist',\n",
       " 'heritag',\n",
       " 'roll',\n",
       " 'candid',\n",
       " 'bank',\n",
       " 'spell',\n",
       " 'progress',\n",
       " 'law',\n",
       " 'landfal',\n",
       " 'jack',\n",
       " 'suffer',\n",
       " 'water',\n",
       " 'rural',\n",
       " 'trial',\n",
       " 'solid',\n",
       " 'extern',\n",
       " 'solut',\n",
       " 'strength',\n",
       " 'belief',\n",
       " 'car',\n",
       " 'portion',\n",
       " 'socialist',\n",
       " 'agent',\n",
       " 'occasion',\n",
       " 'resist',\n",
       " 'bear',\n",
       " 'outer',\n",
       " 'genr',\n",
       " 'sing',\n",
       " 'roughli',\n",
       " 'find',\n",
       " 'soldier',\n",
       " 'shortli',\n",
       " 'reveal',\n",
       " 'pattern',\n",
       " 'tube',\n",
       " 'larg',\n",
       " 'chart',\n",
       " 'miner',\n",
       " 'tourist',\n",
       " 'broadcast',\n",
       " 'fund',\n",
       " 'gene',\n",
       " 'side',\n",
       " 'technic',\n",
       " 'boy',\n",
       " 'market',\n",
       " 'latter',\n",
       " 'jazz',\n",
       " 'cent',\n",
       " 'uniqu',\n",
       " 'drop',\n",
       " 'basi',\n",
       " 'scholar',\n",
       " 'midfield',\n",
       " 'atmospher',\n",
       " 'draw',\n",
       " 'contemporari',\n",
       " 'son',\n",
       " 'expect',\n",
       " 'traffic',\n",
       " 'idea',\n",
       " 'reaction',\n",
       " 'mathematician',\n",
       " 'difficult',\n",
       " 'multi',\n",
       " 'liquid',\n",
       " 'public',\n",
       " 'mission',\n",
       " 'oliv',\n",
       " 'import',\n",
       " 'prefer',\n",
       " 'script',\n",
       " 'avoid',\n",
       " 'factor',\n",
       " 'descend',\n",
       " 'interst',\n",
       " 'set',\n",
       " 'potenti',\n",
       " 'classif',\n",
       " 'templat',\n",
       " 'folk',\n",
       " 'sunday',\n",
       " 'expans',\n",
       " 'coupl',\n",
       " 'exhibit',\n",
       " 'audienc',\n",
       " 'mediterranean',\n",
       " 'facil',\n",
       " 'senior',\n",
       " 'meet',\n",
       " 'item',\n",
       " 'impact',\n",
       " 'bureau',\n",
       " 'photograph',\n",
       " 'confirm',\n",
       " 'girl',\n",
       " 'principl',\n",
       " 'semi',\n",
       " 'discuss',\n",
       " 'arrest',\n",
       " 'attach',\n",
       " 'disk',\n",
       " 'slightli',\n",
       " 'exclus',\n",
       " 'interact',\n",
       " 'pilot',\n",
       " 'charg',\n",
       " 'christma',\n",
       " 'equip',\n",
       " 'intend',\n",
       " 'interview',\n",
       " 'club',\n",
       " 'reflect',\n",
       " 'pioneer',\n",
       " 'plastic',\n",
       " 'eye',\n",
       " ...]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_intersect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unit'"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_intersect[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.39647238e-02,  5.55823803e-01,  1.06922722e+00, -5.80761373e-01,\n",
       "       -1.84090003e-01,  5.90051591e-01, -4.83297288e-01, -1.02137029e+00,\n",
       "       -5.29634774e-01,  5.59159517e-01,  5.48655391e-01, -5.47076106e-01,\n",
       "        7.40445852e-01,  1.05874848e+00,  1.15805231e-01, -6.43091977e-01,\n",
       "       -2.17272550e-01,  9.14282817e-03, -5.67998827e-01,  7.31134772e-01,\n",
       "        3.81624818e-01,  1.66095972e-01,  1.35420918e+00, -6.32261574e-01,\n",
       "        1.36019778e+00,  3.18622977e-01,  6.08311772e-01, -9.46012974e-01,\n",
       "       -8.16127062e-01, -3.75578135e-01,  2.15428099e-01,  8.21336448e-01,\n",
       "        3.31276923e-01,  9.03516561e-02, -8.25725853e-01, -1.05747208e-01,\n",
       "       -2.19876960e-01,  5.83677590e-01,  7.62211204e-01, -5.33324957e-01,\n",
       "       -7.19758987e-01, -3.87935847e-01, -8.95460725e-01, -4.90741104e-01,\n",
       "        8.86917651e-01,  9.73534048e-01, -6.34916961e-01, -1.85901213e+00,\n",
       "        1.65464237e-01, -3.50661904e-01,  4.40119535e-01, -6.48685396e-01,\n",
       "        1.45408392e+00,  1.48301259e-01,  3.76801163e-01, -7.68440843e-01,\n",
       "       -1.64687514e-01,  8.69430482e-01,  1.06486924e-01, -1.75636575e-01,\n",
       "       -7.97931433e-01, -1.77121714e-01, -4.18048054e-01,  4.10883397e-01,\n",
       "       -2.49684185e-01, -7.94470012e-01,  7.96140790e-01,  6.49086654e-01,\n",
       "       -6.67854786e-01,  1.01724342e-01,  4.48515475e-01,  2.93741465e-01,\n",
       "       -3.69512051e-01,  7.26120099e-02, -1.38704312e+00, -5.19931614e-02,\n",
       "       -1.09465075e+00,  4.42699641e-02, -1.88935250e-01, -5.02752483e-01,\n",
       "        6.22499585e-01, -2.21162826e-01, -7.54070461e-01,  6.47206083e-02,\n",
       "       -1.42634416e+00, -1.78687787e+00,  2.01562017e-01, -1.21575201e+00,\n",
       "       -1.88005656e-01, -1.20509721e-01,  4.34873939e-01, -9.30487573e-01,\n",
       "        1.40219644e-01,  5.64335763e-01, -8.77024457e-02,  1.37186468e+00,\n",
       "        8.55210877e-04,  3.81024987e-01,  4.10743356e-02, -3.54462922e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.52])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_df[concrete_df['Word']=='state']['Conc.M'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in concrete_intersect:\n",
    "    word_vectors[word] = word_vectors[word] * 1/concrete_df[concrete_df['stem']==word]['Conc.M'].values.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "== AoA_51715_words.csv ==\n",
    "\n",
    "This file contains \"Age of Acquisition\" (AoA) estimates for about 51k English words, which refers to the approximate age (in years) when a word was learned. Early words, being more basic, have lower average AoA.\n",
    "\n",
    "The main columns you will be interested in are \"Word\" and \"AoA_Kup_lem\". But the others may be useful too.\n",
    "\n",
    "The file contains these columns:\n",
    "\n",
    "Word :: The word in question\n",
    "Alternative.spelling :: if the Word may be spelled frequently in another form\t\n",
    "Freq_pm\t:: Freq of the Word in general English (larger -> more common)\n",
    "Dom_PoS_SUBTLEX\t:: Dominant part of speech in general usage\n",
    "Nletters :: number of letters \n",
    "Nphon :: number of phonemes\n",
    "Nsyll :: number of syllables\n",
    "Lemma_highest_PoS :: the \"lemmatized\" or \"root\" form of the word (in the dominant part of speech. e.g. The root form of the verb \"abates\" is \"abate\".\n",
    "AoA_Kup\t:: The AoA from a previous study by Kuperman et al.\n",
    "Perc_known :: Percent of people who knew the word in the Kuperman et al. study\n",
    "AoA_Kup_lem :: Estimated AoA based on Kuperman et al. study lemmatized words. THIS IS THE MAIN COLUMN OF INTEREST.\n",
    "Perc_known_lem\t:: Estimated percentage of people who would know this form of the word in the Kuperman study.\n",
    "AoA_Bird_lem :: AoA reported in previous study by Bird (2001) \n",
    "AoA_Bristol_lem\t:: AoA reported in previous study from Bristol Univ. (2006)\n",
    "AoA_Cort_lem :: AoA reported in previous study by Cortese & Khanna (2008)\n",
    "AoA_Schock :: AoA reported in previous study by Schock (2012)\n",
    "\n",
    "Original source : http://crr.ugent.be/archives/806"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Alternative.spelling</th>\n",
       "      <th>Freq_pm</th>\n",
       "      <th>Dom_PoS_SUBTLEX</th>\n",
       "      <th>Nletters</th>\n",
       "      <th>Nphon</th>\n",
       "      <th>Nsyll</th>\n",
       "      <th>Lemma_highest_PoS</th>\n",
       "      <th>AoA_Kup</th>\n",
       "      <th>Perc_known</th>\n",
       "      <th>AoA_Kup_lem</th>\n",
       "      <th>Perc_known_lem</th>\n",
       "      <th>AoA_Bird_lem</th>\n",
       "      <th>AoA_Bristol_lem</th>\n",
       "      <th>AoA_Cort_lem</th>\n",
       "      <th>AoA_Schock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>20415.27</td>\n",
       "      <td>Article</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>2.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aardvark</td>\n",
       "      <td>aardvark</td>\n",
       "      <td>0.41</td>\n",
       "      <td>Noun</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>aardvark</td>\n",
       "      <td>9.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abacus</td>\n",
       "      <td>abacus</td>\n",
       "      <td>0.24</td>\n",
       "      <td>Noun</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>abacus</td>\n",
       "      <td>8.69</td>\n",
       "      <td>0.65</td>\n",
       "      <td>8.69</td>\n",
       "      <td>0.65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abacuses</td>\n",
       "      <td>abacuses</td>\n",
       "      <td>0.02</td>\n",
       "      <td>Noun</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>abacus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.69</td>\n",
       "      <td>0.65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abalone</td>\n",
       "      <td>abalone</td>\n",
       "      <td>0.51</td>\n",
       "      <td>Verb</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>abalone</td>\n",
       "      <td>12.23</td>\n",
       "      <td>0.72</td>\n",
       "      <td>12.23</td>\n",
       "      <td>0.72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word Alternative.spelling   Freq_pm Dom_PoS_SUBTLEX  Nletters  Nphon  \\\n",
       "0         a                    a  20415.27         Article         1      1   \n",
       "1  aardvark             aardvark      0.41            Noun         8      7   \n",
       "2    abacus               abacus      0.24            Noun         6      6   \n",
       "3  abacuses             abacuses      0.02            Noun         8      9   \n",
       "4   abalone              abalone      0.51            Verb         7      7   \n",
       "\n",
       "   Nsyll Lemma_highest_PoS  AoA_Kup  Perc_known  AoA_Kup_lem  Perc_known_lem  \\\n",
       "0      1                 a     2.89        1.00         2.89            1.00   \n",
       "1      2          aardvark     9.89        1.00         9.89            1.00   \n",
       "2      3            abacus     8.69        0.65         8.69            0.65   \n",
       "3      4            abacus      NaN         NaN         8.69            0.65   \n",
       "4      4           abalone    12.23        0.72        12.23            0.72   \n",
       "\n",
       "   AoA_Bird_lem  AoA_Bristol_lem  AoA_Cort_lem  AoA_Schock  \n",
       "0          3.16              NaN           NaN         NaN  \n",
       "1           NaN              NaN           NaN         NaN  \n",
       "2           NaN              NaN           NaN         NaN  \n",
       "3           NaN              NaN           NaN         NaN  \n",
       "4           NaN              NaN           NaN         NaN  "
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AoA\n",
    "#Perc_known_lem, AoA_Kup_lem\n",
    "aoawords_path = 'Data/AoA_51715_words.csv'\n",
    "AoA = pd.read_csv(aoawords_path,encoding = 'unicode_escape')\n",
    "AoA = AoA[AoA['Word'].notna()]\n",
    "AoA_set = set(AoA['Word'].values)\n",
    "AoA.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2147     Armageddon\n",
       "18582         FRAYS\n",
       "22665             I\n",
       "27722       Masonic\n",
       "36007     PUSHCHAIR\n",
       "            ...    \n",
       "51710      zucchini\n",
       "51711     zucchinis\n",
       "51712      zwieback\n",
       "51713        zygote\n",
       "51714       zygotes\n",
       "Name: Word, Length: 51714, dtype: object"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AoA['Word'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "AoA['stem'] = AoA['Word'].apply(lemmatize_stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51714"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(AoA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.58"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AoA.AoA_Kup_lem.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.0"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AoA.AoA_Kup_lem.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Alternative.spelling</th>\n",
       "      <th>Freq_pm</th>\n",
       "      <th>Dom_PoS_SUBTLEX</th>\n",
       "      <th>Nletters</th>\n",
       "      <th>Nphon</th>\n",
       "      <th>Nsyll</th>\n",
       "      <th>Lemma_highest_PoS</th>\n",
       "      <th>AoA_Kup</th>\n",
       "      <th>Perc_known</th>\n",
       "      <th>AoA_Kup_lem</th>\n",
       "      <th>Perc_known_lem</th>\n",
       "      <th>AoA_Bird_lem</th>\n",
       "      <th>AoA_Bristol_lem</th>\n",
       "      <th>AoA_Cort_lem</th>\n",
       "      <th>AoA_Schock</th>\n",
       "      <th>stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14878</th>\n",
       "      <td>eisteddfod</td>\n",
       "      <td>eisteddfod</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>eisteddfod</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>eisteddfod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2084</th>\n",
       "      <td>architrave</td>\n",
       "      <td>architrave</td>\n",
       "      <td>0.04</td>\n",
       "      <td>Noun</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>architrave</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>architrav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6274</th>\n",
       "      <td>calceolaria</td>\n",
       "      <td>calceolaria</td>\n",
       "      <td>0.02</td>\n",
       "      <td>Noun</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>calceolaria</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>calceolaria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32931</th>\n",
       "      <td>penury</td>\n",
       "      <td>penury</td>\n",
       "      <td>0.02</td>\n",
       "      <td>Noun</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>penury</td>\n",
       "      <td>20.6</td>\n",
       "      <td>0.28</td>\n",
       "      <td>20.6</td>\n",
       "      <td>0.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>penuri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25243</th>\n",
       "      <td>kendo</td>\n",
       "      <td>kendo</td>\n",
       "      <td>0.37</td>\n",
       "      <td>Noun</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>kendo</td>\n",
       "      <td>20.5</td>\n",
       "      <td>0.11</td>\n",
       "      <td>20.5</td>\n",
       "      <td>0.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kendo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38932</th>\n",
       "      <td>rogation</td>\n",
       "      <td>rogation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>rogation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rogat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42089</th>\n",
       "      <td>smilax</td>\n",
       "      <td>smilax</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>smilax</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>smilax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46368</th>\n",
       "      <td>thulium</td>\n",
       "      <td>thulium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>thulium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>thulium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50862</th>\n",
       "      <td>wickiup</td>\n",
       "      <td>wickiup</td>\n",
       "      <td>0.27</td>\n",
       "      <td>Noun</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>wickiup</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wickiup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50941</th>\n",
       "      <td>williwaw</td>\n",
       "      <td>williwaw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>williwaw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>williwaw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51714 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Word Alternative.spelling  Freq_pm Dom_PoS_SUBTLEX  Nletters  \\\n",
       "14878   eisteddfod           eisteddfod      NaN             NaN        10   \n",
       "2084    architrave           architrave     0.04            Noun        10   \n",
       "6274   calceolaria          calceolaria     0.02            Noun        11   \n",
       "32931       penury               penury     0.02            Noun         6   \n",
       "25243        kendo                kendo     0.37            Noun         5   \n",
       "...            ...                  ...      ...             ...       ...   \n",
       "38932     rogation             rogation      NaN             NaN         8   \n",
       "42089       smilax               smilax      NaN             NaN         6   \n",
       "46368      thulium              thulium      NaN             NaN         7   \n",
       "50862      wickiup              wickiup     0.27            Noun         7   \n",
       "50941     williwaw             williwaw      NaN             NaN         8   \n",
       "\n",
       "       Nphon  Nsyll Lemma_highest_PoS  AoA_Kup  Perc_known  AoA_Kup_lem  \\\n",
       "14878      8      3        eisteddfod     25.0        0.05         25.0   \n",
       "2084       8      3        architrave     21.0        0.05         21.0   \n",
       "6274      11      6       calceolaria     21.0        0.11         21.0   \n",
       "32931      7      3            penury     20.6        0.28         20.6   \n",
       "25243      5      2             kendo     20.5        0.11         20.5   \n",
       "...      ...    ...               ...      ...         ...          ...   \n",
       "38932      7      3          rogation      NaN        0.00          NaN   \n",
       "42089      7      2            smilax      NaN        0.00          NaN   \n",
       "46368      6      3           thulium      NaN        0.00          NaN   \n",
       "50862      6      3           wickiup      NaN        0.00          NaN   \n",
       "50941      6      3          williwaw      NaN        0.00          NaN   \n",
       "\n",
       "       Perc_known_lem  AoA_Bird_lem  AoA_Bristol_lem  AoA_Cort_lem  \\\n",
       "14878            0.05           NaN              NaN           NaN   \n",
       "2084             0.05           NaN              NaN           NaN   \n",
       "6274             0.11           NaN              NaN           NaN   \n",
       "32931            0.28           NaN              NaN           NaN   \n",
       "25243            0.11           NaN              NaN           NaN   \n",
       "...               ...           ...              ...           ...   \n",
       "38932            0.00           NaN              NaN           NaN   \n",
       "42089            0.00           NaN              NaN           NaN   \n",
       "46368            0.00           NaN              NaN           NaN   \n",
       "50862            0.00           NaN              NaN           NaN   \n",
       "50941            0.00           NaN              NaN           NaN   \n",
       "\n",
       "       AoA_Schock         stem  \n",
       "14878         NaN   eisteddfod  \n",
       "2084          NaN    architrav  \n",
       "6274          NaN  calceolaria  \n",
       "32931         NaN       penuri  \n",
       "25243         NaN        kendo  \n",
       "...           ...          ...  \n",
       "38932         NaN        rogat  \n",
       "42089         NaN       smilax  \n",
       "46368         NaN      thulium  \n",
       "50862         NaN      wickiup  \n",
       "50941         NaN     williwaw  \n",
       "\n",
       "[51714 rows x 17 columns]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AoA.sort_values(['AoA_Kup_lem'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(AoA[AoA['AoA_Kup_lem'].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Alternative.spelling</th>\n",
       "      <th>Freq_pm</th>\n",
       "      <th>Dom_PoS_SUBTLEX</th>\n",
       "      <th>Nletters</th>\n",
       "      <th>Nphon</th>\n",
       "      <th>Nsyll</th>\n",
       "      <th>Lemma_highest_PoS</th>\n",
       "      <th>AoA_Kup</th>\n",
       "      <th>Perc_known</th>\n",
       "      <th>AoA_Kup_lem</th>\n",
       "      <th>Perc_known_lem</th>\n",
       "      <th>AoA_Bird_lem</th>\n",
       "      <th>AoA_Bristol_lem</th>\n",
       "      <th>AoA_Cort_lem</th>\n",
       "      <th>AoA_Schock</th>\n",
       "      <th>stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>actinium</td>\n",
       "      <td>actinium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>actinium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>actinium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322</th>\n",
       "      <td>ambuscade</td>\n",
       "      <td>ambuscade</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>ambuscade</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ambuscad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2306</th>\n",
       "      <td>ashlar</td>\n",
       "      <td>ashlar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>ashlar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ashlar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5095</th>\n",
       "      <td>bosky</td>\n",
       "      <td>bosky</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>bosky</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>boski</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6404</th>\n",
       "      <td>canaille</td>\n",
       "      <td>canaille</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>canaille</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>canail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9004</th>\n",
       "      <td>compeer</td>\n",
       "      <td>compeer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>compeer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>compeer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9005</th>\n",
       "      <td>compeers</td>\n",
       "      <td>compeers</td>\n",
       "      <td>0.02</td>\n",
       "      <td>Noun</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>compeer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>compeer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16000</th>\n",
       "      <td>europium</td>\n",
       "      <td>europium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>europium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>europium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19065</th>\n",
       "      <td>gallimaufry</td>\n",
       "      <td>gallimaufry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>gallimaufry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gallimaufri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22498</th>\n",
       "      <td>hutment</td>\n",
       "      <td>hutment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>hutment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hutment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25196</th>\n",
       "      <td>karakul</td>\n",
       "      <td>karakul</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>karakul</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>karakul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25219</th>\n",
       "      <td>kedge</td>\n",
       "      <td>kedge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>kedge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kedg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25575</th>\n",
       "      <td>kyat</td>\n",
       "      <td>kyat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>kyat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kyat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32754</th>\n",
       "      <td>peculation</td>\n",
       "      <td>peculation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>peculation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pecul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34588</th>\n",
       "      <td>pother</td>\n",
       "      <td>pother</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>pother</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pother</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38932</th>\n",
       "      <td>rogation</td>\n",
       "      <td>rogation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>rogation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rogat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42089</th>\n",
       "      <td>smilax</td>\n",
       "      <td>smilax</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>smilax</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>smilax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46368</th>\n",
       "      <td>thulium</td>\n",
       "      <td>thulium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>thulium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>thulium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50862</th>\n",
       "      <td>wickiup</td>\n",
       "      <td>wickiup</td>\n",
       "      <td>0.27</td>\n",
       "      <td>Noun</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>wickiup</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wickiup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50941</th>\n",
       "      <td>williwaw</td>\n",
       "      <td>williwaw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>williwaw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>williwaw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Word Alternative.spelling  Freq_pm Dom_PoS_SUBTLEX  Nletters  \\\n",
       "442       actinium             actinium      NaN             NaN         8   \n",
       "1322     ambuscade            ambuscade      NaN             NaN         9   \n",
       "2306        ashlar               ashlar      NaN             NaN         6   \n",
       "5095         bosky                bosky      NaN             NaN         5   \n",
       "6404      canaille             canaille      NaN             NaN         8   \n",
       "9004       compeer              compeer      NaN             NaN         7   \n",
       "9005      compeers             compeers     0.02            Noun         8   \n",
       "16000     europium             europium      NaN             NaN         8   \n",
       "19065  gallimaufry          gallimaufry      NaN             NaN        11   \n",
       "22498      hutment              hutment      NaN             NaN         7   \n",
       "25196      karakul              karakul      NaN             NaN         7   \n",
       "25219        kedge                kedge      NaN             NaN         5   \n",
       "25575         kyat                 kyat      NaN             NaN         4   \n",
       "32754   peculation           peculation      NaN             NaN        10   \n",
       "34588       pother               pother      NaN             NaN         6   \n",
       "38932     rogation             rogation      NaN             NaN         8   \n",
       "42089       smilax               smilax      NaN             NaN         6   \n",
       "46368      thulium              thulium      NaN             NaN         7   \n",
       "50862      wickiup              wickiup     0.27            Noun         7   \n",
       "50941     williwaw             williwaw      NaN             NaN         8   \n",
       "\n",
       "       Nphon  Nsyll Lemma_highest_PoS  AoA_Kup  Perc_known  AoA_Kup_lem  \\\n",
       "442        8      4          actinium      NaN         0.0          NaN   \n",
       "1322       8      3         ambuscade      NaN         0.0          NaN   \n",
       "2306       5      2            ashlar      NaN         0.0          NaN   \n",
       "5095       4      2             bosky      NaN         0.0          NaN   \n",
       "6404       5      2          canaille      NaN         0.0          NaN   \n",
       "9004       6      3           compeer      NaN         0.0          NaN   \n",
       "9005       7      3           compeer      NaN         NaN          NaN   \n",
       "16000      8      4          europium      NaN         0.0          NaN   \n",
       "19065      9      4       gallimaufry      NaN         0.0          NaN   \n",
       "22498      7      2           hutment      NaN         0.0          NaN   \n",
       "25196      7      3           karakul      NaN         0.0          NaN   \n",
       "25219      3      1             kedge      NaN         0.0          NaN   \n",
       "25575      4      2              kyat      NaN         0.0          NaN   \n",
       "32754     10      4        peculation      NaN         0.0          NaN   \n",
       "34588      5      2            pother      NaN         0.0          NaN   \n",
       "38932      7      3          rogation      NaN         0.0          NaN   \n",
       "42089      7      2            smilax      NaN         0.0          NaN   \n",
       "46368      6      3           thulium      NaN         0.0          NaN   \n",
       "50862      6      3           wickiup      NaN         0.0          NaN   \n",
       "50941      6      3          williwaw      NaN         0.0          NaN   \n",
       "\n",
       "       Perc_known_lem  AoA_Bird_lem  AoA_Bristol_lem  AoA_Cort_lem  \\\n",
       "442               0.0           NaN              NaN           NaN   \n",
       "1322              0.0           NaN              NaN           NaN   \n",
       "2306              0.0           NaN              NaN           NaN   \n",
       "5095              0.0           NaN              NaN           NaN   \n",
       "6404              0.0           NaN              NaN           NaN   \n",
       "9004              0.0           NaN              NaN           NaN   \n",
       "9005              0.0           NaN              NaN           NaN   \n",
       "16000             0.0           NaN              NaN           NaN   \n",
       "19065             0.0           NaN              NaN           NaN   \n",
       "22498             0.0           NaN              NaN           NaN   \n",
       "25196             0.0           NaN              NaN           NaN   \n",
       "25219             0.0           NaN              NaN           NaN   \n",
       "25575             0.0           NaN              NaN           NaN   \n",
       "32754             0.0           NaN              NaN           NaN   \n",
       "34588             0.0           NaN              NaN           NaN   \n",
       "38932             0.0           NaN              NaN           NaN   \n",
       "42089             0.0           NaN              NaN           NaN   \n",
       "46368             0.0           NaN              NaN           NaN   \n",
       "50862             0.0           NaN              NaN           NaN   \n",
       "50941             0.0           NaN              NaN           NaN   \n",
       "\n",
       "       AoA_Schock         stem  \n",
       "442           NaN     actinium  \n",
       "1322          NaN     ambuscad  \n",
       "2306          NaN       ashlar  \n",
       "5095          NaN        boski  \n",
       "6404          NaN       canail  \n",
       "9004          NaN      compeer  \n",
       "9005          NaN      compeer  \n",
       "16000         NaN     europium  \n",
       "19065         NaN  gallimaufri  \n",
       "22498         NaN      hutment  \n",
       "25196         NaN      karakul  \n",
       "25219         NaN         kedg  \n",
       "25575         NaN         kyat  \n",
       "32754         NaN        pecul  \n",
       "34588         NaN       pother  \n",
       "38932         NaN        rogat  \n",
       "42089         NaN       smilax  \n",
       "46368         NaN      thulium  \n",
       "50862         NaN      wickiup  \n",
       "50941         NaN     williwaw  "
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AoA[AoA['AoA_Kup_lem'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to impute all Nan values in AoA_Kup_lem as the max AoA value 25, as they appear to be hard words.\n",
    "AoA['AoA_Kup_lem'].fillna(value=AoA['AoA_Kup_lem'].max(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Alternative.spelling</th>\n",
       "      <th>Freq_pm</th>\n",
       "      <th>Dom_PoS_SUBTLEX</th>\n",
       "      <th>Nletters</th>\n",
       "      <th>Nphon</th>\n",
       "      <th>Nsyll</th>\n",
       "      <th>Lemma_highest_PoS</th>\n",
       "      <th>AoA_Kup</th>\n",
       "      <th>Perc_known</th>\n",
       "      <th>AoA_Kup_lem</th>\n",
       "      <th>Perc_known_lem</th>\n",
       "      <th>AoA_Bird_lem</th>\n",
       "      <th>AoA_Bristol_lem</th>\n",
       "      <th>AoA_Cort_lem</th>\n",
       "      <th>AoA_Schock</th>\n",
       "      <th>stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2306</th>\n",
       "      <td>ashlar</td>\n",
       "      <td>ashlar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>ashlar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ashlar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38932</th>\n",
       "      <td>rogation</td>\n",
       "      <td>rogation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>rogation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rogat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46368</th>\n",
       "      <td>thulium</td>\n",
       "      <td>thulium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>thulium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>thulium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14878</th>\n",
       "      <td>eisteddfod</td>\n",
       "      <td>eisteddfod</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>eisteddfod</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>eisteddfod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5095</th>\n",
       "      <td>bosky</td>\n",
       "      <td>bosky</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>bosky</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>boski</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27395</th>\n",
       "      <td>mamma</td>\n",
       "      <td>mamma</td>\n",
       "      <td>3.02</td>\n",
       "      <td>Noun</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>mama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mamma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27393</th>\n",
       "      <td>mamas</td>\n",
       "      <td>mamas</td>\n",
       "      <td>0.71</td>\n",
       "      <td>Noun</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>mama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27392</th>\n",
       "      <td>mama</td>\n",
       "      <td>mama</td>\n",
       "      <td>103.71</td>\n",
       "      <td>Noun</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>mama</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29050</th>\n",
       "      <td>mommas</td>\n",
       "      <td>mommas</td>\n",
       "      <td>0.10</td>\n",
       "      <td>Noun</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>momma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>momma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29049</th>\n",
       "      <td>momma</td>\n",
       "      <td>momma</td>\n",
       "      <td>8.08</td>\n",
       "      <td>Noun</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>momma</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>momma</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51714 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Word Alternative.spelling  Freq_pm Dom_PoS_SUBTLEX  Nletters  \\\n",
       "2306       ashlar               ashlar      NaN             NaN         6   \n",
       "38932    rogation             rogation      NaN             NaN         8   \n",
       "46368     thulium              thulium      NaN             NaN         7   \n",
       "14878  eisteddfod           eisteddfod      NaN             NaN        10   \n",
       "5095        bosky                bosky      NaN             NaN         5   \n",
       "...           ...                  ...      ...             ...       ...   \n",
       "27395       mamma                mamma     3.02            Noun         5   \n",
       "27393       mamas                mamas     0.71            Noun         5   \n",
       "27392        mama                 mama   103.71            Noun         4   \n",
       "29050      mommas               mommas     0.10            Noun         6   \n",
       "29049       momma                momma     8.08            Noun         5   \n",
       "\n",
       "       Nphon  Nsyll Lemma_highest_PoS  AoA_Kup  Perc_known  AoA_Kup_lem  \\\n",
       "2306       5      2            ashlar      NaN        0.00        25.00   \n",
       "38932      7      3          rogation      NaN        0.00        25.00   \n",
       "46368      6      3           thulium      NaN        0.00        25.00   \n",
       "14878      8      3        eisteddfod    25.00        0.05        25.00   \n",
       "5095       4      2             bosky      NaN        0.00        25.00   \n",
       "...      ...    ...               ...      ...         ...          ...   \n",
       "27395      4      2              mama      NaN         NaN         1.89   \n",
       "27393      5      2              mama      NaN         NaN         1.89   \n",
       "27392      4      2              mama     1.89        1.00         1.89   \n",
       "29050      5      2             momma      NaN         NaN         1.58   \n",
       "29049      4      2             momma     1.58        1.00         1.58   \n",
       "\n",
       "       Perc_known_lem  AoA_Bird_lem  AoA_Bristol_lem  AoA_Cort_lem  \\\n",
       "2306             0.00           NaN              NaN           NaN   \n",
       "38932            0.00           NaN              NaN           NaN   \n",
       "46368            0.00           NaN              NaN           NaN   \n",
       "14878            0.05           NaN              NaN           NaN   \n",
       "5095             0.00           NaN              NaN           NaN   \n",
       "...               ...           ...              ...           ...   \n",
       "27395            1.00           NaN              NaN           NaN   \n",
       "27393            1.00           NaN              NaN           NaN   \n",
       "27392            1.00           NaN              NaN           NaN   \n",
       "29050            1.00           NaN              NaN           NaN   \n",
       "29049            1.00           NaN              NaN           NaN   \n",
       "\n",
       "       AoA_Schock        stem  \n",
       "2306          NaN      ashlar  \n",
       "38932         NaN       rogat  \n",
       "46368         NaN     thulium  \n",
       "14878         NaN  eisteddfod  \n",
       "5095          NaN       boski  \n",
       "...           ...         ...  \n",
       "27395         NaN       mamma  \n",
       "27393         NaN        mama  \n",
       "27392         NaN        mama  \n",
       "29050         NaN       momma  \n",
       "29049         NaN       momma  \n",
       "\n",
       "[51714 rows x 17 columns]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AoA.sort_values(['AoA_Kup_lem'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AoA values range from 0 - 25, which means the smaller the AoA value, the easier the word is. We could possibly use the AoA value to give easier words less weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoa_words = list(AoA['stem'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51714"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aoa_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoa_complement = [word for word in words_in_vector if word not in aoa_words]\n",
    "aoa_intersect = [word for word in words_in_vector if word in aoa_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "905"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aoa_complement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['english',\n",
       " 'septemb',\n",
       " 'british',\n",
       " 'calai',\n",
       " 'juli',\n",
       " 'octob',\n",
       " 'june',\n",
       " 'april',\n",
       " 'england',\n",
       " 'februari',\n",
       " 'london',\n",
       " 'french',\n",
       " 'john',\n",
       " 'ndash',\n",
       " 'germani',\n",
       " 'japanes',\n",
       " 'york',\n",
       " 'america',\n",
       " 'australia',\n",
       " 'nord',\n",
       " 'italian',\n",
       " 'william',\n",
       " 'aisn',\n",
       " 'europ',\n",
       " 'picardi',\n",
       " 'pakistan',\n",
       " 'greek',\n",
       " 'european',\n",
       " 'georg',\n",
       " 'spanish',\n",
       " 'christian',\n",
       " 'normandi',\n",
       " 'india',\n",
       " 'calvado',\n",
       " 'california',\n",
       " 'switzerland',\n",
       " 'commonli',\n",
       " 'canada',\n",
       " 'charl',\n",
       " 'australian',\n",
       " 'itali',\n",
       " 'henri',\n",
       " 'loir',\n",
       " 'canadian',\n",
       " 'scotland',\n",
       " 'girond',\n",
       " 'mari',\n",
       " 'robert',\n",
       " 'ireland',\n",
       " 'africa',\n",
       " 'paul',\n",
       " 'latin',\n",
       " 'florida',\n",
       " 'brazilian',\n",
       " 'aquitain',\n",
       " 'atlant',\n",
       " 'david',\n",
       " 'russian',\n",
       " 'indian',\n",
       " 'chines',\n",
       " 'michael',\n",
       " 'asia',\n",
       " 'pari',\n",
       " 'richard',\n",
       " 'berlin',\n",
       " 'scottish',\n",
       " 'dutch',\n",
       " 'lower',\n",
       " 'spain',\n",
       " 'iowa',\n",
       " 'peter',\n",
       " 'disney',\n",
       " 'throughout',\n",
       " 'thoma',\n",
       " 'wale',\n",
       " 'edward',\n",
       " 'britain',\n",
       " 'wikipedia',\n",
       " 'loui',\n",
       " 'mexico',\n",
       " 'washington',\n",
       " 'martin',\n",
       " 'virginia',\n",
       " 'chicago',\n",
       " 'mainli',\n",
       " 'russia',\n",
       " 'texa',\n",
       " 'partement',\n",
       " 'nintendo',\n",
       " 'victoria',\n",
       " 'irish',\n",
       " 'islam',\n",
       " 'harri',\n",
       " 'african',\n",
       " 'nobel',\n",
       " 'austria',\n",
       " 'brazil',\n",
       " 'netherland',\n",
       " 'belgian',\n",
       " 'oklahoma',\n",
       " 'mario',\n",
       " 'zealand',\n",
       " 'arab',\n",
       " 'jupit',\n",
       " 'romania',\n",
       " 'joseph',\n",
       " 'sarth',\n",
       " 'illinoi',\n",
       " 'armenian',\n",
       " 'particularli',\n",
       " 'formerli',\n",
       " 'austrian',\n",
       " 'nazi',\n",
       " 'manchest',\n",
       " 'carolina',\n",
       " 'poland',\n",
       " 'jesu',\n",
       " 'jewish',\n",
       " 'korea',\n",
       " 'elizabeth',\n",
       " 'prix',\n",
       " 'korean',\n",
       " 'egypt',\n",
       " 'previous',\n",
       " 'rome',\n",
       " 'directli',\n",
       " 'swedish',\n",
       " 'alexand',\n",
       " 'santa',\n",
       " 'saturn',\n",
       " 'scott',\n",
       " 'persian',\n",
       " 'oxford',\n",
       " 'onlin',\n",
       " 'andrew',\n",
       " 'sweden',\n",
       " 'georgia',\n",
       " 'ohio',\n",
       " 'maria',\n",
       " 'smith',\n",
       " 'vienna',\n",
       " 'melbourn',\n",
       " 'daniel',\n",
       " 'kentucki',\n",
       " 'ontario',\n",
       " 'portugues',\n",
       " 'francisco',\n",
       " 'provenc',\n",
       " 'highli',\n",
       " 'pennsylvania',\n",
       " 'tehsil',\n",
       " 'columbia',\n",
       " 'isbn',\n",
       " 'chri',\n",
       " 'linux',\n",
       " 'arthur',\n",
       " 'michigan',\n",
       " 'boston',\n",
       " 'kilometr',\n",
       " 'metr',\n",
       " 'hungari',\n",
       " 'sydney',\n",
       " 'mayenn',\n",
       " 'massachusett',\n",
       " 'iran',\n",
       " 'microsoft',\n",
       " 'johann',\n",
       " 'albert',\n",
       " 'rhine',\n",
       " 'punjab',\n",
       " 'belgium',\n",
       " 'ann',\n",
       " 'frederick',\n",
       " 'kelli',\n",
       " 'stanley',\n",
       " 'czech',\n",
       " 'turkish',\n",
       " 'alabama',\n",
       " 'mississippi',\n",
       " 'indiana',\n",
       " 'swiss',\n",
       " 'roger',\n",
       " 'toronto',\n",
       " 'israel',\n",
       " 'kashmir',\n",
       " 'kong',\n",
       " 'christoph',\n",
       " 'denmark',\n",
       " 'greec',\n",
       " 'singapor',\n",
       " 'aub',\n",
       " 'jackson',\n",
       " 'saxoni',\n",
       " 'walt',\n",
       " 'alaska',\n",
       " 'julian',\n",
       " 'asian',\n",
       " 'steve',\n",
       " 'cambridg',\n",
       " 'shortli',\n",
       " 'gregorian',\n",
       " 'taylor',\n",
       " 'armenia',\n",
       " 'moscow',\n",
       " 'norway',\n",
       " 'kansa',\n",
       " 'minnesota',\n",
       " 'portug',\n",
       " 'walter',\n",
       " 'simpson',\n",
       " 'pierr',\n",
       " 'hamilton',\n",
       " 'carlo',\n",
       " 'ross',\n",
       " 'ardãƒ',\n",
       " 'argentina',\n",
       " 'caribbean',\n",
       " 'finland',\n",
       " 'robinson',\n",
       " 'colorado',\n",
       " 'munich',\n",
       " 'florenc',\n",
       " 'baden',\n",
       " 'dominican',\n",
       " 'lincoln',\n",
       " 'smackdown',\n",
       " 'grammi',\n",
       " 'davi',\n",
       " 'jane',\n",
       " 'abbottabad',\n",
       " 'yorkshir',\n",
       " 'christ',\n",
       " 'philip',\n",
       " 'aargau',\n",
       " 'wilson',\n",
       " 'hitler',\n",
       " 'franci',\n",
       " 'montreal',\n",
       " 'hong',\n",
       " 'stephen',\n",
       " 'jew',\n",
       " 'vietnam',\n",
       " 'hungarian',\n",
       " 'organis',\n",
       " 'benjamin',\n",
       " 'egyptian',\n",
       " 'danish',\n",
       " 'tokyo',\n",
       " 'colour',\n",
       " 'philippin',\n",
       " 'jone',\n",
       " 'karl',\n",
       " 'billi',\n",
       " 'subtrop',\n",
       " 'bavaria',\n",
       " 'pokãƒ',\n",
       " 'matthew',\n",
       " 'playstat',\n",
       " 'johnson',\n",
       " 'fifa',\n",
       " 'easili',\n",
       " 'hollywood',\n",
       " 'mont',\n",
       " 'milan',\n",
       " 'wilhelm',\n",
       " 'brian',\n",
       " 'afghanistan',\n",
       " 'quebec',\n",
       " 'neptun',\n",
       " 'detroit',\n",
       " 'iraq',\n",
       " 'geneva',\n",
       " 'norwegian',\n",
       " 'samuel',\n",
       " 'friday',\n",
       " 'madrid',\n",
       " 'harrison',\n",
       " 'missouri',\n",
       " 'taiwan',\n",
       " 'sarah',\n",
       " 'anna',\n",
       " 'mexican',\n",
       " 'arizona',\n",
       " 'paulo',\n",
       " 'maya',\n",
       " 'michel',\n",
       " 'toni',\n",
       " 'alfr',\n",
       " 'onto',\n",
       " 'graham',\n",
       " 'chile',\n",
       " 'puerto',\n",
       " 'newli',\n",
       " 'juan',\n",
       " 'muhammad',\n",
       " 'westphalia',\n",
       " 'warner',\n",
       " 'philadelphia',\n",
       " 'friedrich',\n",
       " 'vancouv',\n",
       " 'vendãƒ',\n",
       " 'birmingham',\n",
       " 'santo',\n",
       " 'carl',\n",
       " 'ferdinand',\n",
       " 'monday',\n",
       " 'finnish',\n",
       " 'alongsid',\n",
       " 'pittsburgh',\n",
       " 'patrick',\n",
       " 'wisconsin',\n",
       " 'caesar',\n",
       " 'beatl',\n",
       " 'ticino',\n",
       " 'bangladesh',\n",
       " 'hawaii',\n",
       " 'vauclus',\n",
       " 'wrestlemania',\n",
       " 'midland',\n",
       " 'westminst',\n",
       " 'clark',\n",
       " 'bruce',\n",
       " 'darwin',\n",
       " 'jefferson',\n",
       " 'hugh',\n",
       " 'bobbi',\n",
       " 'xbox',\n",
       " 'steven',\n",
       " 'lewi',\n",
       " 'hebrew',\n",
       " 'miller',\n",
       " 'phoenix',\n",
       " 'diego',\n",
       " 'hindu',\n",
       " 'ardã',\n",
       " 'catherin',\n",
       " 'charlott',\n",
       " 'kennedi',\n",
       " 'cuba',\n",
       " 'indonesia',\n",
       " 'jordan',\n",
       " 'arkansa',\n",
       " 'napoleon',\n",
       " 'gabriel',\n",
       " 'viii',\n",
       " 'gaelic',\n",
       " 'howard',\n",
       " 'anthoni',\n",
       " 'monro',\n",
       " 'ukrain',\n",
       " 'tennesse',\n",
       " 'walloon',\n",
       " 'idaho',\n",
       " 'iceland',\n",
       " 'liverpool',\n",
       " 'glasgow',\n",
       " 'indo',\n",
       " 'dougla',\n",
       " 'urdu',\n",
       " 'russel',\n",
       " 'eric',\n",
       " 'orton',\n",
       " 'lawrenc',\n",
       " 'anglo',\n",
       " 'bach',\n",
       " 'edinburgh',\n",
       " 'pakistani',\n",
       " 'flander',\n",
       " 'iranian',\n",
       " 'baptist',\n",
       " 'lennon',\n",
       " 'franklin',\n",
       " 'seattl',\n",
       " 'googl',\n",
       " 'cena',\n",
       " 'atlanta',\n",
       " 'homer',\n",
       " 'celtic',\n",
       " 'hess',\n",
       " 'austen',\n",
       " 'andrea',\n",
       " 'jerusalem',\n",
       " 'uranu',\n",
       " 'alic',\n",
       " 'rico',\n",
       " 'kevin',\n",
       " 'antonio',\n",
       " 'wagner',\n",
       " 'louisiana',\n",
       " 'tamil',\n",
       " 'barcelona',\n",
       " 'connecticut',\n",
       " 'jeff',\n",
       " 'uefa',\n",
       " 'bengal',\n",
       " 'shakespear',\n",
       " 'prussia',\n",
       " 'britannica',\n",
       " 'haiti',\n",
       " 'labour',\n",
       " 'austin',\n",
       " 'alan',\n",
       " 'clinton',\n",
       " 'jacqu',\n",
       " 'perci',\n",
       " 'arnold',\n",
       " 'atlantiqu',\n",
       " 'nichola',\n",
       " 'barri',\n",
       " 'leed',\n",
       " 'heavili',\n",
       " 'hugo',\n",
       " 'allen',\n",
       " 'manhattan',\n",
       " 'giovanni',\n",
       " 'thailand',\n",
       " 'edmund',\n",
       " 'rhode',\n",
       " 'han',\n",
       " 'carter',\n",
       " 'franz',\n",
       " 'gordon',\n",
       " 'otto',\n",
       " 'romanian',\n",
       " 'hercul',\n",
       " 'zeu',\n",
       " 'canadien',\n",
       " 'athen',\n",
       " 'miami',\n",
       " 'eclipt',\n",
       " 'oscar',\n",
       " 'helen',\n",
       " 'serbia',\n",
       " 'ernst',\n",
       " 'roosevelt',\n",
       " 'margaret',\n",
       " 'cleveland',\n",
       " 'norman',\n",
       " 'theodor',\n",
       " 'eddi',\n",
       " 'frankfurt',\n",
       " 'amsterdam',\n",
       " 'forb',\n",
       " 'pokã',\n",
       " 'jura',\n",
       " 'batista',\n",
       " 'baltimor',\n",
       " 'hampshir',\n",
       " 'solothurn',\n",
       " 'gustav',\n",
       " 'houston',\n",
       " 'jammu',\n",
       " 'jonathan',\n",
       " 'queensland',\n",
       " 'nors',\n",
       " 'syria',\n",
       " 'brabant',\n",
       " 'marco',\n",
       " 'phillip',\n",
       " 'maryland',\n",
       " 'shah',\n",
       " 'jimmi',\n",
       " 'madison',\n",
       " 'kurt',\n",
       " 'josã',\n",
       " 'nelson',\n",
       " 'stuart',\n",
       " 'mcmahon',\n",
       " 'greatli',\n",
       " 'brooklyn',\n",
       " 'augustu',\n",
       " 'vega',\n",
       " 'stewart',\n",
       " 'jerri',\n",
       " 'whedon',\n",
       " 'dakota',\n",
       " 'kent',\n",
       " 'malaysia',\n",
       " 'thompson',\n",
       " 'johnni',\n",
       " 'honour',\n",
       " 'briefli',\n",
       " 'fairli',\n",
       " 'sindh',\n",
       " 'peru',\n",
       " 'reich',\n",
       " 'neighbour',\n",
       " 'tuscani',\n",
       " 'herbert',\n",
       " 'holland',\n",
       " 'nasa',\n",
       " 'isra',\n",
       " 'weimar',\n",
       " 'bouch',\n",
       " 'venic',\n",
       " 'ukrainian',\n",
       " 'saxon',\n",
       " 'guerrero',\n",
       " 'louis',\n",
       " 'francesco',\n",
       " 'renault',\n",
       " 'mccartney',\n",
       " 'emmi',\n",
       " 'leones',\n",
       " 'indu',\n",
       " 'slovakia',\n",
       " 'mozart',\n",
       " 'soni',\n",
       " 'amazon',\n",
       " 'lithuania',\n",
       " 'vincent',\n",
       " 'aberdeen',\n",
       " 'lui',\n",
       " 'juliu',\n",
       " 'bernard',\n",
       " 'anglican',\n",
       " 'croatian',\n",
       " 'slavic',\n",
       " 'dave',\n",
       " 'napl',\n",
       " 'janeiro',\n",
       " 'thame',\n",
       " 'utah',\n",
       " 'wright',\n",
       " 'luxembourg',\n",
       " 'nuremberg',\n",
       " 'wayn',\n",
       " 'gregori',\n",
       " 'costa',\n",
       " 'anton',\n",
       " 'pyrã',\n",
       " 'leipzig',\n",
       " 'luke',\n",
       " 'suffolk',\n",
       " 'newfoundland',\n",
       " 'nile',\n",
       " 'arabia',\n",
       " 'oregon',\n",
       " 'constantin',\n",
       " 'nicola',\n",
       " 'charli',\n",
       " 'newton',\n",
       " 'anderson',\n",
       " 'croatia',\n",
       " 'tibetan',\n",
       " 'thursday',\n",
       " 'gilbert',\n",
       " 'terri',\n",
       " 'antarctica',\n",
       " 'buddhism',\n",
       " 'luca',\n",
       " 'strongli',\n",
       " 'knowl',\n",
       " 'ivan',\n",
       " 'donald',\n",
       " 'bueno',\n",
       " 'unesco',\n",
       " 'inland',\n",
       " 'manitoba',\n",
       " 'gari',\n",
       " 'isaac',\n",
       " 'luci',\n",
       " 'suceava',\n",
       " 'persia',\n",
       " 'castil',\n",
       " 'cameron',\n",
       " 'ronald',\n",
       " 'khyber',\n",
       " 'victor',\n",
       " 'leon',\n",
       " 'barbara',\n",
       " 'vendã',\n",
       " 'harvard',\n",
       " 'abraham',\n",
       " 'somewhat',\n",
       " 'kirbi',\n",
       " 'thuringia',\n",
       " 'subspeci',\n",
       " 'petersburg',\n",
       " 'guin',\n",
       " 'sierra',\n",
       " 'salzburg',\n",
       " 'apollo',\n",
       " 'dalla',\n",
       " 'ryan',\n",
       " 'ludwig',\n",
       " 'saudi',\n",
       " 'trojan',\n",
       " 'antarct',\n",
       " 'arrondiss',\n",
       " 'mongol',\n",
       " 'franco',\n",
       " 'columbu',\n",
       " 'dublin',\n",
       " 'teau',\n",
       " 'campbel',\n",
       " 'berkeley',\n",
       " 'nevada',\n",
       " 'mali',\n",
       " 'warsaw',\n",
       " 'flemish',\n",
       " 'subfamili',\n",
       " 'richmond',\n",
       " 'vike',\n",
       " 'tampa',\n",
       " 'publicli',\n",
       " 'heinrich',\n",
       " 'sheffield',\n",
       " 'ralph',\n",
       " 'triniti',\n",
       " 'volkswagen',\n",
       " 'orlean',\n",
       " 'extratrop',\n",
       " 'brandenburg',\n",
       " 'ubuntu',\n",
       " 'nova',\n",
       " 'significantli',\n",
       " 'sicili',\n",
       " 'santiago',\n",
       " 'prussian',\n",
       " 'pakhtunkhwa',\n",
       " 'kane',\n",
       " 'stockholm',\n",
       " 'buffi',\n",
       " 'similarli',\n",
       " 'josãƒ',\n",
       " 'murray',\n",
       " 'sebastian',\n",
       " 'bulgaria',\n",
       " 'easter',\n",
       " 'ernest',\n",
       " 'raymond',\n",
       " 'morgan',\n",
       " 'manuel',\n",
       " 'colombia',\n",
       " 'jason',\n",
       " 'bundesliga',\n",
       " 'soundgarden',\n",
       " 'harbour',\n",
       " 'beij',\n",
       " 'batman',\n",
       " 'panama',\n",
       " 'chakwal',\n",
       " 'sussex',\n",
       " 'vinc',\n",
       " 'neil',\n",
       " 'alex',\n",
       " 'blackhawk',\n",
       " 'tuesday',\n",
       " 'tyler',\n",
       " 'ferrari',\n",
       " 'yugoslavia',\n",
       " 'furbi',\n",
       " 'tommi',\n",
       " 'arabian',\n",
       " 'debian',\n",
       " 'tasmania',\n",
       " 'pragu',\n",
       " 'bermuda',\n",
       " 'chãƒ',\n",
       " 'hume',\n",
       " 'lebanon',\n",
       " 'alexandra',\n",
       " 'serbian',\n",
       " 'anastasia',\n",
       " 'alberta',\n",
       " 'hudson',\n",
       " 'jacob',\n",
       " 'lanka',\n",
       " 'craig',\n",
       " 'twentieth',\n",
       " 'bristol',\n",
       " 'baltic',\n",
       " 'ussr',\n",
       " 'marcu',\n",
       " 'ottawa',\n",
       " 'jamaica',\n",
       " 'jurass',\n",
       " 'pedro',\n",
       " 'victorian',\n",
       " 'increasingli',\n",
       " 'orlando',\n",
       " 'spencer',\n",
       " 'venezuela',\n",
       " 'sega',\n",
       " 'slovak',\n",
       " 'joan',\n",
       " 'dolj',\n",
       " 'parker',\n",
       " 'norfolk',\n",
       " 'necessarili',\n",
       " 'facto',\n",
       " 'valencia',\n",
       " 'haut',\n",
       " 'powel',\n",
       " 'susan',\n",
       " 'wolfgang',\n",
       " 'leonard',\n",
       " 'esperanto',\n",
       " 'collin',\n",
       " 'keith',\n",
       " 'surrey',\n",
       " 'alexandria',\n",
       " 'adolf',\n",
       " 'medici',\n",
       " 'andi',\n",
       " 'hermann',\n",
       " 'warren',\n",
       " 'edgar',\n",
       " 'lithuanian',\n",
       " 'tibet',\n",
       " 'windsor',\n",
       " 'avon',\n",
       " 'fernando',\n",
       " 'pradesh',\n",
       " 'burton',\n",
       " 'ethiopia',\n",
       " 'delhi',\n",
       " 'leonardo',\n",
       " 'latvia',\n",
       " 'bryan',\n",
       " 'fischer',\n",
       " 'calvin',\n",
       " 'burma',\n",
       " 'devon',\n",
       " 'isabella',\n",
       " 'chelsea',\n",
       " 'bart',\n",
       " 'thurgau',\n",
       " 'danni',\n",
       " 'paramount',\n",
       " 'antil',\n",
       " 'philipp',\n",
       " 'nigeria',\n",
       " 'sanskrit',\n",
       " 'bruin',\n",
       " 'claud',\n",
       " 'cyril',\n",
       " 'shawn',\n",
       " 'monaco',\n",
       " 'mauric',\n",
       " 'randi',\n",
       " 'versail',\n",
       " 'floyd',\n",
       " 'torr',\n",
       " 'greenland',\n",
       " 'broadway',\n",
       " 'perth',\n",
       " 'alban',\n",
       " 'aaron',\n",
       " 'nixon',\n",
       " 'morri',\n",
       " 'brighton',\n",
       " 'cole',\n",
       " 'silva',\n",
       " 'pluto',\n",
       " 'wallac',\n",
       " 'lorenzo',\n",
       " 'inca',\n",
       " 'newcastl',\n",
       " 'yanke',\n",
       " 'sudan',\n",
       " 'tico',\n",
       " 'walker',\n",
       " 'aragon',\n",
       " 'fred',\n",
       " 'luigi',\n",
       " 'jose',\n",
       " 'harold',\n",
       " 'hainaut',\n",
       " 'horton',\n",
       " 'webster',\n",
       " 'forev',\n",
       " 'estonia',\n",
       " 'canuck',\n",
       " 'stanford',\n",
       " 'nascar',\n",
       " 'ncaa',\n",
       " 'vill',\n",
       " 'wednesday',\n",
       " 'somerset',\n",
       " 'buddha',\n",
       " 'waterloo',\n",
       " 'romeo',\n",
       " 'kate',\n",
       " 'malta',\n",
       " 'salvador',\n",
       " 'denni',\n",
       " 'evan',\n",
       " 'calgari',\n",
       " 'hindenburg',\n",
       " 'oblast',\n",
       " 'karachi',\n",
       " 'echidna',\n",
       " 'watson',\n",
       " 'nato',\n",
       " 'toyota',\n",
       " 'rudolf',\n",
       " 'antwerp',\n",
       " 'kati',\n",
       " 'livingston',\n",
       " 'properli',\n",
       " 'colin',\n",
       " 'pete',\n",
       " 'chilean',\n",
       " 'luther',\n",
       " 'scala',\n",
       " 'melina',\n",
       " 'bern',\n",
       " 'pablo',\n",
       " 'domingo',\n",
       " 'viola',\n",
       " 'maxwel',\n",
       " 'helsinki',\n",
       " 'owen',\n",
       " 'keyn',\n",
       " 'azerbaijan',\n",
       " 'greg',\n",
       " 'slovenia',\n",
       " 'rover',\n",
       " 'chevrolet',\n",
       " 'rica',\n",
       " 'beyoncã',\n",
       " 'reagan',\n",
       " 'mecklenburg',\n",
       " 'boe',\n",
       " 'krei',\n",
       " 'indonesian',\n",
       " 'jess',\n",
       " 'pichilemu',\n",
       " 'tanzania',\n",
       " 'disambigu',\n",
       " 'thereaft',\n",
       " 'antoin',\n",
       " 'cornwal',\n",
       " 'morocco',\n",
       " 'coburg',\n",
       " 'ruth',\n",
       " 'verd',\n",
       " 'pascal',\n",
       " 'cruz',\n",
       " 'edmonton',\n",
       " 'derbyshir',\n",
       " 'indianapoli',\n",
       " 'osaka',\n",
       " 'chad',\n",
       " 'lisa',\n",
       " 'gettysburg',\n",
       " 'sunderland',\n",
       " 'marina',\n",
       " 'aang',\n",
       " 'dant',\n",
       " 'connor',\n",
       " 'lulu',\n",
       " 'olympiad',\n",
       " 'lancashir',\n",
       " 'princeton',\n",
       " 'thai',\n",
       " 'phil',\n",
       " 'vladimir',\n",
       " 'bavarian',\n",
       " 'yearli',\n",
       " 'ming',\n",
       " 'manga',\n",
       " 'berg',\n",
       " 'oslo',\n",
       " 'rttemberg',\n",
       " 'grameen',\n",
       " 'albani',\n",
       " 'troy',\n",
       " 'lutheran',\n",
       " 'nineteenth',\n",
       " 'eleventh',\n",
       " 'nanci',\n",
       " 'lang',\n",
       " 'benoit',\n",
       " 'predominantli',\n",
       " 'gotha',\n",
       " 'socrat',\n",
       " 'hanov',\n",
       " 'amherst',\n",
       " 'bismarck',\n",
       " 'pasteur',\n",
       " 'lombardi',\n",
       " 'roberto',\n",
       " 'malcolm',\n",
       " 'meanwhil',\n",
       " 'cincinnati',\n",
       " 'czechoslovakia',\n",
       " 'stallon',\n",
       " 'sean',\n",
       " 'todd',\n",
       " 'denver',\n",
       " 'baja',\n",
       " 'unitari',\n",
       " 'yokohama',\n",
       " 'ipswich',\n",
       " 'brandon',\n",
       " 'copenhagen',\n",
       " 'amadeu',\n",
       " 'felix',\n",
       " 'memphi',\n",
       " 'congo',\n",
       " 'beethoven',\n",
       " 'montana']"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aoa_complement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2568"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aoa_intersect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['franc',\n",
       " 'unit',\n",
       " 'commun',\n",
       " 'depart',\n",
       " 'region',\n",
       " 'state',\n",
       " 'american',\n",
       " 'includ',\n",
       " 'call',\n",
       " 'nation',\n",
       " 'play',\n",
       " 'area',\n",
       " 'locat',\n",
       " 'univers',\n",
       " 'district',\n",
       " 'releas',\n",
       " 'year',\n",
       " 'refer',\n",
       " 'name',\n",
       " 'album']"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aoa_intersect[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2504"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([word for word in aoa_intersect if word in concrete_intersect])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in aoa_intersect:\n",
    "    word_vectors[word] = word_vectors[word] * AoA[AoA['stem']==word]['AoA_Kup_lem'].values.mean()/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.60550966e-03,  6.39024749e-02,  1.22927926e-01, -6.67695254e-02,\n",
       "       -2.11646333e-02,  6.78376108e-02, -5.55641800e-02, -1.17425859e-01,\n",
       "       -6.08915463e-02,  6.42859787e-02,  6.30783290e-02, -6.28967583e-02,\n",
       "        8.51282701e-02,  1.21723197e-01,  1.33140050e-02, -7.39356056e-02,\n",
       "       -2.49795970e-02,  1.05114130e-03, -6.53022304e-02,  8.40578005e-02,\n",
       "        4.38750014e-02,  1.90958790e-02,  1.55691996e-01, -7.26904422e-02,\n",
       "        1.56380489e-01,  3.66317481e-02,  6.99369609e-02, -1.08762115e-01,\n",
       "       -9.38292667e-02, -4.31798212e-02,  2.47675404e-02,  9.44281891e-02,\n",
       "        3.80865559e-02,  1.03876339e-02, -9.49328244e-02, -1.21576441e-02,\n",
       "       -2.52790209e-02,  6.71047941e-02,  8.76306146e-02, -6.13158084e-02,\n",
       "       -8.27499330e-02, -4.46005724e-02, -1.02950171e-01, -5.64199835e-02,\n",
       "        1.01967983e-01,  1.11926183e-01, -7.29957372e-02, -2.13728651e-01,\n",
       "        1.90232489e-02, -4.03152257e-02,  5.06000817e-02, -7.45786726e-02,\n",
       "        1.67174488e-01,  1.70500390e-02,  4.33204323e-02, -8.83468315e-02,\n",
       "       -1.89339500e-02,  9.99575034e-02,  1.22426888e-02, -2.01927517e-02,\n",
       "       -9.17373374e-02, -2.03634948e-02, -4.80625443e-02,  4.72388305e-02,\n",
       "       -2.87059266e-02, -9.13393721e-02,  9.15314704e-02,  7.46248066e-02,\n",
       "       -7.67825618e-02,  1.16951391e-02,  5.15653528e-02,  3.37711461e-02,\n",
       "       -4.24824096e-02,  8.34812596e-03, -1.59466892e-01, -5.97759895e-03,\n",
       "       -1.25850841e-01,  5.08967089e-03, -2.17216872e-02, -5.78009225e-02,\n",
       "        7.15681165e-02, -2.54268572e-02, -8.66946876e-02,  7.44086038e-03,\n",
       "       -1.63985297e-01, -2.05435470e-01,  2.31733732e-02, -1.39773726e-01,\n",
       "       -2.16148123e-02, -1.38548752e-02,  4.99969944e-02, -1.06977180e-01,\n",
       "        1.61209051e-02,  6.48810863e-02, -1.00830579e-02,  1.57721817e-01,\n",
       "        9.83226855e-05,  4.38060425e-02,  4.72227298e-03, -4.07522246e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dense_features(tokenized_text,word_vectors):\n",
    "    dense_list=[]\n",
    "    words=[]\n",
    "    for _ in tokenized_text: \n",
    "        words =[word for word in _ if word in word_vectors.key_to_index]\n",
    "        \n",
    "        if len(words) >0:\n",
    "            dense_list.append(np.mean(word_vectors[words],axis=0))\n",
    "            \n",
    "        else: \n",
    "            dense_list.append(np.zeros(word_vectors.vector_size))\n",
    "            \n",
    "    return np.array(dense_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_wv = generate_dense_features(tokenized_text_train,word_vectors)\n",
    "X_test_wv = generate_dense_features(tokenized_text_test,word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(333414, 100)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_wv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_wv = LogisticRegression(random_state=RANDOM_SEED,max_iter=1000).fit(X_train_wv,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5594092665019075"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,lr_wv.predict(X_test_wv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_fun(doc):\n",
    "    return doc\n",
    "vectorizer = TfidfVectorizer(analyzer='word',tokenizer=dummy_fun, preprocessor=dummy_fun, token_pattern=r'(?u)\\b\\w\\w+__\\([\\w\\s]*\\)')\n",
    "X_train_transform = vectorizer.fit_transform(tokenized_text_train)\n",
    "X_test_transform  = vectorizer.transform(tokenized_text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a_nx',\n",
       " 'aabout',\n",
       " 'aabye',\n",
       " 'aach',\n",
       " 'aafc',\n",
       " 'aage',\n",
       " 'aaiil',\n",
       " 'aaliyahs',\n",
       " 'aall',\n",
       " 'aalto',\n",
       " 'aames',\n",
       " 'aamir',\n",
       " 'aang',\n",
       " 'aangã',\n",
       " 'aapep',\n",
       " 'aarberg',\n",
       " 'aarburg',\n",
       " 'aarc',\n",
       " 'aarde',\n",
       " 'aardman',\n",
       " 'aardsma',\n",
       " 'aardvark',\n",
       " 'aardvarks',\n",
       " 'aare',\n",
       " 'aargauer',\n",
       " 'aarhus',\n",
       " 'aaroni',\n",
       " 'aarons',\n",
       " 'aarre',\n",
       " 'aarseth',\n",
       " 'aartselaar',\n",
       " 'aarwangen',\n",
       " 'aasen',\n",
       " 'aashurah',\n",
       " 'aast',\n",
       " 'aastana',\n",
       " 'aave',\n",
       " 'ababa',\n",
       " 'ababba',\n",
       " 'ababda',\n",
       " 'abac',\n",
       " 'abacada',\n",
       " 'abaci',\n",
       " 'aback',\n",
       " 'abacus',\n",
       " 'abacuses',\n",
       " 'abad',\n",
       " 'abagnale',\n",
       " 'abahutu',\n",
       " 'abaj',\n",
       " 'abajo',\n",
       " 'abakanskoye',\n",
       " 'abal',\n",
       " 'abalo',\n",
       " 'abalone',\n",
       " 'abando',\n",
       " 'abandon',\n",
       " 'abandonded',\n",
       " 'abandonment',\n",
       " 'abarat',\n",
       " 'abassi',\n",
       " 'abate',\n",
       " 'abattoirs',\n",
       " 'abatutsi',\n",
       " 'abauzit',\n",
       " 'abavo',\n",
       " 'abazhou',\n",
       " 'abaãºj',\n",
       " 'abba',\n",
       " 'abbado',\n",
       " 'abbadon',\n",
       " 'abbados',\n",
       " 'abbandando',\n",
       " 'abbas',\n",
       " 'abbasi',\n",
       " 'abbasid',\n",
       " 'abbasids',\n",
       " 'abbasies',\n",
       " 'abbass',\n",
       " 'abbassid',\n",
       " 'abbay',\n",
       " 'abbaye',\n",
       " 'abbe',\n",
       " 'abbeydale',\n",
       " 'abbeys',\n",
       " 'abbiamo',\n",
       " 'abbiati',\n",
       " 'abbiss',\n",
       " 'abbondancieri',\n",
       " 'abbondanzieri',\n",
       " 'abbondio',\n",
       " 'abbot',\n",
       " 'abbotsinch',\n",
       " 'abbottabad',\n",
       " 'abbotts',\n",
       " 'abbr',\n",
       " 'abbrev',\n",
       " 'abbreviate',\n",
       " 'abbreviation',\n",
       " 'abbreviations',\n",
       " 'abbruzzese',\n",
       " 'abbs',\n",
       " 'abbud',\n",
       " 'abbã',\n",
       " 'abbãƒ',\n",
       " 'abcd',\n",
       " 'abcs',\n",
       " 'abdacom',\n",
       " 'abdal',\n",
       " 'abdallah',\n",
       " 'abdel',\n",
       " 'abdelazar',\n",
       " 'abdelhafid',\n",
       " 'abdeljalil',\n",
       " 'abdelwahab',\n",
       " 'abdera',\n",
       " 'abderathe',\n",
       " 'abdest',\n",
       " 'abdi',\n",
       " 'abdicate',\n",
       " 'abdicatio',\n",
       " 'abdication',\n",
       " 'abdirashid',\n",
       " 'abdolah',\n",
       " 'abdollah',\n",
       " 'abdomen',\n",
       " 'abdomens',\n",
       " 'abdominal',\n",
       " 'abdominis',\n",
       " 'abdou',\n",
       " 'abdoulaye',\n",
       " 'abdu',\n",
       " 'abduct',\n",
       " 'abduction',\n",
       " 'abdulahi',\n",
       " 'abdulaziz',\n",
       " 'abdullaziz',\n",
       " 'abdun',\n",
       " 'abdurrahman',\n",
       " 'abdus',\n",
       " 'abeba',\n",
       " 'abela',\n",
       " 'abelard',\n",
       " 'abele',\n",
       " 'abelian',\n",
       " 'abelisaurid',\n",
       " 'abella',\n",
       " 'abells',\n",
       " 'abelmoschus',\n",
       " 'abelshauser',\n",
       " 'abelson',\n",
       " 'abendroth',\n",
       " 'abenobashi',\n",
       " 'abenon',\n",
       " 'abenteuer',\n",
       " 'aber',\n",
       " 'abercrombie',\n",
       " 'abercromby',\n",
       " 'aberdeenshire',\n",
       " 'aberdeenshires',\n",
       " 'aberdour',\n",
       " 'aberdovey',\n",
       " 'aberdyfi',\n",
       " 'aberfan',\n",
       " 'aberford',\n",
       " 'aberfoyle',\n",
       " 'abergavenny',\n",
       " 'abergement',\n",
       " 'abergynolwyn',\n",
       " 'aberlin',\n",
       " 'aberrant',\n",
       " 'aberration',\n",
       " 'aberrations',\n",
       " 'aberson',\n",
       " 'abert',\n",
       " 'abertay',\n",
       " 'aberystwyththe',\n",
       " 'abet',\n",
       " 'abeyie',\n",
       " 'abgar',\n",
       " 'abgebrã',\n",
       " 'abgrenzung',\n",
       " 'abhainn',\n",
       " 'abhanga',\n",
       " 'abhangas',\n",
       " 'abhinav',\n",
       " 'abhiras',\n",
       " 'abhor',\n",
       " 'abhorrã',\n",
       " 'abid',\n",
       " 'abidal',\n",
       " 'abide',\n",
       " 'abidine',\n",
       " 'abidos',\n",
       " 'abierta',\n",
       " 'abilities',\n",
       " 'ability',\n",
       " 'abimael',\n",
       " 'abin',\n",
       " 'abio',\n",
       " 'abiogenesis',\n",
       " 'abiotic',\n",
       " 'abiotically',\n",
       " 'abire',\n",
       " 'abisalovich',\n",
       " 'abispa',\n",
       " 'abitur',\n",
       " 'abiword',\n",
       " 'abjadi',\n",
       " 'abjads',\n",
       " 'abjuration',\n",
       " 'abkai',\n",
       " 'abkco',\n",
       " 'abkhaz',\n",
       " 'ablanedo',\n",
       " 'ablation',\n",
       " 'ablative',\n",
       " 'ablaze',\n",
       " 'abled',\n",
       " 'ablest',\n",
       " 'ablon',\n",
       " 'abloy',\n",
       " 'ablutions',\n",
       " 'abma',\n",
       " 'abney',\n",
       " 'abnicum',\n",
       " 'abnormal',\n",
       " 'abnormalities',\n",
       " 'abnormality',\n",
       " 'abnormally',\n",
       " 'abobrãƒ',\n",
       " 'abol',\n",
       " 'abolish',\n",
       " 'abolishment',\n",
       " 'abolition',\n",
       " 'abolitionism',\n",
       " 'abolitionist',\n",
       " 'abolitionists',\n",
       " 'abominations',\n",
       " 'abong',\n",
       " 'aboolian',\n",
       " 'aboot',\n",
       " 'aboriginal',\n",
       " 'aboriginals',\n",
       " 'aborigine',\n",
       " 'aborigines',\n",
       " 'abort',\n",
       " 'abortifacient',\n",
       " 'abortion',\n",
       " 'abortions',\n",
       " 'abortive',\n",
       " 'abou',\n",
       " 'abound',\n",
       " 'aboutus',\n",
       " 'aboveground',\n",
       " 'abra',\n",
       " 'abracadabra',\n",
       " 'abrahamic',\n",
       " 'abrahams',\n",
       " 'abramczik',\n",
       " 'abramovich',\n",
       " 'abrams',\n",
       " 'abrantes',\n",
       " 'abrasion',\n",
       " 'abrasions',\n",
       " 'abraxas',\n",
       " 'abraãƒ',\n",
       " 'abreaction',\n",
       " 'abreu',\n",
       " 'abrictosaurus',\n",
       " 'abridge',\n",
       " 'abridgment',\n",
       " 'abroad',\n",
       " 'abrogant',\n",
       " 'abrogate',\n",
       " 'abronia',\n",
       " 'abrowse',\n",
       " 'abrsm',\n",
       " 'abrupt',\n",
       " 'abruptly',\n",
       " 'abruzzi',\n",
       " 'abrã',\n",
       " 'abscess',\n",
       " 'abscesses',\n",
       " 'abscissa',\n",
       " 'abscond',\n",
       " 'absecon',\n",
       " 'absence',\n",
       " 'absences',\n",
       " 'absent',\n",
       " 'absentee',\n",
       " 'absentia',\n",
       " 'absentpelagic',\n",
       " 'absinth',\n",
       " 'absinthe',\n",
       " 'absinthes',\n",
       " 'absinthium',\n",
       " 'absolut',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absolutepunk',\n",
       " 'absolution',\n",
       " 'absolutist',\n",
       " 'absolutive',\n",
       " 'absolve',\n",
       " 'absorb',\n",
       " 'absorbance',\n",
       " 'absorbances',\n",
       " 'absorbent',\n",
       " 'absorber',\n",
       " 'absorbers',\n",
       " 'absorption',\n",
       " 'absorptive',\n",
       " 'abstain',\n",
       " 'abstention',\n",
       " 'abstentionism',\n",
       " 'abstinence',\n",
       " 'abstract',\n",
       " 'abstraction',\n",
       " 'abstractionists',\n",
       " 'abstractions',\n",
       " 'absurd',\n",
       " 'absurde',\n",
       " 'absurdism',\n",
       " 'absurdist',\n",
       " 'absurdity',\n",
       " 'abtwil',\n",
       " 'abub',\n",
       " 'abubakari',\n",
       " 'abugida',\n",
       " 'abugidas',\n",
       " 'abukuma',\n",
       " 'abul',\n",
       " 'abuladze',\n",
       " 'abulkhair',\n",
       " 'abulm',\n",
       " 'abuls',\n",
       " 'abulã',\n",
       " 'abundance',\n",
       " 'abundant',\n",
       " 'abundantly',\n",
       " 'aburish',\n",
       " 'abuse',\n",
       " 'abusive',\n",
       " 'abusively',\n",
       " 'abut',\n",
       " 'abutere',\n",
       " 'abutments',\n",
       " 'aby',\n",
       " 'abydos',\n",
       " 'abyssal',\n",
       " 'abzekh',\n",
       " 'abãƒ',\n",
       " 'acacia',\n",
       " 'acacias',\n",
       " 'acad',\n",
       " 'acadamias',\n",
       " 'academe',\n",
       " 'academia',\n",
       " 'academic',\n",
       " 'academical',\n",
       " 'academically',\n",
       " 'academician',\n",
       " 'academics',\n",
       " 'academie',\n",
       " 'academies',\n",
       " 'academkniga',\n",
       " 'academy',\n",
       " 'acadia',\n",
       " 'acadians',\n",
       " 'acadã',\n",
       " 'acadãƒ',\n",
       " 'acamprosate',\n",
       " 'acanthaceae',\n",
       " 'acanthaclisinae',\n",
       " 'acanthocephala',\n",
       " 'acanthodii',\n",
       " 'acanthomintha',\n",
       " 'acanthomyops',\n",
       " 'acanthophis',\n",
       " 'acanthophylla',\n",
       " 'acanthostega',\n",
       " 'acapulco',\n",
       " 'acari',\n",
       " 'acarology',\n",
       " 'acaso',\n",
       " 'acasta',\n",
       " 'acca',\n",
       " 'accademia',\n",
       " 'accadian',\n",
       " 'accede',\n",
       " 'accelerate',\n",
       " 'accelerateur',\n",
       " 'acceleration',\n",
       " 'accelerations',\n",
       " 'accelerator',\n",
       " 'accelerators',\n",
       " 'acceleratorsã',\n",
       " 'accelerometer',\n",
       " 'accelerometers',\n",
       " 'accends',\n",
       " 'accent',\n",
       " 'accentschurmann',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'acceptably',\n",
       " 'acceptance',\n",
       " 'acceptor',\n",
       " 'access',\n",
       " 'accessibility',\n",
       " 'accessible',\n",
       " 'accession',\n",
       " 'accessories',\n",
       " 'accessory',\n",
       " 'acchieved',\n",
       " 'acchouhouri',\n",
       " 'acciaiuoli',\n",
       " 'acciarito',\n",
       " 'accident',\n",
       " 'accidental',\n",
       " 'accidentally',\n",
       " 'accidentals',\n",
       " 'accidents',\n",
       " 'accidie',\n",
       " 'accies',\n",
       " 'acciona',\n",
       " 'accipiter',\n",
       " 'accipitridae',\n",
       " 'acciã³n',\n",
       " 'acciãƒ',\n",
       " 'acclaim',\n",
       " 'acclamation',\n",
       " 'acclamations',\n",
       " 'acclimatation',\n",
       " 'acclimate',\n",
       " 'acclimatisation',\n",
       " 'accolade',\n",
       " 'accolades',\n",
       " 'accomack',\n",
       " 'accommodate',\n",
       " 'accommodation',\n",
       " 'accommodations',\n",
       " 'accommodative',\n",
       " 'accompaniment',\n",
       " 'accompanist',\n",
       " 'accompany',\n",
       " 'accomping',\n",
       " 'accomplice',\n",
       " 'accomplices',\n",
       " 'accomplish',\n",
       " 'accomplishers',\n",
       " 'accomplishment',\n",
       " 'accomplishments',\n",
       " 'accomptant',\n",
       " 'accons',\n",
       " 'accord',\n",
       " 'accordance',\n",
       " 'accordingly',\n",
       " 'accordion',\n",
       " 'accordionist',\n",
       " 'accordo',\n",
       " 'accost',\n",
       " 'accouchement',\n",
       " 'account',\n",
       " 'accountability',\n",
       " 'accountable',\n",
       " 'accountancy',\n",
       " 'accountant',\n",
       " 'accountants',\n",
       " 'accountn',\n",
       " 'accountsare',\n",
       " 'accous',\n",
       " 'accouterments',\n",
       " 'accoutrement',\n",
       " 'accoyer',\n",
       " 'accredit',\n",
       " 'accreditation',\n",
       " 'accreditor',\n",
       " 'accreta',\n",
       " 'accrete',\n",
       " 'accretion',\n",
       " 'accross',\n",
       " 'accrue',\n",
       " 'acculturate',\n",
       " 'accumbens',\n",
       " 'accumulate',\n",
       " 'accumulation',\n",
       " 'accumulations',\n",
       " 'accuracy',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'accusamus',\n",
       " 'accusantium',\n",
       " 'accusation',\n",
       " 'accusations',\n",
       " 'accuse',\n",
       " 'accustom',\n",
       " 'ace',\n",
       " 'acedia',\n",
       " 'aceldama',\n",
       " 'aceman',\n",
       " 'acephala',\n",
       " 'acequia',\n",
       " 'acer',\n",
       " 'aceraceae',\n",
       " 'aceramic',\n",
       " 'acerbic',\n",
       " 'acerbo',\n",
       " 'acetaldehyde',\n",
       " 'acetaminophen',\n",
       " 'acetate',\n",
       " 'acetic',\n",
       " 'acetobacter',\n",
       " 'acetone',\n",
       " 'acetyl',\n",
       " 'acetylate',\n",
       " 'acetylation',\n",
       " 'acetylcholine',\n",
       " 'acetylene',\n",
       " 'acetylide',\n",
       " 'acetylsalicylic',\n",
       " 'acevedo',\n",
       " 'achab',\n",
       " 'achaea',\n",
       " 'achaemenid',\n",
       " 'achaius',\n",
       " 'achard',\n",
       " 'acharya',\n",
       " 'achawãƒ',\n",
       " 'ache',\n",
       " 'achebe',\n",
       " 'achelate',\n",
       " 'acheloos',\n",
       " 'achelous',\n",
       " 'achenbach',\n",
       " 'achenes',\n",
       " 'acheron',\n",
       " 'acherontia',\n",
       " 'achery',\n",
       " 'acheulean',\n",
       " 'achhim',\n",
       " 'achi',\n",
       " 'achicourt',\n",
       " 'achiet',\n",
       " 'achievable',\n",
       " 'achieve',\n",
       " 'achievement',\n",
       " 'achievements',\n",
       " 'achila',\n",
       " 'achiles',\n",
       " 'achille',\n",
       " 'achillea',\n",
       " 'achilles',\n",
       " 'achillobator',\n",
       " 'achiote',\n",
       " 'achiral',\n",
       " 'achlorhydria',\n",
       " 'achmad',\n",
       " 'achmed',\n",
       " 'achna',\n",
       " 'achoholic',\n",
       " 'acholi',\n",
       " 'achondrite',\n",
       " 'achondroplasia',\n",
       " 'achondroplastic',\n",
       " 'achonry',\n",
       " 'achromasia',\n",
       " 'achromatopsia',\n",
       " 'achromatosis',\n",
       " 'achromia',\n",
       " 'achterhoek',\n",
       " 'achtice',\n",
       " 'achtung',\n",
       " 'achy',\n",
       " 'achzarit',\n",
       " 'achã',\n",
       " 'achãƒ',\n",
       " 'acib',\n",
       " 'acid',\n",
       " 'acidic',\n",
       " 'acidification',\n",
       " 'acidify',\n",
       " 'acidity',\n",
       " 'acidosis',\n",
       " 'acids',\n",
       " 'acinar',\n",
       " 'acis',\n",
       " 'ackerman',\n",
       " 'ackery',\n",
       " 'ackley',\n",
       " 'acklins',\n",
       " 'acknowledge',\n",
       " 'acknowledgement',\n",
       " 'acknowledgment',\n",
       " 'acknowledgments',\n",
       " 'ackworth',\n",
       " 'acland',\n",
       " 'aclare',\n",
       " 'acme',\n",
       " 'acmi',\n",
       " 'acne',\n",
       " 'acnielsen',\n",
       " 'acolyte',\n",
       " 'acolytes',\n",
       " 'acomyinae',\n",
       " 'acomys',\n",
       " 'aconcagua',\n",
       " 'aconite',\n",
       " 'aconitum',\n",
       " 'acorah',\n",
       " 'acorn',\n",
       " 'acorns',\n",
       " 'acosta',\n",
       " 'acou',\n",
       " 'acoustic',\n",
       " 'acoustical',\n",
       " 'acoustically',\n",
       " 'acoustician',\n",
       " 'acousticly',\n",
       " 'acoustics',\n",
       " 'acpb',\n",
       " 'acquaint',\n",
       " 'acquaintance',\n",
       " 'acquaintances',\n",
       " 'acquarossa',\n",
       " 'acqueville',\n",
       " 'acquiesce',\n",
       " 'acquieses',\n",
       " 'acquin',\n",
       " 'acquire',\n",
       " 'acquisition',\n",
       " 'acquisitions',\n",
       " 'acquit',\n",
       " 'acquittal',\n",
       " 'acrea',\n",
       " 'acrelãƒ',\n",
       " 'acres',\n",
       " 'acrisius',\n",
       " 'acritarch',\n",
       " 'acritarchs',\n",
       " 'acrobat',\n",
       " 'acrobates',\n",
       " 'acrobatic',\n",
       " 'acrobatics',\n",
       " 'acrobaticã',\n",
       " 'acrobats',\n",
       " 'acron',\n",
       " 'acronis',\n",
       " 'acronym',\n",
       " 'acronymic',\n",
       " 'acronymous',\n",
       " 'acronyms',\n",
       " 'acropolis',\n",
       " 'across',\n",
       " 'acrossmanhattan',\n",
       " 'acrylic',\n",
       " 'acrymia',\n",
       " 'acst',\n",
       " 'act',\n",
       " 'acta',\n",
       " 'acte',\n",
       " 'actias',\n",
       " 'actin',\n",
       " 'actinide',\n",
       " 'actinides',\n",
       " 'actinidia',\n",
       " 'actinium',\n",
       " 'actinobacteria',\n",
       " 'actinoid',\n",
       " 'actinolite',\n",
       " 'actinomorphic',\n",
       " 'actinomycetes',\n",
       " 'actinopterygii',\n",
       " 'actinopterygius',\n",
       " 'actinosporea',\n",
       " 'actinotrocha',\n",
       " 'action',\n",
       " 'actionscript',\n",
       " 'actium',\n",
       " 'actius',\n",
       " 'activate',\n",
       " 'activation',\n",
       " 'activator',\n",
       " 'active',\n",
       " 'activebass',\n",
       " 'actively',\n",
       " 'actives',\n",
       " 'activestats',\n",
       " 'activeworlds',\n",
       " 'activex',\n",
       " 'activision',\n",
       " 'activism',\n",
       " 'activist',\n",
       " 'activists',\n",
       " 'activities',\n",
       " 'activitist',\n",
       " 'activitiy',\n",
       " 'activity',\n",
       " 'activitã',\n",
       " 'actor',\n",
       " 'actors',\n",
       " 'actress',\n",
       " 'actresses',\n",
       " 'actual',\n",
       " 'actuality',\n",
       " 'actualitã',\n",
       " 'actually',\n",
       " 'actuaries',\n",
       " 'actuate',\n",
       " 'actuations',\n",
       " 'actus',\n",
       " 'acuatic',\n",
       " 'acuca',\n",
       " 'acuity',\n",
       " 'aculeata',\n",
       " 'aculeatus',\n",
       " 'acupressure',\n",
       " 'acupuncture',\n",
       " 'acura',\n",
       " 'acute',\n",
       " 'acutely',\n",
       " 'acuteness',\n",
       " 'acutus',\n",
       " 'acyclic',\n",
       " 'acyl',\n",
       " 'adachi',\n",
       " 'adad',\n",
       " 'adage',\n",
       " 'adages',\n",
       " 'adagh',\n",
       " 'adagio',\n",
       " 'adair',\n",
       " 'adairville',\n",
       " 'adak',\n",
       " 'adal',\n",
       " 'adalbert',\n",
       " 'adama',\n",
       " 'adamantine',\n",
       " 'adamantium',\n",
       " 'adamey',\n",
       " 'adaminaby',\n",
       " 'adamite',\n",
       " 'adamkus',\n",
       " 'adamlarina',\n",
       " 'adamle',\n",
       " 'adamski',\n",
       " 'adamson',\n",
       " 'adamsville',\n",
       " 'adapiformes',\n",
       " 'adapt',\n",
       " 'adaptability',\n",
       " 'adaptable',\n",
       " 'adaptation',\n",
       " 'adaptations',\n",
       " 'adapter',\n",
       " 'adapters',\n",
       " 'adaption',\n",
       " 'adaptions',\n",
       " 'adaptive',\n",
       " 'adaptively',\n",
       " 'adaptor',\n",
       " 'adas',\n",
       " 'adasaurus',\n",
       " 'adashim',\n",
       " 'adastra',\n",
       " 'adav',\n",
       " 'add',\n",
       " 'addai',\n",
       " 'addakhil',\n",
       " 'addams',\n",
       " 'addax',\n",
       " 'addenbrooke',\n",
       " 'addendum',\n",
       " 'adder',\n",
       " 'adderley',\n",
       " 'adders',\n",
       " 'addicks',\n",
       " 'addict',\n",
       " 'addiction',\n",
       " 'addictions',\n",
       " 'addictive',\n",
       " 'addington',\n",
       " 'addis',\n",
       " 'addiscombe',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'additionally',\n",
       " 'additionals',\n",
       " 'additions',\n",
       " 'additive',\n",
       " 'additively',\n",
       " 'additives',\n",
       " 'addon',\n",
       " 'address',\n",
       " 'addressability',\n",
       " 'addressable',\n",
       " 'adegboyega',\n",
       " 'adegem',\n",
       " 'adelante',\n",
       " 'adelboden',\n",
       " 'adelekan',\n",
       " 'adelheid',\n",
       " 'adelir',\n",
       " 'adelomyrmex',\n",
       " 'adelong',\n",
       " 'adelphotheos',\n",
       " 'adelsheim',\n",
       " 'ademar',\n",
       " 'ademir',\n",
       " 'ademola',\n",
       " 'adenauer',\n",
       " 'adenine',\n",
       " 'adenoidectomy',\n",
       " 'adenoids',\n",
       " 'adenoma',\n",
       " 'adenosine',\n",
       " 'adephaga',\n",
       " 'adept',\n",
       " 'adequality',\n",
       " 'adequate',\n",
       " 'adequately',\n",
       " 'aderbal',\n",
       " 'ades',\n",
       " 'adesa',\n",
       " 'adetokunbo',\n",
       " 'adeus',\n",
       " 'adha',\n",
       " 'adhaerens',\n",
       " 'adhan',\n",
       " 'adhana',\n",
       " 'adhd',\n",
       " 'adhemar',\n",
       " 'adhere',\n",
       " 'adherence',\n",
       " 'adherent',\n",
       " 'adherents',\n",
       " 'adhesion',\n",
       " 'adhesions',\n",
       " 'adhesive',\n",
       " 'adhesives',\n",
       " 'adhlaka',\n",
       " 'adhur',\n",
       " 'adiabatic',\n",
       " 'adiabene',\n",
       " 'adibuddha',\n",
       " 'adic',\n",
       " 'adichie',\n",
       " 'adidas',\n",
       " 'adiel',\n",
       " 'adieu',\n",
       " 'adige',\n",
       " 'adikalar',\n",
       " 'adil',\n",
       " 'adinath',\n",
       " 'adine',\n",
       " 'adinfer',\n",
       " 'adingaheim',\n",
       " 'adiperukku',\n",
       " 'adipisci',\n",
       " 'adipocytes',\n",
       " 'adipose',\n",
       " 'adiposity',\n",
       " 'adipperukku',\n",
       " 'adiri',\n",
       " 'adirondack',\n",
       " 'adit',\n",
       " 'adits',\n",
       " 'adiyiah',\n",
       " 'adjacent',\n",
       " 'adjacã',\n",
       " 'adjacãƒ',\n",
       " 'adjascent',\n",
       " 'adjectival',\n",
       " 'adjectivally',\n",
       " 'adjective',\n",
       " 'adjectives',\n",
       " 'adjei',\n",
       " 'adjemian',\n",
       " 'adjoin',\n",
       " 'adjudge',\n",
       " 'adjudicate',\n",
       " 'adjudication',\n",
       " 'adjudicator',\n",
       " 'adjudicators',\n",
       " 'adjunct',\n",
       " 'adjunctive',\n",
       " 'adjuncts',\n",
       " 'adjuration',\n",
       " 'adjust',\n",
       " 'adjustable',\n",
       " 'adjustment',\n",
       " 'adjustments',\n",
       " 'adjutant',\n",
       " 'adjutants',\n",
       " 'adjuvants',\n",
       " 'adkins',\n",
       " 'adlaka',\n",
       " 'adleman',\n",
       " 'adlon',\n",
       " 'admin',\n",
       " 'adminer',\n",
       " 'administer',\n",
       " 'administeriet',\n",
       " 'administraciã³n',\n",
       " 'administraciãƒ',\n",
       " 'administrate',\n",
       " 'administration',\n",
       " 'administrations',\n",
       " 'administrative',\n",
       " 'administrator',\n",
       " 'administrators',\n",
       " 'admins',\n",
       " 'adminship',\n",
       " 'admira',\n",
       " 'admirable',\n",
       " 'admirably',\n",
       " 'admirals',\n",
       " 'admiralspalast',\n",
       " 'admiralty',\n",
       " 'admiration',\n",
       " 'admire',\n",
       " 'admirer',\n",
       " 'admirers',\n",
       " 'admiringly',\n",
       " 'admission',\n",
       " 'admissions',\n",
       " 'admit',\n",
       " 'admittance',\n",
       " 'admittedly',\n",
       " 'admixture',\n",
       " 'admixtures',\n",
       " 'admonition',\n",
       " 'admont',\n",
       " 'adna',\n",
       " 'adnan',\n",
       " 'adnos',\n",
       " 'adobe',\n",
       " 'adobes',\n",
       " 'adolescence',\n",
       " 'adolescent',\n",
       " 'adolescente',\n",
       " 'adolescents',\n",
       " 'adolphe',\n",
       " 'adom',\n",
       " 'adomnãƒ',\n",
       " 'adonai',\n",
       " 'adopt',\n",
       " 'adoptable',\n",
       " 'adoption',\n",
       " 'adoptionism',\n",
       " 'adoptions',\n",
       " 'adoptive',\n",
       " 'adorable',\n",
       " 'adoration',\n",
       " 'adore',\n",
       " 'adorn',\n",
       " 'adornments',\n",
       " 'adorno',\n",
       " 'adoroam',\n",
       " 'adrastea',\n",
       " 'adrenal',\n",
       " 'adrenalin',\n",
       " 'adrenaline',\n",
       " 'adrenalize',\n",
       " 'adriaan',\n",
       " 'adriaen',\n",
       " 'adriaenszoon',\n",
       " 'adriano',\n",
       " 'adrianopole',\n",
       " 'adrianov',\n",
       " 'adrianus',\n",
       " 'adriatic',\n",
       " 'adriatica',\n",
       " 'adriatico',\n",
       " 'adriã',\n",
       " 'adriãƒ',\n",
       " 'adroam',\n",
       " 'adroguãƒ',\n",
       " 'adsit',\n",
       " 'adso',\n",
       " 'adsorption',\n",
       " 'adsur',\n",
       " 'adtranz',\n",
       " 'adua',\n",
       " 'adug',\n",
       " 'aduki',\n",
       " 'adula',\n",
       " 'adulate',\n",
       " 'adulation',\n",
       " 'adult',\n",
       " 'adultera',\n",
       " 'adulterate',\n",
       " 'adulteration',\n",
       " 'adulterators',\n",
       " 'adulterer',\n",
       " 'adulterers',\n",
       " 'adulterous',\n",
       " 'adultery',\n",
       " 'adulthood',\n",
       " 'adultos',\n",
       " ...]"
      ]
     },
     "execution_count": 672,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<333414x106068 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1944434 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_bow = LogisticRegression(random_state=RANDOM_SEED,max_iter=1000).fit(X_train_transform,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6466876214698755"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,lr_bow.predict(X_test_transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_word = set(word_vectors.index_to_key) #around 6k words in the Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model_word.intersection(concreteset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors['live']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "word_list = []\n",
    "for word in model_word: \n",
    "    word_list.append((word,lemmatizer.lemmatize(word.lower())))\n",
    "df = pd.DataFrame(word_list,columns=['Original','word'])\n",
    "df = df.merge(AoA,left_on='word',right_on='Word',how='left')\n",
    "df = df[['Original','word','Perc_known','AoA_Kup_lem']]\n",
    "word_not_matched = set(df[df['Perc_known'].isnull()].word.values)\n",
    "\n",
    "for i in range(len(df)):   \n",
    "    if df['word'][i][0] in set(('0','1','2','3','4','5','6','7','8','9')) or len(df['word'][i])==1:\n",
    "        df['AoA_Kup_lem'][i] = 3\n",
    "mean_value = df['AoA_Kup_lem'].mean()\n",
    "df['AoA_Kup_lem'].fillna(value=mean_value,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.loc[df['Original']==['troops','weapons']]\n",
    "df[df['Original'].isin(['troops','weapon'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_perc_known(tokenized_text,df):\n",
    "    avg_perc_know=None\n",
    "    perc_know_list=[]\n",
    "    for _ in tokenized_text: \n",
    "        words =[word for word in _ if word in word_vectors.key_to_index]\n",
    "        \n",
    "        if len(words) >0:\n",
    "            avg_perc_know = np.mean(df[df['Original'].isin(words)]['AoA_Kup_lem'])\n",
    "            perc_know_list.append(avg_perc_know)\n",
    "        else: \n",
    "            \n",
    "            perc_know_list.append(0)\n",
    "            \n",
    "    return perc_know_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(X_train_wv)\n",
    "#df_train['year'] = generate_perc_known(tokenized_text_train,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(X_test_wv)\n",
    "#df_test['year'] = generate_perc_known(tokenized_text_test,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.163066</td>\n",
       "      <td>0.066503</td>\n",
       "      <td>0.007967</td>\n",
       "      <td>-0.368197</td>\n",
       "      <td>-0.475971</td>\n",
       "      <td>0.174799</td>\n",
       "      <td>-0.226500</td>\n",
       "      <td>0.288741</td>\n",
       "      <td>-0.101118</td>\n",
       "      <td>0.251682</td>\n",
       "      <td>...</td>\n",
       "      <td>0.343301</td>\n",
       "      <td>0.449110</td>\n",
       "      <td>-0.301583</td>\n",
       "      <td>-0.318929</td>\n",
       "      <td>-0.027628</td>\n",
       "      <td>-0.003120</td>\n",
       "      <td>0.640888</td>\n",
       "      <td>0.395134</td>\n",
       "      <td>-0.211103</td>\n",
       "      <td>7.319698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.098105</td>\n",
       "      <td>-0.697004</td>\n",
       "      <td>-0.067849</td>\n",
       "      <td>0.073167</td>\n",
       "      <td>0.001977</td>\n",
       "      <td>-0.519177</td>\n",
       "      <td>-0.064798</td>\n",
       "      <td>-0.384014</td>\n",
       "      <td>0.359658</td>\n",
       "      <td>-0.080730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100243</td>\n",
       "      <td>-0.152842</td>\n",
       "      <td>0.018108</td>\n",
       "      <td>-0.616458</td>\n",
       "      <td>0.208961</td>\n",
       "      <td>0.239500</td>\n",
       "      <td>-0.078117</td>\n",
       "      <td>0.907243</td>\n",
       "      <td>0.644744</td>\n",
       "      <td>8.900953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.608009</td>\n",
       "      <td>-0.270855</td>\n",
       "      <td>-0.351858</td>\n",
       "      <td>-1.324698</td>\n",
       "      <td>0.509448</td>\n",
       "      <td>0.466696</td>\n",
       "      <td>-0.869674</td>\n",
       "      <td>0.316894</td>\n",
       "      <td>-0.832663</td>\n",
       "      <td>0.482958</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.804097</td>\n",
       "      <td>-1.260673</td>\n",
       "      <td>-0.484280</td>\n",
       "      <td>-1.026836</td>\n",
       "      <td>-0.381989</td>\n",
       "      <td>0.006748</td>\n",
       "      <td>0.651532</td>\n",
       "      <td>0.502151</td>\n",
       "      <td>-1.543706</td>\n",
       "      <td>7.385000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.231419</td>\n",
       "      <td>-0.460309</td>\n",
       "      <td>-0.321846</td>\n",
       "      <td>-0.401228</td>\n",
       "      <td>-1.299778</td>\n",
       "      <td>-0.461486</td>\n",
       "      <td>0.002258</td>\n",
       "      <td>-0.175611</td>\n",
       "      <td>0.296010</td>\n",
       "      <td>0.373852</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068769</td>\n",
       "      <td>0.134842</td>\n",
       "      <td>0.026607</td>\n",
       "      <td>0.200088</td>\n",
       "      <td>0.376173</td>\n",
       "      <td>0.175164</td>\n",
       "      <td>-0.239718</td>\n",
       "      <td>0.463941</td>\n",
       "      <td>-0.541556</td>\n",
       "      <td>8.971588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.155188</td>\n",
       "      <td>0.110082</td>\n",
       "      <td>0.749716</td>\n",
       "      <td>-0.211680</td>\n",
       "      <td>-0.294006</td>\n",
       "      <td>-0.928232</td>\n",
       "      <td>0.095029</td>\n",
       "      <td>0.326077</td>\n",
       "      <td>0.020296</td>\n",
       "      <td>0.458989</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.496064</td>\n",
       "      <td>0.562254</td>\n",
       "      <td>-0.161042</td>\n",
       "      <td>-0.556670</td>\n",
       "      <td>-0.152797</td>\n",
       "      <td>0.216482</td>\n",
       "      <td>-0.109737</td>\n",
       "      <td>1.134926</td>\n",
       "      <td>-0.073294</td>\n",
       "      <td>7.939948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83349</th>\n",
       "      <td>-0.212178</td>\n",
       "      <td>-0.577913</td>\n",
       "      <td>0.233901</td>\n",
       "      <td>-0.283749</td>\n",
       "      <td>-0.250686</td>\n",
       "      <td>-0.740940</td>\n",
       "      <td>-0.073741</td>\n",
       "      <td>0.163121</td>\n",
       "      <td>-0.268991</td>\n",
       "      <td>0.569778</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062439</td>\n",
       "      <td>0.181861</td>\n",
       "      <td>-0.294118</td>\n",
       "      <td>0.674152</td>\n",
       "      <td>-0.312687</td>\n",
       "      <td>-0.416863</td>\n",
       "      <td>0.006465</td>\n",
       "      <td>0.296494</td>\n",
       "      <td>0.144787</td>\n",
       "      <td>7.846061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83350</th>\n",
       "      <td>0.083994</td>\n",
       "      <td>-0.119798</td>\n",
       "      <td>0.014636</td>\n",
       "      <td>-0.046240</td>\n",
       "      <td>-0.176528</td>\n",
       "      <td>-0.371178</td>\n",
       "      <td>-0.049741</td>\n",
       "      <td>-0.063575</td>\n",
       "      <td>0.069346</td>\n",
       "      <td>0.097987</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.106163</td>\n",
       "      <td>0.598239</td>\n",
       "      <td>-0.423099</td>\n",
       "      <td>-0.277646</td>\n",
       "      <td>0.249423</td>\n",
       "      <td>0.238795</td>\n",
       "      <td>-0.084238</td>\n",
       "      <td>0.325800</td>\n",
       "      <td>-0.371009</td>\n",
       "      <td>7.653076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83351</th>\n",
       "      <td>-0.027579</td>\n",
       "      <td>-0.583053</td>\n",
       "      <td>-0.212853</td>\n",
       "      <td>0.064448</td>\n",
       "      <td>-0.001676</td>\n",
       "      <td>-0.386104</td>\n",
       "      <td>-0.194504</td>\n",
       "      <td>0.125628</td>\n",
       "      <td>0.087920</td>\n",
       "      <td>0.013556</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087076</td>\n",
       "      <td>0.200042</td>\n",
       "      <td>0.022237</td>\n",
       "      <td>0.865286</td>\n",
       "      <td>0.345294</td>\n",
       "      <td>0.206362</td>\n",
       "      <td>-0.050420</td>\n",
       "      <td>0.287032</td>\n",
       "      <td>-0.024188</td>\n",
       "      <td>6.618984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83352</th>\n",
       "      <td>0.150752</td>\n",
       "      <td>-0.344787</td>\n",
       "      <td>0.016055</td>\n",
       "      <td>-0.438976</td>\n",
       "      <td>0.105028</td>\n",
       "      <td>-0.072180</td>\n",
       "      <td>-0.229091</td>\n",
       "      <td>0.010541</td>\n",
       "      <td>-0.065317</td>\n",
       "      <td>0.162644</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090400</td>\n",
       "      <td>-0.352687</td>\n",
       "      <td>-0.262663</td>\n",
       "      <td>-0.028436</td>\n",
       "      <td>0.180446</td>\n",
       "      <td>-0.053098</td>\n",
       "      <td>0.068634</td>\n",
       "      <td>-0.034959</td>\n",
       "      <td>0.074879</td>\n",
       "      <td>7.009195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83353</th>\n",
       "      <td>0.798341</td>\n",
       "      <td>-0.436330</td>\n",
       "      <td>-0.095135</td>\n",
       "      <td>-0.875586</td>\n",
       "      <td>-0.725843</td>\n",
       "      <td>-0.983312</td>\n",
       "      <td>-0.478156</td>\n",
       "      <td>0.076523</td>\n",
       "      <td>-0.534273</td>\n",
       "      <td>0.518388</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020779</td>\n",
       "      <td>0.168365</td>\n",
       "      <td>-0.001870</td>\n",
       "      <td>-0.459175</td>\n",
       "      <td>-1.014081</td>\n",
       "      <td>-0.339258</td>\n",
       "      <td>0.264108</td>\n",
       "      <td>0.849447</td>\n",
       "      <td>-0.063408</td>\n",
       "      <td>8.322109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83354 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      0.163066  0.066503  0.007967 -0.368197 -0.475971  0.174799 -0.226500   \n",
       "1      0.098105 -0.697004 -0.067849  0.073167  0.001977 -0.519177 -0.064798   \n",
       "2      0.608009 -0.270855 -0.351858 -1.324698  0.509448  0.466696 -0.869674   \n",
       "3     -0.231419 -0.460309 -0.321846 -0.401228 -1.299778 -0.461486  0.002258   \n",
       "4     -0.155188  0.110082  0.749716 -0.211680 -0.294006 -0.928232  0.095029   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "83349 -0.212178 -0.577913  0.233901 -0.283749 -0.250686 -0.740940 -0.073741   \n",
       "83350  0.083994 -0.119798  0.014636 -0.046240 -0.176528 -0.371178 -0.049741   \n",
       "83351 -0.027579 -0.583053 -0.212853  0.064448 -0.001676 -0.386104 -0.194504   \n",
       "83352  0.150752 -0.344787  0.016055 -0.438976  0.105028 -0.072180 -0.229091   \n",
       "83353  0.798341 -0.436330 -0.095135 -0.875586 -0.725843 -0.983312 -0.478156   \n",
       "\n",
       "              7         8         9  ...        91        92        93  \\\n",
       "0      0.288741 -0.101118  0.251682  ...  0.343301  0.449110 -0.301583   \n",
       "1     -0.384014  0.359658 -0.080730  ...  0.100243 -0.152842  0.018108   \n",
       "2      0.316894 -0.832663  0.482958  ... -0.804097 -1.260673 -0.484280   \n",
       "3     -0.175611  0.296010  0.373852  ... -0.068769  0.134842  0.026607   \n",
       "4      0.326077  0.020296  0.458989  ... -0.496064  0.562254 -0.161042   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "83349  0.163121 -0.268991  0.569778  ... -0.062439  0.181861 -0.294118   \n",
       "83350 -0.063575  0.069346  0.097987  ... -0.106163  0.598239 -0.423099   \n",
       "83351  0.125628  0.087920  0.013556  ... -0.087076  0.200042  0.022237   \n",
       "83352  0.010541 -0.065317  0.162644  ... -0.090400 -0.352687 -0.262663   \n",
       "83353  0.076523 -0.534273  0.518388  ... -0.020779  0.168365 -0.001870   \n",
       "\n",
       "             94        95        96        97        98        99      year  \n",
       "0     -0.318929 -0.027628 -0.003120  0.640888  0.395134 -0.211103  7.319698  \n",
       "1     -0.616458  0.208961  0.239500 -0.078117  0.907243  0.644744  8.900953  \n",
       "2     -1.026836 -0.381989  0.006748  0.651532  0.502151 -1.543706  7.385000  \n",
       "3      0.200088  0.376173  0.175164 -0.239718  0.463941 -0.541556  8.971588  \n",
       "4     -0.556670 -0.152797  0.216482 -0.109737  1.134926 -0.073294  7.939948  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "83349  0.674152 -0.312687 -0.416863  0.006465  0.296494  0.144787  7.846061  \n",
       "83350 -0.277646  0.249423  0.238795 -0.084238  0.325800 -0.371009  7.653076  \n",
       "83351  0.865286  0.345294  0.206362 -0.050420  0.287032 -0.024188  6.618984  \n",
       "83352 -0.028436  0.180446 -0.053098  0.068634 -0.034959  0.074879  7.009195  \n",
       "83353 -0.459175 -1.014081 -0.339258  0.264108  0.849447 -0.063408  8.322109  \n",
       "\n",
       "[83354 rows x 101 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=RANDOM_SEED,max_iter=1000).fit(df_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58372723564556"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,lr.predict(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmatrix_lr_wv=metrics.confusion_matrix(y_test, lr_wv.predict(X_test_wv))\n",
    "\n",
    "ax = sns.heatmap(cmatrix_lr_wv, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['False','True'])\n",
    "ax.yaxis.set_ticklabels(['False','True'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_bow = DummyClassifier(strategy='uniform',random_state=RANDOM_SEED).fit(X_train_transform,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5011277203253593"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, dummy_bow.predict(X_test_transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_wv = DummyClassifier(strategy='uniform',random_state=RANDOM_SEED).fit(X_train_wv,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5011277203253593"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,dummy_wv.predict(X_test_wv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_bow = LogisticRegression(random_state=RANDOM_SEED,max_iter=1000).fit(X_train_transform,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6465916452719725"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,lr_bow.predict(X_test_transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_wv = LogisticRegression(random_state=RANDOM_SEED,max_iter=1000).fit(X_train_wv,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5640041269765098"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,lr_wv.predict(X_test_wv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_bow = RandomForestClassifier(n_estimators=500,max_depth=5,random_state=RANDOM_SEED).fit(X_train_transform,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6416968591789236"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,rf_bow.predict(X_test_transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_wv = RandomForestClassifier(n_estimators=100,max_depth=5,random_state=RANDOM_SEED).fit(X_train_wv,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test,rf_wv.predict(X_test_wv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Unsupervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2,random_state=RANDOM_SEED).fit(X_train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df = pd.DataFrame({'cluster':kmeans.labels_,'y_label':y_train,'text':X_train})\n",
    "cluster_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA Topic Modeling - Consider NMF to create a document-topic matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from nltk.stem.porter import *\n",
    "def lemmatize_stemming(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    #Un-hash next line to use stemming\n",
    "    #return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "    #Un-hash next line to NOT use stemming\n",
    "    return WordNetLemmatizer().lemmatize(text, pos='v')\n",
    "# Tokenize and lemmatize\n",
    "def preprocess(text):\n",
    "    result=[]\n",
    "    for token in gensim.utils.simple_preprocess(text) :\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            #Un-hash next line to use stemming\n",
    "            result.append(lemmatize_stemming(token))\n",
    "            #Un-hash next line to NOT use stemming\n",
    "            #result.append(token)\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"There is manuscript evidence that Austen continued to work on these pieces as late as the period 1809 Ã¢ '' 11 , and that her niece and nephew , Anna and James Edward Austen , made further additions as late as 1814 .\""
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['original_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['manuscript',\n",
       " 'evidence',\n",
       " 'austen',\n",
       " 'continue',\n",
       " 'work',\n",
       " 'piece',\n",
       " 'late',\n",
       " 'period',\n",
       " 'niece',\n",
       " 'nephew',\n",
       " 'anna',\n",
       " 'jam',\n",
       " 'edward',\n",
       " 'austen',\n",
       " 'additions',\n",
       " 'late']"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(df['original_text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell will run about 2 minutes\n",
    "processed_docs = [preprocess(text) for text in df['original_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.corpora.dictionary.Dictionary at 0x1567b848520>"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "#bow_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "416768"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bow_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell will run 10 minutes\n",
    "#lda_model =  gensim.models.LdaMulticore(bow_corpus, \n",
    "#                                   num_topics = 8, \n",
    "#                                   id2word = dictionary,                                    \n",
    "#                                   passes = 10,\n",
    "#                                   workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for idx, topic in lda_model.print_topics(-1):\n",
    "#    print(\"Topic: {} \\nWords: {}\".format(idx, topic ))\n",
    "#    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
