{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import altair as alt\n",
    "import seaborn as sns\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>subcountry</th>\n",
       "      <th>geonameid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, country, subcountry, geonameid]\n",
       "Index: []"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world_cities_df[world_cities_df['country']=='france']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.18.5'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make sure numpy version is < 1.20\n",
    "np.version.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.18.5 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (1.18.5)\n"
     ]
    }
   ],
   "source": [
    "#Install known version of numpy that works\n",
    "!python -m pip install numpy==1.18.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\mryua\\anaconda3\\lib\\site-packages (4.1.2)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from gensim) (1.18.5)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from gensim) (1.5.0)\n",
      "Requirement already satisfied: Cython==0.29.23 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from gensim) (0.29.23)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from gensim) (6.0.0)\n"
     ]
    }
   ],
   "source": [
    "#Install gensim\n",
    "!python -m pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mryua\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mryua\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mryua\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from tqdm.notebook import tqdm\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED=694"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There is manuscript evidence that Austen conti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In a remarkable comparative analysis , Mandaea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Before Persephone was released to Hermes , who...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cogeneration plants are commonly found in dist...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Geneva -LRB- , ; , ; , ; ; -RRB- is the second...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416763</th>\n",
       "      <td>A Duke Nukem 3D version has been sold for Xbox...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416764</th>\n",
       "      <td>However , it is becoming replaced as a method ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416765</th>\n",
       "      <td>There are hand gestures in both Hindu and Budd...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416766</th>\n",
       "      <td>If it is necessary to use colors , try to choo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416767</th>\n",
       "      <td>Calgary Stampeders ,</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>416768 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            original_text  label\n",
       "0       There is manuscript evidence that Austen conti...      1\n",
       "1       In a remarkable comparative analysis , Mandaea...      1\n",
       "2       Before Persephone was released to Hermes , who...      1\n",
       "3       Cogeneration plants are commonly found in dist...      1\n",
       "4       Geneva -LRB- , ; , ; , ; ; -RRB- is the second...      1\n",
       "...                                                   ...    ...\n",
       "416763  A Duke Nukem 3D version has been sold for Xbox...      0\n",
       "416764  However , it is becoming replaced as a method ...      0\n",
       "416765  There are hand gestures in both Hindu and Budd...      0\n",
       "416766  If it is necessary to use colors , try to choo...      0\n",
       "416767                               Calgary Stampeders ,      0\n",
       "\n",
       "[416768 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = 'Data/WikiLarge_Train.csv'\n",
    "df = pd.read_csv(train_path, skiprows=0, skipfooter=0, engine='python')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['label']==1])/len(df) # the dataset label is well balanced "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'He studied in Armenia and Istanbul , then at Wisconsin University which he finished in 1915 .'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[50]['original_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117.921906192414"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['original_text'].apply(lambda x: len(x)).mean()\n",
    "# This means all texts are considered short text, which allows us to use dense representations, \n",
    "# as dense representations work well with short text.\n",
    "# Gensim.KeyedVectors.load('assets/wikipedia.100.word-vecs.kv')??? How to generate and use this???\n",
    "# Maybe we should train word2vec model on the entire corpus. Just training data? TOP 100 word-vectors(features)\n",
    "# Alternatively we could use bag-of-words model, which is term-document matrix representation, having much more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['original_text']\n",
    "y = df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>original_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-2011</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-2011</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-2000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-1997</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.636</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119087</th>\n",
       "      <td>119087</td>\n",
       "      <td>#NAME?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119088</th>\n",
       "      <td>119088</td>\n",
       "      <td>#NAME?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119089</th>\n",
       "      <td>119089</td>\n",
       "      <td>#NAME?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119090</th>\n",
       "      <td>119090</td>\n",
       "      <td>#NAME?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119091</th>\n",
       "      <td>119091</td>\n",
       "      <td>#NAME?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119092 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id original_text  label\n",
       "0            0         -2011    NaN\n",
       "1            1         -2011    NaN\n",
       "2            2         -2000    NaN\n",
       "3            3         -1997    NaN\n",
       "4            4         1.636    NaN\n",
       "...        ...           ...    ...\n",
       "119087  119087        #NAME?    NaN\n",
       "119088  119088        #NAME?    NaN\n",
       "119089  119089        #NAME?    NaN\n",
       "119090  119090        #NAME?    NaN\n",
       "119091  119091        #NAME?    NaN\n",
       "\n",
       "[119092 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_path = 'Data/WikiLarge_Test.csv'\n",
    "test_df = pd.read_csv(test_path, skiprows=0, skipfooter=0, engine='python')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                           10000\n",
       "original_text    An atheist would say that this argument proves...\n",
       "label                                                          NaN\n",
       "Name: 10000, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.iloc[10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119087</th>\n",
       "      <td>119087</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119088</th>\n",
       "      <td>119088</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119089</th>\n",
       "      <td>119089</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119090</th>\n",
       "      <td>119090</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119091</th>\n",
       "      <td>119091</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119092 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  label\n",
       "0            0      0\n",
       "1            1      0\n",
       "2            2      1\n",
       "3            3      1\n",
       "4            4      0\n",
       "...        ...    ...\n",
       "119087  119087      0\n",
       "119088  119088      1\n",
       "119089  119089      1\n",
       "119090  119090      1\n",
       "119091  119091      1\n",
       "\n",
       "[119092 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samplesubmission_path = 'Data/sampleSubmission.csv'\n",
    "samplesubmission_df = pd.read_csv(samplesubmission_path, skiprows=0, skipfooter=0, engine='python')\n",
    "samplesubmission_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conclude, the dataframes we are working with are:\n",
    "\n",
    "dalechall_df, concreteness_df, aoawords_df, train_df, test_df, samplesubmission_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=10,stop_words='english',ngram_range=(1,2))\n",
    "X_train_transform = vectorizer.fit_transform(X_train)\n",
    "X_test_transform  = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<333414x57773 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4071111 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(stopwords.words('english')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "== dale_chall.txt ==\n",
    "\n",
    "This is the Dale Chall 3000 Word List, which is one definition of words that are considered \"basic\" English.\n",
    "\n",
    "A summary is at https://www.readabilityformulas.com/articles/dale-chall-readability-word-list.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic english words\n",
    "dalechall_path = 'Data/dale_chall.txt'\n",
    "dale_chall = pd.read_csv(dalechall_path,delimiter='\\t',header=None,names=['word'])\n",
    "dale = set(dale_chall['word'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2946"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The 2946 words in dale can be combined with the nltk stopwords.\n",
    "### We could maybe assign an arbitrary score to each dale_chall word. - for reference only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will use a geo dataset to add city and country names to the stopwords library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datapackage in c:\\users\\mryua\\anaconda3\\lib\\site-packages (1.15.2)\n",
      "Requirement already satisfied: jsonpointer>=1.10 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from datapackage) (2.3)\n",
      "Requirement already satisfied: tableschema>=1.12.1 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from datapackage) (1.20.2)\n",
      "Requirement already satisfied: jsonschema>=2.5 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from datapackage) (3.2.0)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from datapackage) (1.15.0)\n",
      "Requirement already satisfied: tabulator>=1.29 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from datapackage) (1.53.5)\n",
      "Requirement already satisfied: unicodecsv>=0.14 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from datapackage) (0.14.1)\n",
      "Requirement already satisfied: chardet>=3.0 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from datapackage) (3.0.4)\n",
      "Requirement already satisfied: requests>=2.8 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from datapackage) (2.24.0)\n",
      "Requirement already satisfied: click>=6.7 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from datapackage) (7.1.2)\n",
      "Requirement already satisfied: cached-property>=1.5 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from tableschema>=1.12.1->datapackage) (1.5.2)\n",
      "Requirement already satisfied: isodate>=0.5.4 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from tableschema>=1.12.1->datapackage) (0.6.1)\n",
      "Requirement already satisfied: rfc3986>=1.1.0 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from tableschema>=1.12.1->datapackage) (2.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.4 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from tableschema>=1.12.1->datapackage) (2.8.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from jsonschema>=2.5->datapackage) (19.3.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from jsonschema>=2.5->datapackage) (0.16.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from jsonschema>=2.5->datapackage) (49.2.0.post20200714)\n",
      "Requirement already satisfied: sqlalchemy>=0.9.6 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from tabulator>=1.29->datapackage) (1.3.18)\n",
      "Requirement already satisfied: ijson>=3.0.3 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from tabulator>=1.29->datapackage) (3.1.4)\n",
      "Requirement already satisfied: boto3>=1.9 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from tabulator>=1.29->datapackage) (1.23.0)\n",
      "Requirement already satisfied: openpyxl>=2.6 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from tabulator>=1.29->datapackage) (3.0.4)\n",
      "Requirement already satisfied: xlrd>=1.0 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from tabulator>=1.29->datapackage) (1.2.0)\n",
      "Requirement already satisfied: jsonlines>=1.1 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from tabulator>=1.29->datapackage) (3.0.0)\n",
      "Requirement already satisfied: linear-tsv>=1.0 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from tabulator>=1.29->datapackage) (1.1.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from requests>=2.8->datapackage) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from requests>=2.8->datapackage) (2021.5.30)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from requests>=2.8->datapackage) (1.25.9)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from boto3>=1.9->tabulator>=1.29->datapackage) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.27.0,>=1.26.0 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from boto3>=1.9->tabulator>=1.29->datapackage) (1.26.0)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from boto3>=1.9->tabulator>=1.29->datapackage) (0.5.2)\n",
      "Requirement already satisfied: jdcal in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from openpyxl>=2.6->tabulator>=1.29->datapackage) (1.4.1)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\mryua\\anaconda3\\lib\\site-packages (from openpyxl>=2.6->tabulator>=1.29->datapackage) (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install datapackage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['validation_report', 'world-cities_csv', 'world-cities_json', 'world-cities_zip', 'world-cities_csv_preview', 'world-cities']\n"
     ]
    }
   ],
   "source": [
    "from datapackage import Package\n",
    "package = Package('https://datahub.io/core/world-cities/datapackage.json')\n",
    "# print list of all resources:\n",
    "print(package.resource_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_cities = []\n",
    "for resource in package.resources:\n",
    "    if resource.descriptor['datahub']['type'] == 'derived/csv':\n",
    "        world_cities = resource.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23018"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(world_cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['les Escaldes', 'Andorra', 'Escaldes-Engordany', 3040051],\n",
       " ['Andorra la Vella', 'Andorra', 'Andorra la Vella', 3041563],\n",
       " ['Umm al Qaywayn', 'United Arab Emirates', 'Umm al Qaywayn', 290594],\n",
       " ['Ras al-Khaimah', 'United Arab Emirates', 'Raʼs al Khaymah', 291074],\n",
       " ['Khawr Fakkān', 'United Arab Emirates', 'Ash Shāriqah', 291696],\n",
       " ['Dubai', 'United Arab Emirates', 'Dubai', 292223],\n",
       " ['Dibba Al-Fujairah', 'United Arab Emirates', 'Al Fujayrah', 292231],\n",
       " ['Dibba Al-Hisn', 'United Arab Emirates', 'Al Fujayrah', 292239],\n",
       " ['Sharjah', 'United Arab Emirates', 'Ash Shāriqah', 292672],\n",
       " ['Ar Ruways', 'United Arab Emirates', 'Abu Dhabi', 292688]]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world_cities[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_cities_df = pd.DataFrame(world_cities, columns=['name', 'country', 'subcountry', 'geonameid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>subcountry</th>\n",
       "      <th>geonameid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>les Escaldes</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>Escaldes-Engordany</td>\n",
       "      <td>3040051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>3041563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Umm al Qaywayn</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>Umm al Qaywayn</td>\n",
       "      <td>290594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ras al-Khaimah</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>Raʼs al Khaymah</td>\n",
       "      <td>291074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Khawr Fakkān</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>Ash Shāriqah</td>\n",
       "      <td>291696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23013</th>\n",
       "      <td>Bulawayo</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Bulawayo</td>\n",
       "      <td>894701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23014</th>\n",
       "      <td>Bindura</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Mashonaland Central</td>\n",
       "      <td>895061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23015</th>\n",
       "      <td>Beitbridge</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Matabeleland South</td>\n",
       "      <td>895269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23016</th>\n",
       "      <td>Epworth</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Harare</td>\n",
       "      <td>1085510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23017</th>\n",
       "      <td>Chitungwiza</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Harare</td>\n",
       "      <td>1106542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23018 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name               country           subcountry  geonameid\n",
       "0          les Escaldes               Andorra   Escaldes-Engordany    3040051\n",
       "1      Andorra la Vella               Andorra     Andorra la Vella    3041563\n",
       "2        Umm al Qaywayn  United Arab Emirates       Umm al Qaywayn     290594\n",
       "3        Ras al-Khaimah  United Arab Emirates      Raʼs al Khaymah     291074\n",
       "4          Khawr Fakkān  United Arab Emirates         Ash Shāriqah     291696\n",
       "...                 ...                   ...                  ...        ...\n",
       "23013          Bulawayo              Zimbabwe             Bulawayo     894701\n",
       "23014           Bindura              Zimbabwe  Mashonaland Central     895061\n",
       "23015        Beitbridge              Zimbabwe   Matabeleland South     895269\n",
       "23016           Epworth              Zimbabwe               Harare    1085510\n",
       "23017       Chitungwiza              Zimbabwe               Harare    1106542\n",
       "\n",
       "[23018 rows x 4 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world_cities_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_cities_df = world_cities_df.applymap(lambda s:s.lower() if type(s) == str else s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>subcountry</th>\n",
       "      <th>geonameid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6633</th>\n",
       "      <td>yerres</td>\n",
       "      <td>france</td>\n",
       "      <td>île-de-france</td>\n",
       "      <td>2967245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6634</th>\n",
       "      <td>wittenheim</td>\n",
       "      <td>france</td>\n",
       "      <td>alsace-champagne-ardenne-lorraine</td>\n",
       "      <td>2967318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6635</th>\n",
       "      <td>wattrelos</td>\n",
       "      <td>france</td>\n",
       "      <td>nord-pas-de-calais-picardie</td>\n",
       "      <td>2967421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6636</th>\n",
       "      <td>wasquehal</td>\n",
       "      <td>france</td>\n",
       "      <td>nord-pas-de-calais-picardie</td>\n",
       "      <td>2967438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6637</th>\n",
       "      <td>voiron</td>\n",
       "      <td>france</td>\n",
       "      <td>auvergne-rhône-alpes</td>\n",
       "      <td>2967758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7261</th>\n",
       "      <td>marseille 15</td>\n",
       "      <td>france</td>\n",
       "      <td>provence-alpes-côte d'azur</td>\n",
       "      <td>7284896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7262</th>\n",
       "      <td>marseille 16</td>\n",
       "      <td>france</td>\n",
       "      <td>provence-alpes-côte d'azur</td>\n",
       "      <td>7284897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7263</th>\n",
       "      <td>la defense</td>\n",
       "      <td>france</td>\n",
       "      <td>île-de-france</td>\n",
       "      <td>8504417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7264</th>\n",
       "      <td>saint-quentin-en-yvelines</td>\n",
       "      <td>france</td>\n",
       "      <td>île-de-france</td>\n",
       "      <td>8533870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7265</th>\n",
       "      <td>cergy-pontoise</td>\n",
       "      <td>france</td>\n",
       "      <td>île-de-france</td>\n",
       "      <td>8555643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>633 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name country                         subcountry  \\\n",
       "6633                     yerres  france                      île-de-france   \n",
       "6634                 wittenheim  france  alsace-champagne-ardenne-lorraine   \n",
       "6635                  wattrelos  france        nord-pas-de-calais-picardie   \n",
       "6636                  wasquehal  france        nord-pas-de-calais-picardie   \n",
       "6637                     voiron  france               auvergne-rhône-alpes   \n",
       "...                         ...     ...                                ...   \n",
       "7261               marseille 15  france         provence-alpes-côte d'azur   \n",
       "7262               marseille 16  france         provence-alpes-côte d'azur   \n",
       "7263                 la defense  france                      île-de-france   \n",
       "7264  saint-quentin-en-yvelines  france                      île-de-france   \n",
       "7265             cergy-pontoise  france                      île-de-france   \n",
       "\n",
       "      geonameid  \n",
       "6633    2967245  \n",
       "6634    2967318  \n",
       "6635    2967421  \n",
       "6636    2967438  \n",
       "6637    2967758  \n",
       "...         ...  \n",
       "7261    7284896  \n",
       "7262    7284897  \n",
       "7263    8504417  \n",
       "7264    8533870  \n",
       "7265    8555643  \n",
       "\n",
       "[633 rows x 4 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world_cities_df[world_cities_df['country']=='france']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = set(world_cities_df['name'].unique())\n",
    "countries = set(world_cities_df['country'].unique())\n",
    "subcountries = set(world_cities_df['subcountry'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will add this to stopwords\n",
    "geo_data = cities | countries | subcountries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21940"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "244"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2594"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subcountries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23803"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(geo_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['validation_report', 'language-codes_csv', 'language-codes-3b2_csv', 'language-codes-full_csv', 'ietf-language-tags_csv', 'language-codes_json', 'language-codes-3b2_json', 'language-codes-full_json', 'ietf-language-tags_json', 'language-codes_zip', 'language-codes', 'language-codes-3b2', 'language-codes-full', 'ietf-language-tags']\n"
     ]
    }
   ],
   "source": [
    "language_package = Package('https://datahub.io/core/language-codes/datapackage.json')\n",
    "\n",
    "# print list of all resources:\n",
    "print(language_package.resource_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print processed tabular data (if exists any)\n",
    "languages_data = []\n",
    "#for resource in language_package.resources:\n",
    "#    if resource.descriptor['datahub']['derivedFrom']=='language-codes':\n",
    "#        print(resource.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages_data = language_package.resources[1].read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['aa', 'Afar'],\n",
       " ['ab', 'Abkhazian'],\n",
       " ['ae', 'Avestan'],\n",
       " ['af', 'Afrikaans'],\n",
       " ['ak', 'Akan'],\n",
       " ['am', 'Amharic'],\n",
       " ['an', 'Aragonese'],\n",
       " ['ar', 'Arabic'],\n",
       " ['as', 'Assamese'],\n",
       " ['av', 'Avaric'],\n",
       " ['ay', 'Aymara'],\n",
       " ['az', 'Azerbaijani'],\n",
       " ['ba', 'Bashkir'],\n",
       " ['be', 'Belarusian'],\n",
       " ['bg', 'Bulgarian'],\n",
       " ['bh', 'Bihari languages'],\n",
       " ['bi', 'Bislama'],\n",
       " ['bm', 'Bambara'],\n",
       " ['bn', 'Bengali'],\n",
       " ['bo', 'Tibetan'],\n",
       " ['br', 'Breton'],\n",
       " ['bs', 'Bosnian'],\n",
       " ['ca', 'Catalan; Valencian'],\n",
       " ['ce', 'Chechen'],\n",
       " ['ch', 'Chamorro'],\n",
       " ['co', 'Corsican'],\n",
       " ['cr', 'Cree'],\n",
       " ['cs', 'Czech'],\n",
       " ['cu',\n",
       "  'Church Slavic; Old Slavonic; Church Slavonic; Old Bulgarian; Old Church Slavonic'],\n",
       " ['cv', 'Chuvash'],\n",
       " ['cy', 'Welsh'],\n",
       " ['da', 'Danish'],\n",
       " ['de', 'German'],\n",
       " ['dv', 'Divehi; Dhivehi; Maldivian'],\n",
       " ['dz', 'Dzongkha'],\n",
       " ['ee', 'Ewe'],\n",
       " ['el', 'Greek, Modern (1453-)'],\n",
       " ['en', 'English'],\n",
       " ['eo', 'Esperanto'],\n",
       " ['es', 'Spanish; Castilian'],\n",
       " ['et', 'Estonian'],\n",
       " ['eu', 'Basque'],\n",
       " ['fa', 'Persian'],\n",
       " ['ff', 'Fulah'],\n",
       " ['fi', 'Finnish'],\n",
       " ['fj', 'Fijian'],\n",
       " ['fo', 'Faroese'],\n",
       " ['fr', 'French'],\n",
       " ['fy', 'Western Frisian'],\n",
       " ['ga', 'Irish'],\n",
       " ['gd', 'Gaelic; Scottish Gaelic'],\n",
       " ['gl', 'Galician'],\n",
       " ['gn', 'Guarani'],\n",
       " ['gu', 'Gujarati'],\n",
       " ['gv', 'Manx'],\n",
       " ['ha', 'Hausa'],\n",
       " ['he', 'Hebrew'],\n",
       " ['hi', 'Hindi'],\n",
       " ['ho', 'Hiri Motu'],\n",
       " ['hr', 'Croatian'],\n",
       " ['ht', 'Haitian; Haitian Creole'],\n",
       " ['hu', 'Hungarian'],\n",
       " ['hy', 'Armenian'],\n",
       " ['hz', 'Herero'],\n",
       " ['ia', 'Interlingua (International Auxiliary Language Association)'],\n",
       " ['id', 'Indonesian'],\n",
       " ['ie', 'Interlingue; Occidental'],\n",
       " ['ig', 'Igbo'],\n",
       " ['ii', 'Sichuan Yi; Nuosu'],\n",
       " ['ik', 'Inupiaq'],\n",
       " ['io', 'Ido'],\n",
       " ['is', 'Icelandic'],\n",
       " ['it', 'Italian'],\n",
       " ['iu', 'Inuktitut'],\n",
       " ['ja', 'Japanese'],\n",
       " ['jv', 'Javanese'],\n",
       " ['ka', 'Georgian'],\n",
       " ['kg', 'Kongo'],\n",
       " ['ki', 'Kikuyu; Gikuyu'],\n",
       " ['kj', 'Kuanyama; Kwanyama'],\n",
       " ['kk', 'Kazakh'],\n",
       " ['kl', 'Kalaallisut; Greenlandic'],\n",
       " ['km', 'Central Khmer'],\n",
       " ['kn', 'Kannada'],\n",
       " ['ko', 'Korean'],\n",
       " ['kr', 'Kanuri'],\n",
       " ['ks', 'Kashmiri'],\n",
       " ['ku', 'Kurdish'],\n",
       " ['kv', 'Komi'],\n",
       " ['kw', 'Cornish'],\n",
       " ['ky', 'Kirghiz; Kyrgyz'],\n",
       " ['la', 'Latin'],\n",
       " ['lb', 'Luxembourgish; Letzeburgesch'],\n",
       " ['lg', 'Ganda'],\n",
       " ['li', 'Limburgan; Limburger; Limburgish'],\n",
       " ['ln', 'Lingala'],\n",
       " ['lo', 'Lao'],\n",
       " ['lt', 'Lithuanian'],\n",
       " ['lu', 'Luba-Katanga'],\n",
       " ['lv', 'Latvian'],\n",
       " ['mg', 'Malagasy'],\n",
       " ['mh', 'Marshallese'],\n",
       " ['mi', 'Maori'],\n",
       " ['mk', 'Macedonian'],\n",
       " ['ml', 'Malayalam'],\n",
       " ['mn', 'Mongolian'],\n",
       " ['mr', 'Marathi'],\n",
       " ['ms', 'Malay'],\n",
       " ['mt', 'Maltese'],\n",
       " ['my', 'Burmese'],\n",
       " ['na', 'Nauru'],\n",
       " ['nb', 'Bokmål, Norwegian; Norwegian Bokmål'],\n",
       " ['nd', 'Ndebele, North; North Ndebele'],\n",
       " ['ne', 'Nepali'],\n",
       " ['ng', 'Ndonga'],\n",
       " ['nl', 'Dutch; Flemish'],\n",
       " ['nn', 'Norwegian Nynorsk; Nynorsk, Norwegian'],\n",
       " ['no', 'Norwegian'],\n",
       " ['nr', 'Ndebele, South; South Ndebele'],\n",
       " ['nv', 'Navajo; Navaho'],\n",
       " ['ny', 'Chichewa; Chewa; Nyanja'],\n",
       " ['oc', 'Occitan (post 1500)'],\n",
       " ['oj', 'Ojibwa'],\n",
       " ['om', 'Oromo'],\n",
       " ['or', 'Oriya'],\n",
       " ['os', 'Ossetian; Ossetic'],\n",
       " ['pa', 'Panjabi; Punjabi'],\n",
       " ['pi', 'Pali'],\n",
       " ['pl', 'Polish'],\n",
       " ['ps', 'Pushto; Pashto'],\n",
       " ['pt', 'Portuguese'],\n",
       " ['qu', 'Quechua'],\n",
       " ['rm', 'Romansh'],\n",
       " ['rn', 'Rundi'],\n",
       " ['ro', 'Romanian; Moldavian; Moldovan'],\n",
       " ['ru', 'Russian'],\n",
       " ['rw', 'Kinyarwanda'],\n",
       " ['sa', 'Sanskrit'],\n",
       " ['sc', 'Sardinian'],\n",
       " ['sd', 'Sindhi'],\n",
       " ['se', 'Northern Sami'],\n",
       " ['sg', 'Sango'],\n",
       " ['si', 'Sinhala; Sinhalese'],\n",
       " ['sk', 'Slovak'],\n",
       " ['sl', 'Slovenian'],\n",
       " ['sm', 'Samoan'],\n",
       " ['sn', 'Shona'],\n",
       " ['so', 'Somali'],\n",
       " ['sq', 'Albanian'],\n",
       " ['sr', 'Serbian'],\n",
       " ['ss', 'Swati'],\n",
       " ['st', 'Sotho, Southern'],\n",
       " ['su', 'Sundanese'],\n",
       " ['sv', 'Swedish'],\n",
       " ['sw', 'Swahili'],\n",
       " ['ta', 'Tamil'],\n",
       " ['te', 'Telugu'],\n",
       " ['tg', 'Tajik'],\n",
       " ['th', 'Thai'],\n",
       " ['ti', 'Tigrinya'],\n",
       " ['tk', 'Turkmen'],\n",
       " ['tl', 'Tagalog'],\n",
       " ['tn', 'Tswana'],\n",
       " ['to', 'Tonga (Tonga Islands)'],\n",
       " ['tr', 'Turkish'],\n",
       " ['ts', 'Tsonga'],\n",
       " ['tt', 'Tatar'],\n",
       " ['tw', 'Twi'],\n",
       " ['ty', 'Tahitian'],\n",
       " ['ug', 'Uighur; Uyghur'],\n",
       " ['uk', 'Ukrainian'],\n",
       " ['ur', 'Urdu'],\n",
       " ['uz', 'Uzbek'],\n",
       " ['ve', 'Venda'],\n",
       " ['vi', 'Vietnamese'],\n",
       " ['vo', 'Volapük'],\n",
       " ['wa', 'Walloon'],\n",
       " ['wo', 'Wolof'],\n",
       " ['xh', 'Xhosa'],\n",
       " ['yi', 'Yiddish'],\n",
       " ['yo', 'Yoruba'],\n",
       " ['za', 'Zhuang; Chuang'],\n",
       " ['zh', 'Chinese'],\n",
       " ['zu', 'Zulu']]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha2</th>\n",
       "      <th>english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aa</td>\n",
       "      <td>afar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ab</td>\n",
       "      <td>abkhazian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ae</td>\n",
       "      <td>avestan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>af</td>\n",
       "      <td>afrikaans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ak</td>\n",
       "      <td>akan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>yi</td>\n",
       "      <td>yiddish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>yo</td>\n",
       "      <td>yoruba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>za</td>\n",
       "      <td>zhuang; chuang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>zh</td>\n",
       "      <td>chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>zu</td>\n",
       "      <td>zulu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>184 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    alpha2         english\n",
       "0       aa            afar\n",
       "1       ab       abkhazian\n",
       "2       ae         avestan\n",
       "3       af       afrikaans\n",
       "4       ak            akan\n",
       "..     ...             ...\n",
       "179     yi         yiddish\n",
       "180     yo          yoruba\n",
       "181     za  zhuang; chuang\n",
       "182     zh         chinese\n",
       "183     zu            zulu\n",
       "\n",
       "[184 rows x 2 columns]"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages_df = pd.DataFrame(languages_data, columns=['alpha2', 'english'])\n",
    "languages_df = languages_df.applymap(lambda s:s.lower() if type(s) == str else s)\n",
    "languages_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = set(languages_df['english'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nationality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>afghan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>albanian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>algerian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>andorran</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>wallisian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>welsh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>yemeni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>zambian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>zimbabwean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nationality\n",
       "0        afghan\n",
       "1      albanian\n",
       "2      algerian\n",
       "3      american\n",
       "4      andorran\n",
       "..          ...\n",
       "220   wallisian\n",
       "221       welsh\n",
       "222      yemeni\n",
       "223     zambian\n",
       "224  zimbabwean\n",
       "\n",
       "[225 rows x 1 columns]"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nationality_path = 'Data/CH_Nationality_List_20171130_v1.csv'\n",
    "nationality_df = pd.read_csv(nationality_path, skiprows=0, skipfooter=0, engine='python')\n",
    "nationality_df = nationality_df.applymap(lambda s:s.lower() if type(s) == str else s)\n",
    "nationality_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nationalities = set(nationality_df['Nationality'].unique())\n",
    "len(nationalities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>newPerct2013</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>michael</td>\n",
       "      <td>0.011577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>james</td>\n",
       "      <td>0.010218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>john</td>\n",
       "      <td>0.009675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>robert</td>\n",
       "      <td>0.009493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>david</td>\n",
       "      <td>0.008943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>christina</td>\n",
       "      <td>0.001435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>julie</td>\n",
       "      <td>0.001418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>jordan</td>\n",
       "      <td>0.001416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>kyle</td>\n",
       "      <td>0.001413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>anna</td>\n",
       "      <td>0.001400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0       name  newPerct2013\n",
       "0            1    michael      0.011577\n",
       "1            2      james      0.010218\n",
       "2            3       john      0.009675\n",
       "3            4     robert      0.009493\n",
       "4            5      david      0.008943\n",
       "..         ...        ...           ...\n",
       "95          96  christina      0.001435\n",
       "96          97      julie      0.001418\n",
       "97          98     jordan      0.001416\n",
       "98          99       kyle      0.001413\n",
       "99         100       anna      0.001400\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstname_path = 'Data/new-top-firstNames.csv'\n",
    "firstname_df = pd.read_csv(firstname_path, skiprows=0, skipfooter=0, engine='python')\n",
    "firstname_df = firstname_df.applymap(lambda s:s.lower() if type(s) == str else s)\n",
    "firstname_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstnames = set(firstname_df['name'].unique())\n",
    "len(firstnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>john</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>william</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>james</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>charles</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>george</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6777</th>\n",
       "      <td>laylah</td>\n",
       "      <td>girl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6778</th>\n",
       "      <td>carleigh</td>\n",
       "      <td>girl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6779</th>\n",
       "      <td>kenley</td>\n",
       "      <td>girl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6780</th>\n",
       "      <td>sloane</td>\n",
       "      <td>girl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6781</th>\n",
       "      <td>elianna</td>\n",
       "      <td>girl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6782 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0     1\n",
       "0         john   boy\n",
       "1      william   boy\n",
       "2        james   boy\n",
       "3      charles   boy\n",
       "4       george   boy\n",
       "...        ...   ...\n",
       "6777    laylah  girl\n",
       "6778  carleigh  girl\n",
       "6779    kenley  girl\n",
       "6780    sloane  girl\n",
       "6781   elianna  girl\n",
       "\n",
       "[6782 rows x 2 columns]"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstname_path2 = 'Data/babynames-clean.csv'\n",
    "firstname_df2 = pd.read_csv(firstname_path2, header= None, skiprows=0, skipfooter=0, engine='python')\n",
    "firstname_df2 = firstname_df2.applymap(lambda s:s.lower() if type(s) == str else s)\n",
    "firstname_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6782"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstnames2 = set(firstname_df2[0].unique())\n",
    "len(firstnames2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6782"
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstnames = firstnames | firstnames2\n",
    "len(firstnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>perct2013</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>smith</td>\n",
       "      <td>0.007999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>johnson</td>\n",
       "      <td>0.006346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>williams</td>\n",
       "      <td>0.005330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>brown</td>\n",
       "      <td>0.004724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>jones</td>\n",
       "      <td>0.004676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>vasquez</td>\n",
       "      <td>0.000760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>sanders</td>\n",
       "      <td>0.000753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>jimenez</td>\n",
       "      <td>0.000751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>long</td>\n",
       "      <td>0.000747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>foster</td>\n",
       "      <td>0.000746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0      name  perct2013\n",
       "0            1     smith   0.007999\n",
       "1            2   johnson   0.006346\n",
       "2            3  williams   0.005330\n",
       "3            4     brown   0.004724\n",
       "4            5     jones   0.004676\n",
       "..         ...       ...        ...\n",
       "95          96   vasquez   0.000760\n",
       "96          97   sanders   0.000753\n",
       "97          98   jimenez   0.000751\n",
       "98          99      long   0.000747\n",
       "99         100    foster   0.000746\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surname_path = 'Data/new-top-surnames.csv'\n",
    "surname_df = pd.read_csv(surname_path, skiprows=0, skipfooter=0, engine='python')\n",
    "surname_df = surname_df.applymap(lambda s:s.lower() if type(s) == str else s)\n",
    "surname_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surnames = set(surname_df['name'].unique())\n",
    "len(surnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "days=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']\n",
    "months=['January','February','March', 'April','May','June','July','August','September','October','November','December']\n",
    "calendar = days.copy()\n",
    "calendar.extend(months)\n",
    "calendar = set([w.lower() for w in calendar])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'april',\n",
       " 'august',\n",
       " 'december',\n",
       " 'february',\n",
       " 'friday',\n",
       " 'january',\n",
       " 'july',\n",
       " 'june',\n",
       " 'march',\n",
       " 'may',\n",
       " 'monday',\n",
       " 'november',\n",
       " 'october',\n",
       " 'saturday',\n",
       " 'september',\n",
       " 'sunday',\n",
       " 'thursday',\n",
       " 'tuesday',\n",
       " 'wednesday'}"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "304501    1979-80 Buffalo Sabres NHL 32 1880 74 1 4 2.36...\n",
       "162313    Diseases Lentils in culture Lentils are mentio...\n",
       "336845    Railroads , like the Lehigh Valley Railroad , ...\n",
       "150625    An example of this would be an individual anim...\n",
       "40240     Both the Matanuska and Susitna Rivers have maj...\n",
       "                                ...                        \n",
       "259178    After the Germans invaded Norway in April 1940...\n",
       "365838    July 28 - Henry Bennet , 1st Earl of Arlington...\n",
       "131932    Pancake restaurants are popular family restaur...\n",
       "146867                                 A cycling domestique\n",
       "121958    David Boreanaz 's first paid acting appearance...\n",
       "Name: original_text, Length: 333414, dtype: object"
      ]
     },
     "execution_count": 614,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1979-80 Buffalo Sabres NHL 32 1880 74 1 4 2.36 20 8 4 0 0.000'"
      ]
     },
     "execution_count": 615,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[304501]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['buffalo', 'sabres', 'nhl']"
      ]
     },
     "execution_count": 616,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim.utils.simple_preprocess(X_train[304501])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gensim.parsing.preprocessing.STOPWORDS\n",
    "#stopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text_train=[]\n",
    "tokenized_text_test=[]\n",
    "stopWords = set(stopwords.words('english')) | dale | geo_data | languages | nationalities | firstnames | surnames | calendar\n",
    "# This cell will run 4 minutes\n",
    "import gensim\n",
    "from nltk.stem.porter import *\n",
    "def lemmatize_stemming(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    #Un-hash next line to use stemming\n",
    "    #return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "    #Un-hash next line to NOT use stemming\n",
    "    return WordNetLemmatizer().lemmatize(text, pos='v')\n",
    "\n",
    "# Tokenize and lemmatize\n",
    "def preprocess(text):\n",
    "    result=[]\n",
    "    for token in gensim.utils.simple_preprocess(text) :\n",
    "        if token not in stopWords and len(token) > 3:\n",
    "            #Un-hash next line to use lemmatization/stemming\n",
    "            result.append(lemmatize_stemming(token))\n",
    "            #Un-hash next line to NOT use lemmatization/stemming\n",
    "            #result.append(token)\n",
    "            \n",
    "    return result\n",
    "\n",
    "tokenized_text_train = [preprocess(text) for text in X_train]\n",
    "tokenized_text_test=[preprocess(text) for text in X_test]\n",
    "\n",
    "#for text in tqdm(X_train):\n",
    "#    tokens_in_text = word_tokenize(text)\n",
    "#    tokens_in_text = [word for word in tokens_in_text if word.lower() not in stopWords]\n",
    "#    tokenized_text_train.append(tokens_in_text)\n",
    "    \n",
    "#for text in tqdm(X_test):\n",
    "#    tokens_in_text = word_tokenize(text)\n",
    "#    tokens_in_text = [word for word in tokens_in_text if word.lower() not in stopWords]\n",
    "#    tokenized_text_test.append(tokens_in_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33276"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenized_text_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5883773, 9470970)"
      ]
     },
     "execution_count": 621,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Word2Vec(vector_size=100,window=2,min_count=100,seed= RANDOM_SEED,workers=4)\n",
    "model.build_vocab(tokenized_text_train)\n",
    "model.train(tokenized_text_train,total_examples=model.corpus_count,epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_vectors.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = word_vectors.key_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unite': 0,\n",
       " 'department': 1,\n",
       " 'state': 2,\n",
       " 'region': 3,\n",
       " 'commune': 4,\n",
       " 'include': 5,\n",
       " 'call': 6,\n",
       " 'play': 7,\n",
       " 'national': 8,\n",
       " 'district': 9,\n",
       " 'release': 10,\n",
       " 'years': 11,\n",
       " 'name': 12,\n",
       " 'locate': 13,\n",
       " 'area': 14,\n",
       " 'former': 15,\n",
       " 'series': 16,\n",
       " 'later': 17,\n",
       " 'album': 18,\n",
       " 'league': 19,\n",
       " 'system': 20,\n",
       " 'work': 21,\n",
       " 'century': 22,\n",
       " 'base': 23,\n",
       " 'award': 24,\n",
       " 'population': 25,\n",
       " 'refer': 26,\n",
       " 'largest': 27,\n",
       " 'province': 28,\n",
       " 'start': 29,\n",
       " 'record': 30,\n",
       " 'form': 31,\n",
       " 'ndash': 32,\n",
       " 'create': 33,\n",
       " 'main': 34,\n",
       " 'usually': 35,\n",
       " 'president': 36,\n",
       " 'international': 37,\n",
       " 'force': 38,\n",
       " 'produce': 39,\n",
       " 'type': 40,\n",
       " 'television': 41,\n",
       " 'use': 42,\n",
       " 'species': 43,\n",
       " 'game': 44,\n",
       " 'common': 45,\n",
       " 'feature': 46,\n",
       " 'professional': 47,\n",
       " 'publish': 48,\n",
       " 'found': 49,\n",
       " 'municipality': 50,\n",
       " 'although': 51,\n",
       " 'currently': 52,\n",
       " 'character': 53,\n",
       " 'championship': 54,\n",
       " 'modern': 55,\n",
       " 'famous': 56,\n",
       " 'develop': 57,\n",
       " 'members': 58,\n",
       " 'popular': 59,\n",
       " 'video': 60,\n",
       " 'tropical': 61,\n",
       " 'time': 62,\n",
       " 'serve': 63,\n",
       " 'republic': 64,\n",
       " 'show': 65,\n",
       " 'hurricane': 66,\n",
       " 'within': 67,\n",
       " 'period': 68,\n",
       " 'aisne': 69,\n",
       " 'europe': 70,\n",
       " 'consider': 71,\n",
       " 'official': 72,\n",
       " 'change': 73,\n",
       " 'contain': 74,\n",
       " 'design': 75,\n",
       " 'example': 76,\n",
       " 'move': 77,\n",
       " 'countries': 78,\n",
       " 'result': 79,\n",
       " 'reference': 80,\n",
       " 'original': 81,\n",
       " 'program': 82,\n",
       " 'european': 83,\n",
       " 'calvados': 84,\n",
       " 'total': 85,\n",
       " 'appear': 86,\n",
       " 'accord': 87,\n",
       " 'career': 88,\n",
       " 'minister': 89,\n",
       " 'control': 90,\n",
       " 'support': 91,\n",
       " 'basse': 92,\n",
       " 'normandie': 93,\n",
       " 'allow': 94,\n",
       " 'perform': 95,\n",
       " 'current': 96,\n",
       " 'hockey': 97,\n",
       " 'northwest': 98,\n",
       " 'article': 99,\n",
       " 'commonly': 100,\n",
       " 'border': 101,\n",
       " 'islands': 102,\n",
       " 'footballer': 103,\n",
       " 'local': 104,\n",
       " 'empire': 105,\n",
       " 'wrestle': 106,\n",
       " 'star': 107,\n",
       " 'division': 108,\n",
       " 'range': 109,\n",
       " 'establish': 110,\n",
       " 'open': 111,\n",
       " 'actor': 112,\n",
       " 'study': 113,\n",
       " 'originally': 114,\n",
       " 'join': 115,\n",
       " 'part': 116,\n",
       " 'cause': 117,\n",
       " 'remain': 118,\n",
       " 'role': 119,\n",
       " 'continue': 120,\n",
       " 'political': 121,\n",
       " 'receive': 122,\n",
       " 'consist': 123,\n",
       " 'version': 124,\n",
       " 'human': 125,\n",
       " 'similar': 126,\n",
       " 'days': 127,\n",
       " 'emperor': 128,\n",
       " 'mean': 129,\n",
       " 'provide': 130,\n",
       " 'areas': 131,\n",
       " 'process': 132,\n",
       " 'final': 133,\n",
       " 'network': 134,\n",
       " 'pay': 135,\n",
       " 'science': 136,\n",
       " 'source': 137,\n",
       " 'book': 138,\n",
       " 'loire': 139,\n",
       " 'describe': 140,\n",
       " 'association': 141,\n",
       " 'operate': 142,\n",
       " 'ancient': 143,\n",
       " 'style': 144,\n",
       " 'military': 145,\n",
       " 'place': 146,\n",
       " 'gironde': 147,\n",
       " 'computer': 148,\n",
       " 'event': 149,\n",
       " 'position': 150,\n",
       " 'events': 151,\n",
       " 'energy': 152,\n",
       " 'complete': 153,\n",
       " 'various': 154,\n",
       " 'africa': 155,\n",
       " 'picardie': 156,\n",
       " 'sign': 157,\n",
       " 'languages': 158,\n",
       " 'natural': 159,\n",
       " 'replace': 160,\n",
       " 'prime': 161,\n",
       " 'aquitaine': 162,\n",
       " 'generally': 163,\n",
       " 'atlantic': 164,\n",
       " 'discover': 165,\n",
       " 'reach': 166,\n",
       " 'census': 167,\n",
       " 'development': 168,\n",
       " 'formula': 169,\n",
       " 'exist': 170,\n",
       " 'director': 171,\n",
       " 'relate': 172,\n",
       " 'represent': 173,\n",
       " 'orchestra': 174,\n",
       " 'parliament': 175,\n",
       " 'writer': 176,\n",
       " 'team': 177,\n",
       " 'project': 178,\n",
       " 'site': 179,\n",
       " 'race': 180,\n",
       " 'songs': 181,\n",
       " 'special': 182,\n",
       " 'model': 183,\n",
       " 'occur': 184,\n",
       " 'systems': 185,\n",
       " 'film': 186,\n",
       " 'plant': 187,\n",
       " 'sport': 188,\n",
       " 'information': 189,\n",
       " 'image': 190,\n",
       " 'others': 191,\n",
       " 'port': 192,\n",
       " 'follow': 193,\n",
       " 'chemical': 194,\n",
       " 'number': 195,\n",
       " 'rule': 196,\n",
       " 'software': 197,\n",
       " 'object': 198,\n",
       " 'win': 199,\n",
       " 'group': 200,\n",
       " 'theory': 201,\n",
       " 'highest': 202,\n",
       " 'cities': 203,\n",
       " 'cover': 204,\n",
       " 'organization': 205,\n",
       " 'actress': 206,\n",
       " 'tour': 207,\n",
       " 'train': 208,\n",
       " 'almost': 209,\n",
       " 'lead': 210,\n",
       " 'movement': 211,\n",
       " 'across': 212,\n",
       " 'speak': 213,\n",
       " 'elect': 214,\n",
       " 'stadium': 215,\n",
       " 'increase': 216,\n",
       " 'return': 217,\n",
       " 'composer': 218,\n",
       " 'research': 219,\n",
       " 'opera': 220,\n",
       " 'novel': 221,\n",
       " 'culture': 222,\n",
       " 'live': 223,\n",
       " 'studio': 224,\n",
       " 'divide': 225,\n",
       " 'influence': 226,\n",
       " 'independent': 227,\n",
       " 'debut': 228,\n",
       " 'officially': 229,\n",
       " 'entertainment': 230,\n",
       " 'players': 231,\n",
       " 'community': 232,\n",
       " 'structure': 233,\n",
       " 'claim': 234,\n",
       " 'lower': 235,\n",
       " 'simply': 236,\n",
       " 'introduce': 237,\n",
       " 'social': 238,\n",
       " 'end': 239,\n",
       " 'issue': 240,\n",
       " 'involve': 241,\n",
       " 'catholic': 242,\n",
       " 'pass': 243,\n",
       " 'animals': 244,\n",
       " 'especially': 245,\n",
       " 'northwestern': 246,\n",
       " 'disney': 247,\n",
       " 'genus': 248,\n",
       " 'throughout': 249,\n",
       " 'retire': 250,\n",
       " 'guitar': 251,\n",
       " 'soviet': 252,\n",
       " 'act': 253,\n",
       " 'brand': 254,\n",
       " 'territory': 255,\n",
       " 'traditional': 256,\n",
       " 'mass': 257,\n",
       " 'add': 258,\n",
       " 'britain': 259,\n",
       " 'grow': 260,\n",
       " 'word': 261,\n",
       " 'airport': 262,\n",
       " 'production': 263,\n",
       " 'travel': 264,\n",
       " 'wikipedia': 265,\n",
       " 'approximately': 266,\n",
       " 'native': 267,\n",
       " 'announce': 268,\n",
       " 'effect': 269,\n",
       " 'politician': 270,\n",
       " 'unit': 271,\n",
       " 'defeat': 272,\n",
       " 'come': 273,\n",
       " 'standard': 274,\n",
       " 'civil': 275,\n",
       " 'oldest': 276,\n",
       " 'define': 277,\n",
       " 'units': 278,\n",
       " 'available': 279,\n",
       " 'data': 280,\n",
       " 'direct': 281,\n",
       " 'society': 282,\n",
       " 'point': 283,\n",
       " 'successful': 284,\n",
       " 'associate': 285,\n",
       " 'channel': 286,\n",
       " 'distance': 287,\n",
       " 'musical': 288,\n",
       " 'rank': 289,\n",
       " 'action': 290,\n",
       " 'academy': 291,\n",
       " 'limit': 292,\n",
       " 'report': 293,\n",
       " 'help': 294,\n",
       " 'service': 295,\n",
       " 'super': 296,\n",
       " 'pacific': 297,\n",
       " 'orbit': 298,\n",
       " 'average': 299,\n",
       " 'require': 300,\n",
       " 'instrument': 301,\n",
       " 'episode': 302,\n",
       " 'education': 303,\n",
       " 'page': 304,\n",
       " 'term': 305,\n",
       " 'websites': 306,\n",
       " 'smaller': 307,\n",
       " 'windows': 308,\n",
       " 'section': 309,\n",
       " 'premier': 310,\n",
       " 'secretary': 311,\n",
       " 'mainly': 312,\n",
       " 'turn': 313,\n",
       " 'date': 314,\n",
       " 'dynasty': 315,\n",
       " 'attempt': 316,\n",
       " 'larger': 317,\n",
       " 'function': 318,\n",
       " 'estimate': 319,\n",
       " 'mountains': 320,\n",
       " 'note': 321,\n",
       " 'make': 322,\n",
       " 'arts': 323,\n",
       " 'line': 324,\n",
       " 'compose': 325,\n",
       " 'label': 326,\n",
       " 'cathedral': 327,\n",
       " 'scale': 328,\n",
       " 'nintendo': 329,\n",
       " 'festival': 330,\n",
       " 'performance': 331,\n",
       " 'thus': 332,\n",
       " 'say': 333,\n",
       " 'administrative': 334,\n",
       " 'albums': 335,\n",
       " 'fiction': 336,\n",
       " 'metropolitan': 337,\n",
       " 'students': 338,\n",
       " 'alpes': 339,\n",
       " 'nations': 340,\n",
       " 'partement': 341,\n",
       " 'producer': 342,\n",
       " 'nuclear': 343,\n",
       " 'success': 344,\n",
       " 'display': 345,\n",
       " 'months': 346,\n",
       " 'typically': 347,\n",
       " 'become': 348,\n",
       " 'surround': 349,\n",
       " 'link': 350,\n",
       " 'female': 351,\n",
       " 'own': 352,\n",
       " 'recognize': 353,\n",
       " 'material': 354,\n",
       " 'nobel': 355,\n",
       " 'addition': 356,\n",
       " 'want': 357,\n",
       " 'conduct': 358,\n",
       " 'list': 359,\n",
       " 'decide': 360,\n",
       " 'african': 361,\n",
       " 'believe': 362,\n",
       " 'arm': 363,\n",
       " 'right': 364,\n",
       " 'title': 365,\n",
       " 'derive': 366,\n",
       " 'school': 367,\n",
       " 'text': 368,\n",
       " 'museum': 369,\n",
       " 'finish': 370,\n",
       " 'things': 371,\n",
       " 'greater': 372,\n",
       " 'concert': 373,\n",
       " 'suggest': 374,\n",
       " 'religious': 375,\n",
       " 'widely': 376,\n",
       " 'cells': 377,\n",
       " 'pope': 378,\n",
       " 'attack': 379,\n",
       " 'edition': 380,\n",
       " 'election': 381,\n",
       " 'take': 382,\n",
       " 'physical': 383,\n",
       " 'institute': 384,\n",
       " 'compound': 385,\n",
       " 'pressure': 386,\n",
       " 'higher': 387,\n",
       " 'purpose': 388,\n",
       " 'eventually': 389,\n",
       " 'single': 390,\n",
       " 'practice': 391,\n",
       " 'picardy': 392,\n",
       " 'primary': 393,\n",
       " 'lie': 394,\n",
       " 'borough': 395,\n",
       " 'combine': 396,\n",
       " 'condition': 397,\n",
       " 'plan': 398,\n",
       " 'private': 399,\n",
       " 'extend': 400,\n",
       " 'guitarist': 401,\n",
       " 'musician': 402,\n",
       " 'enter': 403,\n",
       " 'code': 404,\n",
       " 'treaty': 405,\n",
       " 'symbol': 406,\n",
       " 'situate': 407,\n",
       " 'house': 408,\n",
       " 'category': 409,\n",
       " 'professor': 410,\n",
       " 'comedy': 411,\n",
       " 'towns': 412,\n",
       " 'sarthe': 413,\n",
       " 'survive': 414,\n",
       " 'share': 415,\n",
       " 'website': 416,\n",
       " 'engineer': 417,\n",
       " 'songwriter': 418,\n",
       " 'season': 419,\n",
       " 'build': 420,\n",
       " 'regard': 421,\n",
       " 'declare': 422,\n",
       " 'worldwide': 423,\n",
       " 'particularly': 424,\n",
       " 'connect': 425,\n",
       " 'nature': 426,\n",
       " 'status': 427,\n",
       " 'host': 428,\n",
       " 'active': 429,\n",
       " 'air': 430,\n",
       " 'regions': 431,\n",
       " 'internet': 432,\n",
       " 'economic': 433,\n",
       " 'historical': 434,\n",
       " 'formerly': 435,\n",
       " 'location': 436,\n",
       " 'humans': 437,\n",
       " 'copy': 438,\n",
       " 'apply': 439,\n",
       " 'animate': 440,\n",
       " 'nickname': 441,\n",
       " 'classical': 442,\n",
       " 'temperature': 443,\n",
       " 'democratic': 444,\n",
       " 'destroy': 445,\n",
       " 'multiple': 446,\n",
       " 'elements': 447,\n",
       " 'alternative': 448,\n",
       " 'planet': 449,\n",
       " 'particular': 450,\n",
       " 'bass': 451,\n",
       " 'industry': 452,\n",
       " 'revolution': 453,\n",
       " 'olympic': 454,\n",
       " 'nation': 455,\n",
       " 'appoint': 456,\n",
       " 'draft': 457,\n",
       " 'fall': 458,\n",
       " 'jewish': 459,\n",
       " 'experience': 460,\n",
       " 'primarily': 461,\n",
       " 'launch': 462,\n",
       " 'hold': 463,\n",
       " 'future': 464,\n",
       " 'access': 465,\n",
       " 'adopt': 466,\n",
       " 'individual': 467,\n",
       " 'foreign': 468,\n",
       " 'parent': 469,\n",
       " 'rat': 470,\n",
       " 'prix': 471,\n",
       " 'recent': 472,\n",
       " 'chess': 473,\n",
       " 'regular': 474,\n",
       " 'korea': 475,\n",
       " 'statistics': 476,\n",
       " 'older': 477,\n",
       " 'advance': 478,\n",
       " 'depression': 479,\n",
       " 'graduate': 480,\n",
       " 'capture': 481,\n",
       " 'literature': 482,\n",
       " 'zone': 483,\n",
       " 'disease': 484,\n",
       " 'need': 485,\n",
       " 'founder': 486,\n",
       " 'flower': 487,\n",
       " 'complex': 488,\n",
       " 'power': 489,\n",
       " 'account': 490,\n",
       " 'inhabitants': 491,\n",
       " 'peninsula': 492,\n",
       " 'southeast': 493,\n",
       " 'earlier': 494,\n",
       " 'ask': 495,\n",
       " 'vote': 496,\n",
       " 'commercial': 497,\n",
       " 'basketball': 498,\n",
       " 'medical': 499,\n",
       " 'greatest': 500,\n",
       " 'user': 501,\n",
       " 'poet': 502,\n",
       " 'despite': 503,\n",
       " 'conference': 504,\n",
       " 'license': 505,\n",
       " 'age': 506,\n",
       " 'stand': 507,\n",
       " 'southeastern': 508,\n",
       " 'previously': 509,\n",
       " 'fame': 510,\n",
       " 'solar': 511,\n",
       " 'degree': 512,\n",
       " 'southwestern': 513,\n",
       " 'wind': 514,\n",
       " 'hours': 515,\n",
       " 'succeed': 516,\n",
       " 'directly': 517,\n",
       " 'collection': 518,\n",
       " 'variety': 519,\n",
       " 'principal': 520,\n",
       " 'digital': 521,\n",
       " 'probably': 522,\n",
       " 'brothers': 523,\n",
       " 'discovery': 524,\n",
       " 'previous': 525,\n",
       " 'notable': 526,\n",
       " 'construction': 527,\n",
       " 'carry': 528,\n",
       " 'accept': 529,\n",
       " 'friends': 530,\n",
       " 'competition': 531,\n",
       " 'theme': 532,\n",
       " 'personal': 533,\n",
       " 'war': 534,\n",
       " 'look': 535,\n",
       " 'longer': 536,\n",
       " 'drama': 537,\n",
       " 'reduce': 538,\n",
       " 'vocals': 539,\n",
       " 'focus': 540,\n",
       " 'campaign': 541,\n",
       " 'attend': 542,\n",
       " 'comprise': 543,\n",
       " 'biggest': 544,\n",
       " 'challenge': 545,\n",
       " 'interest': 546,\n",
       " 'circuit': 547,\n",
       " 'paint': 548,\n",
       " 'rename': 549,\n",
       " 'saturn': 550,\n",
       " 'organize': 551,\n",
       " 'counties': 552,\n",
       " 'entire': 553,\n",
       " 'foundation': 554,\n",
       " 'compete': 555,\n",
       " 'band': 556,\n",
       " 'annual': 557,\n",
       " 'cultural': 558,\n",
       " 'problems': 559,\n",
       " 'leave': 560,\n",
       " 'security': 561,\n",
       " 'belong': 562,\n",
       " 'transfer': 563,\n",
       " 'online': 564,\n",
       " 'bomb': 565,\n",
       " 'element': 566,\n",
       " 'offer': 567,\n",
       " 'cycle': 568,\n",
       " 'raise': 569,\n",
       " 'score': 570,\n",
       " 'examples': 571,\n",
       " 'edit': 572,\n",
       " 'station': 573,\n",
       " 'acid': 574,\n",
       " 'appearance': 575,\n",
       " 'recently': 576,\n",
       " 'technology': 577,\n",
       " 'symphony': 578,\n",
       " 'fictional': 579,\n",
       " 'mix': 580,\n",
       " 'commission': 581,\n",
       " 'head': 582,\n",
       " 'majority': 583,\n",
       " 'olympics': 584,\n",
       " 'merge': 585,\n",
       " 'distribution': 586,\n",
       " 'architecture': 587,\n",
       " 'significant': 588,\n",
       " 'document': 589,\n",
       " 'transport': 590,\n",
       " 'reign': 591,\n",
       " 'express': 592,\n",
       " 'cyclone': 593,\n",
       " 'gain': 594,\n",
       " 'begin': 595,\n",
       " 'picture': 596,\n",
       " 'users': 597,\n",
       " 'identify': 598,\n",
       " 'order': 599,\n",
       " 'scientific': 600,\n",
       " 'soccer': 601,\n",
       " 'mythology': 602,\n",
       " 'occupy': 603,\n",
       " 'maintain': 604,\n",
       " 'sell': 605,\n",
       " 'translate': 606,\n",
       " 'separate': 607,\n",
       " 'artists': 608,\n",
       " 'present': 609,\n",
       " 'bird': 610,\n",
       " 'specific': 611,\n",
       " 'format': 612,\n",
       " 'run': 613,\n",
       " 'fight': 614,\n",
       " 'device': 615,\n",
       " 'headquarter': 616,\n",
       " 'give': 617,\n",
       " 'weeks': 618,\n",
       " 'muslim': 619,\n",
       " 'asteroid': 620,\n",
       " 'close': 621,\n",
       " 'adventure': 622,\n",
       " 'command': 623,\n",
       " 'flow': 624,\n",
       " 'products': 625,\n",
       " 'core': 626,\n",
       " 'climate': 627,\n",
       " 'roles': 628,\n",
       " 'content': 629,\n",
       " 'land': 630,\n",
       " 'committee': 631,\n",
       " 'initially': 632,\n",
       " 'satellite': 633,\n",
       " 'color': 634,\n",
       " 'philosophy': 635,\n",
       " 'contest': 636,\n",
       " 'achieve': 637,\n",
       " 'origin': 638,\n",
       " 'ship': 639,\n",
       " 'actually': 640,\n",
       " 'congress': 641,\n",
       " 'hand': 642,\n",
       " 'constitution': 643,\n",
       " 'highly': 644,\n",
       " 'provence': 645,\n",
       " 'nazi': 646,\n",
       " 'method': 647,\n",
       " 'anti': 648,\n",
       " 'determine': 649,\n",
       " 'angle': 650,\n",
       " 'commonwealth': 651,\n",
       " 'affect': 652,\n",
       " 'overall': 653,\n",
       " 'isbn': 654,\n",
       " 'signal': 655,\n",
       " 'diameter': 656,\n",
       " 'celebrate': 657,\n",
       " 'count': 658,\n",
       " 'vary': 659,\n",
       " 'happen': 660,\n",
       " 'cancer': 661,\n",
       " 'linux': 662,\n",
       " 'solo': 663,\n",
       " 'agree': 664,\n",
       " 'executive': 665,\n",
       " 'younger': 666,\n",
       " 'volume': 667,\n",
       " 'mention': 668,\n",
       " 'numerous': 669,\n",
       " 'store': 670,\n",
       " 'relationship': 671,\n",
       " 'credit': 672,\n",
       " 'originate': 673,\n",
       " 'evidence': 674,\n",
       " 'corporation': 675,\n",
       " 'tree': 676,\n",
       " 'physics': 677,\n",
       " 'regional': 678,\n",
       " 'underground': 679,\n",
       " 'industrial': 680,\n",
       " 'earn': 681,\n",
       " 'versions': 682,\n",
       " 'provinces': 683,\n",
       " 'labor': 684,\n",
       " 'growth': 685,\n",
       " 'environment': 686,\n",
       " 'earliest': 687,\n",
       " 'student': 688,\n",
       " 'case': 689,\n",
       " 'product': 690,\n",
       " 'religion': 691,\n",
       " 'breed': 692,\n",
       " 'cast': 693,\n",
       " 'islamic': 694,\n",
       " 'longest': 695,\n",
       " 'strike': 696,\n",
       " 'mathematics': 697,\n",
       " 'basic': 698,\n",
       " 'administration': 699,\n",
       " 'measure': 700,\n",
       " 'therefore': 701,\n",
       " 'kill': 702,\n",
       " 'track': 703,\n",
       " 'tell': 704,\n",
       " 'promote': 705,\n",
       " 'triple': 706,\n",
       " 'letter': 707,\n",
       " 'contract': 708,\n",
       " 'drug': 709,\n",
       " 'ways': 710,\n",
       " 'troop': 711,\n",
       " 'last': 712,\n",
       " 'compare': 713,\n",
       " 'company': 714,\n",
       " 'punk': 715,\n",
       " 'shape': 716,\n",
       " 'level': 717,\n",
       " 'prior': 718,\n",
       " 'policy': 719,\n",
       " 'indicate': 720,\n",
       " 'sit': 721,\n",
       " 'khan': 722,\n",
       " 'visit': 723,\n",
       " 'adult': 724,\n",
       " 'match': 725,\n",
       " 'invent': 726,\n",
       " 'operation': 727,\n",
       " 'pronounce': 728,\n",
       " 'normally': 729,\n",
       " 'whether': 730,\n",
       " 'wrestler': 731,\n",
       " 'responsible': 732,\n",
       " 'approach': 733,\n",
       " 'materials': 734,\n",
       " 'blue': 735,\n",
       " 'incorporate': 736,\n",
       " 'medal': 737,\n",
       " 'concern': 738,\n",
       " 'federation': 739,\n",
       " 'microsoft': 740,\n",
       " 'unlike': 741,\n",
       " 'expand': 742,\n",
       " 'creation': 743,\n",
       " 'address': 744,\n",
       " 'supply': 745,\n",
       " 'fantasy': 746,\n",
       " 'manage': 747,\n",
       " 'hill': 748,\n",
       " 'authority': 749,\n",
       " 'legal': 750,\n",
       " 'fail': 751,\n",
       " 'centuries': 752,\n",
       " 'field': 753,\n",
       " 'console': 754,\n",
       " 'bury': 755,\n",
       " 'rhine': 756,\n",
       " 'propose': 757,\n",
       " 'construct': 758,\n",
       " 'detail': 759,\n",
       " 'nominate': 760,\n",
       " 'teach': 761,\n",
       " 'distinguish': 762,\n",
       " 'church': 763,\n",
       " 'select': 764,\n",
       " 'secondary': 765,\n",
       " 'relatively': 766,\n",
       " 'billion': 767,\n",
       " 'goals': 768,\n",
       " 'historic': 769,\n",
       " 'electronic': 770,\n",
       " 'universe': 771,\n",
       " 'remove': 772,\n",
       " 'alone': 773,\n",
       " 'kilometres': 774,\n",
       " 'aircraft': 775,\n",
       " 'evolution': 776,\n",
       " 'view': 777,\n",
       " 'medieval': 778,\n",
       " 'generation': 779,\n",
       " 'management': 780,\n",
       " 'print': 781,\n",
       " 'novels': 782,\n",
       " 'families': 783,\n",
       " 'mine': 784,\n",
       " 'trade': 785,\n",
       " 'layer': 786,\n",
       " 'prevent': 787,\n",
       " 'vice': 788,\n",
       " 'classic': 789,\n",
       " 'staff': 790,\n",
       " 'deaths': 791,\n",
       " 'try': 792,\n",
       " 'meter': 793,\n",
       " 'entry': 794,\n",
       " 'completely': 795,\n",
       " 'concept': 796,\n",
       " 'sexual': 797,\n",
       " 'classify': 798,\n",
       " 'piece': 799,\n",
       " 'dictionary': 800,\n",
       " 'density': 801,\n",
       " 'kong': 802,\n",
       " 'ability': 803,\n",
       " 'reserve': 804,\n",
       " 'activity': 805,\n",
       " 'lack': 806,\n",
       " 'motion': 807,\n",
       " 'biography': 808,\n",
       " 'tradition': 809,\n",
       " 'reform': 810,\n",
       " 'assembly': 811,\n",
       " 'depend': 812,\n",
       " 'chamber': 813,\n",
       " 'weight': 814,\n",
       " 'aube': 815,\n",
       " 'territories': 816,\n",
       " 'frequently': 817,\n",
       " 'orthodox': 818,\n",
       " 'conservative': 819,\n",
       " 'carbon': 820,\n",
       " 'heritage': 821,\n",
       " 'minutes': 822,\n",
       " 'theatre': 823,\n",
       " 'spell': 824,\n",
       " 'ally': 825,\n",
       " 'municipalities': 826,\n",
       " 'azur': 827,\n",
       " 'manufacture': 828,\n",
       " 'water': 829,\n",
       " 'roll': 830,\n",
       " 'rural': 831,\n",
       " 'agreement': 832,\n",
       " 'landfall': 833,\n",
       " 'parallel': 834,\n",
       " 'portion': 835,\n",
       " 'cars': 836,\n",
       " 'ministry': 837,\n",
       " 'trophy': 838,\n",
       " 'outer': 839,\n",
       " 'championships': 840,\n",
       " 'roughly': 841,\n",
       " 'soldier': 842,\n",
       " 'find': 843,\n",
       " 'reveal': 844,\n",
       " 'strength': 845,\n",
       " 'shortly': 846,\n",
       " 'tube': 847,\n",
       " 'experiment': 848,\n",
       " 'gregorian': 849,\n",
       " 'pattern': 850,\n",
       " 'mark': 851,\n",
       " 'closely': 852,\n",
       " 'convert': 853,\n",
       " 'fund': 854,\n",
       " 'largely': 855,\n",
       " 'sing': 856,\n",
       " 'laws': 857,\n",
       " 'side': 858,\n",
       " 'tribe': 859,\n",
       " 'applications': 860,\n",
       " 'opposite': 861,\n",
       " 'episodes': 862,\n",
       " 'writers': 863,\n",
       " 'definition': 864,\n",
       " 'agency': 865,\n",
       " 'traditionally': 866,\n",
       " 'cents': 867,\n",
       " 'boys': 868,\n",
       " 'chart': 869,\n",
       " 'observe': 870,\n",
       " 'latter': 871,\n",
       " 'draw': 872,\n",
       " 'activities': 873,\n",
       " 'sons': 874,\n",
       " 'govern': 875,\n",
       " 'sequel': 876,\n",
       " 'market': 877,\n",
       " 'economy': 878,\n",
       " 'marine': 879,\n",
       " 'jazz': 880,\n",
       " 'traffic': 881,\n",
       " 'designate': 882,\n",
       " 'ideas': 883,\n",
       " 'reason': 884,\n",
       " 'drop': 885,\n",
       " 'difficult': 886,\n",
       " 'asian': 887,\n",
       " 'external': 888,\n",
       " 'multi': 889,\n",
       " 'inspire': 890,\n",
       " 'problem': 891,\n",
       " 'engines': 892,\n",
       " 'script': 893,\n",
       " 'distribute': 894,\n",
       " 'distinct': 895,\n",
       " 'scene': 896,\n",
       " 'studios': 897,\n",
       " 'temple': 898,\n",
       " 'additional': 899,\n",
       " 'couple': 900,\n",
       " 'metres': 901,\n",
       " 'philosopher': 902,\n",
       " 'folk': 903,\n",
       " 'meet': 904,\n",
       " 'mediterranean': 905,\n",
       " 'impact': 906,\n",
       " 'formal': 907,\n",
       " 'interstate': 908,\n",
       " 'ardãƒ': 909,\n",
       " 'semi': 910,\n",
       " 'girls': 911,\n",
       " 'affairs': 912,\n",
       " 'respectively': 913,\n",
       " 'bureau': 914,\n",
       " 'arrest': 915,\n",
       " 'musicians': 916,\n",
       " 'slightly': 917,\n",
       " 'disk': 918,\n",
       " 'caribbean': 919,\n",
       " 'charge': 920,\n",
       " 'burn': 921,\n",
       " 'senior': 922,\n",
       " 'christmas': 923,\n",
       " 'suffer': 924,\n",
       " 'prominent': 925,\n",
       " 'lyric': 926,\n",
       " 'alphabet': 927,\n",
       " 'club': 928,\n",
       " 'sciences': 929,\n",
       " 'pioneer': 930,\n",
       " 'memory': 931,\n",
       " 'eye': 932,\n",
       " 'avoid': 933,\n",
       " 'intend': 934,\n",
       " 'target': 935,\n",
       " 'write': 936,\n",
       " 'hit': 937,\n",
       " 'legend': 938,\n",
       " 'drum': 939,\n",
       " 'tehsil': 940,\n",
       " 'colony': 941,\n",
       " 'egg': 942,\n",
       " 'computers': 943,\n",
       " 'contact': 944,\n",
       " 'tournament': 945,\n",
       " 'factor': 946,\n",
       " 'global': 947,\n",
       " 'midfielder': 948,\n",
       " 'socialist': 949,\n",
       " 'smackdown': 950,\n",
       " 'workers': 951,\n",
       " 'universities': 952,\n",
       " 'organizations': 953,\n",
       " 'interview': 954,\n",
       " 'formation': 955,\n",
       " 'pilot': 956,\n",
       " 'size': 957,\n",
       " 'extreme': 958,\n",
       " 'councils': 959,\n",
       " 'abbottabad': 960,\n",
       " 'grammy': 961,\n",
       " 'bond': 962,\n",
       " 'knight': 963,\n",
       " 'yorkshire': 964,\n",
       " 'collect': 965,\n",
       " 'communist': 966,\n",
       " 'request': 967,\n",
       " 'span': 968,\n",
       " 'fan': 969,\n",
       " 'basis': 970,\n",
       " 'conflict': 971,\n",
       " 'plot': 972,\n",
       " 'bear': 973,\n",
       " 'supreme': 974,\n",
       " 'franchise': 975,\n",
       " 'purchase': 976,\n",
       " 'voice': 977,\n",
       " 'editor': 978,\n",
       " 'property': 979,\n",
       " 'initial': 980,\n",
       " 'behavior': 981,\n",
       " 'kinds': 982,\n",
       " 'grant': 983,\n",
       " 'earthquake': 984,\n",
       " 'designation': 985,\n",
       " 'journal': 986,\n",
       " 'atomic': 987,\n",
       " 'johann': 988,\n",
       " 'stay': 989,\n",
       " 'chairman': 990,\n",
       " 'register': 991,\n",
       " 'individuals': 992,\n",
       " 'continental': 993,\n",
       " 'oppose': 994,\n",
       " 'test': 995,\n",
       " 'immediately': 996,\n",
       " 'permanent': 997,\n",
       " 'flavor': 998,\n",
       " 'internal': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 625,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True])"
      ]
     },
     "execution_count": 626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors[0] == word_vectors['unite']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2896"
      ]
     },
     "execution_count": 627,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_in_vector = word_vectors.index_to_key\n",
    "len(words_in_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word's Difficulty Considered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "== Concreteness_ratings_Brysbaert_et_al_BRM.txt ==\n",
    "\n",
    "This file contains concreteness ratings for 40 thousand English lemma words gathered via Amazon Mechanical Turk. The ratings come from a larger list of 63 thousand words and represent all English words known to 85% of the raters.\n",
    "\n",
    "The file contains eight columns:\n",
    "1. The word\n",
    "2. Whether it is a single word or a two-word expression \n",
    "3. The mean concreteness rating\n",
    "4. The standard deviation of the concreteness ratings\n",
    "5. The number of persons indicating they did not know the word\n",
    "6. The total number of persons who rated the word\n",
    "7. Percentage participants who knew the word\n",
    "8. The SUBTLEX-US frequency count (on a total of 51 million; Brysbaert & New, 2009) \n",
    "9. The dominant part-of-speech usage\n",
    "\n",
    "Original source: http://crr.ugent.be/archives/1330\n",
    "\n",
    "Brysbaert, M., Warriner, A.B., & Kuperman, V. (2014). Concreteness ratings for 40 thousand generally known English word lemmas. Behavior Research Methods, 46, 904-911.\n",
    "http://crr.ugent.be/papers/Brysbaert_Warriner_Kuperman_BRM_Concreteness_ratings.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concreteness rating - the higher Conc.M, the easier the word is.\n",
    "concreteness_path = 'Data/Concreteness_ratings_Brysbaert_et_al_BRM.txt'\n",
    "concrete_df = pd.read_csv(concreteness_path,delimiter='\\t', keep_default_na=False)\n",
    "concreteset=(concrete_df['Word'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Bigram</th>\n",
       "      <th>Conc.M</th>\n",
       "      <th>Conc.SD</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent_known</th>\n",
       "      <th>SUBTLEX</th>\n",
       "      <th>Dom_Pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>roadsweeper</td>\n",
       "      <td>0</td>\n",
       "      <td>4.85</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>traindriver</td>\n",
       "      <td>0</td>\n",
       "      <td>4.54</td>\n",
       "      <td>0.71</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tush</td>\n",
       "      <td>0</td>\n",
       "      <td>4.45</td>\n",
       "      <td>1.01</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>0.88</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hairdress</td>\n",
       "      <td>0</td>\n",
       "      <td>3.93</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pharmaceutics</td>\n",
       "      <td>0</td>\n",
       "      <td>3.77</td>\n",
       "      <td>1.41</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39949</th>\n",
       "      <td>unenvied</td>\n",
       "      <td>0</td>\n",
       "      <td>1.21</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39950</th>\n",
       "      <td>agnostically</td>\n",
       "      <td>0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39951</th>\n",
       "      <td>conceptualistic</td>\n",
       "      <td>0</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.50</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39952</th>\n",
       "      <td>conventionalism</td>\n",
       "      <td>0</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39953</th>\n",
       "      <td>essentialness</td>\n",
       "      <td>0</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39954 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Word  Bigram  Conc.M  Conc.SD  Unknown  Total  \\\n",
       "0          roadsweeper       0    4.85     0.37        1     27   \n",
       "1          traindriver       0    4.54     0.71        3     29   \n",
       "2                 tush       0    4.45     1.01        3     25   \n",
       "3            hairdress       0    3.93     1.28        0     29   \n",
       "4        pharmaceutics       0    3.77     1.41        4     26   \n",
       "...                ...     ...     ...      ...      ...    ...   \n",
       "39949         unenvied       0    1.21     0.62        1     30   \n",
       "39950     agnostically       0    1.20     0.50        2     27   \n",
       "39951  conceptualistic       0    1.18     0.50        4     26   \n",
       "39952  conventionalism       0    1.18     0.48        1     29   \n",
       "39953    essentialness       0    1.04     0.20        2     26   \n",
       "\n",
       "       Percent_known  SUBTLEX Dom_Pos  \n",
       "0               0.96        0       0  \n",
       "1               0.90        0       0  \n",
       "2               0.88       66       0  \n",
       "3               1.00        1       0  \n",
       "4               0.85        0       0  \n",
       "...              ...      ...     ...  \n",
       "39949           0.97        0    #N/A  \n",
       "39950           0.93        0    #N/A  \n",
       "39951           0.85        0    #N/A  \n",
       "39952           0.97        0    #N/A  \n",
       "39953           0.92        0    #N/A  \n",
       "\n",
       "[39954 rows x 9 columns]"
      ]
     },
     "execution_count": 629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    37058\n",
       "1     2896\n",
       "Name: Bigram, dtype: int64"
      ]
     },
     "execution_count": 630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_df.Bigram.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Bigram</th>\n",
       "      <th>Conc.M</th>\n",
       "      <th>Conc.SD</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent_known</th>\n",
       "      <th>SUBTLEX</th>\n",
       "      <th>Dom_Pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28707</th>\n",
       "      <td>baking soda</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28709</th>\n",
       "      <td>baseball bat</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28710</th>\n",
       "      <td>bath towel</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28711</th>\n",
       "      <td>beach ball</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28712</th>\n",
       "      <td>bed sheet</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39619</th>\n",
       "      <td>tantamount to</td>\n",
       "      <td>1</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.85</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39857</th>\n",
       "      <td>chance on</td>\n",
       "      <td>1</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39871</th>\n",
       "      <td>free rein</td>\n",
       "      <td>1</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0.63</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39899</th>\n",
       "      <td>by chance</td>\n",
       "      <td>1</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39947</th>\n",
       "      <td>in principle</td>\n",
       "      <td>1</td>\n",
       "      <td>1.21</td>\n",
       "      <td>0.41</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2896 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Word  Bigram  Conc.M  Conc.SD  Unknown  Total  Percent_known  \\\n",
       "28707    baking soda       1    5.00     0.00        0     30           1.00   \n",
       "28709   baseball bat       1    5.00     0.00        0     29           1.00   \n",
       "28710     bath towel       1    5.00     0.00        0     29           1.00   \n",
       "28711     beach ball       1    5.00     0.00        0     28           1.00   \n",
       "28712      bed sheet       1    5.00     0.00        0     28           1.00   \n",
       "...              ...     ...     ...      ...      ...    ...            ...   \n",
       "39619  tantamount to       1    1.52     0.85        4     27           0.85   \n",
       "39857      chance on       1    1.38     0.75        2     28           0.93   \n",
       "39871      free rein       1    1.37     0.63        2     29           0.93   \n",
       "39899      by chance       1    1.34     0.72        1     30           0.97   \n",
       "39947   in principle       1    1.21     0.41        4     28           0.86   \n",
       "\n",
       "       SUBTLEX Dom_Pos  \n",
       "28707        0    #N/A  \n",
       "28709        0    #N/A  \n",
       "28710        0    #N/A  \n",
       "28711        0    #N/A  \n",
       "28712        0    #N/A  \n",
       "...        ...     ...  \n",
       "39619        0    #N/A  \n",
       "39857        0    #N/A  \n",
       "39871        0    #N/A  \n",
       "39899        0    #N/A  \n",
       "39947        0    #N/A  \n",
       "\n",
       "[2896 rows x 9 columns]"
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_df[concrete_df.Bigram==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Bigram</th>\n",
       "      <th>Conc.M</th>\n",
       "      <th>Conc.SD</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent_known</th>\n",
       "      <th>SUBTLEX</th>\n",
       "      <th>Dom_Pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Word, Bigram, Conc.M, Conc.SD, Unknown, Total, Percent_known, SUBTLEX, Dom_Pos]\n",
       "Index: []"
      ]
     },
     "execution_count": 632,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#There is no Nan value in Conc.M column\n",
    "concrete_df[concrete_df['Conc.M'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are we gonna consider bigrams in this dataset, given it's only a small fraction ~ 8% in size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.04"
      ]
     },
     "execution_count": 633,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(concrete_df['Conc.M'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 634,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(concrete_df['Conc.M'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concreteness values range from 1 - 5, we could possible use the inverse value of concreteness to scale it to a 0-1 range and give easier words less weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_words = list(concrete_df['Word'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39954"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(concrete_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_complement = [word for word in words_in_vector if word not in concrete_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "570"
      ]
     },
     "execution_count": 638,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(concrete_complement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['years',\n",
       " 'largest',\n",
       " 'ndash',\n",
       " 'members',\n",
       " 'aisne',\n",
       " 'europe',\n",
       " 'countries',\n",
       " 'european',\n",
       " 'calvados',\n",
       " 'basse',\n",
       " 'normandie',\n",
       " 'islands',\n",
       " 'areas',\n",
       " 'loire',\n",
       " 'gironde',\n",
       " 'events',\n",
       " 'africa',\n",
       " 'picardie',\n",
       " 'languages',\n",
       " 'aquitaine',\n",
       " 'songs',\n",
       " 'systems',\n",
       " 'others',\n",
       " 'cities',\n",
       " 'players',\n",
       " 'animals',\n",
       " 'disney',\n",
       " 'britain',\n",
       " 'oldest',\n",
       " 'units',\n",
       " 'websites',\n",
       " 'windows',\n",
       " 'larger',\n",
       " 'mountains',\n",
       " 'albums',\n",
       " 'students',\n",
       " 'alpes',\n",
       " 'nations',\n",
       " 'partement',\n",
       " 'months',\n",
       " 'nobel',\n",
       " 'african',\n",
       " 'things',\n",
       " 'cells',\n",
       " 'picardy',\n",
       " 'towns',\n",
       " 'sarthe',\n",
       " 'regions',\n",
       " 'humans',\n",
       " 'elements',\n",
       " 'prix',\n",
       " 'korea',\n",
       " 'inhabitants',\n",
       " 'earlier',\n",
       " 'greatest',\n",
       " 'hours',\n",
       " 'brothers',\n",
       " 'friends',\n",
       " 'vocals',\n",
       " 'saturn',\n",
       " 'counties',\n",
       " 'problems',\n",
       " 'examples',\n",
       " 'users',\n",
       " 'artists',\n",
       " 'weeks',\n",
       " 'products',\n",
       " 'roles',\n",
       " 'provence',\n",
       " 'nazi',\n",
       " 'isbn',\n",
       " 'linux',\n",
       " 'versions',\n",
       " 'provinces',\n",
       " 'earliest',\n",
       " 'longest',\n",
       " 'khan',\n",
       " 'materials',\n",
       " 'microsoft',\n",
       " 'centuries',\n",
       " 'rhine',\n",
       " 'goals',\n",
       " 'kilometres',\n",
       " 'novels',\n",
       " 'families',\n",
       " 'deaths',\n",
       " 'kong',\n",
       " 'aube',\n",
       " 'territories',\n",
       " 'minutes',\n",
       " 'theatre',\n",
       " 'municipalities',\n",
       " 'azur',\n",
       " 'cars',\n",
       " 'championships',\n",
       " 'gregorian',\n",
       " 'laws',\n",
       " 'applications',\n",
       " 'episodes',\n",
       " 'writers',\n",
       " 'cents',\n",
       " 'boys',\n",
       " 'activities',\n",
       " 'ideas',\n",
       " 'asian',\n",
       " 'engines',\n",
       " 'studios',\n",
       " 'metres',\n",
       " 'ardãƒ',\n",
       " 'girls',\n",
       " 'affairs',\n",
       " 'musicians',\n",
       " 'caribbean',\n",
       " 'sciences',\n",
       " 'tehsil',\n",
       " 'computers',\n",
       " 'smackdown',\n",
       " 'workers',\n",
       " 'universities',\n",
       " 'organizations',\n",
       " 'councils',\n",
       " 'abbottabad',\n",
       " 'grammy',\n",
       " 'yorkshire',\n",
       " 'kinds',\n",
       " 'johann',\n",
       " 'individuals',\n",
       " 'montreal',\n",
       " 'hong',\n",
       " 'hitler',\n",
       " 'organisms',\n",
       " 'jews',\n",
       " 'tribes',\n",
       " 'gods',\n",
       " 'muslims',\n",
       " 'ones',\n",
       " 'smallest',\n",
       " 'pokãƒ',\n",
       " 'mammals',\n",
       " 'relations',\n",
       " 'villages',\n",
       " 'fifa',\n",
       " 'youngest',\n",
       " 'operations',\n",
       " 'kilometers',\n",
       " 'kings',\n",
       " 'weapons',\n",
       " 'arab',\n",
       " 'neptune',\n",
       " 'methods',\n",
       " 'decades',\n",
       " 'leaders',\n",
       " 'colour',\n",
       " 'puerto',\n",
       " 'devices',\n",
       " 'asteroids',\n",
       " 'westphalia',\n",
       " 'properties',\n",
       " 'communities',\n",
       " 'rout',\n",
       " 'particles',\n",
       " 'thousands',\n",
       " 'friedrich',\n",
       " 'bros',\n",
       " 'vendãƒ',\n",
       " 'differences',\n",
       " 'scientists',\n",
       " 'temperatures',\n",
       " 'tallest',\n",
       " 'degrees',\n",
       " 'males',\n",
       " 'prefecture',\n",
       " 'vaucluse',\n",
       " 'drivers',\n",
       " 'sisters',\n",
       " 'appearances',\n",
       " 'mar',\n",
       " 'beatles',\n",
       " 'wrestlemania',\n",
       " 'composers',\n",
       " 'critics',\n",
       " 'females',\n",
       " 'residents',\n",
       " 'items',\n",
       " 'legs',\n",
       " 'performances',\n",
       " 'ardã',\n",
       " 'elections',\n",
       " 'christians',\n",
       " 'institutions',\n",
       " 'airlines',\n",
       " 'viii',\n",
       " 'saxe',\n",
       " 'romans',\n",
       " 'americans',\n",
       " 'representatives',\n",
       " 'authorities',\n",
       " 'glasgow',\n",
       " 'indo',\n",
       " 'planets',\n",
       " 'byzantine',\n",
       " 'anglo',\n",
       " 'duchy',\n",
       " 'governments',\n",
       " 'orton',\n",
       " 'rangers',\n",
       " 'bach',\n",
       " 'edinburgh',\n",
       " 'colonies',\n",
       " 'divisions',\n",
       " 'standards',\n",
       " 'homo',\n",
       " 'hundreds',\n",
       " 'poems',\n",
       " 'uranus',\n",
       " 'origins',\n",
       " 'roads',\n",
       " 'actors',\n",
       " 'uefa',\n",
       " 'scholars',\n",
       " 'techniques',\n",
       " 'tram',\n",
       " 'offices',\n",
       " 'contributions',\n",
       " 'citizens',\n",
       " 'prussia',\n",
       " 'wagner',\n",
       " 'cyclones',\n",
       " 'populations',\n",
       " 'texts',\n",
       " 'departments',\n",
       " 'boundaries',\n",
       " 'productions',\n",
       " 'winners',\n",
       " 'adults',\n",
       " 'vehicles',\n",
       " 'britannica',\n",
       " 'officials',\n",
       " 'resources',\n",
       " 'movements',\n",
       " 'shakespeare',\n",
       " 'efforts',\n",
       " 'instructions',\n",
       " 'molecules',\n",
       " 'persons',\n",
       " 'closest',\n",
       " 'passengers',\n",
       " 'labour',\n",
       " 'electrons',\n",
       " 'zeus',\n",
       " 'insects',\n",
       " 'serie',\n",
       " 'hurricanes',\n",
       " 'ecliptic',\n",
       " 'atlantiques',\n",
       " 'genera',\n",
       " 'canadiens',\n",
       " 'bengal',\n",
       " 'forbes',\n",
       " 'colleges',\n",
       " 'pokã',\n",
       " 'lowest',\n",
       " 'jura',\n",
       " 'batista',\n",
       " 'bits',\n",
       " 'foods',\n",
       " 'fossils',\n",
       " 'hampshire',\n",
       " 'components',\n",
       " 'brabant',\n",
       " 'norse',\n",
       " 'beliefs',\n",
       " 'operas',\n",
       " 'frankfurt',\n",
       " 'josã',\n",
       " 'communications',\n",
       " 'editors',\n",
       " 'maritimes',\n",
       " 'shah',\n",
       " 'mcmahon',\n",
       " 'theorem',\n",
       " 'whedon',\n",
       " 'mosques',\n",
       " 'shire',\n",
       " 'instal',\n",
       " 'baptist',\n",
       " 'worlds',\n",
       " 'newspapers',\n",
       " 'neighbour',\n",
       " 'aspects',\n",
       " 'visitors',\n",
       " 'bouches',\n",
       " 'societies',\n",
       " 'traditions',\n",
       " 'oceans',\n",
       " 'symptoms',\n",
       " 'symbols',\n",
       " 'dollars',\n",
       " 'videos',\n",
       " 'renault',\n",
       " 'leonese',\n",
       " 'indus',\n",
       " 'sony',\n",
       " 'nasa',\n",
       " 'locomotives',\n",
       " 'daughters',\n",
       " 'variations',\n",
       " 'slavic',\n",
       " 'atoms',\n",
       " 'generations',\n",
       " 'reich',\n",
       " 'finals',\n",
       " 'janeiro',\n",
       " 'mccartney',\n",
       " 'michaels',\n",
       " 'centre',\n",
       " 'fastest',\n",
       " 'rulers',\n",
       " 'categories',\n",
       " 'observations',\n",
       " 'mozart',\n",
       " 'nuremberg',\n",
       " 'railways',\n",
       " 'suffolk',\n",
       " 'historians',\n",
       " 'costa',\n",
       " 'pyrã',\n",
       " 'predators',\n",
       " 'arabia',\n",
       " 'singers',\n",
       " 'simpsons',\n",
       " 'diseases',\n",
       " 'antarctica',\n",
       " 'strongest',\n",
       " 'scenes',\n",
       " 'newfoundland',\n",
       " 'knowles',\n",
       " 'buenos',\n",
       " 'americas',\n",
       " 'persia',\n",
       " 'khyber',\n",
       " 'unesco',\n",
       " 'castile',\n",
       " 'vendã',\n",
       " 'anglican',\n",
       " 'thames',\n",
       " 'armies',\n",
       " 'organs',\n",
       " 'programme',\n",
       " 'honour',\n",
       " 'harvard',\n",
       " 'amazon',\n",
       " 'alps',\n",
       " 'petersburg',\n",
       " 'saudi',\n",
       " 'vector',\n",
       " 'winger',\n",
       " 'restaurants',\n",
       " 'organise',\n",
       " 'georg',\n",
       " 'relatives',\n",
       " 'apollo',\n",
       " 'laureate',\n",
       " 'households',\n",
       " 'teau',\n",
       " 'plat',\n",
       " 'wider',\n",
       " 'flemish',\n",
       " 'policies',\n",
       " 'locations',\n",
       " 'nazis',\n",
       " 'extratropical',\n",
       " 'heinrich',\n",
       " 'producers',\n",
       " 'crimes',\n",
       " 'pakhtunkhwa',\n",
       " 'josãƒ',\n",
       " 'ubuntu',\n",
       " 'kingdoms',\n",
       " 'prisoners',\n",
       " 'bundesliga',\n",
       " 'minerals',\n",
       " 'glands',\n",
       " 'harbour',\n",
       " 'relationships',\n",
       " 'religions',\n",
       " 'editions',\n",
       " 'sussex',\n",
       " 'chakwal',\n",
       " 'soundgarden',\n",
       " 'industries',\n",
       " 'blackhawks',\n",
       " 'ferrari',\n",
       " 'yugoslavia',\n",
       " 'emirates',\n",
       " 'saxon',\n",
       " 'victims',\n",
       " 'platforms',\n",
       " 'chãƒ',\n",
       " 'hume',\n",
       " 'prussian',\n",
       " 'skills',\n",
       " 'debian',\n",
       " 'theories',\n",
       " 'dinosaurs',\n",
       " 'giants',\n",
       " 'doors',\n",
       " 'volkswagen',\n",
       " 'lanka',\n",
       " 'emperors',\n",
       " 'ussr',\n",
       " 'basilica',\n",
       " 'wiki',\n",
       " 'duties',\n",
       " 'jurassic',\n",
       " 'supporters',\n",
       " 'substances',\n",
       " 'varieties',\n",
       " 'creatures',\n",
       " 'tehsils',\n",
       " 'empress',\n",
       " 'readers',\n",
       " 'baltic',\n",
       " 'sainte',\n",
       " 'unions',\n",
       " 'reactions',\n",
       " 'facto',\n",
       " 'descendants',\n",
       " 'sega',\n",
       " 'wolfgang',\n",
       " 'astronomers',\n",
       " 'settlers',\n",
       " 'viewers',\n",
       " 'arabian',\n",
       " 'medici',\n",
       " 'victorian',\n",
       " 'athletes',\n",
       " 'tibet',\n",
       " 'arrondissement',\n",
       " 'candidates',\n",
       " 'collections',\n",
       " 'vegas',\n",
       " 'boroughs',\n",
       " 'grande',\n",
       " 'germanic',\n",
       " 'pradesh',\n",
       " 'trials',\n",
       " 'directors',\n",
       " 'environments',\n",
       " 'europeans',\n",
       " 'competitions',\n",
       " 'burma',\n",
       " 'enemies',\n",
       " 'continents',\n",
       " 'cardinals',\n",
       " 'antilles',\n",
       " 'georges',\n",
       " 'germans',\n",
       " 'canton',\n",
       " 'fischer',\n",
       " 'owners',\n",
       " 'stronger',\n",
       " 'businesses',\n",
       " 'proteins',\n",
       " 'employees',\n",
       " 'fewer',\n",
       " 'tournaments',\n",
       " 'tourists',\n",
       " 'teachers',\n",
       " 'ions',\n",
       " 'broadway',\n",
       " 'bruins',\n",
       " 'silva',\n",
       " 'pluto',\n",
       " 'acids',\n",
       " 'seas',\n",
       " 'subfamily',\n",
       " 'tico',\n",
       " 'conductors',\n",
       " 'agents',\n",
       " 'extant',\n",
       " 'hainaut',\n",
       " 'bishops',\n",
       " 'indians',\n",
       " 'settlements',\n",
       " 'nixon',\n",
       " 'volcanoes',\n",
       " 'monuments',\n",
       " 'nascar',\n",
       " 'airways',\n",
       " 'compositions',\n",
       " 'photos',\n",
       " 'presidents',\n",
       " 'ncaa',\n",
       " 'organisation',\n",
       " 'lessons',\n",
       " 'medals',\n",
       " 'hindenburg',\n",
       " 'antwerp',\n",
       " 'theaters',\n",
       " 'wrestlers',\n",
       " 'fibers',\n",
       " 'keynes',\n",
       " 'valleys',\n",
       " 'kreis',\n",
       " 'boeing',\n",
       " 'beyoncã',\n",
       " 'mecklenburg',\n",
       " 'genes',\n",
       " 'chevrolet',\n",
       " 'greeks',\n",
       " 'slower',\n",
       " 'heights',\n",
       " 'magazines',\n",
       " 'ville',\n",
       " 'scala',\n",
       " 'lions',\n",
       " 'derbyshire',\n",
       " 'pichilemu',\n",
       " 'buddha',\n",
       " 'cyrillic',\n",
       " 'warriors',\n",
       " 'genres',\n",
       " 'patients',\n",
       " 'busiest',\n",
       " 'denominations',\n",
       " 'publications',\n",
       " 'rica',\n",
       " 'followers',\n",
       " 'nato',\n",
       " 'developers',\n",
       " 'gettysburg',\n",
       " 'topics',\n",
       " 'ants',\n",
       " 'dialects',\n",
       " 'aang',\n",
       " 'prayers',\n",
       " 'vertebrates',\n",
       " 'lancashire',\n",
       " 'ears',\n",
       " 'poets',\n",
       " 'sunderland',\n",
       " 'ming',\n",
       " 'oblast',\n",
       " 'mongol',\n",
       " 'translations',\n",
       " 'researchers',\n",
       " 'rttemberg',\n",
       " 'dolphins',\n",
       " 'bavarian',\n",
       " 'trojan',\n",
       " 'haute',\n",
       " 'rhode',\n",
       " 'grameen',\n",
       " 'benoit',\n",
       " 'specimens',\n",
       " 'agencies',\n",
       " 'disambiguation',\n",
       " 'defence',\n",
       " 'czechoslovakia',\n",
       " 'stallone',\n",
       " 'vegetables',\n",
       " 'recipes',\n",
       " 'immigrants',\n",
       " 'catholics',\n",
       " 'terminus',\n",
       " 'earthquakes',\n",
       " 'amadeus',\n",
       " 'ipswich',\n",
       " 'congo']"
      ]
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_complement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_intersect = [word for word in words_in_vector if word in concrete_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2326"
      ]
     },
     "execution_count": 641,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(concrete_intersect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unite'"
      ]
     },
     "execution_count": 642,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_intersect[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.34864047, -0.96178025,  1.0424236 , -0.27514943, -1.125268  ,\n",
       "        0.17379373, -0.5000698 ,  0.61671704,  0.3502842 , -0.0587092 ,\n",
       "        0.11508509, -0.21317965,  1.1454185 , -0.40656507, -0.89661133,\n",
       "       -1.2150089 ,  0.40510127, -0.758923  , -0.7322218 , -0.38091078,\n",
       "        0.09221615,  0.01026862,  0.4988388 ,  0.6096505 ,  1.1464705 ,\n",
       "       -0.46910125,  0.2855899 , -0.5065553 , -1.1206437 ,  0.49509016,\n",
       "       -0.4553206 , -0.20433855,  0.1936442 ,  0.00710674,  1.4585135 ,\n",
       "       -0.3271947 ,  0.09666988,  0.23133074,  0.59747565,  0.6051638 ,\n",
       "       -0.821614  , -0.25832888, -0.08141857, -1.1627805 , -0.1859263 ,\n",
       "       -0.74427146, -0.2904973 , -1.0154371 , -0.09791026, -0.28925666,\n",
       "       -0.27558604, -0.28107327,  0.45664597, -0.73296994,  0.01105025,\n",
       "       -0.03365638,  0.07879242, -0.16169213, -0.5991656 , -0.29063004,\n",
       "        0.4216433 , -0.01379751, -0.18666983,  0.22629549, -1.3479476 ,\n",
       "       -0.8134935 , -0.31116077,  0.22562763, -0.07893478,  0.5850851 ,\n",
       "        0.4344932 ,  0.543718  , -0.5242279 ,  0.45136374,  0.7665201 ,\n",
       "       -0.44161308,  0.32743797,  0.94204414, -0.17063637,  0.1022554 ,\n",
       "       -0.49121517, -1.631073  , -0.55016595,  0.23735161,  0.07527448,\n",
       "        0.5882919 ,  0.4307339 , -0.47949505, -0.19959149,  0.45376033,\n",
       "       -0.05501731, -0.36052817,  1.1274532 , -0.0575669 , -0.6127581 ,\n",
       "        0.16628341,  1.0270311 ,  0.8726847 , -0.5509129 , -0.74375904],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 643,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.52])"
      ]
     },
     "execution_count": 644,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_df[concrete_df['Word']=='state']['Conc.M'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in concrete_intersect:\n",
    "    word_vectors[word] = word_vectors[word] * 1/concrete_df[concrete_df['Word']==word]['Conc.M'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "== AoA_51715_words.csv ==\n",
    "\n",
    "This file contains \"Age of Acquisition\" (AoA) estimates for about 51k English words, which refers to the approximate age (in years) when a word was learned. Early words, being more basic, have lower average AoA.\n",
    "\n",
    "The main columns you will be interested in are \"Word\" and \"AoA_Kup_lem\". But the others may be useful too.\n",
    "\n",
    "The file contains these columns:\n",
    "\n",
    "Word :: The word in question\n",
    "Alternative.spelling :: if the Word may be spelled frequently in another form\t\n",
    "Freq_pm\t:: Freq of the Word in general English (larger -> more common)\n",
    "Dom_PoS_SUBTLEX\t:: Dominant part of speech in general usage\n",
    "Nletters :: number of letters \n",
    "Nphon :: number of phonemes\n",
    "Nsyll :: number of syllables\n",
    "Lemma_highest_PoS :: the \"lemmatized\" or \"root\" form of the word (in the dominant part of speech. e.g. The root form of the verb \"abates\" is \"abate\".\n",
    "AoA_Kup\t:: The AoA from a previous study by Kuperman et al.\n",
    "Perc_known :: Percent of people who knew the word in the Kuperman et al. study\n",
    "AoA_Kup_lem :: Estimated AoA based on Kuperman et al. study lemmatized words. THIS IS THE MAIN COLUMN OF INTEREST.\n",
    "Perc_known_lem\t:: Estimated percentage of people who would know this form of the word in the Kuperman study.\n",
    "AoA_Bird_lem :: AoA reported in previous study by Bird (2001) \n",
    "AoA_Bristol_lem\t:: AoA reported in previous study from Bristol Univ. (2006)\n",
    "AoA_Cort_lem :: AoA reported in previous study by Cortese & Khanna (2008)\n",
    "AoA_Schock :: AoA reported in previous study by Schock (2012)\n",
    "\n",
    "Original source : http://crr.ugent.be/archives/806"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Alternative.spelling</th>\n",
       "      <th>Freq_pm</th>\n",
       "      <th>Dom_PoS_SUBTLEX</th>\n",
       "      <th>Nletters</th>\n",
       "      <th>Nphon</th>\n",
       "      <th>Nsyll</th>\n",
       "      <th>Lemma_highest_PoS</th>\n",
       "      <th>AoA_Kup</th>\n",
       "      <th>Perc_known</th>\n",
       "      <th>AoA_Kup_lem</th>\n",
       "      <th>Perc_known_lem</th>\n",
       "      <th>AoA_Bird_lem</th>\n",
       "      <th>AoA_Bristol_lem</th>\n",
       "      <th>AoA_Cort_lem</th>\n",
       "      <th>AoA_Schock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>20415.27</td>\n",
       "      <td>Article</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>2.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aardvark</td>\n",
       "      <td>aardvark</td>\n",
       "      <td>0.41</td>\n",
       "      <td>Noun</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>aardvark</td>\n",
       "      <td>9.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abacus</td>\n",
       "      <td>abacus</td>\n",
       "      <td>0.24</td>\n",
       "      <td>Noun</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>abacus</td>\n",
       "      <td>8.69</td>\n",
       "      <td>0.65</td>\n",
       "      <td>8.69</td>\n",
       "      <td>0.65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abacuses</td>\n",
       "      <td>abacuses</td>\n",
       "      <td>0.02</td>\n",
       "      <td>Noun</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>abacus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.69</td>\n",
       "      <td>0.65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abalone</td>\n",
       "      <td>abalone</td>\n",
       "      <td>0.51</td>\n",
       "      <td>Verb</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>abalone</td>\n",
       "      <td>12.23</td>\n",
       "      <td>0.72</td>\n",
       "      <td>12.23</td>\n",
       "      <td>0.72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word Alternative.spelling   Freq_pm Dom_PoS_SUBTLEX  Nletters  Nphon  \\\n",
       "0         a                    a  20415.27         Article         1      1   \n",
       "1  aardvark             aardvark      0.41            Noun         8      7   \n",
       "2    abacus               abacus      0.24            Noun         6      6   \n",
       "3  abacuses             abacuses      0.02            Noun         8      9   \n",
       "4   abalone              abalone      0.51            Verb         7      7   \n",
       "\n",
       "   Nsyll Lemma_highest_PoS  AoA_Kup  Perc_known  AoA_Kup_lem  Perc_known_lem  \\\n",
       "0      1                 a     2.89        1.00         2.89            1.00   \n",
       "1      2          aardvark     9.89        1.00         9.89            1.00   \n",
       "2      3            abacus     8.69        0.65         8.69            0.65   \n",
       "3      4            abacus      NaN         NaN         8.69            0.65   \n",
       "4      4           abalone    12.23        0.72        12.23            0.72   \n",
       "\n",
       "   AoA_Bird_lem  AoA_Bristol_lem  AoA_Cort_lem  AoA_Schock  \n",
       "0          3.16              NaN           NaN         NaN  \n",
       "1           NaN              NaN           NaN         NaN  \n",
       "2           NaN              NaN           NaN         NaN  \n",
       "3           NaN              NaN           NaN         NaN  \n",
       "4           NaN              NaN           NaN         NaN  "
      ]
     },
     "execution_count": 646,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AoA\n",
    "#Perc_known_lem, AoA_Kup_lem\n",
    "aoawords_path = 'Data/AoA_51715_words.csv'\n",
    "AoA = pd.read_csv(aoawords_path,encoding = 'unicode_escape')\n",
    "AoA_set = set(AoA['Word'].values)\n",
    "AoA.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51715"
      ]
     },
     "execution_count": 647,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(AoA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.58"
      ]
     },
     "execution_count": 648,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AoA.AoA_Kup_lem.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.0"
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AoA.AoA_Kup_lem.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Alternative.spelling</th>\n",
       "      <th>Freq_pm</th>\n",
       "      <th>Dom_PoS_SUBTLEX</th>\n",
       "      <th>Nletters</th>\n",
       "      <th>Nphon</th>\n",
       "      <th>Nsyll</th>\n",
       "      <th>Lemma_highest_PoS</th>\n",
       "      <th>AoA_Kup</th>\n",
       "      <th>Perc_known</th>\n",
       "      <th>AoA_Kup_lem</th>\n",
       "      <th>Perc_known_lem</th>\n",
       "      <th>AoA_Bird_lem</th>\n",
       "      <th>AoA_Bristol_lem</th>\n",
       "      <th>AoA_Cort_lem</th>\n",
       "      <th>AoA_Schock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14878</th>\n",
       "      <td>eisteddfod</td>\n",
       "      <td>eisteddfod</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>eisteddfod</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2084</th>\n",
       "      <td>architrave</td>\n",
       "      <td>architrave</td>\n",
       "      <td>0.04</td>\n",
       "      <td>Noun</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>architrave</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6274</th>\n",
       "      <td>calceolaria</td>\n",
       "      <td>calceolaria</td>\n",
       "      <td>0.02</td>\n",
       "      <td>Noun</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>calceolaria</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32931</th>\n",
       "      <td>penury</td>\n",
       "      <td>penury</td>\n",
       "      <td>0.02</td>\n",
       "      <td>Noun</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>penury</td>\n",
       "      <td>20.6</td>\n",
       "      <td>0.28</td>\n",
       "      <td>20.6</td>\n",
       "      <td>0.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25243</th>\n",
       "      <td>kendo</td>\n",
       "      <td>kendo</td>\n",
       "      <td>0.37</td>\n",
       "      <td>Noun</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>kendo</td>\n",
       "      <td>20.5</td>\n",
       "      <td>0.11</td>\n",
       "      <td>20.5</td>\n",
       "      <td>0.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38932</th>\n",
       "      <td>rogation</td>\n",
       "      <td>rogation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>rogation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42089</th>\n",
       "      <td>smilax</td>\n",
       "      <td>smilax</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>smilax</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46368</th>\n",
       "      <td>thulium</td>\n",
       "      <td>thulium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>thulium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50862</th>\n",
       "      <td>wickiup</td>\n",
       "      <td>wickiup</td>\n",
       "      <td>0.27</td>\n",
       "      <td>Noun</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>wickiup</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50941</th>\n",
       "      <td>williwaw</td>\n",
       "      <td>williwaw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>williwaw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51715 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Word Alternative.spelling  Freq_pm Dom_PoS_SUBTLEX  Nletters  \\\n",
       "14878   eisteddfod           eisteddfod      NaN             NaN        10   \n",
       "2084    architrave           architrave     0.04            Noun        10   \n",
       "6274   calceolaria          calceolaria     0.02            Noun        11   \n",
       "32931       penury               penury     0.02            Noun         6   \n",
       "25243        kendo                kendo     0.37            Noun         5   \n",
       "...            ...                  ...      ...             ...       ...   \n",
       "38932     rogation             rogation      NaN             NaN         8   \n",
       "42089       smilax               smilax      NaN             NaN         6   \n",
       "46368      thulium              thulium      NaN             NaN         7   \n",
       "50862      wickiup              wickiup     0.27            Noun         7   \n",
       "50941     williwaw             williwaw      NaN             NaN         8   \n",
       "\n",
       "       Nphon  Nsyll Lemma_highest_PoS  AoA_Kup  Perc_known  AoA_Kup_lem  \\\n",
       "14878      8      3        eisteddfod     25.0        0.05         25.0   \n",
       "2084       8      3        architrave     21.0        0.05         21.0   \n",
       "6274      11      6       calceolaria     21.0        0.11         21.0   \n",
       "32931      7      3            penury     20.6        0.28         20.6   \n",
       "25243      5      2             kendo     20.5        0.11         20.5   \n",
       "...      ...    ...               ...      ...         ...          ...   \n",
       "38932      7      3          rogation      NaN        0.00          NaN   \n",
       "42089      7      2            smilax      NaN        0.00          NaN   \n",
       "46368      6      3           thulium      NaN        0.00          NaN   \n",
       "50862      6      3           wickiup      NaN        0.00          NaN   \n",
       "50941      6      3          williwaw      NaN        0.00          NaN   \n",
       "\n",
       "       Perc_known_lem  AoA_Bird_lem  AoA_Bristol_lem  AoA_Cort_lem  AoA_Schock  \n",
       "14878            0.05           NaN              NaN           NaN         NaN  \n",
       "2084             0.05           NaN              NaN           NaN         NaN  \n",
       "6274             0.11           NaN              NaN           NaN         NaN  \n",
       "32931            0.28           NaN              NaN           NaN         NaN  \n",
       "25243            0.11           NaN              NaN           NaN         NaN  \n",
       "...               ...           ...              ...           ...         ...  \n",
       "38932            0.00           NaN              NaN           NaN         NaN  \n",
       "42089            0.00           NaN              NaN           NaN         NaN  \n",
       "46368            0.00           NaN              NaN           NaN         NaN  \n",
       "50862            0.00           NaN              NaN           NaN         NaN  \n",
       "50941            0.00           NaN              NaN           NaN         NaN  \n",
       "\n",
       "[51715 rows x 16 columns]"
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AoA.sort_values(['AoA_Kup_lem'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(AoA[AoA['AoA_Kup_lem'].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Alternative.spelling</th>\n",
       "      <th>Freq_pm</th>\n",
       "      <th>Dom_PoS_SUBTLEX</th>\n",
       "      <th>Nletters</th>\n",
       "      <th>Nphon</th>\n",
       "      <th>Nsyll</th>\n",
       "      <th>Lemma_highest_PoS</th>\n",
       "      <th>AoA_Kup</th>\n",
       "      <th>Perc_known</th>\n",
       "      <th>AoA_Kup_lem</th>\n",
       "      <th>Perc_known_lem</th>\n",
       "      <th>AoA_Bird_lem</th>\n",
       "      <th>AoA_Bristol_lem</th>\n",
       "      <th>AoA_Cort_lem</th>\n",
       "      <th>AoA_Schock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>actinium</td>\n",
       "      <td>actinium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>actinium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322</th>\n",
       "      <td>ambuscade</td>\n",
       "      <td>ambuscade</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>ambuscade</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2306</th>\n",
       "      <td>ashlar</td>\n",
       "      <td>ashlar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>ashlar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5095</th>\n",
       "      <td>bosky</td>\n",
       "      <td>bosky</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>bosky</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6404</th>\n",
       "      <td>canaille</td>\n",
       "      <td>canaille</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>canaille</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9004</th>\n",
       "      <td>compeer</td>\n",
       "      <td>compeer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>compeer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9005</th>\n",
       "      <td>compeers</td>\n",
       "      <td>compeers</td>\n",
       "      <td>0.02</td>\n",
       "      <td>Noun</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>compeer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16000</th>\n",
       "      <td>europium</td>\n",
       "      <td>europium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>europium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19065</th>\n",
       "      <td>gallimaufry</td>\n",
       "      <td>gallimaufry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>gallimaufry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22498</th>\n",
       "      <td>hutment</td>\n",
       "      <td>hutment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>hutment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25196</th>\n",
       "      <td>karakul</td>\n",
       "      <td>karakul</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>karakul</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25219</th>\n",
       "      <td>kedge</td>\n",
       "      <td>kedge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>kedge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25575</th>\n",
       "      <td>kyat</td>\n",
       "      <td>kyat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>kyat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32754</th>\n",
       "      <td>peculation</td>\n",
       "      <td>peculation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>peculation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34588</th>\n",
       "      <td>pother</td>\n",
       "      <td>pother</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>pother</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38932</th>\n",
       "      <td>rogation</td>\n",
       "      <td>rogation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>rogation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42089</th>\n",
       "      <td>smilax</td>\n",
       "      <td>smilax</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>smilax</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46368</th>\n",
       "      <td>thulium</td>\n",
       "      <td>thulium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>thulium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50862</th>\n",
       "      <td>wickiup</td>\n",
       "      <td>wickiup</td>\n",
       "      <td>0.27</td>\n",
       "      <td>Noun</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>wickiup</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50941</th>\n",
       "      <td>williwaw</td>\n",
       "      <td>williwaw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>williwaw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Word Alternative.spelling  Freq_pm Dom_PoS_SUBTLEX  Nletters  \\\n",
       "442       actinium             actinium      NaN             NaN         8   \n",
       "1322     ambuscade            ambuscade      NaN             NaN         9   \n",
       "2306        ashlar               ashlar      NaN             NaN         6   \n",
       "5095         bosky                bosky      NaN             NaN         5   \n",
       "6404      canaille             canaille      NaN             NaN         8   \n",
       "9004       compeer              compeer      NaN             NaN         7   \n",
       "9005      compeers             compeers     0.02            Noun         8   \n",
       "16000     europium             europium      NaN             NaN         8   \n",
       "19065  gallimaufry          gallimaufry      NaN             NaN        11   \n",
       "22498      hutment              hutment      NaN             NaN         7   \n",
       "25196      karakul              karakul      NaN             NaN         7   \n",
       "25219        kedge                kedge      NaN             NaN         5   \n",
       "25575         kyat                 kyat      NaN             NaN         4   \n",
       "32754   peculation           peculation      NaN             NaN        10   \n",
       "34588       pother               pother      NaN             NaN         6   \n",
       "38932     rogation             rogation      NaN             NaN         8   \n",
       "42089       smilax               smilax      NaN             NaN         6   \n",
       "46368      thulium              thulium      NaN             NaN         7   \n",
       "50862      wickiup              wickiup     0.27            Noun         7   \n",
       "50941     williwaw             williwaw      NaN             NaN         8   \n",
       "\n",
       "       Nphon  Nsyll Lemma_highest_PoS  AoA_Kup  Perc_known  AoA_Kup_lem  \\\n",
       "442        8      4          actinium      NaN         0.0          NaN   \n",
       "1322       8      3         ambuscade      NaN         0.0          NaN   \n",
       "2306       5      2            ashlar      NaN         0.0          NaN   \n",
       "5095       4      2             bosky      NaN         0.0          NaN   \n",
       "6404       5      2          canaille      NaN         0.0          NaN   \n",
       "9004       6      3           compeer      NaN         0.0          NaN   \n",
       "9005       7      3           compeer      NaN         NaN          NaN   \n",
       "16000      8      4          europium      NaN         0.0          NaN   \n",
       "19065      9      4       gallimaufry      NaN         0.0          NaN   \n",
       "22498      7      2           hutment      NaN         0.0          NaN   \n",
       "25196      7      3           karakul      NaN         0.0          NaN   \n",
       "25219      3      1             kedge      NaN         0.0          NaN   \n",
       "25575      4      2              kyat      NaN         0.0          NaN   \n",
       "32754     10      4        peculation      NaN         0.0          NaN   \n",
       "34588      5      2            pother      NaN         0.0          NaN   \n",
       "38932      7      3          rogation      NaN         0.0          NaN   \n",
       "42089      7      2            smilax      NaN         0.0          NaN   \n",
       "46368      6      3           thulium      NaN         0.0          NaN   \n",
       "50862      6      3           wickiup      NaN         0.0          NaN   \n",
       "50941      6      3          williwaw      NaN         0.0          NaN   \n",
       "\n",
       "       Perc_known_lem  AoA_Bird_lem  AoA_Bristol_lem  AoA_Cort_lem  AoA_Schock  \n",
       "442               0.0           NaN              NaN           NaN         NaN  \n",
       "1322              0.0           NaN              NaN           NaN         NaN  \n",
       "2306              0.0           NaN              NaN           NaN         NaN  \n",
       "5095              0.0           NaN              NaN           NaN         NaN  \n",
       "6404              0.0           NaN              NaN           NaN         NaN  \n",
       "9004              0.0           NaN              NaN           NaN         NaN  \n",
       "9005              0.0           NaN              NaN           NaN         NaN  \n",
       "16000             0.0           NaN              NaN           NaN         NaN  \n",
       "19065             0.0           NaN              NaN           NaN         NaN  \n",
       "22498             0.0           NaN              NaN           NaN         NaN  \n",
       "25196             0.0           NaN              NaN           NaN         NaN  \n",
       "25219             0.0           NaN              NaN           NaN         NaN  \n",
       "25575             0.0           NaN              NaN           NaN         NaN  \n",
       "32754             0.0           NaN              NaN           NaN         NaN  \n",
       "34588             0.0           NaN              NaN           NaN         NaN  \n",
       "38932             0.0           NaN              NaN           NaN         NaN  \n",
       "42089             0.0           NaN              NaN           NaN         NaN  \n",
       "46368             0.0           NaN              NaN           NaN         NaN  \n",
       "50862             0.0           NaN              NaN           NaN         NaN  \n",
       "50941             0.0           NaN              NaN           NaN         NaN  "
      ]
     },
     "execution_count": 652,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AoA[AoA['AoA_Kup_lem'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to impute all Nan values in AoA_Kup_lem as the max AoA value 25, as they appear to be hard words.\n",
    "AoA['AoA_Kup_lem'].fillna(value=AoA['AoA_Kup_lem'].max(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Alternative.spelling</th>\n",
       "      <th>Freq_pm</th>\n",
       "      <th>Dom_PoS_SUBTLEX</th>\n",
       "      <th>Nletters</th>\n",
       "      <th>Nphon</th>\n",
       "      <th>Nsyll</th>\n",
       "      <th>Lemma_highest_PoS</th>\n",
       "      <th>AoA_Kup</th>\n",
       "      <th>Perc_known</th>\n",
       "      <th>AoA_Kup_lem</th>\n",
       "      <th>Perc_known_lem</th>\n",
       "      <th>AoA_Bird_lem</th>\n",
       "      <th>AoA_Bristol_lem</th>\n",
       "      <th>AoA_Cort_lem</th>\n",
       "      <th>AoA_Schock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2306</th>\n",
       "      <td>ashlar</td>\n",
       "      <td>ashlar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>ashlar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38932</th>\n",
       "      <td>rogation</td>\n",
       "      <td>rogation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>rogation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46368</th>\n",
       "      <td>thulium</td>\n",
       "      <td>thulium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>thulium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14878</th>\n",
       "      <td>eisteddfod</td>\n",
       "      <td>eisteddfod</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>eisteddfod</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5095</th>\n",
       "      <td>bosky</td>\n",
       "      <td>bosky</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>bosky</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27395</th>\n",
       "      <td>mamma</td>\n",
       "      <td>mamma</td>\n",
       "      <td>3.02</td>\n",
       "      <td>Noun</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>mama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27393</th>\n",
       "      <td>mamas</td>\n",
       "      <td>mamas</td>\n",
       "      <td>0.71</td>\n",
       "      <td>Noun</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>mama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27392</th>\n",
       "      <td>mama</td>\n",
       "      <td>mama</td>\n",
       "      <td>103.71</td>\n",
       "      <td>Noun</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>mama</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29050</th>\n",
       "      <td>mommas</td>\n",
       "      <td>mommas</td>\n",
       "      <td>0.10</td>\n",
       "      <td>Noun</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>momma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29049</th>\n",
       "      <td>momma</td>\n",
       "      <td>momma</td>\n",
       "      <td>8.08</td>\n",
       "      <td>Noun</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>momma</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51715 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Word Alternative.spelling  Freq_pm Dom_PoS_SUBTLEX  Nletters  \\\n",
       "2306       ashlar               ashlar      NaN             NaN         6   \n",
       "38932    rogation             rogation      NaN             NaN         8   \n",
       "46368     thulium              thulium      NaN             NaN         7   \n",
       "14878  eisteddfod           eisteddfod      NaN             NaN        10   \n",
       "5095        bosky                bosky      NaN             NaN         5   \n",
       "...           ...                  ...      ...             ...       ...   \n",
       "27395       mamma                mamma     3.02            Noun         5   \n",
       "27393       mamas                mamas     0.71            Noun         5   \n",
       "27392        mama                 mama   103.71            Noun         4   \n",
       "29050      mommas               mommas     0.10            Noun         6   \n",
       "29049       momma                momma     8.08            Noun         5   \n",
       "\n",
       "       Nphon  Nsyll Lemma_highest_PoS  AoA_Kup  Perc_known  AoA_Kup_lem  \\\n",
       "2306       5      2            ashlar      NaN        0.00        25.00   \n",
       "38932      7      3          rogation      NaN        0.00        25.00   \n",
       "46368      6      3           thulium      NaN        0.00        25.00   \n",
       "14878      8      3        eisteddfod    25.00        0.05        25.00   \n",
       "5095       4      2             bosky      NaN        0.00        25.00   \n",
       "...      ...    ...               ...      ...         ...          ...   \n",
       "27395      4      2              mama      NaN         NaN         1.89   \n",
       "27393      5      2              mama      NaN         NaN         1.89   \n",
       "27392      4      2              mama     1.89        1.00         1.89   \n",
       "29050      5      2             momma      NaN         NaN         1.58   \n",
       "29049      4      2             momma     1.58        1.00         1.58   \n",
       "\n",
       "       Perc_known_lem  AoA_Bird_lem  AoA_Bristol_lem  AoA_Cort_lem  AoA_Schock  \n",
       "2306             0.00           NaN              NaN           NaN         NaN  \n",
       "38932            0.00           NaN              NaN           NaN         NaN  \n",
       "46368            0.00           NaN              NaN           NaN         NaN  \n",
       "14878            0.05           NaN              NaN           NaN         NaN  \n",
       "5095             0.00           NaN              NaN           NaN         NaN  \n",
       "...               ...           ...              ...           ...         ...  \n",
       "27395            1.00           NaN              NaN           NaN         NaN  \n",
       "27393            1.00           NaN              NaN           NaN         NaN  \n",
       "27392            1.00           NaN              NaN           NaN         NaN  \n",
       "29050            1.00           NaN              NaN           NaN         NaN  \n",
       "29049            1.00           NaN              NaN           NaN         NaN  \n",
       "\n",
       "[51715 rows x 16 columns]"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AoA.sort_values(['AoA_Kup_lem'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AoA values range from 0 - 25, which means the smaller the AoA value, the easier the word is. We could possibly use the AoA value to give easier words less weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoa_words = list(AoA['Word'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51715"
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aoa_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoa_complement = [word for word in words_in_vector if word not in aoa_words]\n",
    "aoa_intersect = [word for word in words_in_vector if word in aoa_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "342"
      ]
     },
     "execution_count": 658,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aoa_complement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ndash',\n",
       " 'usually',\n",
       " 'aisne',\n",
       " 'europe',\n",
       " 'european',\n",
       " 'calvados',\n",
       " 'basse',\n",
       " 'normandie',\n",
       " 'commonly',\n",
       " 'loire',\n",
       " 'gironde',\n",
       " 'africa',\n",
       " 'picardie',\n",
       " 'aquitaine',\n",
       " 'generally',\n",
       " 'atlantic',\n",
       " 'officially',\n",
       " 'lower',\n",
       " 'especially',\n",
       " 'disney',\n",
       " 'throughout',\n",
       " 'britain',\n",
       " 'wikipedia',\n",
       " 'approximately',\n",
       " 'pacific',\n",
       " 'mainly',\n",
       " 'nintendo',\n",
       " 'alpes',\n",
       " 'partement',\n",
       " 'typically',\n",
       " 'nobel',\n",
       " 'african',\n",
       " 'widely',\n",
       " 'picardy',\n",
       " 'sarthe',\n",
       " 'particularly',\n",
       " 'formerly',\n",
       " 'olympic',\n",
       " 'jewish',\n",
       " 'prix',\n",
       " 'korea',\n",
       " 'previously',\n",
       " 'directly',\n",
       " 'probably',\n",
       " 'saturn',\n",
       " 'online',\n",
       " 'recently',\n",
       " 'highly',\n",
       " 'provence',\n",
       " 'nazi',\n",
       " 'isbn',\n",
       " 'linux',\n",
       " 'islamic',\n",
       " 'microsoft',\n",
       " 'unlike',\n",
       " 'rhine',\n",
       " 'relatively',\n",
       " 'kilometres',\n",
       " 'completely',\n",
       " 'kong',\n",
       " 'aube',\n",
       " 'frequently',\n",
       " 'municipalities',\n",
       " 'azur',\n",
       " 'shortly',\n",
       " 'gregorian',\n",
       " 'closely',\n",
       " 'largely',\n",
       " 'traditionally',\n",
       " 'asian',\n",
       " 'metres',\n",
       " 'ardãƒ',\n",
       " 'respectively',\n",
       " 'caribbean',\n",
       " 'tehsil',\n",
       " 'smackdown',\n",
       " 'abbottabad',\n",
       " 'grammy',\n",
       " 'yorkshire',\n",
       " 'johann',\n",
       " 'montreal',\n",
       " 'hong',\n",
       " 'hitler',\n",
       " 'jews',\n",
       " 'subsequently',\n",
       " 'muslims',\n",
       " 'specifically',\n",
       " 'islam',\n",
       " 'pokãƒ',\n",
       " 'playstation',\n",
       " 'possibly',\n",
       " 'easily',\n",
       " 'fifa',\n",
       " 'subtropical',\n",
       " 'notably',\n",
       " 'christianity',\n",
       " 'arab',\n",
       " 'neptune',\n",
       " 'historically',\n",
       " 'colour',\n",
       " 'onto',\n",
       " 'puerto',\n",
       " 'newly',\n",
       " 'westphalia',\n",
       " 'extremely',\n",
       " 'friedrich',\n",
       " 'vendãƒ',\n",
       " 'entirely',\n",
       " 'alongside',\n",
       " 'vaucluse',\n",
       " 'voyager',\n",
       " 'beatles',\n",
       " 'wrestlemania',\n",
       " 'xbox',\n",
       " 'ardã',\n",
       " 'christians',\n",
       " 'formally',\n",
       " 'gaelic',\n",
       " 'viii',\n",
       " 'saxe',\n",
       " 'romans',\n",
       " 'americans',\n",
       " 'glasgow',\n",
       " 'indo',\n",
       " 'anglo',\n",
       " 'orton',\n",
       " 'bach',\n",
       " 'edinburgh',\n",
       " 'google',\n",
       " 'uranus',\n",
       " 'uefa',\n",
       " 'prussia',\n",
       " 'wagner',\n",
       " 'celtic',\n",
       " 'heavily',\n",
       " 'annually',\n",
       " 'britannica',\n",
       " 'shakespeare',\n",
       " 'labour',\n",
       " 'hindu',\n",
       " 'zeus',\n",
       " 'serie',\n",
       " 'ecliptic',\n",
       " 'atlantiques',\n",
       " 'canadiens',\n",
       " 'bengal',\n",
       " 'forbes',\n",
       " 'pokã',\n",
       " 'jura',\n",
       " 'batista',\n",
       " 'hampshire',\n",
       " 'brabant',\n",
       " 'commons',\n",
       " 'norse',\n",
       " 'operas',\n",
       " 'frankfurt',\n",
       " 'josã',\n",
       " 'overseas',\n",
       " 'maritimes',\n",
       " 'greatly',\n",
       " 'shah',\n",
       " 'mcmahon',\n",
       " 'whedon',\n",
       " 'gradually',\n",
       " 'briefly',\n",
       " 'instal',\n",
       " 'fairly',\n",
       " 'baptist',\n",
       " 'neighbour',\n",
       " 'bouches',\n",
       " 'renault',\n",
       " 'leonese',\n",
       " 'indus',\n",
       " 'sony',\n",
       " 'nasa',\n",
       " 'slavic',\n",
       " 'reich',\n",
       " 'janeiro',\n",
       " 'mccartney',\n",
       " 'michaels',\n",
       " 'mozart',\n",
       " 'nuremberg',\n",
       " 'suffolk',\n",
       " 'costa',\n",
       " 'pyrã',\n",
       " 'arabia',\n",
       " 'simpsons',\n",
       " 'antarctica',\n",
       " 'buddhism',\n",
       " 'newfoundland',\n",
       " 'knowles',\n",
       " 'strongly',\n",
       " 'buenos',\n",
       " 'inland',\n",
       " 'americas',\n",
       " 'internationally',\n",
       " 'persia',\n",
       " 'khyber',\n",
       " 'unesco',\n",
       " 'successfully',\n",
       " 'castile',\n",
       " 'vendã',\n",
       " 'anglican',\n",
       " 'thames',\n",
       " 'orient',\n",
       " 'somewhat',\n",
       " 'subspecies',\n",
       " 'programme',\n",
       " 'honour',\n",
       " 'harvard',\n",
       " 'amazon',\n",
       " 'alps',\n",
       " 'petersburg',\n",
       " 'saudi',\n",
       " 'antarctic',\n",
       " 'organise',\n",
       " 'georg',\n",
       " 'apollo',\n",
       " 'teau',\n",
       " 'exclusively',\n",
       " 'flemish',\n",
       " 'publicly',\n",
       " 'nazis',\n",
       " 'extratropical',\n",
       " 'heinrich',\n",
       " 'similarly',\n",
       " 'significantly',\n",
       " 'pakhtunkhwa',\n",
       " 'josãƒ',\n",
       " 'ubuntu',\n",
       " 'bundesliga',\n",
       " 'harbour',\n",
       " 'sussex',\n",
       " 'chakwal',\n",
       " 'soundgarden',\n",
       " 'blackhawks',\n",
       " 'ferrari',\n",
       " 'yugoslavia',\n",
       " 'emirates',\n",
       " 'saxon',\n",
       " 'chãƒ',\n",
       " 'hume',\n",
       " 'prussian',\n",
       " 'debian',\n",
       " 'volkswagen',\n",
       " 'lanka',\n",
       " 'twentieth',\n",
       " 'ussr',\n",
       " 'jurassic',\n",
       " 'loosely',\n",
       " 'tehsils',\n",
       " 'increasingly',\n",
       " 'baltic',\n",
       " 'sainte',\n",
       " 'facto',\n",
       " 'partially',\n",
       " 'necessarily',\n",
       " 'sega',\n",
       " 'wolfgang',\n",
       " 'arabian',\n",
       " 'medici',\n",
       " 'victorian',\n",
       " 'tibet',\n",
       " 'arrondissement',\n",
       " 'vegas',\n",
       " 'grande',\n",
       " 'germanic',\n",
       " 'pradesh',\n",
       " 'independently',\n",
       " 'europeans',\n",
       " 'burma',\n",
       " 'antilles',\n",
       " 'commercially',\n",
       " 'georges',\n",
       " 'germans',\n",
       " 'canton',\n",
       " 'fischer',\n",
       " 'broadway',\n",
       " 'bruins',\n",
       " 'silva',\n",
       " 'pluto',\n",
       " 'subfamily',\n",
       " 'tico',\n",
       " 'forever',\n",
       " 'hainaut',\n",
       " 'indians',\n",
       " 'nixon',\n",
       " 'nascar',\n",
       " 'ncaa',\n",
       " 'organisation',\n",
       " 'simultaneously',\n",
       " 'legally',\n",
       " 'hindenburg',\n",
       " 'antwerp',\n",
       " 'properly',\n",
       " 'keynes',\n",
       " 'apparently',\n",
       " 'kreis',\n",
       " 'boeing',\n",
       " 'beyoncã',\n",
       " 'mecklenburg',\n",
       " 'thereafter',\n",
       " 'chevrolet',\n",
       " 'greeks',\n",
       " 'ville',\n",
       " 'scala',\n",
       " 'additionally',\n",
       " 'derbyshire',\n",
       " 'pichilemu',\n",
       " 'buddha',\n",
       " 'cyrillic',\n",
       " 'rica',\n",
       " 'nato',\n",
       " 'gettysburg',\n",
       " 'aang',\n",
       " 'lancashire',\n",
       " 'sunderland',\n",
       " 'ming',\n",
       " 'extensively',\n",
       " 'yearly',\n",
       " 'oblast',\n",
       " 'mongol',\n",
       " 'nineteenth',\n",
       " 'rttemberg',\n",
       " 'bavarian',\n",
       " 'trojan',\n",
       " 'haute',\n",
       " 'rhode',\n",
       " 'grameen',\n",
       " 'predominantly',\n",
       " 'benoit',\n",
       " 'disambiguation',\n",
       " 'czechoslovakia',\n",
       " 'eleventh',\n",
       " 'stallone',\n",
       " 'meanwhile',\n",
       " 'unitary',\n",
       " 'catholics',\n",
       " 'sexually',\n",
       " 'amadeus',\n",
       " 'ipswich',\n",
       " 'congo']"
      ]
     },
     "execution_count": 659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aoa_complement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'saitama',\n",
       " 'shardara',\n",
       " 'rapallo',\n",
       " 'wazīrābād',\n",
       " 'malvar',\n",
       " 'vīsāvadar',\n",
       " 'yōkaichiba',\n",
       " 'fundación',\n",
       " 'gondomar',\n",
       " 'konya',\n",
       " 'skadovs’k',\n",
       " 'tulsa',\n",
       " 'grenoble',\n",
       " 'la fría',\n",
       " 'masumbwe',\n",
       " 'yangzhou',\n",
       " 'belleville',\n",
       " 'cortazar',\n",
       " 'southall',\n",
       " 'kolhāpur',\n",
       " 'zürich (kreis 12)',\n",
       " 'bhubaneshwar',\n",
       " 'puurs',\n",
       " 'challans',\n",
       " 'kėdainiai',\n",
       " 'kalach',\n",
       " 'montebello',\n",
       " 'north valley stream',\n",
       " 'astorga',\n",
       " 'pingliang',\n",
       " 'ijūin',\n",
       " 'joliette',\n",
       " 'kwale',\n",
       " 'nador',\n",
       " 'chhala',\n",
       " 'vikhorevka',\n",
       " 'wellingborough',\n",
       " 'asyūţ',\n",
       " 'viçosa',\n",
       " 'beveren',\n",
       " 'ossett',\n",
       " 'rustenburg',\n",
       " 'santiago de los caballeros',\n",
       " 'almansa',\n",
       " 'santa maria capua vetere',\n",
       " 'leer',\n",
       " 'pilsen',\n",
       " 'gaspar',\n",
       " 'žiar nad hronom',\n",
       " 'labé',\n",
       " 'lys’va',\n",
       " 'altagracia de orituco',\n",
       " 'banning',\n",
       " 'port moody',\n",
       " 'cibinong',\n",
       " 'deventer',\n",
       " 'harīpur',\n",
       " 'cần giờ',\n",
       " 'kundla',\n",
       " 'city center',\n",
       " 'antibes',\n",
       " 'diwek',\n",
       " 'lake zurich',\n",
       " 'kangaba',\n",
       " 'maghār',\n",
       " 'ashta',\n",
       " 'pimentel',\n",
       " 'linxia chengguanzhen',\n",
       " 'jerez de la frontera',\n",
       " 'arrentela',\n",
       " 'breda',\n",
       " 'supaul',\n",
       " 'yeadon',\n",
       " 'ostuncalco',\n",
       " 'dhuburi',\n",
       " 'naraura',\n",
       " 'eltham',\n",
       " 'santiago pinotepa nacional',\n",
       " 'egra',\n",
       " 'skawina',\n",
       " 'lübeck',\n",
       " 'cachoeira do sul',\n",
       " 'tolga',\n",
       " 'kélibia',\n",
       " 'bhairab bāzār',\n",
       " 'desenzano del garda',\n",
       " 'ōyama',\n",
       " 'mount lebanon',\n",
       " 'mcdonough',\n",
       " 'taunggyi',\n",
       " 'falāvarjān',\n",
       " 'sakata',\n",
       " 'oklahoma city',\n",
       " 'loandjili',\n",
       " 'algete',\n",
       " 'la chapelle-sur-erdre',\n",
       " 'radnor',\n",
       " 'veshnyaki',\n",
       " 'camaçari',\n",
       " 'ciudad sandino',\n",
       " 'mahālingpur',\n",
       " 'new malden',\n",
       " 'san benito',\n",
       " 'zhezqazghan',\n",
       " 'frohnau',\n",
       " 'hennigsdorf',\n",
       " 'mastic',\n",
       " 'makakilo',\n",
       " 'mithi',\n",
       " 'wajir',\n",
       " 'les ulis',\n",
       " 'port angeles',\n",
       " 'sijunjung',\n",
       " 'piaseczno',\n",
       " 'west valley city',\n",
       " 'emirdağ',\n",
       " 'yudong',\n",
       " 'imperial beach',\n",
       " 'cacocum',\n",
       " 'kuchera',\n",
       " 'ciamis',\n",
       " 'almaty',\n",
       " 'ahraura',\n",
       " 'malmö',\n",
       " 'kolokani',\n",
       " 'tabora',\n",
       " 'svetlograd',\n",
       " 'charlottetown',\n",
       " 'são jerônimo',\n",
       " 'culemborg',\n",
       " 'phulera',\n",
       " 'mauá',\n",
       " 'synel’nykove',\n",
       " 'bolzano',\n",
       " 'ilobu',\n",
       " 'mount martha',\n",
       " 'naivasha',\n",
       " 'gisenyi',\n",
       " 'bayshore gardens',\n",
       " 'east florence',\n",
       " 'la cruz',\n",
       " 'seoul',\n",
       " 'pont-à-mousson',\n",
       " 'katav-ivanovsk',\n",
       " 'kariya',\n",
       " 'dasmariñas',\n",
       " 'torrox',\n",
       " 'sannois',\n",
       " 'vemalwāda',\n",
       " 'rozzano',\n",
       " 'werdohl',\n",
       " 'zadar',\n",
       " 'corozal',\n",
       " 'candiac',\n",
       " 'al ‘ulá',\n",
       " 'douar tindja',\n",
       " 'hamtramck',\n",
       " 'wodzisław śląski',\n",
       " 'nazran’',\n",
       " 'anyama',\n",
       " 'horad zhodzina',\n",
       " 'corvallis',\n",
       " 'gangārāmpur',\n",
       " 'al hārithah',\n",
       " 'reconquista',\n",
       " 'laboulaye',\n",
       " 'misawa',\n",
       " 'wiener neustadt',\n",
       " 'tervuren',\n",
       " 'uray',\n",
       " 'costa mesa',\n",
       " 'bắc giang',\n",
       " 'tāsgaon',\n",
       " 'kertih',\n",
       " 'tandil',\n",
       " 'bījār',\n",
       " 'tortola',\n",
       " 'farragut',\n",
       " 'pistoia',\n",
       " 'alotenango',\n",
       " 'sunām',\n",
       " 'bloemhof',\n",
       " 'tobias barreto',\n",
       " 'seynod',\n",
       " 'saint-jean-sur-richelieu',\n",
       " 'mānāvadar',\n",
       " 'quthbullapur',\n",
       " 'papanasam',\n",
       " 'nagano',\n",
       " 'horlivka',\n",
       " 'yangliuqing',\n",
       " 'salamá',\n",
       " 'concord',\n",
       " 'wakimachi',\n",
       " 'tomigusuku',\n",
       " 'jolārpettai',\n",
       " 'bouinan',\n",
       " 'nāngal township',\n",
       " 'mililani town',\n",
       " 'taverny',\n",
       " 'nantes',\n",
       " 'avignon',\n",
       " 'soba',\n",
       " 'jesi',\n",
       " 'sōka',\n",
       " 'leichlingen',\n",
       " 'kyzyl-kyya',\n",
       " 'ivoti',\n",
       " 'sodhra',\n",
       " 'maría la baja',\n",
       " 'tabou',\n",
       " 'kaliningrad',\n",
       " 'sonsonate',\n",
       " 'abhayāpuri',\n",
       " 'launceston',\n",
       " 'leiderdorp',\n",
       " 'kharsia',\n",
       " 'mangilao village',\n",
       " 'kudus',\n",
       " 'bernau bei berlin',\n",
       " 'wauwatosa',\n",
       " 'la laja',\n",
       " 'rheinberg',\n",
       " 'salwá',\n",
       " 'asia',\n",
       " 'seabra',\n",
       " 'caucasia',\n",
       " 'heilbron',\n",
       " 'qoryooley',\n",
       " 'lota',\n",
       " 'ciudad guzmán',\n",
       " 'santa isabel',\n",
       " 'torredembarra',\n",
       " 'albufeira',\n",
       " 'conversano',\n",
       " 'gokak',\n",
       " 'khairābād',\n",
       " 'harrison',\n",
       " 'jūrmala',\n",
       " 'zürich (kreis 10) / wipkingen',\n",
       " 'tārūt',\n",
       " 'wete',\n",
       " 'dodola',\n",
       " 'la breita',\n",
       " 'çubuk',\n",
       " 'machalí',\n",
       " 'dęblin',\n",
       " 'chełm',\n",
       " 'khāliş',\n",
       " 'samara',\n",
       " 'bāpatla',\n",
       " 'ballymena',\n",
       " 'khorugh',\n",
       " 'singojuruh',\n",
       " 'békés',\n",
       " 'namp’o',\n",
       " 'piedecuesta',\n",
       " 'télimélé',\n",
       " 'são pedro da aldeia',\n",
       " 'rafsanjān',\n",
       " 'parung',\n",
       " 'morsi',\n",
       " 'binghamton',\n",
       " 'ermua',\n",
       " 'novogireyevo',\n",
       " 'keystone',\n",
       " 'bismil',\n",
       " 'oroquieta',\n",
       " 'jogbani',\n",
       " 'pinhão',\n",
       " 'l’isle-sur-la-sorgue',\n",
       " 'mishawaka',\n",
       " 'bcharré',\n",
       " 'kikwit',\n",
       " 'mauganj',\n",
       " 'kaura namoda',\n",
       " 'peniche',\n",
       " 'aburi',\n",
       " 'segamat',\n",
       " 'ilmenau',\n",
       " 'ontinyent',\n",
       " 'yutan',\n",
       " 'jhānsi',\n",
       " 'chlef',\n",
       " 'chizhou',\n",
       " 'oradea',\n",
       " 'chillupār',\n",
       " 'villa allende',\n",
       " 'pingzhuang',\n",
       " 'rochdale',\n",
       " 'çarşamba',\n",
       " 'bitola',\n",
       " 'lianyuan',\n",
       " 'joensuu',\n",
       " 'al jahrā’',\n",
       " 'pandan',\n",
       " 'nauen',\n",
       " 'pagaluñgan',\n",
       " 'newry',\n",
       " 'mytilíni',\n",
       " 'takanosu',\n",
       " 'los ángeles',\n",
       " 'royan',\n",
       " 'keta',\n",
       " 'tiruvalla',\n",
       " 'shaoguan',\n",
       " 'serchhīp',\n",
       " 'kutná hora',\n",
       " 'nepalgunj',\n",
       " 'matsudo',\n",
       " 'khenifra',\n",
       " 'surendranagar',\n",
       " 'chunskiy',\n",
       " 'sivaganga',\n",
       " 'huai yot',\n",
       " 'sitampiky',\n",
       " 'la rioja',\n",
       " 'belëv',\n",
       " 'bethal',\n",
       " 'zhigulevsk',\n",
       " 'hsinchu',\n",
       " 'lüderitz',\n",
       " 'são tomé',\n",
       " 'königsbrunn',\n",
       " 'sisŏphŏn',\n",
       " 'niquero',\n",
       " 'pisco',\n",
       " 'perris',\n",
       " 'baeza',\n",
       " 'cikampek',\n",
       " 'boû arfa',\n",
       " 'al ḩāmūl',\n",
       " 'whangarei',\n",
       " 'liberal',\n",
       " 'cambre',\n",
       " 'lakshmīpur',\n",
       " 'tharangambadi',\n",
       " 'jasper',\n",
       " 'new delhi',\n",
       " 'iwade',\n",
       " 'janakpur',\n",
       " 'rockingham',\n",
       " 'saint-augustin-de-desmaures',\n",
       " 'kırklareli',\n",
       " 'weiden',\n",
       " 'medemblik',\n",
       " 'baia mare',\n",
       " 'rutland',\n",
       " 'sittwe',\n",
       " 'ermesinde',\n",
       " 'tuen mun',\n",
       " 'barnstable',\n",
       " 'jagalūr',\n",
       " 'örnsköldsvik',\n",
       " 'taquara',\n",
       " 'mohyliv-podil’s’kyy',\n",
       " 'perm',\n",
       " 'molde',\n",
       " 'tarkwa',\n",
       " 'nandigāma',\n",
       " 'teguise',\n",
       " 'port glasgow',\n",
       " 'pires do rio',\n",
       " 'zhuangyuan',\n",
       " 'springs',\n",
       " 'yāval',\n",
       " 'werota',\n",
       " 'gastonia',\n",
       " 'srīnagar',\n",
       " 'ar rumaythah',\n",
       " 'nioro du rip',\n",
       " 'dunwoody',\n",
       " 'londrina',\n",
       " 'najaf',\n",
       " 'yafo',\n",
       " 'kyshtym',\n",
       " 'sant just desvern',\n",
       " 'fontenay-aux-roses',\n",
       " 'capivari',\n",
       " 'llaillay',\n",
       " 'arang',\n",
       " 'pinar de chamartín',\n",
       " 'río gallegos',\n",
       " 'raebareli',\n",
       " 'fort erie',\n",
       " 'divo',\n",
       " 'xiaoweizhai',\n",
       " 'tashtagol',\n",
       " 'filderstadt',\n",
       " 'visakhapatnam',\n",
       " 'cusco',\n",
       " 'sanjō',\n",
       " 'wanparti',\n",
       " 'dalton',\n",
       " 'brymbo',\n",
       " 'schwalmstadt',\n",
       " 'batu berendam',\n",
       " 'izberbash',\n",
       " 'boksitogorsk',\n",
       " 'yanbu',\n",
       " 'wageningen',\n",
       " 'coronel suárez',\n",
       " 'saki',\n",
       " 'don luan',\n",
       " 'marijampolė',\n",
       " 'sinjār',\n",
       " 'ayamonte',\n",
       " 'phnom penh',\n",
       " 'huarmey',\n",
       " 'raalte',\n",
       " 'bhīlwāra',\n",
       " 'tinsukia',\n",
       " 'vinnytsya',\n",
       " 'americana',\n",
       " 'sierre',\n",
       " 'princeton',\n",
       " 'trípoli',\n",
       " 'pokhara',\n",
       " 'zhangjiagang',\n",
       " 'itararé',\n",
       " 'santo antônio do monte',\n",
       " 'alghero',\n",
       " 'sicklerville',\n",
       " 'tepeaca',\n",
       " 'hameln',\n",
       " 'buzovna',\n",
       " 'bastī',\n",
       " 'sabanagrande',\n",
       " 'saravia',\n",
       " 'budënnovsk',\n",
       " 'isfara',\n",
       " 'mutengene',\n",
       " 'antsiranana',\n",
       " 'ghosī',\n",
       " 'oakley',\n",
       " 'russeifa',\n",
       " 'padalarang',\n",
       " 'svyetlahorsk',\n",
       " 'ríohacha',\n",
       " 'puruliya',\n",
       " 'panalanoy',\n",
       " 'ylöjärvi',\n",
       " 'dili',\n",
       " 'kīsh',\n",
       " 'vaasa',\n",
       " 'passos',\n",
       " 'sidi mérouane',\n",
       " 'hadjout',\n",
       " 'bolgatanga',\n",
       " 'zeya',\n",
       " 'athis-mons',\n",
       " 'rāth',\n",
       " 'lüdenscheid',\n",
       " 'klungkung',\n",
       " 'madisonville',\n",
       " 'jutiapa',\n",
       " 'burscheid',\n",
       " 'syracuse',\n",
       " 'komono',\n",
       " 'porriño',\n",
       " 'sadalgi',\n",
       " 'bogotol',\n",
       " 'kreuzlingen',\n",
       " 'gerede',\n",
       " 'xianshuigu',\n",
       " 'mandlā',\n",
       " 'noida',\n",
       " 'santa rosa de viterbo',\n",
       " 'baddomalhi',\n",
       " 'burgess hill',\n",
       " 'al hoceïma',\n",
       " 'bacoor',\n",
       " 'am timan',\n",
       " 'bunschoten',\n",
       " 'heusden',\n",
       " 'vāda',\n",
       " 'zgorzelec',\n",
       " 'chāndor',\n",
       " 'las margaritas',\n",
       " 'roi et',\n",
       " 'coquitlam',\n",
       " 'banaz',\n",
       " 'kovdor',\n",
       " 'prospect',\n",
       " 'atherton',\n",
       " 'kaffrine',\n",
       " 'armenia',\n",
       " 'sidi aïssa',\n",
       " 'oderzo',\n",
       " 'bourgoin-jallieu',\n",
       " 'teplice',\n",
       " 'haiphong',\n",
       " 'kinzan',\n",
       " 'ashford',\n",
       " 'bernburg',\n",
       " 'bassar',\n",
       " 'hikone',\n",
       " 'ghātsīla',\n",
       " 'veenendaal',\n",
       " 'osuna',\n",
       " 'vasa',\n",
       " 'tondi',\n",
       " 'reni',\n",
       " 'medford',\n",
       " 'saalfelden am steinernen meer',\n",
       " 'uman',\n",
       " 'six-fours-les-plages',\n",
       " 'baicheng',\n",
       " 'houilles',\n",
       " 'sofo-birnin-gwari',\n",
       " 'buxton',\n",
       " 'farrukhnagar',\n",
       " 'zanesville',\n",
       " 'mohács',\n",
       " 'ardabīl',\n",
       " 'ramallah',\n",
       " 'toguchin',\n",
       " 'miahuatlán de porfirio díaz',\n",
       " 'ennepetal',\n",
       " 'kassel',\n",
       " 'kalāt',\n",
       " 'alvin',\n",
       " 'pāveh',\n",
       " 'bloemfontein',\n",
       " 'rastatt',\n",
       " 'loncoche',\n",
       " 'yuyao',\n",
       " 'alenquer',\n",
       " 'degema hulk',\n",
       " 'zheleznogorsk',\n",
       " \"st. john's\",\n",
       " 'monterotondo',\n",
       " 'al wajh',\n",
       " 'metapán',\n",
       " 'kurihashi',\n",
       " 'al mukallā',\n",
       " 'lisburn',\n",
       " 'ullal',\n",
       " 'harda khās',\n",
       " 'znomenka',\n",
       " 'nara-shi',\n",
       " 'ploemeur',\n",
       " 'aalter',\n",
       " 'kabanga',\n",
       " 'regensburg',\n",
       " 'bende',\n",
       " 'delcevo',\n",
       " 'coyah',\n",
       " 'ngoro',\n",
       " 'annecy',\n",
       " 'schenectady',\n",
       " 'fleury-les-aubrais',\n",
       " 'tanguiéta',\n",
       " 'abbeville',\n",
       " 'anlu',\n",
       " 'ilula',\n",
       " 'gürsu',\n",
       " 'lillehammer',\n",
       " 'dreux',\n",
       " 'gescher',\n",
       " 'kodār',\n",
       " 'chemini',\n",
       " 'pedro meoqui',\n",
       " 'barcelos',\n",
       " 'jieyang',\n",
       " 'crépy-en-valois',\n",
       " 'thousand oaks',\n",
       " 'bangassou',\n",
       " 'hindoria',\n",
       " 'kodarmā',\n",
       " 'coruripe',\n",
       " 'rādhan',\n",
       " 'satka',\n",
       " 'douarnenez',\n",
       " 'tirat karmel',\n",
       " 'catanzaro',\n",
       " 'surrey',\n",
       " 'érd',\n",
       " 'tak',\n",
       " 'basildon',\n",
       " 'karlovy vary',\n",
       " 'kuala lipis',\n",
       " 'kalakkādu',\n",
       " 'şişli',\n",
       " 'citrus heights',\n",
       " 'gorontalo',\n",
       " 'hamina',\n",
       " 'wigston magna',\n",
       " 'qom',\n",
       " 'muhammadābād',\n",
       " 'magole',\n",
       " 'kuju',\n",
       " 'quezon city',\n",
       " 'coimbra',\n",
       " 'ramanayyapeta',\n",
       " 'goražde',\n",
       " 'romsey',\n",
       " 'ciego de ávila',\n",
       " 'baranagar',\n",
       " 'arakkonam',\n",
       " 'bartoszyce',\n",
       " 'ampasimanolotra',\n",
       " 'solok',\n",
       " 'serov',\n",
       " 'wolfenbüttel',\n",
       " 'v.s.k.valasai (dindigul-dist.)',\n",
       " 'esquel',\n",
       " 'kontagora',\n",
       " 'burnaby',\n",
       " 'olney',\n",
       " 'sumy',\n",
       " 'việt trì',\n",
       " 'graz',\n",
       " 'cloverly',\n",
       " 'san juan de aznalfarache',\n",
       " 'kātpādi',\n",
       " 'tiruppuvanam',\n",
       " 'laramie',\n",
       " 'würselen',\n",
       " 'köln',\n",
       " 'most',\n",
       " 'bakal',\n",
       " 'mawlamyinegyunn',\n",
       " 'protvino',\n",
       " 'badagry',\n",
       " 'quwaysinā',\n",
       " 'palwal',\n",
       " 'the crossings',\n",
       " 'sangla hill',\n",
       " 'st austell',\n",
       " 'hosdurga',\n",
       " 'busembatia',\n",
       " 'tsuruga',\n",
       " 'kharakvasla',\n",
       " 'tetuán de las victorias',\n",
       " 'periyakulam',\n",
       " 'bodegraven',\n",
       " 'jawor',\n",
       " 'vilyuchinsk',\n",
       " 'redding',\n",
       " 'pare',\n",
       " 'tezpur',\n",
       " 'kosonsoy',\n",
       " 'ferrol',\n",
       " 'novato',\n",
       " 'břeclav',\n",
       " 'chancay',\n",
       " 'theniet el had',\n",
       " 'south portland gardens',\n",
       " 'corinth',\n",
       " 'roth',\n",
       " 'fort abbās',\n",
       " 'hellevoetsluis',\n",
       " 'lambayeque',\n",
       " 'sandakan',\n",
       " 'dakar',\n",
       " 'mīrpur māthelo',\n",
       " 'tingi',\n",
       " 'šeškinė',\n",
       " 'stockbridge',\n",
       " 'ibotirama',\n",
       " 'abreus',\n",
       " 'chaparral',\n",
       " 'luckeesarai',\n",
       " 'kesabpur',\n",
       " 'shāhjānpur',\n",
       " 'cajicá',\n",
       " 'são joão del rei',\n",
       " 'virudunagar',\n",
       " 'yono',\n",
       " 'qŭshkŭpir',\n",
       " 'makó',\n",
       " 'el attaf',\n",
       " 'maba',\n",
       " 'jacaltenango',\n",
       " 'liaozhong',\n",
       " 'imus',\n",
       " 'castillejos',\n",
       " 'lālmohan',\n",
       " 'koulamoutou',\n",
       " 'north canton',\n",
       " 'korbach',\n",
       " 'bell gardens',\n",
       " 'tanay',\n",
       " 'north salt lake',\n",
       " 'ennis',\n",
       " 'matteson',\n",
       " 'mahbūbābād',\n",
       " 'anta',\n",
       " 'colegiales',\n",
       " 'villavicencio',\n",
       " 'kikinda',\n",
       " 'königslutter am elm',\n",
       " 'chekhov',\n",
       " 'mizdah',\n",
       " 'korāput',\n",
       " 'keelung',\n",
       " 'chosica',\n",
       " 'altos',\n",
       " 'reigate',\n",
       " 'logroño',\n",
       " 'morton grove',\n",
       " 'lushnjë',\n",
       " 'achern',\n",
       " 'puerto montt',\n",
       " 'konch',\n",
       " 'kuznetsovs’k',\n",
       " 'maracay',\n",
       " 'sant celoni',\n",
       " 'amla',\n",
       " 'mytishchi',\n",
       " 'guelma',\n",
       " 'oberasbach',\n",
       " 'jēkabpils',\n",
       " 'itabuna',\n",
       " 'shouguang',\n",
       " 'kyustendil',\n",
       " 'marte',\n",
       " 'al khafjī',\n",
       " 'shin’ichi',\n",
       " 'songadh',\n",
       " 'ilchester',\n",
       " 'injambakkam',\n",
       " 'fasā',\n",
       " 'schwerte',\n",
       " 'borken',\n",
       " 'mokotów',\n",
       " 'greenville',\n",
       " 'jinan',\n",
       " 'barberena',\n",
       " 'afşin',\n",
       " 'combs-la-ville',\n",
       " 'phuntsholing',\n",
       " 'sirohi',\n",
       " 'stevenage',\n",
       " 'dawei',\n",
       " 'brăila',\n",
       " 'diyarb najm',\n",
       " 'évora',\n",
       " 'ameca',\n",
       " 'kadayanallur',\n",
       " 'hālol',\n",
       " 'krasnovishersk',\n",
       " 'isahaya',\n",
       " 'norwalk',\n",
       " 'ijsselstein',\n",
       " 'bawāna',\n",
       " 'lilongwe',\n",
       " 'georgīevka',\n",
       " 'lennestadt',\n",
       " 'apopa',\n",
       " 'powai',\n",
       " 'obanazawa',\n",
       " 'zeytinburnu',\n",
       " 'uchkeken',\n",
       " 'mbarara',\n",
       " 'richmond hill',\n",
       " 'castiglione delle stiviere',\n",
       " 'patti',\n",
       " 'northwich',\n",
       " 'casal di principe',\n",
       " 'mlonggo',\n",
       " 'tubbergen',\n",
       " 'tessaoua',\n",
       " 'tourcoing',\n",
       " 'moncada',\n",
       " 'baildon',\n",
       " 'riverton',\n",
       " 'dorsten',\n",
       " 'boulogne-sur-mer',\n",
       " 'coralville',\n",
       " 'kakamega',\n",
       " 'surin',\n",
       " 'key west',\n",
       " 'bhachāu',\n",
       " 'johns creek',\n",
       " 'hamanoichi',\n",
       " 'āzādshahr',\n",
       " 'tlalnepantla',\n",
       " 'san luis',\n",
       " 'catolé do rocha',\n",
       " 'teotihuacán de arista',\n",
       " 'hernani',\n",
       " 'leça da palmeira',\n",
       " 'gelemso',\n",
       " 'yawata',\n",
       " 'sants-montjuïc',\n",
       " 'tiruvannāmalai',\n",
       " 'matehuala',\n",
       " 'tikrīt',\n",
       " 'karaj',\n",
       " 'malingao',\n",
       " 'acapulco de juárez',\n",
       " 'ashmūn',\n",
       " 'ḩawsh ‘īsá',\n",
       " 'malahide',\n",
       " 'tiruppur',\n",
       " \"vasyl'evsky ostrov\",\n",
       " 'develi',\n",
       " 'texcoco de mora',\n",
       " 'abnūb',\n",
       " 'monte alto',\n",
       " 'dalai',\n",
       " 'ahrensburg',\n",
       " 'dubna',\n",
       " 'hāsilpur',\n",
       " 'baiersbronn',\n",
       " 'port sudan',\n",
       " 'agadir',\n",
       " 'suluova',\n",
       " 'kissidougou',\n",
       " 'ebetsu',\n",
       " 'annaba',\n",
       " 'villamaría',\n",
       " 'usevia',\n",
       " 'san narciso',\n",
       " 'al ḩudaydah',\n",
       " 'hāthras',\n",
       " 'chalkída',\n",
       " 'joão câmara',\n",
       " 'sukuta',\n",
       " 'santo tomé',\n",
       " 'ol kalou',\n",
       " 'palm city',\n",
       " 'ādīgrat',\n",
       " 'mendaha',\n",
       " 'chignahuapan',\n",
       " 'kaset sombun',\n",
       " 'gibara',\n",
       " 'calw',\n",
       " 'kovel’',\n",
       " 'aku',\n",
       " 'le creusot',\n",
       " 'nevşehir',\n",
       " 'mabalacat city',\n",
       " 'central point',\n",
       " 'vaniyambadi',\n",
       " 'irinjālakuda',\n",
       " 'dhuliān',\n",
       " 'manaus',\n",
       " 'chaguanas',\n",
       " 'neustrelitz',\n",
       " 'pandacaqui',\n",
       " 'kulai',\n",
       " 'maştağa',\n",
       " 'huy',\n",
       " 'sonīpat',\n",
       " 'hoge vucht',\n",
       " 'tambov',\n",
       " 'tal’ne',\n",
       " 'pompéu',\n",
       " 'kangasala',\n",
       " 'erdenet',\n",
       " 'bata',\n",
       " 'evergreen park',\n",
       " 'retreat',\n",
       " 'clement town',\n",
       " 'benevento',\n",
       " 'cerro azul',\n",
       " 'kamyshin',\n",
       " 'erlangen',\n",
       " 'abreu e lima',\n",
       " 'khalīlābād',\n",
       " 'ivatsevichy',\n",
       " 'waterford',\n",
       " 'fabijoniškės',\n",
       " 'carlet',\n",
       " 'apolda',\n",
       " 'kibungo',\n",
       " 'nizhnesortymskiy',\n",
       " 'calapan',\n",
       " 'saarbrücken',\n",
       " 'shimokizukuri',\n",
       " 'macon',\n",
       " 'la maná',\n",
       " 'dumka',\n",
       " 'charlottenlund',\n",
       " 'topki',\n",
       " 'conception bay south',\n",
       " 'poggiomarino',\n",
       " 'ghauspur',\n",
       " 'kaset wisai',\n",
       " 'tinde',\n",
       " 'barretos',\n",
       " 'obihiro',\n",
       " 'saint-louis',\n",
       " 'bendigo',\n",
       " 'mejorada del campo',\n",
       " 'chūhar kāna',\n",
       " 'singapore',\n",
       " 'baturité',\n",
       " '‘izbat al burj',\n",
       " 'ash shuhadā’',\n",
       " 'astanajapura',\n",
       " 'sainthia',\n",
       " 'montero',\n",
       " 'pirapora',\n",
       " 'ferozepore',\n",
       " 'mumbwa',\n",
       " 'galatina',\n",
       " 'padre bernardo',\n",
       " 'deeside',\n",
       " 'guanhães',\n",
       " 'manbij',\n",
       " 'yancheng',\n",
       " 'budapest ix. kerület',\n",
       " 'duba',\n",
       " 'santa cruz de la palma',\n",
       " 'la oroya',\n",
       " 'santa rita do sapucaí',\n",
       " 'dunaújváros',\n",
       " 'mersing',\n",
       " 'otavalo',\n",
       " 'alum rock',\n",
       " 'zaida',\n",
       " 'tinghir',\n",
       " 'rāmpura',\n",
       " 'chandler',\n",
       " 'djidiouia',\n",
       " 'luau',\n",
       " 'morār',\n",
       " 'el triunfo',\n",
       " 'pandua',\n",
       " 'barra dos coqueiros',\n",
       " 'kāliyāganj',\n",
       " 'dzüünharaa',\n",
       " 'badalona',\n",
       " 'gujō',\n",
       " 'güigüe',\n",
       " 'spijkenisse',\n",
       " 'bressanone',\n",
       " 'coatzintla',\n",
       " 'kuppam',\n",
       " 'sosnowiec',\n",
       " 'erkrath',\n",
       " 'hayvoron',\n",
       " 'savanūr',\n",
       " 'jaffna',\n",
       " 'richland',\n",
       " 'yutz',\n",
       " 'chennevières-sur-marne',\n",
       " 'kabanovo',\n",
       " 'segrate',\n",
       " 'zile',\n",
       " 'labis',\n",
       " 'khāsh',\n",
       " 'kihangara',\n",
       " 'plettenberg',\n",
       " 'amod',\n",
       " 'huamantla',\n",
       " 'tiberias',\n",
       " 'tanque verde',\n",
       " 'menomonie',\n",
       " 'schorndorf',\n",
       " 'chatham',\n",
       " 'kardítsa',\n",
       " 'fastiv',\n",
       " 'minatitlan',\n",
       " 'trujillo alto',\n",
       " 'hidalgo del parral',\n",
       " 'kazincbarcika',\n",
       " 'saïda',\n",
       " 'lūnāvāda',\n",
       " 'yavatmāl',\n",
       " 'murcia',\n",
       " 'fougères',\n",
       " 'roxas',\n",
       " 'cové',\n",
       " 'alcañiz',\n",
       " 'misrikh',\n",
       " 'échirolles',\n",
       " 'phillaur',\n",
       " 'lokoja',\n",
       " 'asbury park',\n",
       " 'downey',\n",
       " 'markkleeberg',\n",
       " 'boiro',\n",
       " 'puliyangudi',\n",
       " 'wałcz',\n",
       " 'veracruz',\n",
       " 'zhaodong',\n",
       " 'winter park',\n",
       " 'syriam',\n",
       " 'nueva italia de ruiz',\n",
       " 'bulanık',\n",
       " 'rostock',\n",
       " 'mustafakemalpaşa',\n",
       " 'jhīnjhak',\n",
       " 'ijuí',\n",
       " 'lancy',\n",
       " 'dhanaula',\n",
       " 'inhambane',\n",
       " 'tsiombe',\n",
       " 'port blair',\n",
       " 'santa cruz del norte',\n",
       " 'dracut',\n",
       " 'bijie',\n",
       " 'vitória',\n",
       " 'naberezhnyye chelny',\n",
       " 'qiongshan',\n",
       " ...}"
      ]
     },
     "execution_count": 675,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'afghanistan',\n",
       " 'aland islands',\n",
       " 'albania',\n",
       " 'algeria',\n",
       " 'american samoa',\n",
       " 'andorra',\n",
       " 'angola',\n",
       " 'anguilla',\n",
       " 'antigua and barbuda',\n",
       " 'argentina',\n",
       " 'armenia',\n",
       " 'aruba',\n",
       " 'australia',\n",
       " 'austria',\n",
       " 'azerbaijan',\n",
       " 'bahamas',\n",
       " 'bahrain',\n",
       " 'bangladesh',\n",
       " 'barbados',\n",
       " 'belarus',\n",
       " 'belgium',\n",
       " 'belize',\n",
       " 'benin',\n",
       " 'bermuda',\n",
       " 'bhutan',\n",
       " 'bolivia',\n",
       " 'bonaire, saint eustatius and saba',\n",
       " 'bosnia and herzegovina',\n",
       " 'botswana',\n",
       " 'brazil',\n",
       " 'british virgin islands',\n",
       " 'brunei',\n",
       " 'bulgaria',\n",
       " 'burkina faso',\n",
       " 'burundi',\n",
       " 'cambodia',\n",
       " 'cameroon',\n",
       " 'canada',\n",
       " 'cape verde',\n",
       " 'cayman islands',\n",
       " 'central african republic',\n",
       " 'chad',\n",
       " 'chile',\n",
       " 'china',\n",
       " 'christmas island',\n",
       " 'cocos islands',\n",
       " 'colombia',\n",
       " 'comoros',\n",
       " 'cook islands',\n",
       " 'costa rica',\n",
       " 'croatia',\n",
       " 'cuba',\n",
       " 'curacao',\n",
       " 'cyprus',\n",
       " 'czech republic',\n",
       " 'democratic republic of the congo',\n",
       " 'denmark',\n",
       " 'djibouti',\n",
       " 'dominica',\n",
       " 'dominican republic',\n",
       " 'east timor',\n",
       " 'ecuador',\n",
       " 'egypt',\n",
       " 'el salvador',\n",
       " 'equatorial guinea',\n",
       " 'eritrea',\n",
       " 'estonia',\n",
       " 'ethiopia',\n",
       " 'falkland islands',\n",
       " 'faroe islands',\n",
       " 'fiji',\n",
       " 'finland',\n",
       " 'france',\n",
       " 'french guiana',\n",
       " 'french polynesia',\n",
       " 'french southern territories',\n",
       " 'gabon',\n",
       " 'gambia',\n",
       " 'georgia',\n",
       " 'germany',\n",
       " 'ghana',\n",
       " 'gibraltar',\n",
       " 'greece',\n",
       " 'greenland',\n",
       " 'grenada',\n",
       " 'guadeloupe',\n",
       " 'guam',\n",
       " 'guatemala',\n",
       " 'guernsey',\n",
       " 'guinea',\n",
       " 'guinea-bissau',\n",
       " 'guyana',\n",
       " 'haiti',\n",
       " 'honduras',\n",
       " 'hong kong',\n",
       " 'hungary',\n",
       " 'iceland',\n",
       " 'india',\n",
       " 'indonesia',\n",
       " 'iran',\n",
       " 'iraq',\n",
       " 'ireland',\n",
       " 'isle of man',\n",
       " 'israel',\n",
       " 'italy',\n",
       " 'ivory coast',\n",
       " 'jamaica',\n",
       " 'japan',\n",
       " 'jersey',\n",
       " 'jordan',\n",
       " 'kazakhstan',\n",
       " 'kenya',\n",
       " 'kiribati',\n",
       " 'kosovo',\n",
       " 'kuwait',\n",
       " 'kyrgyzstan',\n",
       " 'laos',\n",
       " 'latvia',\n",
       " 'lebanon',\n",
       " 'lesotho',\n",
       " 'liberia',\n",
       " 'libya',\n",
       " 'liechtenstein',\n",
       " 'lithuania',\n",
       " 'luxembourg',\n",
       " 'macao',\n",
       " 'macedonia',\n",
       " 'madagascar',\n",
       " 'malawi',\n",
       " 'malaysia',\n",
       " 'maldives',\n",
       " 'mali',\n",
       " 'malta',\n",
       " 'marshall islands',\n",
       " 'martinique',\n",
       " 'mauritania',\n",
       " 'mauritius',\n",
       " 'mayotte',\n",
       " 'mexico',\n",
       " 'micronesia',\n",
       " 'moldova',\n",
       " 'monaco',\n",
       " 'mongolia',\n",
       " 'montenegro',\n",
       " 'montserrat',\n",
       " 'morocco',\n",
       " 'mozambique',\n",
       " 'myanmar',\n",
       " 'namibia',\n",
       " 'nauru',\n",
       " 'nepal',\n",
       " 'netherlands',\n",
       " 'new caledonia',\n",
       " 'new zealand',\n",
       " 'nicaragua',\n",
       " 'niger',\n",
       " 'nigeria',\n",
       " 'niue',\n",
       " 'norfolk island',\n",
       " 'north korea',\n",
       " 'northern mariana islands',\n",
       " 'norway',\n",
       " 'oman',\n",
       " 'pakistan',\n",
       " 'palau',\n",
       " 'palestinian territory',\n",
       " 'panama',\n",
       " 'papua new guinea',\n",
       " 'paraguay',\n",
       " 'peru',\n",
       " 'philippines',\n",
       " 'pitcairn',\n",
       " 'poland',\n",
       " 'portugal',\n",
       " 'puerto rico',\n",
       " 'qatar',\n",
       " 'republic of the congo',\n",
       " 'reunion',\n",
       " 'romania',\n",
       " 'russia',\n",
       " 'rwanda',\n",
       " 'saint barthelemy',\n",
       " 'saint helena',\n",
       " 'saint kitts and nevis',\n",
       " 'saint lucia',\n",
       " 'saint martin',\n",
       " 'saint pierre and miquelon',\n",
       " 'saint vincent and the grenadines',\n",
       " 'samoa',\n",
       " 'san marino',\n",
       " 'sao tome and principe',\n",
       " 'saudi arabia',\n",
       " 'senegal',\n",
       " 'serbia',\n",
       " 'seychelles',\n",
       " 'sierra leone',\n",
       " 'singapore',\n",
       " 'sint maarten',\n",
       " 'slovakia',\n",
       " 'slovenia',\n",
       " 'solomon islands',\n",
       " 'somalia',\n",
       " 'south africa',\n",
       " 'south georgia and the south sandwich islands',\n",
       " 'south korea',\n",
       " 'south sudan',\n",
       " 'spain',\n",
       " 'sri lanka',\n",
       " 'sudan',\n",
       " 'suriname',\n",
       " 'svalbard and jan mayen',\n",
       " 'swaziland',\n",
       " 'sweden',\n",
       " 'switzerland',\n",
       " 'syria',\n",
       " 'taiwan',\n",
       " 'tajikistan',\n",
       " 'tanzania',\n",
       " 'thailand',\n",
       " 'togo',\n",
       " 'tonga',\n",
       " 'trinidad and tobago',\n",
       " 'tunisia',\n",
       " 'turkey',\n",
       " 'turkmenistan',\n",
       " 'turks and caicos islands',\n",
       " 'tuvalu',\n",
       " 'u.s. virgin islands',\n",
       " 'uganda',\n",
       " 'ukraine',\n",
       " 'united arab emirates',\n",
       " 'united kingdom',\n",
       " 'united states',\n",
       " 'uruguay',\n",
       " 'uzbekistan',\n",
       " 'vanuatu',\n",
       " 'vatican',\n",
       " 'venezuela',\n",
       " 'vietnam',\n",
       " 'wallis and futuna',\n",
       " 'western sahara',\n",
       " 'yemen',\n",
       " 'zambia',\n",
       " 'zimbabwe'}"
      ]
     },
     "execution_count": 677,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2554"
      ]
     },
     "execution_count": 660,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aoa_intersect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unite',\n",
       " 'department',\n",
       " 'state',\n",
       " 'region',\n",
       " 'commune',\n",
       " 'include',\n",
       " 'call',\n",
       " 'play',\n",
       " 'national',\n",
       " 'district',\n",
       " 'release',\n",
       " 'years',\n",
       " 'name',\n",
       " 'locate',\n",
       " 'area',\n",
       " 'former',\n",
       " 'series',\n",
       " 'later',\n",
       " 'album',\n",
       " 'league']"
      ]
     },
     "execution_count": 661,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aoa_intersect[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2226"
      ]
     },
     "execution_count": 662,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([word for word in aoa_intersect if word in concrete_intersect])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in aoa_intersect:\n",
    "    word_vectors[word] = word_vectors[word] * AoA[AoA['Word']==word]['AoA_Kup_lem'].values/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02531605, -0.06983836,  0.07569417, -0.0199796 , -0.08170979,\n",
       "        0.0126198 , -0.03631189,  0.04478207,  0.02543541, -0.00426309,\n",
       "        0.00835675, -0.01547975,  0.083173  , -0.02952217, -0.06510621,\n",
       "       -0.08822621,  0.02941588, -0.05510816, -0.05316929, -0.02765932,\n",
       "        0.00669615,  0.00074564,  0.0362225 ,  0.04426894,  0.0832494 ,\n",
       "       -0.03406315,  0.02073772, -0.03678282, -0.08137402,  0.0359503 ,\n",
       "       -0.03306248, -0.01483777,  0.01406121,  0.00051605,  0.10590797,\n",
       "       -0.0237588 ,  0.00701955,  0.01679777,  0.04338488,  0.04394314,\n",
       "       -0.05966038, -0.0187582 , -0.0059121 , -0.08443372, -0.01350078,\n",
       "       -0.05404426, -0.02109407, -0.07373458, -0.00710962, -0.02100398,\n",
       "       -0.02001131, -0.02040975,  0.03315873, -0.05322361,  0.0008024 ,\n",
       "       -0.00244391,  0.0057214 , -0.01174105, -0.04350759, -0.0211037 ,\n",
       "        0.03061705, -0.00100189, -0.01355478,  0.01643214, -0.09787938,\n",
       "       -0.05907072, -0.02259452,  0.01638364, -0.00573174,  0.04248516,\n",
       "        0.03155013,  0.03948134, -0.0380661 ,  0.03277516,  0.05565981,\n",
       "       -0.03206713,  0.02377646,  0.06840525, -0.01239053,  0.00742514,\n",
       "       -0.03566892, -0.11843814, -0.03994955,  0.01723496,  0.00546595,\n",
       "        0.04271801,  0.03127715, -0.03481788, -0.01449306,  0.03294919,\n",
       "       -0.00399501, -0.02617926,  0.08186848, -0.00418014, -0.04449459,\n",
       "        0.01207444,  0.07457646,  0.06336881, -0.04000379, -0.05400705],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dense_features(tokenized_text,word_vectors):\n",
    "    dense_list=[]\n",
    "    words=[]\n",
    "    for _ in tokenized_text: \n",
    "        words =[word for word in _ if word in word_vectors.key_to_index]\n",
    "        \n",
    "        if len(words) >0:\n",
    "            dense_list.append(np.mean(word_vectors[words],axis=0))\n",
    "            \n",
    "        else: \n",
    "            dense_list.append(np.zeros(word_vectors.vector_size))\n",
    "            \n",
    "    return np.array(dense_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_wv = generate_dense_features(tokenized_text_train,word_vectors)\n",
    "X_test_wv = generate_dense_features(tokenized_text_test,word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(333414, 100)"
      ]
     },
     "execution_count": 667,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_wv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_wv = LogisticRegression(random_state=RANDOM_SEED,max_iter=1000).fit(X_train_wv,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5863305900136766"
      ]
     },
     "execution_count": 669,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,lr_wv.predict(X_test_wv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_fun(doc):\n",
    "    return doc\n",
    "vectorizer = TfidfVectorizer(analyzer='word',tokenizer=dummy_fun, preprocessor=dummy_fun, token_pattern=r'(?u)\\b\\w\\w+__\\([\\w\\s]*\\)')\n",
    "X_train_transform = vectorizer.fit_transform(tokenized_text_train)\n",
    "X_test_transform  = vectorizer.transform(tokenized_text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103167"
      ]
     },
     "execution_count": 671,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a_nx',\n",
       " 'aabout',\n",
       " 'aabye',\n",
       " 'aach',\n",
       " 'aafc',\n",
       " 'aage',\n",
       " 'aaiil',\n",
       " 'aaliyahs',\n",
       " 'aall',\n",
       " 'aalto',\n",
       " 'aames',\n",
       " 'aamir',\n",
       " 'aang',\n",
       " 'aangã',\n",
       " 'aapep',\n",
       " 'aarberg',\n",
       " 'aarburg',\n",
       " 'aarc',\n",
       " 'aarde',\n",
       " 'aardman',\n",
       " 'aardsma',\n",
       " 'aardvark',\n",
       " 'aardvarks',\n",
       " 'aare',\n",
       " 'aargauer',\n",
       " 'aarhus',\n",
       " 'aaroni',\n",
       " 'aarons',\n",
       " 'aarre',\n",
       " 'aarseth',\n",
       " 'aartselaar',\n",
       " 'aarwangen',\n",
       " 'aasen',\n",
       " 'aashurah',\n",
       " 'aast',\n",
       " 'aastana',\n",
       " 'aave',\n",
       " 'ababa',\n",
       " 'ababba',\n",
       " 'ababda',\n",
       " 'abac',\n",
       " 'abacada',\n",
       " 'abaci',\n",
       " 'aback',\n",
       " 'abacus',\n",
       " 'abacuses',\n",
       " 'abad',\n",
       " 'abagnale',\n",
       " 'abahutu',\n",
       " 'abaj',\n",
       " 'abajo',\n",
       " 'abakanskoye',\n",
       " 'abal',\n",
       " 'abalo',\n",
       " 'abalone',\n",
       " 'abando',\n",
       " 'abandon',\n",
       " 'abandonded',\n",
       " 'abandonment',\n",
       " 'abarat',\n",
       " 'abassi',\n",
       " 'abate',\n",
       " 'abattoirs',\n",
       " 'abatutsi',\n",
       " 'abauzit',\n",
       " 'abavo',\n",
       " 'abazhou',\n",
       " 'abaãºj',\n",
       " 'abba',\n",
       " 'abbado',\n",
       " 'abbadon',\n",
       " 'abbados',\n",
       " 'abbandando',\n",
       " 'abbas',\n",
       " 'abbasi',\n",
       " 'abbasid',\n",
       " 'abbasids',\n",
       " 'abbasies',\n",
       " 'abbass',\n",
       " 'abbassid',\n",
       " 'abbay',\n",
       " 'abbaye',\n",
       " 'abbe',\n",
       " 'abbeydale',\n",
       " 'abbeys',\n",
       " 'abbiamo',\n",
       " 'abbiati',\n",
       " 'abbiss',\n",
       " 'abbondancieri',\n",
       " 'abbondanzieri',\n",
       " 'abbondio',\n",
       " 'abbot',\n",
       " 'abbotsinch',\n",
       " 'abbottabad',\n",
       " 'abbotts',\n",
       " 'abbr',\n",
       " 'abbrev',\n",
       " 'abbreviate',\n",
       " 'abbreviation',\n",
       " 'abbreviations',\n",
       " 'abbruzzese',\n",
       " 'abbs',\n",
       " 'abbud',\n",
       " 'abbã',\n",
       " 'abbãƒ',\n",
       " 'abcd',\n",
       " 'abcs',\n",
       " 'abdacom',\n",
       " 'abdal',\n",
       " 'abdallah',\n",
       " 'abdel',\n",
       " 'abdelazar',\n",
       " 'abdelhafid',\n",
       " 'abdeljalil',\n",
       " 'abdelwahab',\n",
       " 'abdera',\n",
       " 'abderathe',\n",
       " 'abdest',\n",
       " 'abdi',\n",
       " 'abdicate',\n",
       " 'abdicatio',\n",
       " 'abdication',\n",
       " 'abdirashid',\n",
       " 'abdolah',\n",
       " 'abdollah',\n",
       " 'abdomen',\n",
       " 'abdomens',\n",
       " 'abdominal',\n",
       " 'abdominis',\n",
       " 'abdou',\n",
       " 'abdoulaye',\n",
       " 'abdu',\n",
       " 'abduct',\n",
       " 'abduction',\n",
       " 'abdulahi',\n",
       " 'abdulaziz',\n",
       " 'abdullaziz',\n",
       " 'abdun',\n",
       " 'abdurrahman',\n",
       " 'abdus',\n",
       " 'abeba',\n",
       " 'abela',\n",
       " 'abelard',\n",
       " 'abele',\n",
       " 'abelian',\n",
       " 'abelisaurid',\n",
       " 'abella',\n",
       " 'abells',\n",
       " 'abelmoschus',\n",
       " 'abelshauser',\n",
       " 'abelson',\n",
       " 'abendroth',\n",
       " 'abenobashi',\n",
       " 'abenon',\n",
       " 'abenteuer',\n",
       " 'aber',\n",
       " 'abercrombie',\n",
       " 'abercromby',\n",
       " 'aberdeenshire',\n",
       " 'aberdeenshires',\n",
       " 'aberdour',\n",
       " 'aberdovey',\n",
       " 'aberdyfi',\n",
       " 'aberfan',\n",
       " 'aberford',\n",
       " 'aberfoyle',\n",
       " 'abergavenny',\n",
       " 'abergement',\n",
       " 'abergynolwyn',\n",
       " 'aberlin',\n",
       " 'aberrant',\n",
       " 'aberration',\n",
       " 'aberrations',\n",
       " 'aberson',\n",
       " 'abert',\n",
       " 'abertay',\n",
       " 'aberystwyththe',\n",
       " 'abet',\n",
       " 'abeyie',\n",
       " 'abgar',\n",
       " 'abgebrã',\n",
       " 'abgrenzung',\n",
       " 'abhainn',\n",
       " 'abhanga',\n",
       " 'abhangas',\n",
       " 'abhinav',\n",
       " 'abhiras',\n",
       " 'abhor',\n",
       " 'abhorrã',\n",
       " 'abid',\n",
       " 'abidal',\n",
       " 'abide',\n",
       " 'abidine',\n",
       " 'abidos',\n",
       " 'abierta',\n",
       " 'abilities',\n",
       " 'ability',\n",
       " 'abimael',\n",
       " 'abin',\n",
       " 'abio',\n",
       " 'abiogenesis',\n",
       " 'abiotic',\n",
       " 'abiotically',\n",
       " 'abire',\n",
       " 'abisalovich',\n",
       " 'abispa',\n",
       " 'abitur',\n",
       " 'abiword',\n",
       " 'abjadi',\n",
       " 'abjads',\n",
       " 'abjuration',\n",
       " 'abkai',\n",
       " 'abkco',\n",
       " 'abkhaz',\n",
       " 'ablanedo',\n",
       " 'ablation',\n",
       " 'ablative',\n",
       " 'ablaze',\n",
       " 'abled',\n",
       " 'ablest',\n",
       " 'ablon',\n",
       " 'abloy',\n",
       " 'ablutions',\n",
       " 'abma',\n",
       " 'abney',\n",
       " 'abnicum',\n",
       " 'abnormal',\n",
       " 'abnormalities',\n",
       " 'abnormality',\n",
       " 'abnormally',\n",
       " 'abobrãƒ',\n",
       " 'abol',\n",
       " 'abolish',\n",
       " 'abolishment',\n",
       " 'abolition',\n",
       " 'abolitionism',\n",
       " 'abolitionist',\n",
       " 'abolitionists',\n",
       " 'abominations',\n",
       " 'abong',\n",
       " 'aboolian',\n",
       " 'aboot',\n",
       " 'aboriginal',\n",
       " 'aboriginals',\n",
       " 'aborigine',\n",
       " 'aborigines',\n",
       " 'abort',\n",
       " 'abortifacient',\n",
       " 'abortion',\n",
       " 'abortions',\n",
       " 'abortive',\n",
       " 'abou',\n",
       " 'abound',\n",
       " 'aboutus',\n",
       " 'aboveground',\n",
       " 'abra',\n",
       " 'abracadabra',\n",
       " 'abrahamic',\n",
       " 'abrahams',\n",
       " 'abramczik',\n",
       " 'abramovich',\n",
       " 'abrams',\n",
       " 'abrantes',\n",
       " 'abrasion',\n",
       " 'abrasions',\n",
       " 'abraxas',\n",
       " 'abraãƒ',\n",
       " 'abreaction',\n",
       " 'abreu',\n",
       " 'abrictosaurus',\n",
       " 'abridge',\n",
       " 'abridgment',\n",
       " 'abroad',\n",
       " 'abrogant',\n",
       " 'abrogate',\n",
       " 'abronia',\n",
       " 'abrowse',\n",
       " 'abrsm',\n",
       " 'abrupt',\n",
       " 'abruptly',\n",
       " 'abruzzi',\n",
       " 'abrã',\n",
       " 'abscess',\n",
       " 'abscesses',\n",
       " 'abscissa',\n",
       " 'abscond',\n",
       " 'absecon',\n",
       " 'absence',\n",
       " 'absences',\n",
       " 'absent',\n",
       " 'absentee',\n",
       " 'absentia',\n",
       " 'absentpelagic',\n",
       " 'absinth',\n",
       " 'absinthe',\n",
       " 'absinthes',\n",
       " 'absinthium',\n",
       " 'absolut',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absolutepunk',\n",
       " 'absolution',\n",
       " 'absolutist',\n",
       " 'absolutive',\n",
       " 'absolve',\n",
       " 'absorb',\n",
       " 'absorbance',\n",
       " 'absorbances',\n",
       " 'absorbent',\n",
       " 'absorber',\n",
       " 'absorbers',\n",
       " 'absorption',\n",
       " 'absorptive',\n",
       " 'abstain',\n",
       " 'abstention',\n",
       " 'abstentionism',\n",
       " 'abstinence',\n",
       " 'abstract',\n",
       " 'abstraction',\n",
       " 'abstractionists',\n",
       " 'abstractions',\n",
       " 'absurd',\n",
       " 'absurde',\n",
       " 'absurdism',\n",
       " 'absurdist',\n",
       " 'absurdity',\n",
       " 'abtwil',\n",
       " 'abub',\n",
       " 'abubakari',\n",
       " 'abugida',\n",
       " 'abugidas',\n",
       " 'abukuma',\n",
       " 'abul',\n",
       " 'abuladze',\n",
       " 'abulkhair',\n",
       " 'abulm',\n",
       " 'abuls',\n",
       " 'abulã',\n",
       " 'abundance',\n",
       " 'abundant',\n",
       " 'abundantly',\n",
       " 'aburish',\n",
       " 'abuse',\n",
       " 'abusive',\n",
       " 'abusively',\n",
       " 'abut',\n",
       " 'abutere',\n",
       " 'abutments',\n",
       " 'aby',\n",
       " 'abydos',\n",
       " 'abyssal',\n",
       " 'abzekh',\n",
       " 'abãƒ',\n",
       " 'acacia',\n",
       " 'acacias',\n",
       " 'acad',\n",
       " 'acadamias',\n",
       " 'academe',\n",
       " 'academia',\n",
       " 'academic',\n",
       " 'academical',\n",
       " 'academically',\n",
       " 'academician',\n",
       " 'academics',\n",
       " 'academie',\n",
       " 'academies',\n",
       " 'academkniga',\n",
       " 'academy',\n",
       " 'acadia',\n",
       " 'acadians',\n",
       " 'acadã',\n",
       " 'acadãƒ',\n",
       " 'acamprosate',\n",
       " 'acanthaceae',\n",
       " 'acanthaclisinae',\n",
       " 'acanthocephala',\n",
       " 'acanthodii',\n",
       " 'acanthomintha',\n",
       " 'acanthomyops',\n",
       " 'acanthophis',\n",
       " 'acanthophylla',\n",
       " 'acanthostega',\n",
       " 'acapulco',\n",
       " 'acari',\n",
       " 'acarology',\n",
       " 'acaso',\n",
       " 'acasta',\n",
       " 'acca',\n",
       " 'accademia',\n",
       " 'accadian',\n",
       " 'accede',\n",
       " 'accelerate',\n",
       " 'accelerateur',\n",
       " 'acceleration',\n",
       " 'accelerations',\n",
       " 'accelerator',\n",
       " 'accelerators',\n",
       " 'acceleratorsã',\n",
       " 'accelerometer',\n",
       " 'accelerometers',\n",
       " 'accends',\n",
       " 'accent',\n",
       " 'accentschurmann',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'acceptably',\n",
       " 'acceptance',\n",
       " 'acceptor',\n",
       " 'access',\n",
       " 'accessibility',\n",
       " 'accessible',\n",
       " 'accession',\n",
       " 'accessories',\n",
       " 'accessory',\n",
       " 'acchieved',\n",
       " 'acchouhouri',\n",
       " 'acciaiuoli',\n",
       " 'acciarito',\n",
       " 'accident',\n",
       " 'accidental',\n",
       " 'accidentally',\n",
       " 'accidentals',\n",
       " 'accidents',\n",
       " 'accidie',\n",
       " 'accies',\n",
       " 'acciona',\n",
       " 'accipiter',\n",
       " 'accipitridae',\n",
       " 'acciã³n',\n",
       " 'acciãƒ',\n",
       " 'acclaim',\n",
       " 'acclamation',\n",
       " 'acclamations',\n",
       " 'acclimatation',\n",
       " 'acclimate',\n",
       " 'acclimatisation',\n",
       " 'accolade',\n",
       " 'accolades',\n",
       " 'accomack',\n",
       " 'accommodate',\n",
       " 'accommodation',\n",
       " 'accommodations',\n",
       " 'accommodative',\n",
       " 'accompaniment',\n",
       " 'accompanist',\n",
       " 'accompany',\n",
       " 'accomping',\n",
       " 'accomplice',\n",
       " 'accomplices',\n",
       " 'accomplish',\n",
       " 'accomplishers',\n",
       " 'accomplishment',\n",
       " 'accomplishments',\n",
       " 'accomptant',\n",
       " 'accons',\n",
       " 'accord',\n",
       " 'accordance',\n",
       " 'accordingly',\n",
       " 'accordion',\n",
       " 'accordionist',\n",
       " 'accordo',\n",
       " 'accost',\n",
       " 'accouchement',\n",
       " 'account',\n",
       " 'accountability',\n",
       " 'accountable',\n",
       " 'accountancy',\n",
       " 'accountant',\n",
       " 'accountants',\n",
       " 'accountn',\n",
       " 'accountsare',\n",
       " 'accous',\n",
       " 'accouterments',\n",
       " 'accoutrement',\n",
       " 'accoyer',\n",
       " 'accredit',\n",
       " 'accreditation',\n",
       " 'accreditor',\n",
       " 'accreta',\n",
       " 'accrete',\n",
       " 'accretion',\n",
       " 'accross',\n",
       " 'accrue',\n",
       " 'acculturate',\n",
       " 'accumbens',\n",
       " 'accumulate',\n",
       " 'accumulation',\n",
       " 'accumulations',\n",
       " 'accuracy',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'accusamus',\n",
       " 'accusantium',\n",
       " 'accusation',\n",
       " 'accusations',\n",
       " 'accuse',\n",
       " 'accustom',\n",
       " 'ace',\n",
       " 'acedia',\n",
       " 'aceldama',\n",
       " 'aceman',\n",
       " 'acephala',\n",
       " 'acequia',\n",
       " 'acer',\n",
       " 'aceraceae',\n",
       " 'aceramic',\n",
       " 'acerbic',\n",
       " 'acerbo',\n",
       " 'acetaldehyde',\n",
       " 'acetaminophen',\n",
       " 'acetate',\n",
       " 'acetic',\n",
       " 'acetobacter',\n",
       " 'acetone',\n",
       " 'acetyl',\n",
       " 'acetylate',\n",
       " 'acetylation',\n",
       " 'acetylcholine',\n",
       " 'acetylene',\n",
       " 'acetylide',\n",
       " 'acetylsalicylic',\n",
       " 'acevedo',\n",
       " 'achab',\n",
       " 'achaea',\n",
       " 'achaemenid',\n",
       " 'achaius',\n",
       " 'achard',\n",
       " 'acharya',\n",
       " 'achawãƒ',\n",
       " 'ache',\n",
       " 'achebe',\n",
       " 'achelate',\n",
       " 'acheloos',\n",
       " 'achelous',\n",
       " 'achenbach',\n",
       " 'achenes',\n",
       " 'acheron',\n",
       " 'acherontia',\n",
       " 'achery',\n",
       " 'acheulean',\n",
       " 'achhim',\n",
       " 'achi',\n",
       " 'achicourt',\n",
       " 'achiet',\n",
       " 'achievable',\n",
       " 'achieve',\n",
       " 'achievement',\n",
       " 'achievements',\n",
       " 'achila',\n",
       " 'achiles',\n",
       " 'achille',\n",
       " 'achillea',\n",
       " 'achilles',\n",
       " 'achillobator',\n",
       " 'achiote',\n",
       " 'achiral',\n",
       " 'achlorhydria',\n",
       " 'achmad',\n",
       " 'achmed',\n",
       " 'achna',\n",
       " 'achoholic',\n",
       " 'acholi',\n",
       " 'achondrite',\n",
       " 'achondroplasia',\n",
       " 'achondroplastic',\n",
       " 'achonry',\n",
       " 'achromasia',\n",
       " 'achromatopsia',\n",
       " 'achromatosis',\n",
       " 'achromia',\n",
       " 'achterhoek',\n",
       " 'achtice',\n",
       " 'achtung',\n",
       " 'achy',\n",
       " 'achzarit',\n",
       " 'achã',\n",
       " 'achãƒ',\n",
       " 'acib',\n",
       " 'acid',\n",
       " 'acidic',\n",
       " 'acidification',\n",
       " 'acidify',\n",
       " 'acidity',\n",
       " 'acidosis',\n",
       " 'acids',\n",
       " 'acinar',\n",
       " 'acis',\n",
       " 'ackerman',\n",
       " 'ackery',\n",
       " 'ackley',\n",
       " 'acklins',\n",
       " 'acknowledge',\n",
       " 'acknowledgement',\n",
       " 'acknowledgment',\n",
       " 'acknowledgments',\n",
       " 'ackworth',\n",
       " 'acland',\n",
       " 'aclare',\n",
       " 'acme',\n",
       " 'acmi',\n",
       " 'acne',\n",
       " 'acnielsen',\n",
       " 'acolyte',\n",
       " 'acolytes',\n",
       " 'acomyinae',\n",
       " 'acomys',\n",
       " 'aconcagua',\n",
       " 'aconite',\n",
       " 'aconitum',\n",
       " 'acorah',\n",
       " 'acorn',\n",
       " 'acorns',\n",
       " 'acosta',\n",
       " 'acou',\n",
       " 'acoustic',\n",
       " 'acoustical',\n",
       " 'acoustically',\n",
       " 'acoustician',\n",
       " 'acousticly',\n",
       " 'acoustics',\n",
       " 'acpb',\n",
       " 'acquaint',\n",
       " 'acquaintance',\n",
       " 'acquaintances',\n",
       " 'acquarossa',\n",
       " 'acqueville',\n",
       " 'acquiesce',\n",
       " 'acquieses',\n",
       " 'acquin',\n",
       " 'acquire',\n",
       " 'acquisition',\n",
       " 'acquisitions',\n",
       " 'acquit',\n",
       " 'acquittal',\n",
       " 'acrea',\n",
       " 'acrelãƒ',\n",
       " 'acres',\n",
       " 'acrisius',\n",
       " 'acritarch',\n",
       " 'acritarchs',\n",
       " 'acrobat',\n",
       " 'acrobates',\n",
       " 'acrobatic',\n",
       " 'acrobatics',\n",
       " 'acrobaticã',\n",
       " 'acrobats',\n",
       " 'acron',\n",
       " 'acronis',\n",
       " 'acronym',\n",
       " 'acronymic',\n",
       " 'acronymous',\n",
       " 'acronyms',\n",
       " 'acropolis',\n",
       " 'across',\n",
       " 'acrossmanhattan',\n",
       " 'acrylic',\n",
       " 'acrymia',\n",
       " 'acst',\n",
       " 'act',\n",
       " 'acta',\n",
       " 'acte',\n",
       " 'actias',\n",
       " 'actin',\n",
       " 'actinide',\n",
       " 'actinides',\n",
       " 'actinidia',\n",
       " 'actinium',\n",
       " 'actinobacteria',\n",
       " 'actinoid',\n",
       " 'actinolite',\n",
       " 'actinomorphic',\n",
       " 'actinomycetes',\n",
       " 'actinopterygii',\n",
       " 'actinopterygius',\n",
       " 'actinosporea',\n",
       " 'actinotrocha',\n",
       " 'action',\n",
       " 'actionscript',\n",
       " 'actium',\n",
       " 'actius',\n",
       " 'activate',\n",
       " 'activation',\n",
       " 'activator',\n",
       " 'active',\n",
       " 'activebass',\n",
       " 'actively',\n",
       " 'actives',\n",
       " 'activestats',\n",
       " 'activeworlds',\n",
       " 'activex',\n",
       " 'activision',\n",
       " 'activism',\n",
       " 'activist',\n",
       " 'activists',\n",
       " 'activities',\n",
       " 'activitist',\n",
       " 'activitiy',\n",
       " 'activity',\n",
       " 'activitã',\n",
       " 'actor',\n",
       " 'actors',\n",
       " 'actress',\n",
       " 'actresses',\n",
       " 'actual',\n",
       " 'actuality',\n",
       " 'actualitã',\n",
       " 'actually',\n",
       " 'actuaries',\n",
       " 'actuate',\n",
       " 'actuations',\n",
       " 'actus',\n",
       " 'acuatic',\n",
       " 'acuca',\n",
       " 'acuity',\n",
       " 'aculeata',\n",
       " 'aculeatus',\n",
       " 'acupressure',\n",
       " 'acupuncture',\n",
       " 'acura',\n",
       " 'acute',\n",
       " 'acutely',\n",
       " 'acuteness',\n",
       " 'acutus',\n",
       " 'acyclic',\n",
       " 'acyl',\n",
       " 'adachi',\n",
       " 'adad',\n",
       " 'adage',\n",
       " 'adages',\n",
       " 'adagh',\n",
       " 'adagio',\n",
       " 'adair',\n",
       " 'adairville',\n",
       " 'adak',\n",
       " 'adal',\n",
       " 'adalbert',\n",
       " 'adama',\n",
       " 'adamantine',\n",
       " 'adamantium',\n",
       " 'adamey',\n",
       " 'adaminaby',\n",
       " 'adamite',\n",
       " 'adamkus',\n",
       " 'adamlarina',\n",
       " 'adamle',\n",
       " 'adamski',\n",
       " 'adamson',\n",
       " 'adamsville',\n",
       " 'adapiformes',\n",
       " 'adapt',\n",
       " 'adaptability',\n",
       " 'adaptable',\n",
       " 'adaptation',\n",
       " 'adaptations',\n",
       " 'adapter',\n",
       " 'adapters',\n",
       " 'adaption',\n",
       " 'adaptions',\n",
       " 'adaptive',\n",
       " 'adaptively',\n",
       " 'adaptor',\n",
       " 'adas',\n",
       " 'adasaurus',\n",
       " 'adashim',\n",
       " 'adastra',\n",
       " 'adav',\n",
       " 'add',\n",
       " 'addai',\n",
       " 'addakhil',\n",
       " 'addams',\n",
       " 'addax',\n",
       " 'addenbrooke',\n",
       " 'addendum',\n",
       " 'adder',\n",
       " 'adderley',\n",
       " 'adders',\n",
       " 'addicks',\n",
       " 'addict',\n",
       " 'addiction',\n",
       " 'addictions',\n",
       " 'addictive',\n",
       " 'addington',\n",
       " 'addis',\n",
       " 'addiscombe',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'additionally',\n",
       " 'additionals',\n",
       " 'additions',\n",
       " 'additive',\n",
       " 'additively',\n",
       " 'additives',\n",
       " 'addon',\n",
       " 'address',\n",
       " 'addressability',\n",
       " 'addressable',\n",
       " 'adegboyega',\n",
       " 'adegem',\n",
       " 'adelante',\n",
       " 'adelboden',\n",
       " 'adelekan',\n",
       " 'adelheid',\n",
       " 'adelir',\n",
       " 'adelomyrmex',\n",
       " 'adelong',\n",
       " 'adelphotheos',\n",
       " 'adelsheim',\n",
       " 'ademar',\n",
       " 'ademir',\n",
       " 'ademola',\n",
       " 'adenauer',\n",
       " 'adenine',\n",
       " 'adenoidectomy',\n",
       " 'adenoids',\n",
       " 'adenoma',\n",
       " 'adenosine',\n",
       " 'adephaga',\n",
       " 'adept',\n",
       " 'adequality',\n",
       " 'adequate',\n",
       " 'adequately',\n",
       " 'aderbal',\n",
       " 'ades',\n",
       " 'adesa',\n",
       " 'adetokunbo',\n",
       " 'adeus',\n",
       " 'adha',\n",
       " 'adhaerens',\n",
       " 'adhan',\n",
       " 'adhana',\n",
       " 'adhd',\n",
       " 'adhemar',\n",
       " 'adhere',\n",
       " 'adherence',\n",
       " 'adherent',\n",
       " 'adherents',\n",
       " 'adhesion',\n",
       " 'adhesions',\n",
       " 'adhesive',\n",
       " 'adhesives',\n",
       " 'adhlaka',\n",
       " 'adhur',\n",
       " 'adiabatic',\n",
       " 'adiabene',\n",
       " 'adibuddha',\n",
       " 'adic',\n",
       " 'adichie',\n",
       " 'adidas',\n",
       " 'adiel',\n",
       " 'adieu',\n",
       " 'adige',\n",
       " 'adikalar',\n",
       " 'adil',\n",
       " 'adinath',\n",
       " 'adine',\n",
       " 'adinfer',\n",
       " 'adingaheim',\n",
       " 'adiperukku',\n",
       " 'adipisci',\n",
       " 'adipocytes',\n",
       " 'adipose',\n",
       " 'adiposity',\n",
       " 'adipperukku',\n",
       " 'adiri',\n",
       " 'adirondack',\n",
       " 'adit',\n",
       " 'adits',\n",
       " 'adiyiah',\n",
       " 'adjacent',\n",
       " 'adjacã',\n",
       " 'adjacãƒ',\n",
       " 'adjascent',\n",
       " 'adjectival',\n",
       " 'adjectivally',\n",
       " 'adjective',\n",
       " 'adjectives',\n",
       " 'adjei',\n",
       " 'adjemian',\n",
       " 'adjoin',\n",
       " 'adjudge',\n",
       " 'adjudicate',\n",
       " 'adjudication',\n",
       " 'adjudicator',\n",
       " 'adjudicators',\n",
       " 'adjunct',\n",
       " 'adjunctive',\n",
       " 'adjuncts',\n",
       " 'adjuration',\n",
       " 'adjust',\n",
       " 'adjustable',\n",
       " 'adjustment',\n",
       " 'adjustments',\n",
       " 'adjutant',\n",
       " 'adjutants',\n",
       " 'adjuvants',\n",
       " 'adkins',\n",
       " 'adlaka',\n",
       " 'adleman',\n",
       " 'adlon',\n",
       " 'admin',\n",
       " 'adminer',\n",
       " 'administer',\n",
       " 'administeriet',\n",
       " 'administraciã³n',\n",
       " 'administraciãƒ',\n",
       " 'administrate',\n",
       " 'administration',\n",
       " 'administrations',\n",
       " 'administrative',\n",
       " 'administrator',\n",
       " 'administrators',\n",
       " 'admins',\n",
       " 'adminship',\n",
       " 'admira',\n",
       " 'admirable',\n",
       " 'admirably',\n",
       " 'admirals',\n",
       " 'admiralspalast',\n",
       " 'admiralty',\n",
       " 'admiration',\n",
       " 'admire',\n",
       " 'admirer',\n",
       " 'admirers',\n",
       " 'admiringly',\n",
       " 'admission',\n",
       " 'admissions',\n",
       " 'admit',\n",
       " 'admittance',\n",
       " 'admittedly',\n",
       " 'admixture',\n",
       " 'admixtures',\n",
       " 'admonition',\n",
       " 'admont',\n",
       " 'adna',\n",
       " 'adnan',\n",
       " 'adnos',\n",
       " 'adobe',\n",
       " 'adobes',\n",
       " 'adolescence',\n",
       " 'adolescent',\n",
       " 'adolescente',\n",
       " 'adolescents',\n",
       " 'adolphe',\n",
       " 'adom',\n",
       " 'adomnãƒ',\n",
       " 'adonai',\n",
       " 'adopt',\n",
       " 'adoptable',\n",
       " 'adoption',\n",
       " 'adoptionism',\n",
       " 'adoptions',\n",
       " 'adoptive',\n",
       " 'adorable',\n",
       " 'adoration',\n",
       " 'adore',\n",
       " 'adorn',\n",
       " 'adornments',\n",
       " 'adorno',\n",
       " 'adoroam',\n",
       " 'adrastea',\n",
       " 'adrenal',\n",
       " 'adrenalin',\n",
       " 'adrenaline',\n",
       " 'adrenalize',\n",
       " 'adriaan',\n",
       " 'adriaen',\n",
       " 'adriaenszoon',\n",
       " 'adriano',\n",
       " 'adrianopole',\n",
       " 'adrianov',\n",
       " 'adrianus',\n",
       " 'adriatic',\n",
       " 'adriatica',\n",
       " 'adriatico',\n",
       " 'adriã',\n",
       " 'adriãƒ',\n",
       " 'adroam',\n",
       " 'adroguãƒ',\n",
       " 'adsit',\n",
       " 'adso',\n",
       " 'adsorption',\n",
       " 'adsur',\n",
       " 'adtranz',\n",
       " 'adua',\n",
       " 'adug',\n",
       " 'aduki',\n",
       " 'adula',\n",
       " 'adulate',\n",
       " 'adulation',\n",
       " 'adult',\n",
       " 'adultera',\n",
       " 'adulterate',\n",
       " 'adulteration',\n",
       " 'adulterators',\n",
       " 'adulterer',\n",
       " 'adulterers',\n",
       " 'adulterous',\n",
       " 'adultery',\n",
       " 'adulthood',\n",
       " 'adultos',\n",
       " ...]"
      ]
     },
     "execution_count": 672,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<333414x106068 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1944434 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_bow = LogisticRegression(random_state=RANDOM_SEED,max_iter=1000).fit(X_train_transform,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6466876214698755"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,lr_bow.predict(X_test_transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_word = set(word_vectors.index_to_key) #around 6k words in the Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model_word.intersection(concreteset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors['live']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "word_list = []\n",
    "for word in model_word: \n",
    "    word_list.append((word,lemmatizer.lemmatize(word.lower())))\n",
    "df = pd.DataFrame(word_list,columns=['Original','word'])\n",
    "df = df.merge(AoA,left_on='word',right_on='Word',how='left')\n",
    "df = df[['Original','word','Perc_known','AoA_Kup_lem']]\n",
    "word_not_matched = set(df[df['Perc_known'].isnull()].word.values)\n",
    "\n",
    "for i in range(len(df)):   \n",
    "    if df['word'][i][0] in set(('0','1','2','3','4','5','6','7','8','9')) or len(df['word'][i])==1:\n",
    "        df['AoA_Kup_lem'][i] = 3\n",
    "mean_value = df['AoA_Kup_lem'].mean()\n",
    "df['AoA_Kup_lem'].fillna(value=mean_value,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.loc[df['Original']==['troops','weapons']]\n",
    "df[df['Original'].isin(['troops','weapon'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_perc_known(tokenized_text,df):\n",
    "    avg_perc_know=None\n",
    "    perc_know_list=[]\n",
    "    for _ in tokenized_text: \n",
    "        words =[word for word in _ if word in word_vectors.key_to_index]\n",
    "        \n",
    "        if len(words) >0:\n",
    "            avg_perc_know = np.mean(df[df['Original'].isin(words)]['AoA_Kup_lem'])\n",
    "            perc_know_list.append(avg_perc_know)\n",
    "        else: \n",
    "            \n",
    "            perc_know_list.append(0)\n",
    "            \n",
    "    return perc_know_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(X_train_wv)\n",
    "#df_train['year'] = generate_perc_known(tokenized_text_train,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(X_test_wv)\n",
    "#df_test['year'] = generate_perc_known(tokenized_text_test,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.163066</td>\n",
       "      <td>0.066503</td>\n",
       "      <td>0.007967</td>\n",
       "      <td>-0.368197</td>\n",
       "      <td>-0.475971</td>\n",
       "      <td>0.174799</td>\n",
       "      <td>-0.226500</td>\n",
       "      <td>0.288741</td>\n",
       "      <td>-0.101118</td>\n",
       "      <td>0.251682</td>\n",
       "      <td>...</td>\n",
       "      <td>0.343301</td>\n",
       "      <td>0.449110</td>\n",
       "      <td>-0.301583</td>\n",
       "      <td>-0.318929</td>\n",
       "      <td>-0.027628</td>\n",
       "      <td>-0.003120</td>\n",
       "      <td>0.640888</td>\n",
       "      <td>0.395134</td>\n",
       "      <td>-0.211103</td>\n",
       "      <td>7.319698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.098105</td>\n",
       "      <td>-0.697004</td>\n",
       "      <td>-0.067849</td>\n",
       "      <td>0.073167</td>\n",
       "      <td>0.001977</td>\n",
       "      <td>-0.519177</td>\n",
       "      <td>-0.064798</td>\n",
       "      <td>-0.384014</td>\n",
       "      <td>0.359658</td>\n",
       "      <td>-0.080730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100243</td>\n",
       "      <td>-0.152842</td>\n",
       "      <td>0.018108</td>\n",
       "      <td>-0.616458</td>\n",
       "      <td>0.208961</td>\n",
       "      <td>0.239500</td>\n",
       "      <td>-0.078117</td>\n",
       "      <td>0.907243</td>\n",
       "      <td>0.644744</td>\n",
       "      <td>8.900953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.608009</td>\n",
       "      <td>-0.270855</td>\n",
       "      <td>-0.351858</td>\n",
       "      <td>-1.324698</td>\n",
       "      <td>0.509448</td>\n",
       "      <td>0.466696</td>\n",
       "      <td>-0.869674</td>\n",
       "      <td>0.316894</td>\n",
       "      <td>-0.832663</td>\n",
       "      <td>0.482958</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.804097</td>\n",
       "      <td>-1.260673</td>\n",
       "      <td>-0.484280</td>\n",
       "      <td>-1.026836</td>\n",
       "      <td>-0.381989</td>\n",
       "      <td>0.006748</td>\n",
       "      <td>0.651532</td>\n",
       "      <td>0.502151</td>\n",
       "      <td>-1.543706</td>\n",
       "      <td>7.385000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.231419</td>\n",
       "      <td>-0.460309</td>\n",
       "      <td>-0.321846</td>\n",
       "      <td>-0.401228</td>\n",
       "      <td>-1.299778</td>\n",
       "      <td>-0.461486</td>\n",
       "      <td>0.002258</td>\n",
       "      <td>-0.175611</td>\n",
       "      <td>0.296010</td>\n",
       "      <td>0.373852</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068769</td>\n",
       "      <td>0.134842</td>\n",
       "      <td>0.026607</td>\n",
       "      <td>0.200088</td>\n",
       "      <td>0.376173</td>\n",
       "      <td>0.175164</td>\n",
       "      <td>-0.239718</td>\n",
       "      <td>0.463941</td>\n",
       "      <td>-0.541556</td>\n",
       "      <td>8.971588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.155188</td>\n",
       "      <td>0.110082</td>\n",
       "      <td>0.749716</td>\n",
       "      <td>-0.211680</td>\n",
       "      <td>-0.294006</td>\n",
       "      <td>-0.928232</td>\n",
       "      <td>0.095029</td>\n",
       "      <td>0.326077</td>\n",
       "      <td>0.020296</td>\n",
       "      <td>0.458989</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.496064</td>\n",
       "      <td>0.562254</td>\n",
       "      <td>-0.161042</td>\n",
       "      <td>-0.556670</td>\n",
       "      <td>-0.152797</td>\n",
       "      <td>0.216482</td>\n",
       "      <td>-0.109737</td>\n",
       "      <td>1.134926</td>\n",
       "      <td>-0.073294</td>\n",
       "      <td>7.939948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83349</th>\n",
       "      <td>-0.212178</td>\n",
       "      <td>-0.577913</td>\n",
       "      <td>0.233901</td>\n",
       "      <td>-0.283749</td>\n",
       "      <td>-0.250686</td>\n",
       "      <td>-0.740940</td>\n",
       "      <td>-0.073741</td>\n",
       "      <td>0.163121</td>\n",
       "      <td>-0.268991</td>\n",
       "      <td>0.569778</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062439</td>\n",
       "      <td>0.181861</td>\n",
       "      <td>-0.294118</td>\n",
       "      <td>0.674152</td>\n",
       "      <td>-0.312687</td>\n",
       "      <td>-0.416863</td>\n",
       "      <td>0.006465</td>\n",
       "      <td>0.296494</td>\n",
       "      <td>0.144787</td>\n",
       "      <td>7.846061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83350</th>\n",
       "      <td>0.083994</td>\n",
       "      <td>-0.119798</td>\n",
       "      <td>0.014636</td>\n",
       "      <td>-0.046240</td>\n",
       "      <td>-0.176528</td>\n",
       "      <td>-0.371178</td>\n",
       "      <td>-0.049741</td>\n",
       "      <td>-0.063575</td>\n",
       "      <td>0.069346</td>\n",
       "      <td>0.097987</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.106163</td>\n",
       "      <td>0.598239</td>\n",
       "      <td>-0.423099</td>\n",
       "      <td>-0.277646</td>\n",
       "      <td>0.249423</td>\n",
       "      <td>0.238795</td>\n",
       "      <td>-0.084238</td>\n",
       "      <td>0.325800</td>\n",
       "      <td>-0.371009</td>\n",
       "      <td>7.653076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83351</th>\n",
       "      <td>-0.027579</td>\n",
       "      <td>-0.583053</td>\n",
       "      <td>-0.212853</td>\n",
       "      <td>0.064448</td>\n",
       "      <td>-0.001676</td>\n",
       "      <td>-0.386104</td>\n",
       "      <td>-0.194504</td>\n",
       "      <td>0.125628</td>\n",
       "      <td>0.087920</td>\n",
       "      <td>0.013556</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087076</td>\n",
       "      <td>0.200042</td>\n",
       "      <td>0.022237</td>\n",
       "      <td>0.865286</td>\n",
       "      <td>0.345294</td>\n",
       "      <td>0.206362</td>\n",
       "      <td>-0.050420</td>\n",
       "      <td>0.287032</td>\n",
       "      <td>-0.024188</td>\n",
       "      <td>6.618984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83352</th>\n",
       "      <td>0.150752</td>\n",
       "      <td>-0.344787</td>\n",
       "      <td>0.016055</td>\n",
       "      <td>-0.438976</td>\n",
       "      <td>0.105028</td>\n",
       "      <td>-0.072180</td>\n",
       "      <td>-0.229091</td>\n",
       "      <td>0.010541</td>\n",
       "      <td>-0.065317</td>\n",
       "      <td>0.162644</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090400</td>\n",
       "      <td>-0.352687</td>\n",
       "      <td>-0.262663</td>\n",
       "      <td>-0.028436</td>\n",
       "      <td>0.180446</td>\n",
       "      <td>-0.053098</td>\n",
       "      <td>0.068634</td>\n",
       "      <td>-0.034959</td>\n",
       "      <td>0.074879</td>\n",
       "      <td>7.009195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83353</th>\n",
       "      <td>0.798341</td>\n",
       "      <td>-0.436330</td>\n",
       "      <td>-0.095135</td>\n",
       "      <td>-0.875586</td>\n",
       "      <td>-0.725843</td>\n",
       "      <td>-0.983312</td>\n",
       "      <td>-0.478156</td>\n",
       "      <td>0.076523</td>\n",
       "      <td>-0.534273</td>\n",
       "      <td>0.518388</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020779</td>\n",
       "      <td>0.168365</td>\n",
       "      <td>-0.001870</td>\n",
       "      <td>-0.459175</td>\n",
       "      <td>-1.014081</td>\n",
       "      <td>-0.339258</td>\n",
       "      <td>0.264108</td>\n",
       "      <td>0.849447</td>\n",
       "      <td>-0.063408</td>\n",
       "      <td>8.322109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83354 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      0.163066  0.066503  0.007967 -0.368197 -0.475971  0.174799 -0.226500   \n",
       "1      0.098105 -0.697004 -0.067849  0.073167  0.001977 -0.519177 -0.064798   \n",
       "2      0.608009 -0.270855 -0.351858 -1.324698  0.509448  0.466696 -0.869674   \n",
       "3     -0.231419 -0.460309 -0.321846 -0.401228 -1.299778 -0.461486  0.002258   \n",
       "4     -0.155188  0.110082  0.749716 -0.211680 -0.294006 -0.928232  0.095029   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "83349 -0.212178 -0.577913  0.233901 -0.283749 -0.250686 -0.740940 -0.073741   \n",
       "83350  0.083994 -0.119798  0.014636 -0.046240 -0.176528 -0.371178 -0.049741   \n",
       "83351 -0.027579 -0.583053 -0.212853  0.064448 -0.001676 -0.386104 -0.194504   \n",
       "83352  0.150752 -0.344787  0.016055 -0.438976  0.105028 -0.072180 -0.229091   \n",
       "83353  0.798341 -0.436330 -0.095135 -0.875586 -0.725843 -0.983312 -0.478156   \n",
       "\n",
       "              7         8         9  ...        91        92        93  \\\n",
       "0      0.288741 -0.101118  0.251682  ...  0.343301  0.449110 -0.301583   \n",
       "1     -0.384014  0.359658 -0.080730  ...  0.100243 -0.152842  0.018108   \n",
       "2      0.316894 -0.832663  0.482958  ... -0.804097 -1.260673 -0.484280   \n",
       "3     -0.175611  0.296010  0.373852  ... -0.068769  0.134842  0.026607   \n",
       "4      0.326077  0.020296  0.458989  ... -0.496064  0.562254 -0.161042   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "83349  0.163121 -0.268991  0.569778  ... -0.062439  0.181861 -0.294118   \n",
       "83350 -0.063575  0.069346  0.097987  ... -0.106163  0.598239 -0.423099   \n",
       "83351  0.125628  0.087920  0.013556  ... -0.087076  0.200042  0.022237   \n",
       "83352  0.010541 -0.065317  0.162644  ... -0.090400 -0.352687 -0.262663   \n",
       "83353  0.076523 -0.534273  0.518388  ... -0.020779  0.168365 -0.001870   \n",
       "\n",
       "             94        95        96        97        98        99      year  \n",
       "0     -0.318929 -0.027628 -0.003120  0.640888  0.395134 -0.211103  7.319698  \n",
       "1     -0.616458  0.208961  0.239500 -0.078117  0.907243  0.644744  8.900953  \n",
       "2     -1.026836 -0.381989  0.006748  0.651532  0.502151 -1.543706  7.385000  \n",
       "3      0.200088  0.376173  0.175164 -0.239718  0.463941 -0.541556  8.971588  \n",
       "4     -0.556670 -0.152797  0.216482 -0.109737  1.134926 -0.073294  7.939948  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "83349  0.674152 -0.312687 -0.416863  0.006465  0.296494  0.144787  7.846061  \n",
       "83350 -0.277646  0.249423  0.238795 -0.084238  0.325800 -0.371009  7.653076  \n",
       "83351  0.865286  0.345294  0.206362 -0.050420  0.287032 -0.024188  6.618984  \n",
       "83352 -0.028436  0.180446 -0.053098  0.068634 -0.034959  0.074879  7.009195  \n",
       "83353 -0.459175 -1.014081 -0.339258  0.264108  0.849447 -0.063408  8.322109  \n",
       "\n",
       "[83354 rows x 101 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=RANDOM_SEED,max_iter=1000).fit(df_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58372723564556"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,lr.predict(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_bow = DummyClassifier(strategy='uniform',random_state=RANDOM_SEED).fit(X_train_transform,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5011277203253593"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, dummy_bow.predict(X_test_transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_wv = DummyClassifier(strategy='uniform',random_state=RANDOM_SEED).fit(X_train_wv,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5011277203253593"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,dummy_wv.predict(X_test_wv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_bow = LogisticRegression(random_state=RANDOM_SEED,max_iter=1000).fit(X_train_transform,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6465916452719725"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,lr_bow.predict(X_test_transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_wv = LogisticRegression(random_state=RANDOM_SEED,max_iter=1000).fit(X_train_wv,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5640041269765098"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,lr_wv.predict(X_test_wv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_bow = RandomForestClassifier(n_estimators=500,max_depth=5,random_state=RANDOM_SEED).fit(X_train_transform,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6416968591789236"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,rf_bow.predict(X_test_transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_wv = RandomForestClassifier(n_estimators=100,max_depth=5,random_state=RANDOM_SEED).fit(X_train_wv,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test,rf_wv.predict(X_test_wv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Unsupervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2,random_state=RANDOM_SEED).fit(X_train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df = pd.DataFrame({'cluster':kmeans.labels_,'y_label':y_train,'text':X_train})\n",
    "cluster_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA Topic Modeling - Consider NMF to create a document-topic matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from nltk.stem.porter import *\n",
    "def lemmatize_stemming(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    #Un-hash next line to use stemming\n",
    "    #return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "    #Un-hash next line to NOT use stemming\n",
    "    return WordNetLemmatizer().lemmatize(text, pos='v')\n",
    "# Tokenize and lemmatize\n",
    "def preprocess(text):\n",
    "    result=[]\n",
    "    for token in gensim.utils.simple_preprocess(text) :\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            #Un-hash next line to use stemming\n",
    "            result.append(lemmatize_stemming(token))\n",
    "            #Un-hash next line to NOT use stemming\n",
    "            #result.append(token)\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"There is manuscript evidence that Austen continued to work on these pieces as late as the period 1809 Ã¢ '' 11 , and that her niece and nephew , Anna and James Edward Austen , made further additions as late as 1814 .\""
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['original_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['manuscript',\n",
       " 'evidence',\n",
       " 'austen',\n",
       " 'continue',\n",
       " 'work',\n",
       " 'piece',\n",
       " 'late',\n",
       " 'period',\n",
       " 'niece',\n",
       " 'nephew',\n",
       " 'anna',\n",
       " 'jam',\n",
       " 'edward',\n",
       " 'austen',\n",
       " 'additions',\n",
       " 'late']"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(df['original_text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell will run about 2 minutes\n",
    "processed_docs = [preprocess(text) for text in df['original_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.corpora.dictionary.Dictionary at 0x1567b848520>"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "#bow_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "416768"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bow_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell will run 10 minutes\n",
    "#lda_model =  gensim.models.LdaMulticore(bow_corpus, \n",
    "#                                   num_topics = 8, \n",
    "#                                   id2word = dictionary,                                    \n",
    "#                                   passes = 10,\n",
    "#                                   workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for idx, topic in lda_model.print_topics(-1):\n",
    "#    print(\"Topic: {} \\nWords: {}\".format(idx, topic ))\n",
    "#    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
