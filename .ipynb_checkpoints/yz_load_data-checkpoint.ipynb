{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import altair as alt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.18.5'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make sure numpy version is < 1.20\n",
    "np.version.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The following command must be run outside of the IPython shell:\n",
      "\n",
      "    $ pip install gensim\n",
      "\n",
      "The Python package manager (pip) can only be used from outside of IPython.\n",
      "Please reissue the `pip` command in a separate terminal or command prompt.\n",
      "\n",
      "See the Python documentation for more information on how to install packages:\n",
      "\n",
      "    https://docs.python.org/3/installing/\n"
     ]
    }
   ],
   "source": [
    "# pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "from tqdm.notebook import tqdm\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED=694"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There is manuscript evidence that Austen conti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In a remarkable comparative analysis , Mandaea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Before Persephone was released to Hermes , who...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cogeneration plants are commonly found in dist...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Geneva -LRB- , ; , ; , ; ; -RRB- is the second...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       original_text  label\n",
       "0  There is manuscript evidence that Austen conti...      1\n",
       "1  In a remarkable comparative analysis , Mandaea...      1\n",
       "2  Before Persephone was released to Hermes , who...      1\n",
       "3  Cogeneration plants are commonly found in dist...      1\n",
       "4  Geneva -LRB- , ; , ; , ; ; -RRB- is the second...      1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = 'Data/WikiLarge_Train.csv'\n",
    "df = pd.read_csv(train_path, skiprows=0, skipfooter=0, engine='python')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['label']==1])/len(df) # the dataset label is well balanced "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'He studied in Armenia and Istanbul , then at Wisconsin University which he finished in 1915 .'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[50]['original_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117.77629520500614"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['original_text'].apply(lambda x: len(x)).mean()\n",
    "# This means all texts are considered short text, which allows us to use dense representations, \n",
    "# as dense representations work well with short text.\n",
    "# Gensim.KeyedVectors.load('assets/wikipedia.100.word-vecs.kv')??? How to generate and use this???\n",
    "# Maybe we should train word2vec model on the entire corpus. Just training data? TOP 100 word-vectors(features)\n",
    "# Alternatively we could use bag-of-words model, which is term-document matrix representation, having much more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['original_text']\n",
    "y = df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>original_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-2011</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-2011</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-2000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-1997</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.636</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id original_text  label\n",
       "0   0         -2011    NaN\n",
       "1   1         -2011    NaN\n",
       "2   2         -2000    NaN\n",
       "3   3         -1997    NaN\n",
       "4   4         1.636    NaN"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_path = 'Data/WikiLarge_Test.csv'\n",
    "test_df = pd.read_csv(test_path, skiprows=0, skipfooter=0, engine='python')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                           10000\n",
       "original_text    An atheist would say that this argument proves...\n",
       "label                                                          NaN\n",
       "Name: 10000, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.iloc[10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label\n",
       "0   0      0\n",
       "1   1      0\n",
       "2   2      1\n",
       "3   3      1\n",
       "4   4      0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samplesubmission_path = 'Data/sampleSubmission.csv'\n",
    "samplesubmission_df = pd.read_csv(samplesubmission_path, skiprows=0, skipfooter=0, engine='python')\n",
    "samplesubmission_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conclude, the dataframes we are working with are:\n",
    "\n",
    "dalechall_df, concreteness_df, aoawords_df, train_df, test_df, samplesubmission_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=10,stop_words='english',ngram_range=(1,2))\n",
    "X_train_transform = vectorizer.fit_transform(X_train)\n",
    "X_test_transform  = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<333414x57516 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4053454 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(stopwords.words('english')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "== dale_chall.txt ==\n",
    "\n",
    "This is the Dale Chall 3000 Word List, which is one definition of words that are considered \"basic\" English.\n",
    "\n",
    "A summary is at https://www.readabilityformulas.com/articles/dale-chall-readability-word-list.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic english words\n",
    "dalechall_path = 'Data/dale_chall.txt'\n",
    "dale_chall = pd.read_csv(dalechall_path,delimiter='\\t',header=None,names=['word'])\n",
    "dale = set(dale_chall['word'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2946"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The 2946 words in dale can be combined with the nltk stopwords.\n",
    "### We could maybe assign an arbitrary score to each dale_chall word. - for reference only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords = set(stopwords.words('english')) | dale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2986"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "304501    1979-80 Buffalo Sabres NHL 32 1880 74 1 4 2.36...\n",
       "162313    Diseases Lentils in culture Lentils are mentio...\n",
       "336845    Railroads , like the Lehigh Valley Railroad , ...\n",
       "150625    An example of this would be an individual anim...\n",
       "40240     Both the Matanuska and Susitna Rivers have maj...\n",
       "212458                                            Mettingen\n",
       "347657    Its analog nature has also been the cause of a...\n",
       "114073    Cooperation of the Republic of Kazakhstan with...\n",
       "415175                             Importance to philosophy\n",
       "143466    The most extreme can attain wind speeds of mor...\n",
       "166397    Theory Exams These are written papers on the t...\n",
       "936       Finland , Turkey , and New Zealand -LRB- as pa...\n",
       "352629    The first single from the album , '' So Here W...\n",
       "77068     USB does not support cyclical networks and the...\n",
       "215851            Yes -LRB- album -RRB- , their debut album\n",
       "30026     Some researchers regard Myxini as not belongin...\n",
       "106295    The aircraft , traveling at about 404 knots , ...\n",
       "466       They are members of the Pacific Division of th...\n",
       "134537    The two leagues agreed to merge in 2006Women '...\n",
       "392348                            Avon , Minnesota , a city\n",
       "208564         The Shiba Inu is a breed of dog from Japan .\n",
       "103108    Metamorphic rock is the result of the transfor...\n",
       "47174     The final design resulted in WrestleMania 23 h...\n",
       "252629                                             Location\n",
       "211696                                           References\n",
       "51819     Mendoza -LRB- -RRB- is the capital city of Men...\n",
       "212046    Scarlett hurries home to find Rhett and tell h...\n",
       "320308    He was born a Prince of Savoy in Turin to Vict...\n",
       "233283    This article mostly describes the visual syste...\n",
       "396623    He was the host of the weekly American Top 40 ...\n",
       "                                ...                        \n",
       "184779    Dylan Postl -LRB- born May 29 , 1986 -RRB- is ...\n",
       "214176    1869 - Henri Matisse , French painter -LRB- d....\n",
       "235796          Eisai , founder of the Rinzai school of Zen\n",
       "103355    Models a couple of metres wide were sold to be...\n",
       "267455    Birthplace of Italian football legend Paolo Ro...\n",
       "199041    The book presents the author 's composite acco...\n",
       "252709    Examples of Physical Coefficients Coefficient ...\n",
       "327069                                         Pete Farndon\n",
       "194027    Since the bus topology consists of only one wi...\n",
       "321879    1807 - David Rice Atchison , American politici...\n",
       "262913                                                 Uses\n",
       "64820     Its role is multifaceted due largely to the in...\n",
       "329365    Xenon gas is used in electron tubes , bacteric...\n",
       "41090     Geography The district covers the islands Rüge...\n",
       "278167                             Today , it is accepted .\n",
       "191335    The United Kingdom is made up of four constitu...\n",
       "175203    In addition to four male and two female member...\n",
       "388468      Its home stadium is Carlos Tartiere in Oviedo .\n",
       "374871    Saudi Arabia is to the west and is connected t...\n",
       "87498     Faust tries to save Gretchen from death by att...\n",
       "137337    Phosphorus -LRB- -RRB- is the chemical element...\n",
       "54886     Chase lives with her mother Cathy Chase and wa...\n",
       "207892    In 1870 , he quit his job at the Kreuzzeitung ...\n",
       "110268    According to Tessa Hofmann , Turkish officials...\n",
       "119879    Dike is a city in Grundy County , Iowa , Unite...\n",
       "259178    After the Germans invaded Norway in April 1940...\n",
       "365838    July 28 - Henry Bennet , 1st Earl of Arlington...\n",
       "131932    Pancake restaurants are popular family restaur...\n",
       "146867                                 A cycling domestique\n",
       "121958    David Boreanaz 's first paid acting appearance...\n",
       "Name: original_text, Length: 333414, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1979-80 Buffalo Sabres NHL 32 1880 74 1 4 2.36 20 8 4 0 0.000'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[304501]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['buffalo', 'sabres', 'nhl']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "gensim.utils.simple_preprocess(X_train[304501])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gensim.parsing.preprocessing.STOPWORDS\n",
    "#stopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text_train=[]\n",
    "tokenized_text_test=[]\n",
    "stopWords = set(stopwords.words('english')) | dale\n",
    "# This cell will run 4 minutes\n",
    "import gensim\n",
    "from nltk.stem.porter import *\n",
    "def lemmatize_stemming(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    #Un-hash next line to use stemming\n",
    "    #return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "    #Un-hash next line to NOT use stemming\n",
    "    return WordNetLemmatizer().lemmatize(text, pos='v')\n",
    "\n",
    "# Tokenize and lemmatize\n",
    "def preprocess(text):\n",
    "    result=[]\n",
    "    for token in gensim.utils.simple_preprocess(text) :\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            #Un-hash next line to use lemmatization/stemming\n",
    "            result.append(lemmatize_stemming(token))\n",
    "            #Un-hash next line to NOT use lemmatization/stemming\n",
    "            #result.append(token)\n",
    "            \n",
    "    return result\n",
    "\n",
    "tokenized_text_train = [preprocess(text) for text in X_train]\n",
    "tokenized_text_test=[preprocess(text) for text in X_test]\n",
    "\n",
    "#for text in tqdm(X_train):\n",
    "#    tokens_in_text = word_tokenize(text)\n",
    "#    tokens_in_text = [word for word in tokens_in_text if word.lower() not in stopWords]\n",
    "#    tokenized_text_train.append(tokens_in_text)\n",
    "    \n",
    "#for text in tqdm(X_test):\n",
    "#    tokens_in_text = word_tokenize(text)\n",
    "#    tokens_in_text = [word for word in tokens_in_text if word.lower() not in stopWords]\n",
    "#    tokenized_text_test.append(tokens_in_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenized_text_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11281343, 15510955)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Word2Vec(vector_size=100,window=2,min_count=100,seed= RANDOM_SEED,workers=4)\n",
    "model.build_vocab(tokenized_text_train)\n",
    "model.train(tokenized_text_train,total_examples=model.corpus_count,epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "The vocab attribute was removed from KeyedVector in Gensim 4.0.0.\nUse KeyedVector's .key_to_index dict, .index_to_key list, and methods .get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\nSee https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-1ce1b1396e88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mword_vectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mvocab\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    660\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         raise AttributeError(\n\u001b[0;32m--> 662\u001b[0;31m             \u001b[0;34m\"The vocab attribute was removed from KeyedVector in Gensim 4.0.0.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m             \u001b[0;34m\"Use KeyedVector's .key_to_index dict, .index_to_key list, and methods \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0;34m\".get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: The vocab attribute was removed from KeyedVector in Gensim 4.0.0.\nUse KeyedVector's .key_to_index dict, .index_to_key list, and methods .get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\nSee https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4"
     ]
    }
   ],
   "source": [
    "word_vectors.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = word_vectors.key_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': 0,\n",
       " 'bear': 1,\n",
       " 'france': 2,\n",
       " 'city': 3,\n",
       " 'know': 4,\n",
       " 'unite': 5,\n",
       " 'department': 6,\n",
       " 'play': 7,\n",
       " 'region': 8,\n",
       " 'commune': 9,\n",
       " 'time': 10,\n",
       " 'north': 11,\n",
       " 'world': 12,\n",
       " 'football': 13,\n",
       " 'american': 14,\n",
       " 'call': 15,\n",
       " 'include': 16,\n",
       " 'people': 17,\n",
       " 'south': 18,\n",
       " 'game': 19,\n",
       " 'work': 20,\n",
       " 'team': 21,\n",
       " 'national': 22,\n",
       " 'form': 23,\n",
       " 'county': 24,\n",
       " 'player': 25,\n",
       " 'district': 26,\n",
       " 'write': 27,\n",
       " 'release': 28,\n",
       " 'year': 29,\n",
       " 'years': 30,\n",
       " 'english': 31,\n",
       " 'name': 32,\n",
       " 'second': 33,\n",
       " 'live': 34,\n",
       " 'locate': 35,\n",
       " 'number': 36,\n",
       " 'west': 37,\n",
       " 'music': 38,\n",
       " 'band': 39,\n",
       " 'film': 40,\n",
       " 'area': 41,\n",
       " 'group': 42,\n",
       " 'record': 43,\n",
       " 'town': 44,\n",
       " 'university': 45,\n",
       " 'series': 46,\n",
       " 'later': 47,\n",
       " 'september': 48,\n",
       " 'season': 49,\n",
       " 'build': 50,\n",
       " 'british': 51,\n",
       " 'january': 52,\n",
       " 'base': 53,\n",
       " 'march': 54,\n",
       " 'calais': 55,\n",
       " 'east': 56,\n",
       " 'album': 57,\n",
       " 'school': 58,\n",
       " 'begin': 59,\n",
       " 'german': 60,\n",
       " 'october': 61,\n",
       " 'start': 62,\n",
       " 'july': 63,\n",
       " 'league': 64,\n",
       " 'take': 65,\n",
       " 'august': 66,\n",
       " 'book': 67,\n",
       " 'river': 68,\n",
       " 'june': 69,\n",
       " 'give': 70,\n",
       " 'mean': 71,\n",
       " 'place': 72,\n",
       " 'december': 73,\n",
       " 'family': 74,\n",
       " 'april': 75,\n",
       " 'november': 76,\n",
       " 'england': 77,\n",
       " 'like': 78,\n",
       " 'best': 79,\n",
       " 'february': 80,\n",
       " 'century': 81,\n",
       " 'northern': 82,\n",
       " 'follow': 83,\n",
       " 'award': 84,\n",
       " 'come': 85,\n",
       " 'early': 86,\n",
       " 'french': 87,\n",
       " 'history': 88,\n",
       " 'london': 89,\n",
       " 'king': 90,\n",
       " 'population': 91,\n",
       " 'refer': 92,\n",
       " 'leave': 93,\n",
       " 'capital': 94,\n",
       " 'john': 95,\n",
       " 'largest': 96,\n",
       " 'province': 97,\n",
       " 'western': 98,\n",
       " 'line': 99,\n",
       " 'term': 100,\n",
       " 'ndash': 101,\n",
       " 'create': 102,\n",
       " 'government': 103,\n",
       " 'rock': 104,\n",
       " 'small': 105,\n",
       " 'germany': 106,\n",
       " 'central': 107,\n",
       " 'main': 108,\n",
       " 'life': 109,\n",
       " 'major': 110,\n",
       " 'club': 111,\n",
       " 'usually': 112,\n",
       " 'president': 113,\n",
       " 'language': 114,\n",
       " 'die': 115,\n",
       " 'japanese': 116,\n",
       " 'word': 117,\n",
       " 'single': 118,\n",
       " 'water': 119,\n",
       " 'long': 120,\n",
       " 'international': 121,\n",
       " 'high': 122,\n",
       " 'star': 123,\n",
       " 'force': 124,\n",
       " 'island': 125,\n",
       " 'hold': 126,\n",
       " 'change': 127,\n",
       " 'large': 128,\n",
       " 'company': 129,\n",
       " 'produce': 130,\n",
       " 'party': 131,\n",
       " 'house': 132,\n",
       " 'type': 133,\n",
       " 'television': 134,\n",
       " 'near': 135,\n",
       " 'different': 136,\n",
       " 'species': 137,\n",
       " 'open': 138,\n",
       " 'say': 139,\n",
       " 'common': 140,\n",
       " 'great': 141,\n",
       " 'york': 142,\n",
       " 'home': 143,\n",
       " 'church': 144,\n",
       " 'study': 145,\n",
       " 'southern': 146,\n",
       " 'center': 147,\n",
       " 'saint': 148,\n",
       " 'general': 149,\n",
       " 'country': 150,\n",
       " 'feature': 151,\n",
       " 'million': 152,\n",
       " 'kingdom': 153,\n",
       " 'title': 154,\n",
       " 'power': 155,\n",
       " 'publish': 156,\n",
       " 'professional': 157,\n",
       " 'found': 158,\n",
       " 'go': 159,\n",
       " 'death': 160,\n",
       " 'municipality': 161,\n",
       " 'member': 162,\n",
       " 'song': 163,\n",
       " 'land': 164,\n",
       " 'move': 165,\n",
       " 'serve': 166,\n",
       " 'point': 167,\n",
       " 'currently': 168,\n",
       " 'character': 169,\n",
       " 'order': 170,\n",
       " 'station': 171,\n",
       " 'union': 172,\n",
       " 'australia': 173,\n",
       " 'list': 174,\n",
       " 'lead': 175,\n",
       " 'service': 176,\n",
       " 'championship': 177,\n",
       " 'make': 178,\n",
       " 'america': 179,\n",
       " 'japan': 180,\n",
       " 'appear': 181,\n",
       " 'modern': 182,\n",
       " 'famous': 183,\n",
       " 'develop': 184,\n",
       " 'body': 185,\n",
       " 'eastern': 186,\n",
       " 'father': 187,\n",
       " 'important': 188,\n",
       " 'members': 189,\n",
       " 'storm': 190,\n",
       " 'cause': 191,\n",
       " 'nord': 192,\n",
       " 'popular': 193,\n",
       " 'park': 194,\n",
       " 'video': 195,\n",
       " 'tropical': 196,\n",
       " 'right': 197,\n",
       " 'roman': 198,\n",
       " 'race': 199,\n",
       " 'republic': 200,\n",
       " 'show': 201,\n",
       " 'italian': 202,\n",
       " 'plant': 203,\n",
       " 'hurricane': 204,\n",
       " 'white': 205,\n",
       " 'period': 206,\n",
       " 'aisne': 207,\n",
       " 'europe': 208,\n",
       " 'college': 209,\n",
       " 'black': 210,\n",
       " 'public': 211,\n",
       " 'consider': 212,\n",
       " 'official': 213,\n",
       " 'contain': 214,\n",
       " 'head': 215,\n",
       " 'pakistan': 216,\n",
       " 'page': 217,\n",
       " 'design': 218,\n",
       " 'children': 219,\n",
       " 'example': 220,\n",
       " 'color': 221,\n",
       " 'countries': 222,\n",
       " 'singer': 223,\n",
       " 'spanish': 224,\n",
       " 'result': 225,\n",
       " 'jam': 226,\n",
       " 'grow': 227,\n",
       " 'reference': 228,\n",
       " 'short': 229,\n",
       " 'join': 230,\n",
       " 'help': 231,\n",
       " 'original': 232,\n",
       " 'program': 233,\n",
       " 'greek': 234,\n",
       " 'remain': 235,\n",
       " 'sell': 236,\n",
       " 'present': 237,\n",
       " 'european': 238,\n",
       " 'royal': 239,\n",
       " 'india': 240,\n",
       " 'movie': 241,\n",
       " 'rule': 242,\n",
       " 'match': 243,\n",
       " 'kill': 244,\n",
       " 'calvados': 245,\n",
       " 'total': 246,\n",
       " 'william': 247,\n",
       " 'level': 248,\n",
       " 'accord': 249,\n",
       " 'california': 250,\n",
       " 'career': 251,\n",
       " 'minister': 252,\n",
       " 'control': 253,\n",
       " 'date': 254,\n",
       " 'support': 255,\n",
       " 'basse': 256,\n",
       " 'normandie': 257,\n",
       " 'council': 258,\n",
       " 'battle': 259,\n",
       " 'allow': 260,\n",
       " 'receive': 261,\n",
       " 'person': 262,\n",
       " 'late': 263,\n",
       " 'sport': 264,\n",
       " 'switzerland': 265,\n",
       " 'perform': 266,\n",
       " 'free': 267,\n",
       " 'return': 268,\n",
       " 'current': 269,\n",
       " 'sign': 270,\n",
       " 'george': 271,\n",
       " 'hockey': 272,\n",
       " 'northwest': 273,\n",
       " 'pay': 274,\n",
       " 'train': 275,\n",
       " 'article': 276,\n",
       " 'canton': 277,\n",
       " 'commonly': 278,\n",
       " 'border': 279,\n",
       " 'young': 280,\n",
       " 'islands': 281,\n",
       " 'reach': 282,\n",
       " 'footballer': 283,\n",
       " 'local': 284,\n",
       " 'empire': 285,\n",
       " 'canada': 286,\n",
       " 'wrestle': 287,\n",
       " 'today': 288,\n",
       " 'earth': 289,\n",
       " 'division': 290,\n",
       " 'class': 291,\n",
       " 'think': 292,\n",
       " 'lake': 293,\n",
       " 'link': 294,\n",
       " 'cover': 295,\n",
       " 'range': 296,\n",
       " 'establish': 297,\n",
       " 'marry': 298,\n",
       " 'actor': 299,\n",
       " 'originally': 300,\n",
       " 'part': 301,\n",
       " 'role': 302,\n",
       " 'field': 303,\n",
       " 'charles': 304,\n",
       " 'mother': 305,\n",
       " 'continue': 306,\n",
       " 'army': 307,\n",
       " 'speak': 308,\n",
       " 'light': 309,\n",
       " 'metal': 310,\n",
       " 'political': 311,\n",
       " 'consist': 312,\n",
       " 'blue': 313,\n",
       " 'china': 314,\n",
       " 'version': 315,\n",
       " 'human': 316,\n",
       " 'similar': 317,\n",
       " 'days': 318,\n",
       " 'emperor': 319,\n",
       " 'pass': 320,\n",
       " 'provide': 321,\n",
       " 'areas': 322,\n",
       " 'grand': 323,\n",
       " 'queen': 324,\n",
       " 'process': 325,\n",
       " 'australian': 326,\n",
       " 'village': 327,\n",
       " 'italy': 328,\n",
       " 'direct': 329,\n",
       " 'coast': 330,\n",
       " 'lose': 331,\n",
       " 'final': 332,\n",
       " 'network': 333,\n",
       " 'close': 334,\n",
       " 'science': 335,\n",
       " 'have': 336,\n",
       " 'source': 337,\n",
       " 'loire': 338,\n",
       " 'describe': 339,\n",
       " 'size': 340,\n",
       " 'host': 341,\n",
       " 'association': 342,\n",
       " 'christian': 343,\n",
       " 'operate': 344,\n",
       " 'attack': 345,\n",
       " 'seat': 346,\n",
       " 'see': 347,\n",
       " 'henry': 348,\n",
       " 'ancient': 349,\n",
       " 'style': 350,\n",
       " 'end': 351,\n",
       " 'miles': 352,\n",
       " 'military': 353,\n",
       " 'story': 354,\n",
       " 'gironde': 355,\n",
       " 'wind': 356,\n",
       " 'women': 357,\n",
       " 'scotland': 358,\n",
       " 'turn': 359,\n",
       " 'event': 360,\n",
       " 'position': 361,\n",
       " 'events': 362,\n",
       " 'canadian': 363,\n",
       " 'energy': 364,\n",
       " 'middle': 365,\n",
       " 'road': 366,\n",
       " 'complete': 367,\n",
       " 'discover': 368,\n",
       " 'green': 369,\n",
       " 'radio': 370,\n",
       " 'ireland': 371,\n",
       " 'author': 372,\n",
       " 'africa': 373,\n",
       " 'picardie': 374,\n",
       " 'mark': 375,\n",
       " 'space': 376,\n",
       " 'note': 377,\n",
       " 'report': 378,\n",
       " 'cross': 379,\n",
       " 'champion': 380,\n",
       " 'languages': 381,\n",
       " 'defeat': 382,\n",
       " 'natural': 383,\n",
       " 'half': 384,\n",
       " 'railway': 385,\n",
       " 'paul': 386,\n",
       " 'separate': 387,\n",
       " 'leader': 388,\n",
       " 'replace': 389,\n",
       " 'love': 390,\n",
       " 'seven': 391,\n",
       " 'rise': 392,\n",
       " 'wife': 393,\n",
       " 'office': 394,\n",
       " 'prime': 395,\n",
       " 'aquitaine': 396,\n",
       " 'florida': 397,\n",
       " 'good': 398,\n",
       " 'brazilian': 399,\n",
       " 'calendar': 400,\n",
       " 'generally': 401,\n",
       " 'little': 402,\n",
       " 'atlantic': 403,\n",
       " 'tour': 404,\n",
       " 'development': 405,\n",
       " 'census': 406,\n",
       " 'formula': 407,\n",
       " 'latin': 408,\n",
       " 'exist': 409,\n",
       " 'track': 410,\n",
       " 'director': 411,\n",
       " 'david': 412,\n",
       " 'hall': 413,\n",
       " 'square': 414,\n",
       " 'fight': 415,\n",
       " 'view': 416,\n",
       " 'food': 417,\n",
       " 'robert': 418,\n",
       " 'tree': 419,\n",
       " 'believe': 420,\n",
       " 'relate': 421,\n",
       " 'surface': 422,\n",
       " 'represent': 423,\n",
       " 'court': 424,\n",
       " 'chinese': 425,\n",
       " 'case': 426,\n",
       " 'bank': 427,\n",
       " 'trade': 428,\n",
       " 'orchestra': 429,\n",
       " 'russian': 430,\n",
       " 'parliament': 431,\n",
       " 'hand': 432,\n",
       " 'stand': 433,\n",
       " 'writer': 434,\n",
       " 'project': 435,\n",
       " 'valley': 436,\n",
       " 'hill': 437,\n",
       " 'site': 438,\n",
       " 'songs': 439,\n",
       " 'ocean': 440,\n",
       " 'prize': 441,\n",
       " 'special': 442,\n",
       " 'model': 443,\n",
       " 'occur': 444,\n",
       " 'systems': 445,\n",
       " 'divide': 446,\n",
       " 'asia': 447,\n",
       " 'paris': 448,\n",
       " 'information': 449,\n",
       " 'image': 450,\n",
       " 'daughter': 451,\n",
       " 'letter': 452,\n",
       " 'port': 453,\n",
       " 'southwest': 454,\n",
       " 'brother': 455,\n",
       " 'moon': 456,\n",
       " 'chemical': 457,\n",
       " 'break': 458,\n",
       " 'tell': 459,\n",
       " 'need': 460,\n",
       " 'plan': 461,\n",
       " 'run': 462,\n",
       " 'software': 463,\n",
       " 'object': 464,\n",
       " 'win': 465,\n",
       " 'meet': 466,\n",
       " 'theory': 467,\n",
       " 'better': 468,\n",
       " 'fall': 469,\n",
       " 'highest': 470,\n",
       " 'cities': 471,\n",
       " 'organization': 472,\n",
       " 'actress': 473,\n",
       " 'bring': 474,\n",
       " 'night': 475,\n",
       " 'want': 476,\n",
       " 'movement': 477,\n",
       " 'elect': 478,\n",
       " 'scottish': 479,\n",
       " 'stadium': 480,\n",
       " 'increase': 481,\n",
       " 'composer': 482,\n",
       " 'summer': 483,\n",
       " 'fourth': 484,\n",
       " 'research': 485,\n",
       " 'opera': 486,\n",
       " 'indian': 487,\n",
       " 'share': 488,\n",
       " 'street': 489,\n",
       " 'novel': 490,\n",
       " 'culture': 491,\n",
       " 'dutch': 492,\n",
       " 'use': 493,\n",
       " 'studio': 494,\n",
       " 'berlin': 495,\n",
       " 'influence': 496,\n",
       " 'independent': 497,\n",
       " 'debut': 498,\n",
       " 'post': 499,\n",
       " 'officially': 500,\n",
       " 'entertainment': 501,\n",
       " 'ring': 502,\n",
       " 'players': 503,\n",
       " 'send': 504,\n",
       " 'richard': 505,\n",
       " 'community': 506,\n",
       " 'structure': 507,\n",
       " 'claim': 508,\n",
       " 'sound': 509,\n",
       " 'lower': 510,\n",
       " 'vote': 511,\n",
       " 'simply': 512,\n",
       " 'introduce': 513,\n",
       " 'spain': 514,\n",
       " 'ship': 515,\n",
       " 'social': 516,\n",
       " 'issue': 517,\n",
       " 'involve': 518,\n",
       " 'prince': 519,\n",
       " 'market': 520,\n",
       " 'catholic': 521,\n",
       " 'instead': 522,\n",
       " 'iowa': 523,\n",
       " 'federal': 524,\n",
       " 'drive': 525,\n",
       " 'sing': 526,\n",
       " 'animals': 527,\n",
       " 'especially': 528,\n",
       " 'northwestern': 529,\n",
       " 'scale': 530,\n",
       " 'disney': 531,\n",
       " 'genus': 532,\n",
       " 'michael': 533,\n",
       " 'thomas': 534,\n",
       " 'duke': 535,\n",
       " 'count': 536,\n",
       " 'retire': 537,\n",
       " 'guitar': 538,\n",
       " 'paint': 539,\n",
       " 'soviet': 540,\n",
       " 'act': 541,\n",
       " 'away': 542,\n",
       " 'brand': 543,\n",
       " 'peter': 544,\n",
       " 'wales': 545,\n",
       " 'territory': 546,\n",
       " 'traditional': 547,\n",
       " 'mass': 548,\n",
       " 'bird': 549,\n",
       " 'britain': 550,\n",
       " 'add': 551,\n",
       " 'enter': 552,\n",
       " 'stop': 553,\n",
       " 'airport': 554,\n",
       " 'mountain': 555,\n",
       " 'production': 556,\n",
       " 'travel': 557,\n",
       " 'voice': 558,\n",
       " 'blood': 559,\n",
       " 'fish': 560,\n",
       " 'wikipedia': 561,\n",
       " 'look': 562,\n",
       " 'approximately': 563,\n",
       " 'stage': 564,\n",
       " 'native': 565,\n",
       " 'announce': 566,\n",
       " 'child': 567,\n",
       " 'louis': 568,\n",
       " 'stone': 569,\n",
       " 'effect': 570,\n",
       " 'length': 571,\n",
       " 'shape': 572,\n",
       " 'gold': 573,\n",
       " 'politician': 574,\n",
       " 'bridge': 575,\n",
       " 'unit': 576,\n",
       " 'teach': 577,\n",
       " 'figure': 578,\n",
       " 'finish': 579,\n",
       " 'mexico': 580,\n",
       " 'standard': 581,\n",
       " 'civil': 582,\n",
       " 'engineer': 583,\n",
       " 'oldest': 584,\n",
       " 'define': 585,\n",
       " 'units': 586,\n",
       " 'branch': 587,\n",
       " 'available': 588,\n",
       " 'winter': 589,\n",
       " 'data': 590,\n",
       " 'damage': 591,\n",
       " 'society': 592,\n",
       " 'chart': 593,\n",
       " 'outside': 594,\n",
       " 'lord': 595,\n",
       " 'successful': 596,\n",
       " 'associate': 597,\n",
       " 'channel': 598,\n",
       " 'picture': 599,\n",
       " 'distance': 600,\n",
       " 'heat': 601,\n",
       " 'musical': 602,\n",
       " 'decide': 603,\n",
       " 'washington': 604,\n",
       " 'governor': 605,\n",
       " 'rank': 606,\n",
       " 'academy': 607,\n",
       " 'action': 608,\n",
       " 'read': 609,\n",
       " 'limit': 610,\n",
       " 'round': 611,\n",
       " 'lie': 612,\n",
       " 'minor': 613,\n",
       " 'super': 614,\n",
       " 'pacific': 615,\n",
       " 'virginia': 616,\n",
       " 'real': 617,\n",
       " 'grind': 618,\n",
       " 'orbit': 619,\n",
       " 'average': 620,\n",
       " 'upper': 621,\n",
       " 'edward': 622,\n",
       " 'require': 623,\n",
       " 'piece': 624,\n",
       " 'instrument': 625,\n",
       " 'strong': 626,\n",
       " 'draw': 627,\n",
       " 'episode': 628,\n",
       " 'education': 629,\n",
       " 'copy': 630,\n",
       " 'choose': 631,\n",
       " 'flow': 632,\n",
       " 'brown': 633,\n",
       " 'police': 634,\n",
       " 'chief': 635,\n",
       " 'websites': 636,\n",
       " 'manager': 637,\n",
       " 'try': 638,\n",
       " 'smaller': 639,\n",
       " 'windows': 640,\n",
       " 'section': 641,\n",
       " 'premier': 642,\n",
       " 'martin': 643,\n",
       " 'chicago': 644,\n",
       " 'secretary': 645,\n",
       " 'artist': 646,\n",
       " 'mainly': 647,\n",
       " 'dance': 648,\n",
       " 'baseball': 649,\n",
       " 'score': 650,\n",
       " 'dynasty': 651,\n",
       " 'russia': 652,\n",
       " 'news': 653,\n",
       " 'attempt': 654,\n",
       " 'larger': 655,\n",
       " 'function': 656,\n",
       " 'estimate': 657,\n",
       " 'texas': 658,\n",
       " 'mountains': 659,\n",
       " 'store': 660,\n",
       " 'mary': 661,\n",
       " 'parent': 662,\n",
       " 'arts': 663,\n",
       " 'flower': 664,\n",
       " 'angeles': 665,\n",
       " 'business': 666,\n",
       " 'wear': 667,\n",
       " 'wall': 668,\n",
       " 'compose': 669,\n",
       " 'label': 670,\n",
       " 'soon': 671,\n",
       " 'cathedral': 672,\n",
       " 'carry': 673,\n",
       " 'nintendo': 674,\n",
       " 'festival': 675,\n",
       " 'performance': 676,\n",
       " 'administrative': 677,\n",
       " 'peak': 678,\n",
       " 'victoria': 679,\n",
       " 'albums': 680,\n",
       " 'fiction': 681,\n",
       " 'metropolitan': 682,\n",
       " 'woman': 683,\n",
       " 'learn': 684,\n",
       " 'students': 685,\n",
       " 'connect': 686,\n",
       " 'alpes': 687,\n",
       " 'nations': 688,\n",
       " 'irish': 689,\n",
       " 'magazine': 690,\n",
       " 'nuclear': 691,\n",
       " 'producer': 692,\n",
       " 'forest': 693,\n",
       " 'flag': 694,\n",
       " 'ball': 695,\n",
       " 'success': 696,\n",
       " 'wide': 697,\n",
       " 'display': 698,\n",
       " 'conductor': 699,\n",
       " 'months': 700,\n",
       " 'face': 701,\n",
       " 'typically': 702,\n",
       " 'cell': 703,\n",
       " 'measure': 704,\n",
       " 'surround': 705,\n",
       " 'centre': 706,\n",
       " 'female': 707,\n",
       " 'beach': 708,\n",
       " 'board': 709,\n",
       " 'own': 710,\n",
       " 'material': 711,\n",
       " 'recognize': 712,\n",
       " 'value': 713,\n",
       " 'block': 714,\n",
       " 'certain': 715,\n",
       " 'nobel': 716,\n",
       " 'able': 717,\n",
       " 'addition': 718,\n",
       " 'talk': 719,\n",
       " 'conduct': 720,\n",
       " 'reason': 721,\n",
       " 'african': 722,\n",
       " 'destroy': 723,\n",
       " 'speed': 724,\n",
       " 'animal': 725,\n",
       " 'austria': 726,\n",
       " 'arm': 727,\n",
       " 'electric': 728,\n",
       " 'peace': 729,\n",
       " 'derive': 730,\n",
       " 'museum': 731,\n",
       " 'text': 732,\n",
       " 'birth': 733,\n",
       " 'brazil': 734,\n",
       " 'money': 735,\n",
       " 'dark': 736,\n",
       " 'castle': 737,\n",
       " 'things': 738,\n",
       " 'coach': 739,\n",
       " 'greater': 740,\n",
       " 'concert': 741,\n",
       " 'rail': 742,\n",
       " 'religious': 743,\n",
       " 'suggest': 744,\n",
       " 'spring': 745,\n",
       " 'heavy': 746,\n",
       " 'widely': 747,\n",
       " 'cells': 748,\n",
       " 'pope': 749,\n",
       " 'wing': 750,\n",
       " 'belong': 751,\n",
       " 'election': 752,\n",
       " 'edition': 753,\n",
       " 'engine': 754,\n",
       " 'sister': 755,\n",
       " 'hard': 756,\n",
       " 'visit': 757,\n",
       " 'physical': 758,\n",
       " 'institute': 759,\n",
       " 'test': 760,\n",
       " 'offer': 761,\n",
       " 'netherlands': 762,\n",
       " 'compound': 763,\n",
       " 'belgian': 764,\n",
       " 'pressure': 765,\n",
       " 'purpose': 766,\n",
       " 'higher': 767,\n",
       " 'oklahoma': 768,\n",
       " 'independence': 769,\n",
       " 'wave': 770,\n",
       " 'garden': 771,\n",
       " 'eventually': 772,\n",
       " 'mario': 773,\n",
       " 'practice': 774,\n",
       " 'picardy': 775,\n",
       " 'lady': 776,\n",
       " 'primary': 777,\n",
       " 'camp': 778,\n",
       " 'honor': 779,\n",
       " 'charge': 780,\n",
       " 'golden': 781,\n",
       " 'press': 782,\n",
       " 'officer': 783,\n",
       " 'spend': 784,\n",
       " 'borough': 785,\n",
       " 'mount': 786,\n",
       " 'condition': 787,\n",
       " 'combine': 788,\n",
       " 'gain': 789,\n",
       " 'private': 790,\n",
       " 'media': 791,\n",
       " 'extend': 792,\n",
       " 'romania': 793,\n",
       " 'guitarist': 794,\n",
       " 'musician': 795,\n",
       " 'zealand': 796,\n",
       " 'double': 797,\n",
       " 'code': 798,\n",
       " 'joseph': 799,\n",
       " 'treaty': 800,\n",
       " 'symbol': 801,\n",
       " 'situate': 802,\n",
       " 'jupiter': 803,\n",
       " 'category': 804,\n",
       " 'rest': 805,\n",
       " 'spell': 806,\n",
       " 'professor': 807,\n",
       " 'possible': 808,\n",
       " 'comedy': 809,\n",
       " 'towns': 810,\n",
       " 'raise': 811,\n",
       " 'heart': 812,\n",
       " 'sarthe': 813,\n",
       " 'doctor': 814,\n",
       " 'survive': 815,\n",
       " 'website': 816,\n",
       " 'holy': 817,\n",
       " 'string': 818,\n",
       " 'illinois': 819,\n",
       " 'songwriter': 820,\n",
       " 'attend': 821,\n",
       " 'paper': 822,\n",
       " 'declare': 823,\n",
       " 'worldwide': 824,\n",
       " 'particularly': 825,\n",
       " 'nature': 826,\n",
       " 'subject': 827,\n",
       " 'broadcast': 828,\n",
       " 'status': 829,\n",
       " 'active': 830,\n",
       " 'regions': 831,\n",
       " 'air': 832,\n",
       " 'internet': 833,\n",
       " 'machine': 834,\n",
       " 'economic': 835,\n",
       " 'historical': 836,\n",
       " 'location': 837,\n",
       " 'master': 838,\n",
       " 'fifth': 839,\n",
       " 'humans': 840,\n",
       " 'apply': 841,\n",
       " 'inside': 842,\n",
       " 'animate': 843,\n",
       " 'dead': 844,\n",
       " 'cold': 845,\n",
       " 'nickname': 846,\n",
       " 'temperature': 847,\n",
       " 'classical': 848,\n",
       " 'card': 849,\n",
       " 'austrian': 850,\n",
       " 'democratic': 851,\n",
       " 'roll': 852,\n",
       " 'multiple': 853,\n",
       " 'stories': 854,\n",
       " 'manchester': 855,\n",
       " 'elements': 856,\n",
       " 'yellow': 857,\n",
       " 'alternative': 858,\n",
       " 'planet': 859,\n",
       " 'particular': 860,\n",
       " 'happen': 861,\n",
       " 'bass': 862,\n",
       " 'poland': 863,\n",
       " 'industry': 864,\n",
       " 'urban': 865,\n",
       " 'health': 866,\n",
       " 'revolution': 867,\n",
       " 'jesus': 868,\n",
       " 'olympic': 869,\n",
       " 'harry': 870,\n",
       " 'draft': 871,\n",
       " 'nation': 872,\n",
       " 'appoint': 873,\n",
       " 'jewish': 874,\n",
       " 'experience': 875,\n",
       " 'primarily': 876,\n",
       " 'feet': 877,\n",
       " 'elizabeth': 878,\n",
       " 'launch': 879,\n",
       " 'access': 880,\n",
       " 'future': 881,\n",
       " 'carolina': 882,\n",
       " 'nearly': 883,\n",
       " 'adopt': 884,\n",
       " 'foreign': 885,\n",
       " 'individual': 886,\n",
       " 'prix': 887,\n",
       " 'rat': 888,\n",
       " 'friend': 889,\n",
       " 'chess': 890,\n",
       " 'recent': 891,\n",
       " 'true': 892,\n",
       " 'regular': 893,\n",
       " 'file': 894,\n",
       " 'korea': 895,\n",
       " 'statistics': 896,\n",
       " 'advance': 897,\n",
       " 'older': 898,\n",
       " 'captain': 899,\n",
       " 'depression': 900,\n",
       " 'graduate': 901,\n",
       " 'literature': 902,\n",
       " 'capture': 903,\n",
       " 'keep': 904,\n",
       " 'piano': 905,\n",
       " 'disease': 906,\n",
       " 'zone': 907,\n",
       " 'founder': 908,\n",
       " 'shoot': 909,\n",
       " 'complex': 910,\n",
       " 'account': 911,\n",
       " 'peninsula': 912,\n",
       " 'southeast': 913,\n",
       " 'inhabitants': 914,\n",
       " 'ask': 915,\n",
       " 'earlier': 916,\n",
       " 'commercial': 917,\n",
       " 'greatest': 918,\n",
       " 'medical': 919,\n",
       " 'basketball': 920,\n",
       " 'despite': 921,\n",
       " 'conference': 922,\n",
       " 'poet': 923,\n",
       " 'protect': 924,\n",
       " 'license': 925,\n",
       " 'age': 926,\n",
       " 'previously': 927,\n",
       " 'simple': 928,\n",
       " 'southeastern': 929,\n",
       " 'user': 930,\n",
       " 'fame': 931,\n",
       " 'solar': 932,\n",
       " 'soldier': 933,\n",
       " 'egypt': 934,\n",
       " 'rome': 935,\n",
       " 'degree': 936,\n",
       " 'southwestern': 937,\n",
       " 'male': 938,\n",
       " 'cook': 939,\n",
       " 'succeed': 940,\n",
       " 'hours': 941,\n",
       " 'swedish': 942,\n",
       " 'directly': 943,\n",
       " 'horse': 944,\n",
       " 'collection': 945,\n",
       " 'iron': 946,\n",
       " 'library': 947,\n",
       " 'variety': 948,\n",
       " 'principal': 949,\n",
       " 'digital': 950,\n",
       " 'crown': 951,\n",
       " 'probably': 952,\n",
       " 'brothers': 953,\n",
       " 'armenian': 954,\n",
       " 'discovery': 955,\n",
       " 'korean': 956,\n",
       " 'previous': 957,\n",
       " 'print': 958,\n",
       " 'alexander': 959,\n",
       " 'construction': 960,\n",
       " 'notable': 961,\n",
       " 'accept': 962,\n",
       " 'weather': 963,\n",
       " 'santa': 964,\n",
       " 'friends': 965,\n",
       " 'table': 966,\n",
       " 'theme': 967,\n",
       " 'competition': 968,\n",
       " 'medicine': 969,\n",
       " 'idea': 970,\n",
       " 'personal': 971,\n",
       " 'war': 972,\n",
       " 'past': 973,\n",
       " 'longer': 974,\n",
       " 'scott': 975,\n",
       " 'deal': 976,\n",
       " 'review': 977,\n",
       " 'grant': 978,\n",
       " 'remove': 979,\n",
       " 'drama': 980,\n",
       " 'vocals': 981,\n",
       " 'reduce': 982,\n",
       " 'focus': 983,\n",
       " 'campaign': 984,\n",
       " 'comprise': 985,\n",
       " 'circuit': 986,\n",
       " 'biggest': 987,\n",
       " 'challenge': 988,\n",
       " 'stay': 989,\n",
       " 'rename': 990,\n",
       " 'saturn': 991,\n",
       " 'organize': 992,\n",
       " 'beat': 993,\n",
       " 'counties': 994,\n",
       " 'foundation': 995,\n",
       " 'entire': 996,\n",
       " 'compete': 997,\n",
       " 'week': 998,\n",
       " 'annual': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors[0] == word_vectors['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4289"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_in_vector = word_vectors.index_to_key\n",
    "len(words_in_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word's Difficulty Considered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "== Concreteness_ratings_Brysbaert_et_al_BRM.txt ==\n",
    "\n",
    "This file contains concreteness ratings for 40 thousand English lemma words gathered via Amazon Mechanical Turk. The ratings come from a larger list of 63 thousand words and represent all English words known to 85% of the raters.\n",
    "\n",
    "The file contains eight columns:\n",
    "1. The word\n",
    "2. Whether it is a single word or a two-word expression \n",
    "3. The mean concreteness rating\n",
    "4. The standard deviation of the concreteness ratings\n",
    "5. The number of persons indicating they did not know the word\n",
    "6. The total number of persons who rated the word\n",
    "7. Percentage participants who knew the word\n",
    "8. The SUBTLEX-US frequency count (on a total of 51 million; Brysbaert & New, 2009) \n",
    "9. The dominant part-of-speech usage\n",
    "\n",
    "Original source: http://crr.ugent.be/archives/1330\n",
    "\n",
    "Brysbaert, M., Warriner, A.B., & Kuperman, V. (2014). Concreteness ratings for 40 thousand generally known English word lemmas. Behavior Research Methods, 46, 904-911.\n",
    "http://crr.ugent.be/papers/Brysbaert_Warriner_Kuperman_BRM_Concreteness_ratings.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concreteness rating - the higher Conc.M, the easier the word is.\n",
    "concreteness_path = 'Data/Concreteness_ratings_Brysbaert_et_al_BRM.txt'\n",
    "concrete_df = pd.read_csv(concreteness_path,delimiter='\\t', keep_default_na=False)\n",
    "concreteset=(concrete_df['Word'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Bigram</th>\n",
       "      <th>Conc.M</th>\n",
       "      <th>Conc.SD</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent_known</th>\n",
       "      <th>SUBTLEX</th>\n",
       "      <th>Dom_Pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>roadsweeper</td>\n",
       "      <td>0</td>\n",
       "      <td>4.85</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>traindriver</td>\n",
       "      <td>0</td>\n",
       "      <td>4.54</td>\n",
       "      <td>0.71</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tush</td>\n",
       "      <td>0</td>\n",
       "      <td>4.45</td>\n",
       "      <td>1.01</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>0.88</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hairdress</td>\n",
       "      <td>0</td>\n",
       "      <td>3.93</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pharmaceutics</td>\n",
       "      <td>0</td>\n",
       "      <td>3.77</td>\n",
       "      <td>1.41</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hoover</td>\n",
       "      <td>0</td>\n",
       "      <td>3.76</td>\n",
       "      <td>1.23</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>0.86</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>shopkeeping</td>\n",
       "      <td>0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pushiness</td>\n",
       "      <td>0</td>\n",
       "      <td>2.48</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>underdevelop</td>\n",
       "      <td>0</td>\n",
       "      <td>2.37</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tirelessness</td>\n",
       "      <td>0</td>\n",
       "      <td>2.28</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>oldfashioned</td>\n",
       "      <td>0</td>\n",
       "      <td>2.26</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>wellmannered</td>\n",
       "      <td>0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1.14</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>dismissiveness</td>\n",
       "      <td>0</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>spitefulness</td>\n",
       "      <td>0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>untruthfulness</td>\n",
       "      <td>0</td>\n",
       "      <td>1.73</td>\n",
       "      <td>0.92</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dispiritedness</td>\n",
       "      <td>0</td>\n",
       "      <td>1.56</td>\n",
       "      <td>0.71</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sled</td>\n",
       "      <td>0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1.00</td>\n",
       "      <td>149</td>\n",
       "      <td>Adjective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>plunger</td>\n",
       "      <td>0</td>\n",
       "      <td>4.96</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>1.00</td>\n",
       "      <td>48</td>\n",
       "      <td>Adjective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "      <td>4.93</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6363</td>\n",
       "      <td>Adjective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>waterbed</td>\n",
       "      <td>0</td>\n",
       "      <td>4.93</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1.00</td>\n",
       "      <td>27</td>\n",
       "      <td>Adjective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>cymbal</td>\n",
       "      <td>0</td>\n",
       "      <td>4.92</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.96</td>\n",
       "      <td>13</td>\n",
       "      <td>Adjective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ginger</td>\n",
       "      <td>0</td>\n",
       "      <td>4.92</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>1.00</td>\n",
       "      <td>327</td>\n",
       "      <td>Adjective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>bobsled</td>\n",
       "      <td>0</td>\n",
       "      <td>4.90</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>48</td>\n",
       "      <td>Adjective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>cardboard</td>\n",
       "      <td>0</td>\n",
       "      <td>4.90</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>138</td>\n",
       "      <td>Adjective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>olive</td>\n",
       "      <td>0</td>\n",
       "      <td>4.90</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1.00</td>\n",
       "      <td>375</td>\n",
       "      <td>Adjective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>dogsled</td>\n",
       "      <td>0</td>\n",
       "      <td>4.89</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>Adjective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>rubber</td>\n",
       "      <td>0</td>\n",
       "      <td>4.86</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>714</td>\n",
       "      <td>Adjective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>soybean</td>\n",
       "      <td>0</td>\n",
       "      <td>4.82</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1.00</td>\n",
       "      <td>25</td>\n",
       "      <td>Adjective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>tangerine</td>\n",
       "      <td>0</td>\n",
       "      <td>4.81</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1.00</td>\n",
       "      <td>38</td>\n",
       "      <td>Adjective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>headrest</td>\n",
       "      <td>0</td>\n",
       "      <td>4.80</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6</td>\n",
       "      <td>Adjective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39924</th>\n",
       "      <td>inapprehensive</td>\n",
       "      <td>0</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39925</th>\n",
       "      <td>inscrutableness</td>\n",
       "      <td>0</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.61</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39926</th>\n",
       "      <td>irrespectively</td>\n",
       "      <td>0</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39927</th>\n",
       "      <td>legalism</td>\n",
       "      <td>0</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.76</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39928</th>\n",
       "      <td>indeterminately</td>\n",
       "      <td>0</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.62</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39929</th>\n",
       "      <td>unexceptionably</td>\n",
       "      <td>0</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.55</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39930</th>\n",
       "      <td>acceptableness</td>\n",
       "      <td>0</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.54</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39931</th>\n",
       "      <td>figurativeness</td>\n",
       "      <td>0</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39932</th>\n",
       "      <td>hallowedness</td>\n",
       "      <td>0</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.68</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39933</th>\n",
       "      <td>prophetical</td>\n",
       "      <td>0</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39934</th>\n",
       "      <td>futureless</td>\n",
       "      <td>0</td>\n",
       "      <td>1.27</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39935</th>\n",
       "      <td>improvable</td>\n",
       "      <td>0</td>\n",
       "      <td>1.27</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39936</th>\n",
       "      <td>undisputedly</td>\n",
       "      <td>0</td>\n",
       "      <td>1.27</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39937</th>\n",
       "      <td>unendingly</td>\n",
       "      <td>0</td>\n",
       "      <td>1.27</td>\n",
       "      <td>0.55</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39938</th>\n",
       "      <td>unmeant</td>\n",
       "      <td>0</td>\n",
       "      <td>1.27</td>\n",
       "      <td>0.55</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39939</th>\n",
       "      <td>answerability</td>\n",
       "      <td>0</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.62</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39940</th>\n",
       "      <td>objectivism</td>\n",
       "      <td>0</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.71</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39941</th>\n",
       "      <td>treasonously</td>\n",
       "      <td>0</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.86</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39942</th>\n",
       "      <td>knowingness</td>\n",
       "      <td>0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.53</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39943</th>\n",
       "      <td>advantageously</td>\n",
       "      <td>0</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0.44</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39944</th>\n",
       "      <td>inconclusiveness</td>\n",
       "      <td>0</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39945</th>\n",
       "      <td>infinitively</td>\n",
       "      <td>0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.59</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39946</th>\n",
       "      <td>irresolutely</td>\n",
       "      <td>0</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.52</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39947</th>\n",
       "      <td>in principle</td>\n",
       "      <td>1</td>\n",
       "      <td>1.21</td>\n",
       "      <td>0.41</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39948</th>\n",
       "      <td>interpretively</td>\n",
       "      <td>0</td>\n",
       "      <td>1.21</td>\n",
       "      <td>0.51</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39949</th>\n",
       "      <td>unenvied</td>\n",
       "      <td>0</td>\n",
       "      <td>1.21</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39950</th>\n",
       "      <td>agnostically</td>\n",
       "      <td>0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39951</th>\n",
       "      <td>conceptualistic</td>\n",
       "      <td>0</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.50</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39952</th>\n",
       "      <td>conventionalism</td>\n",
       "      <td>0</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39953</th>\n",
       "      <td>essentialness</td>\n",
       "      <td>0</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39954 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Word  Bigram  Conc.M  Conc.SD  Unknown  Total  \\\n",
       "0           roadsweeper       0    4.85     0.37        1     27   \n",
       "1           traindriver       0    4.54     0.71        3     29   \n",
       "2                  tush       0    4.45     1.01        3     25   \n",
       "3             hairdress       0    3.93     1.28        0     29   \n",
       "4         pharmaceutics       0    3.77     1.41        4     26   \n",
       "5                hoover       0    3.76     1.23        4     29   \n",
       "6           shopkeeping       0    3.18     1.19        1     29   \n",
       "7             pushiness       0    2.48     1.24        1     30   \n",
       "8          underdevelop       0    2.37     1.40        0     30   \n",
       "9          tirelessness       0    2.28     1.28        1     30   \n",
       "10         oldfashioned       0    2.26     1.02        0     27   \n",
       "11         wellmannered       0    2.25     1.14        2     30   \n",
       "12       dismissiveness       0    1.83     1.00        1     30   \n",
       "13         spitefulness       0    1.80     0.76        0     25   \n",
       "14       untruthfulness       0    1.73     0.92        4     30   \n",
       "15       dispiritedness       0    1.56     0.71        3     28   \n",
       "16                 sled       0    5.00     0.00        0     28   \n",
       "17              plunger       0    4.96     0.20        0     26   \n",
       "18                human       0    4.93     0.26        0     28   \n",
       "19             waterbed       0    4.93     0.27        0     27   \n",
       "20               cymbal       0    4.92     0.28        1     25   \n",
       "21               ginger       0    4.92     0.27        0     26   \n",
       "22              bobsled       0    4.90     0.41        0     29   \n",
       "23            cardboard       0    4.90     0.41        0     29   \n",
       "24                olive       0    4.90     0.31        0     30   \n",
       "25              dogsled       0    4.89     0.32        0     27   \n",
       "26               rubber       0    4.86     0.74        0     29   \n",
       "27              soybean       0    4.82     0.77        0     28   \n",
       "28            tangerine       0    4.81     0.62        0     27   \n",
       "29             headrest       0    4.80     0.76        0     30   \n",
       "...                 ...     ...     ...      ...      ...    ...   \n",
       "39924    inapprehensive       0    1.30     0.54        1     28   \n",
       "39925   inscrutableness       0    1.30     0.61        3     30   \n",
       "39926    irrespectively       0    1.30     0.67        0     27   \n",
       "39927          legalism       0    1.30     0.76        3     26   \n",
       "39928   indeterminately       0    1.29     0.62        4     28   \n",
       "39929   unexceptionably       0    1.29     0.55        4     28   \n",
       "39930    acceptableness       0    1.28     0.54        4     29   \n",
       "39931    figurativeness       0    1.28     0.59        1     30   \n",
       "39932      hallowedness       0    1.28     0.68        4     29   \n",
       "39933       prophetical       0    1.28     0.59        1     30   \n",
       "39934        futureless       0    1.27     0.52        1     31   \n",
       "39935        improvable       0    1.27     0.52        0     30   \n",
       "39936      undisputedly       0    1.27     0.53        2     28   \n",
       "39937        unendingly       0    1.27     0.55        3     25   \n",
       "39938           unmeant       0    1.27     0.55        3     25   \n",
       "39939     answerability       0    1.26     0.62        4     27   \n",
       "39940       objectivism       0    1.26     0.71        2     29   \n",
       "39941      treasonously       0    1.26     0.86        2     25   \n",
       "39942       knowingness       0    1.25     0.53        3     27   \n",
       "39943    advantageously       0    1.24     0.44        3     28   \n",
       "39944  inconclusiveness       0    1.24     0.52        0     25   \n",
       "39945      infinitively       0    1.23     0.59        3     29   \n",
       "39946      irresolutely       0    1.22     0.52        3     26   \n",
       "39947      in principle       1    1.21     0.41        4     28   \n",
       "39948    interpretively       0    1.21     0.51        1     25   \n",
       "39949          unenvied       0    1.21     0.62        1     30   \n",
       "39950      agnostically       0    1.20     0.50        2     27   \n",
       "39951   conceptualistic       0    1.18     0.50        4     26   \n",
       "39952   conventionalism       0    1.18     0.48        1     29   \n",
       "39953     essentialness       0    1.04     0.20        2     26   \n",
       "\n",
       "       Percent_known  SUBTLEX    Dom_Pos  \n",
       "0               0.96        0          0  \n",
       "1               0.90        0          0  \n",
       "2               0.88       66          0  \n",
       "3               1.00        1          0  \n",
       "4               0.85        0          0  \n",
       "5               0.86      162          0  \n",
       "6               0.97        0          0  \n",
       "7               0.97        0          0  \n",
       "8               1.00        0          0  \n",
       "9               0.97        0          0  \n",
       "10              1.00        0          0  \n",
       "11              0.93        0          0  \n",
       "12              0.97        0          0  \n",
       "13              1.00        0          0  \n",
       "14              0.87        0          0  \n",
       "15              0.89        0          0  \n",
       "16              1.00      149  Adjective  \n",
       "17              1.00       48  Adjective  \n",
       "18              1.00     6363  Adjective  \n",
       "19              1.00       27  Adjective  \n",
       "20              0.96       13  Adjective  \n",
       "21              1.00      327  Adjective  \n",
       "22              1.00       48  Adjective  \n",
       "23              1.00      138  Adjective  \n",
       "24              1.00      375  Adjective  \n",
       "25              1.00        2  Adjective  \n",
       "26              1.00      714  Adjective  \n",
       "27              1.00       25  Adjective  \n",
       "28              1.00       38  Adjective  \n",
       "29              1.00        6  Adjective  \n",
       "...              ...      ...        ...  \n",
       "39924           0.96        0       #N/A  \n",
       "39925           0.90        0       #N/A  \n",
       "39926           1.00        0       #N/A  \n",
       "39927           0.88        0       #N/A  \n",
       "39928           0.86        0       #N/A  \n",
       "39929           0.86        0       #N/A  \n",
       "39930           0.86        0       #N/A  \n",
       "39931           0.97        0       #N/A  \n",
       "39932           0.86        0       #N/A  \n",
       "39933           0.97        0       #N/A  \n",
       "39934           0.97        0       #N/A  \n",
       "39935           1.00        0       #N/A  \n",
       "39936           0.93        0       #N/A  \n",
       "39937           0.88        0       #N/A  \n",
       "39938           0.88        0       #N/A  \n",
       "39939           0.85        0       #N/A  \n",
       "39940           0.93        0       #N/A  \n",
       "39941           0.92        0       #N/A  \n",
       "39942           0.89        0       #N/A  \n",
       "39943           0.89        0       #N/A  \n",
       "39944           1.00        0       #N/A  \n",
       "39945           0.90        0       #N/A  \n",
       "39946           0.88        0       #N/A  \n",
       "39947           0.86        0       #N/A  \n",
       "39948           0.96        0       #N/A  \n",
       "39949           0.97        0       #N/A  \n",
       "39950           0.93        0       #N/A  \n",
       "39951           0.85        0       #N/A  \n",
       "39952           0.97        0       #N/A  \n",
       "39953           0.92        0       #N/A  \n",
       "\n",
       "[39954 rows x 9 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    37058\n",
       "1     2896\n",
       "Name: Bigram, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_df.Bigram.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Bigram</th>\n",
       "      <th>Conc.M</th>\n",
       "      <th>Conc.SD</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent_known</th>\n",
       "      <th>SUBTLEX</th>\n",
       "      <th>Dom_Pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28707</th>\n",
       "      <td>baking soda</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28709</th>\n",
       "      <td>baseball bat</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28710</th>\n",
       "      <td>bath towel</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28711</th>\n",
       "      <td>beach ball</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28712</th>\n",
       "      <td>bed sheet</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28714</th>\n",
       "      <td>big toe</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28715</th>\n",
       "      <td>birth certificate</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28716</th>\n",
       "      <td>bomb shelter</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28717</th>\n",
       "      <td>bowling ball</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28718</th>\n",
       "      <td>brussels sprouts</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28719</th>\n",
       "      <td>business card</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28720</th>\n",
       "      <td>cassette player</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28722</th>\n",
       "      <td>cement mixer</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28723</th>\n",
       "      <td>chain saw</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28724</th>\n",
       "      <td>chicken breast</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28725</th>\n",
       "      <td>chocolate bar</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28726</th>\n",
       "      <td>chocolate cake</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28727</th>\n",
       "      <td>cigarette butt</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28728</th>\n",
       "      <td>coffee cup</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28729</th>\n",
       "      <td>coffee machine</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28730</th>\n",
       "      <td>computer mouse</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28731</th>\n",
       "      <td>coral snake</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28732</th>\n",
       "      <td>cream cheese</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28733</th>\n",
       "      <td>dill pickle</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28734</th>\n",
       "      <td>dirt bike</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28735</th>\n",
       "      <td>evening dress</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28736</th>\n",
       "      <td>eye drops</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28739</th>\n",
       "      <td>fishing boat</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28740</th>\n",
       "      <td>football helmet</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28741</th>\n",
       "      <td>french horn</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38596</th>\n",
       "      <td>fast track</td>\n",
       "      <td>1</td>\n",
       "      <td>1.74</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38714</th>\n",
       "      <td>double standard</td>\n",
       "      <td>1</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38718</th>\n",
       "      <td>give in</td>\n",
       "      <td>1</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38729</th>\n",
       "      <td>problem solving</td>\n",
       "      <td>1</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38878</th>\n",
       "      <td>in vain</td>\n",
       "      <td>1</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38891</th>\n",
       "      <td>moral sense</td>\n",
       "      <td>1</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38902</th>\n",
       "      <td>take for</td>\n",
       "      <td>1</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38938</th>\n",
       "      <td>dog days</td>\n",
       "      <td>1</td>\n",
       "      <td>1.68</td>\n",
       "      <td>1.07</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38988</th>\n",
       "      <td>better off</td>\n",
       "      <td>1</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39008</th>\n",
       "      <td>human nature</td>\n",
       "      <td>1</td>\n",
       "      <td>1.67</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39027</th>\n",
       "      <td>present tense</td>\n",
       "      <td>1</td>\n",
       "      <td>1.67</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39061</th>\n",
       "      <td>wise up</td>\n",
       "      <td>1</td>\n",
       "      <td>1.66</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39184</th>\n",
       "      <td>soul searching</td>\n",
       "      <td>1</td>\n",
       "      <td>1.63</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39215</th>\n",
       "      <td>hard up</td>\n",
       "      <td>1</td>\n",
       "      <td>1.62</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39228</th>\n",
       "      <td>on average</td>\n",
       "      <td>1</td>\n",
       "      <td>1.62</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39266</th>\n",
       "      <td>resort to</td>\n",
       "      <td>1</td>\n",
       "      <td>1.61</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39300</th>\n",
       "      <td>so so</td>\n",
       "      <td>1</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.71</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39302</th>\n",
       "      <td>thus far</td>\n",
       "      <td>1</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.12</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39438</th>\n",
       "      <td>life assurance</td>\n",
       "      <td>1</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39464</th>\n",
       "      <td>free will</td>\n",
       "      <td>1</td>\n",
       "      <td>1.56</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39468</th>\n",
       "      <td>ill will</td>\n",
       "      <td>1</td>\n",
       "      <td>1.56</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39496</th>\n",
       "      <td>good natured</td>\n",
       "      <td>1</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39498</th>\n",
       "      <td>in demand</td>\n",
       "      <td>1</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39536</th>\n",
       "      <td>high time</td>\n",
       "      <td>1</td>\n",
       "      <td>1.54</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39613</th>\n",
       "      <td>quantum leap</td>\n",
       "      <td>1</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39619</th>\n",
       "      <td>tantamount to</td>\n",
       "      <td>1</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.85</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39857</th>\n",
       "      <td>chance on</td>\n",
       "      <td>1</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39871</th>\n",
       "      <td>free rein</td>\n",
       "      <td>1</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0.63</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39899</th>\n",
       "      <td>by chance</td>\n",
       "      <td>1</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39947</th>\n",
       "      <td>in principle</td>\n",
       "      <td>1</td>\n",
       "      <td>1.21</td>\n",
       "      <td>0.41</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2896 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Word  Bigram  Conc.M  Conc.SD  Unknown  Total  \\\n",
       "28707        baking soda       1    5.00     0.00        0     30   \n",
       "28709       baseball bat       1    5.00     0.00        0     29   \n",
       "28710         bath towel       1    5.00     0.00        0     29   \n",
       "28711         beach ball       1    5.00     0.00        0     28   \n",
       "28712          bed sheet       1    5.00     0.00        0     28   \n",
       "28714            big toe       1    5.00     0.00        1     29   \n",
       "28715  birth certificate       1    5.00     0.00        0     27   \n",
       "28716       bomb shelter       1    5.00     0.00        0     28   \n",
       "28717       bowling ball       1    5.00     0.00        0     30   \n",
       "28718   brussels sprouts       1    5.00     0.00        0     28   \n",
       "28719      business card       1    5.00     0.00        0     29   \n",
       "28720    cassette player       1    5.00     0.00        0     28   \n",
       "28722       cement mixer       1    5.00     0.00        1     29   \n",
       "28723          chain saw       1    5.00     0.00        0     28   \n",
       "28724     chicken breast       1    5.00     0.00        0     25   \n",
       "28725      chocolate bar       1    5.00     0.00        0     27   \n",
       "28726     chocolate cake       1    5.00     0.00        0     28   \n",
       "28727     cigarette butt       1    5.00     0.00        0     27   \n",
       "28728         coffee cup       1    5.00     0.00        0     25   \n",
       "28729     coffee machine       1    5.00     0.00        0     29   \n",
       "28730     computer mouse       1    5.00     0.00        0     27   \n",
       "28731        coral snake       1    5.00     0.00        0     27   \n",
       "28732       cream cheese       1    5.00     0.00        0     28   \n",
       "28733        dill pickle       1    5.00     0.00        0     26   \n",
       "28734          dirt bike       1    5.00     0.00        0     27   \n",
       "28735      evening dress       1    5.00     0.00        0     29   \n",
       "28736          eye drops       1    5.00     0.00        0     27   \n",
       "28739       fishing boat       1    5.00     0.00        0     30   \n",
       "28740    football helmet       1    5.00     0.00        0     28   \n",
       "28741        french horn       1    5.00     0.00        0     28   \n",
       "...                  ...     ...     ...      ...      ...    ...   \n",
       "38596         fast track       1    1.74     0.90        0     27   \n",
       "38714    double standard       1    1.72     0.84        0     29   \n",
       "38718            give in       1    1.72     0.92        0     29   \n",
       "38729    problem solving       1    1.72     1.00        0     29   \n",
       "38878            in vain       1    1.69     0.85        1     30   \n",
       "38891        moral sense       1    1.69     1.00        1     30   \n",
       "38902           take for       1    1.69     1.11        1     30   \n",
       "38938           dog days       1    1.68     1.07        2     27   \n",
       "38988         better off       1    1.67     0.88        0     27   \n",
       "39008       human nature       1    1.67     1.11        0     27   \n",
       "39027      present tense       1    1.67     1.09        0     30   \n",
       "39061            wise up       1    1.66     0.90        0     29   \n",
       "39184     soul searching       1    1.63     0.81        0     30   \n",
       "39215            hard up       1    1.62     0.98        1     30   \n",
       "39228         on average       1    1.62     0.80        0     26   \n",
       "39266          resort to       1    1.61     1.07        1     29   \n",
       "39300              so so       1    1.60     0.71        1     26   \n",
       "39302           thus far       1    1.60     1.12        2     27   \n",
       "39438     life assurance       1    1.57     1.03        3     24   \n",
       "39464          free will       1    1.56     1.09        0     27   \n",
       "39468           ill will       1    1.56     1.12        0     27   \n",
       "39496       good natured       1    1.55     0.87        0     29   \n",
       "39498          in demand       1    1.55     0.91        0     29   \n",
       "39536          high time       1    1.54     0.76        1     27   \n",
       "39613       quantum leap       1    1.52     0.95        0     29   \n",
       "39619      tantamount to       1    1.52     0.85        4     27   \n",
       "39857          chance on       1    1.38     0.75        2     28   \n",
       "39871          free rein       1    1.37     0.63        2     29   \n",
       "39899          by chance       1    1.34     0.72        1     30   \n",
       "39947       in principle       1    1.21     0.41        4     28   \n",
       "\n",
       "       Percent_known  SUBTLEX Dom_Pos  \n",
       "28707           1.00        0    #N/A  \n",
       "28709           1.00        0    #N/A  \n",
       "28710           1.00        0    #N/A  \n",
       "28711           1.00        0    #N/A  \n",
       "28712           1.00        0    #N/A  \n",
       "28714           0.97        0    #N/A  \n",
       "28715           1.00        0    #N/A  \n",
       "28716           1.00        0    #N/A  \n",
       "28717           1.00        0    #N/A  \n",
       "28718           1.00        0    #N/A  \n",
       "28719           1.00        0    #N/A  \n",
       "28720           1.00        0    #N/A  \n",
       "28722           0.97        0    #N/A  \n",
       "28723           1.00        0    #N/A  \n",
       "28724           1.00        0    #N/A  \n",
       "28725           1.00        0    #N/A  \n",
       "28726           1.00        0    #N/A  \n",
       "28727           1.00        0    #N/A  \n",
       "28728           1.00        0    #N/A  \n",
       "28729           1.00        0    #N/A  \n",
       "28730           1.00        0    #N/A  \n",
       "28731           1.00        0    #N/A  \n",
       "28732           1.00        0    #N/A  \n",
       "28733           1.00        0    #N/A  \n",
       "28734           1.00        0    #N/A  \n",
       "28735           1.00        0    #N/A  \n",
       "28736           1.00        0    #N/A  \n",
       "28739           1.00        0    #N/A  \n",
       "28740           1.00        0    #N/A  \n",
       "28741           1.00        0    #N/A  \n",
       "...              ...      ...     ...  \n",
       "38596           1.00        0    #N/A  \n",
       "38714           1.00        0    #N/A  \n",
       "38718           1.00        0    #N/A  \n",
       "38729           1.00        0    #N/A  \n",
       "38878           0.97        0    #N/A  \n",
       "38891           0.97        0    #N/A  \n",
       "38902           0.97        0    #N/A  \n",
       "38938           0.93        0    #N/A  \n",
       "38988           1.00        0    #N/A  \n",
       "39008           1.00        0    #N/A  \n",
       "39027           1.00        0    #N/A  \n",
       "39061           1.00        0    #N/A  \n",
       "39184           1.00        0    #N/A  \n",
       "39215           0.97        0    #N/A  \n",
       "39228           1.00        0    #N/A  \n",
       "39266           0.97        0    #N/A  \n",
       "39300           0.96        0    #N/A  \n",
       "39302           0.93        0    #N/A  \n",
       "39438           0.88        0    #N/A  \n",
       "39464           1.00        0    #N/A  \n",
       "39468           1.00        0    #N/A  \n",
       "39496           1.00        0    #N/A  \n",
       "39498           1.00        0    #N/A  \n",
       "39536           0.96        0    #N/A  \n",
       "39613           1.00        0    #N/A  \n",
       "39619           0.85        0    #N/A  \n",
       "39857           0.93        0    #N/A  \n",
       "39871           0.93        0    #N/A  \n",
       "39899           0.97        0    #N/A  \n",
       "39947           0.86        0    #N/A  \n",
       "\n",
       "[2896 rows x 9 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_df[concrete_df.Bigram==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Bigram</th>\n",
       "      <th>Conc.M</th>\n",
       "      <th>Conc.SD</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent_known</th>\n",
       "      <th>SUBTLEX</th>\n",
       "      <th>Dom_Pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Word, Bigram, Conc.M, Conc.SD, Unknown, Total, Percent_known, SUBTLEX, Dom_Pos]\n",
       "Index: []"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#There is no Nan value in Conc.M column\n",
    "concrete_df[concrete_df['Conc.M'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are we gonna consider bigrams in this dataset, given it's only a small fraction ~ 8% in size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.04"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(concrete_df['Conc.M'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(concrete_df['Conc.M'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concreteness values range from 1 - 5, we could possible use the inverse value of concreteness to scale it to a 0-1 range and give easier words less weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_words = list(concrete_df['Word'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39954"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(concrete_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_complement = [word for word in words_in_vector if word not in concrete_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1183"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(concrete_complement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['france',\n",
       " 'american',\n",
       " 'years',\n",
       " 'english',\n",
       " 'british',\n",
       " 'calais',\n",
       " 'german',\n",
       " 'england',\n",
       " 'french',\n",
       " 'london',\n",
       " 'largest',\n",
       " 'ndash',\n",
       " 'germany',\n",
       " 'japanese',\n",
       " 'york',\n",
       " 'australia',\n",
       " 'america',\n",
       " 'members',\n",
       " 'nord',\n",
       " 'italian']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_complement[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_intersect = [word for word in words_in_vector if word in concrete_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3106"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(concrete_intersect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'state'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_intersect[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.372295  , -0.3264386 , -0.11591633,  0.10724376, -0.859541  ,\n",
       "       -0.31402323,  0.30943885, -0.2370478 , -0.02047741,  0.76785094,\n",
       "        0.66699207, -0.5079781 , -0.41995406, -0.90916175,  0.44861373,\n",
       "        0.37239227, -0.974161  , -0.17485079,  0.29458228,  0.2758199 ,\n",
       "        0.2652389 ,  0.84322256,  0.5988596 ,  0.7058779 ,  0.6509312 ,\n",
       "        0.02872065,  0.3975248 , -0.0038205 ,  0.25104943,  0.9827795 ,\n",
       "        1.2137177 , -0.5331144 ,  0.40142608, -0.45400727,  1.0007509 ,\n",
       "        0.8970303 ,  0.6914144 , -0.04437791, -0.16248846, -0.24229772,\n",
       "       -0.7975834 , -0.6311169 ,  0.8232582 , -1.7890751 ,  0.7274249 ,\n",
       "        0.33917788,  0.6947416 , -0.9246903 , -0.3547988 ,  0.29738325,\n",
       "       -1.360706  , -0.02596921,  0.28942904,  0.37975082, -0.33179292,\n",
       "       -0.5229446 ,  0.9814854 ,  1.1986082 , -0.9550803 , -0.9266022 ,\n",
       "       -0.15589905,  0.5517955 , -2.297992  , -0.56640947, -0.05236883,\n",
       "       -0.7666    , -0.62583685, -0.07760017,  1.0713048 ,  1.2863549 ,\n",
       "        0.4013921 ,  0.37228888,  0.7379714 , -0.19486685,  0.5740469 ,\n",
       "        0.8225626 ,  0.7377949 , -1.4866037 , -0.01304581,  0.3571163 ,\n",
       "        0.75121367,  0.14015196, -2.0670614 ,  0.6571309 , -0.9075349 ,\n",
       "       -0.05102115, -0.70791864, -0.6259407 , -1.4448755 ,  0.24297266,\n",
       "        0.16807975, -1.1628312 ,  0.6222025 ,  0.13223512, -1.1435513 ,\n",
       "       -0.23714794, -0.1259625 , -0.9504131 ,  0.18177998, -0.65267074],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.52])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_df[concrete_df['Word']=='state']['Conc.M'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in concrete_intersect:\n",
    "    word_vectors[word] = word_vectors[word] * 1/concrete_df[concrete_df['Word']==word]['Conc.M'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "== AoA_51715_words.csv ==\n",
    "\n",
    "This file contains \"Age of Acquisition\" (AoA) estimates for about 51k English words, which refers to the approximate age (in years) when a word was learned. Early words, being more basic, have lower average AoA.\n",
    "\n",
    "The main columns you will be interested in are \"Word\" and \"AoA_Kup_lem\". But the others may be useful too.\n",
    "\n",
    "The file contains these columns:\n",
    "\n",
    "Word :: The word in question\n",
    "Alternative.spelling :: if the Word may be spelled frequently in another form\t\n",
    "Freq_pm\t:: Freq of the Word in general English (larger -> more common)\n",
    "Dom_PoS_SUBTLEX\t:: Dominant part of speech in general usage\n",
    "Nletters :: number of letters \n",
    "Nphon :: number of phonemes\n",
    "Nsyll :: number of syllables\n",
    "Lemma_highest_PoS :: the \"lemmatized\" or \"root\" form of the word (in the dominant part of speech. e.g. The root form of the verb \"abates\" is \"abate\".\n",
    "AoA_Kup\t:: The AoA from a previous study by Kuperman et al.\n",
    "Perc_known :: Percent of people who knew the word in the Kuperman et al. study\n",
    "AoA_Kup_lem :: Estimated AoA based on Kuperman et al. study lemmatized words. THIS IS THE MAIN COLUMN OF INTEREST.\n",
    "Perc_known_lem\t:: Estimated percentage of people who would know this form of the word in the Kuperman study.\n",
    "AoA_Bird_lem :: AoA reported in previous study by Bird (2001) \n",
    "AoA_Bristol_lem\t:: AoA reported in previous study from Bristol Univ. (2006)\n",
    "AoA_Cort_lem :: AoA reported in previous study by Cortese & Khanna (2008)\n",
    "AoA_Schock :: AoA reported in previous study by Schock (2012)\n",
    "\n",
    "Original source : http://crr.ugent.be/archives/806"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Alternative.spelling</th>\n",
       "      <th>Freq_pm</th>\n",
       "      <th>Dom_PoS_SUBTLEX</th>\n",
       "      <th>Nletters</th>\n",
       "      <th>Nphon</th>\n",
       "      <th>Nsyll</th>\n",
       "      <th>Lemma_highest_PoS</th>\n",
       "      <th>AoA_Kup</th>\n",
       "      <th>Perc_known</th>\n",
       "      <th>AoA_Kup_lem</th>\n",
       "      <th>Perc_known_lem</th>\n",
       "      <th>AoA_Bird_lem</th>\n",
       "      <th>AoA_Bristol_lem</th>\n",
       "      <th>AoA_Cort_lem</th>\n",
       "      <th>AoA_Schock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>20415.27</td>\n",
       "      <td>Article</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>2.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aardvark</td>\n",
       "      <td>aardvark</td>\n",
       "      <td>0.41</td>\n",
       "      <td>Noun</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>aardvark</td>\n",
       "      <td>9.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abacus</td>\n",
       "      <td>abacus</td>\n",
       "      <td>0.24</td>\n",
       "      <td>Noun</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>abacus</td>\n",
       "      <td>8.69</td>\n",
       "      <td>0.65</td>\n",
       "      <td>8.69</td>\n",
       "      <td>0.65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abacuses</td>\n",
       "      <td>abacuses</td>\n",
       "      <td>0.02</td>\n",
       "      <td>Noun</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>abacus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.69</td>\n",
       "      <td>0.65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abalone</td>\n",
       "      <td>abalone</td>\n",
       "      <td>0.51</td>\n",
       "      <td>Verb</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>abalone</td>\n",
       "      <td>12.23</td>\n",
       "      <td>0.72</td>\n",
       "      <td>12.23</td>\n",
       "      <td>0.72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word Alternative.spelling   Freq_pm Dom_PoS_SUBTLEX  Nletters  Nphon  \\\n",
       "0         a                    a  20415.27         Article         1      1   \n",
       "1  aardvark             aardvark      0.41            Noun         8      7   \n",
       "2    abacus               abacus      0.24            Noun         6      6   \n",
       "3  abacuses             abacuses      0.02            Noun         8      9   \n",
       "4   abalone              abalone      0.51            Verb         7      7   \n",
       "\n",
       "   Nsyll Lemma_highest_PoS  AoA_Kup  Perc_known  AoA_Kup_lem  Perc_known_lem  \\\n",
       "0      1                 a     2.89        1.00         2.89            1.00   \n",
       "1      2          aardvark     9.89        1.00         9.89            1.00   \n",
       "2      3            abacus     8.69        0.65         8.69            0.65   \n",
       "3      4            abacus      NaN         NaN         8.69            0.65   \n",
       "4      4           abalone    12.23        0.72        12.23            0.72   \n",
       "\n",
       "   AoA_Bird_lem  AoA_Bristol_lem  AoA_Cort_lem  AoA_Schock  \n",
       "0          3.16              NaN           NaN         NaN  \n",
       "1           NaN              NaN           NaN         NaN  \n",
       "2           NaN              NaN           NaN         NaN  \n",
       "3           NaN              NaN           NaN         NaN  \n",
       "4           NaN              NaN           NaN         NaN  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AoA\n",
    "#Perc_known_lem, AoA_Kup_lem\n",
    "aoawords_path = 'Data/AoA_51715_words.csv'\n",
    "AoA = pd.read_csv(aoawords_path,encoding = 'unicode_escape')\n",
    "AoA_set = set(AoA['Word'].values)\n",
    "AoA.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51715"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(AoA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.58"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AoA.AoA_Kup_lem.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AoA.AoA_Kup_lem.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Alternative.spelling</th>\n",
       "      <th>Freq_pm</th>\n",
       "      <th>Dom_PoS_SUBTLEX</th>\n",
       "      <th>Nletters</th>\n",
       "      <th>Nphon</th>\n",
       "      <th>Nsyll</th>\n",
       "      <th>Lemma_highest_PoS</th>\n",
       "      <th>AoA_Kup</th>\n",
       "      <th>Perc_known</th>\n",
       "      <th>AoA_Kup_lem</th>\n",
       "      <th>Perc_known_lem</th>\n",
       "      <th>AoA_Bird_lem</th>\n",
       "      <th>AoA_Bristol_lem</th>\n",
       "      <th>AoA_Cort_lem</th>\n",
       "      <th>AoA_Schock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14878</th>\n",
       "      <td>eisteddfod</td>\n",
       "      <td>eisteddfod</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>eisteddfod</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2084</th>\n",
       "      <td>architrave</td>\n",
       "      <td>architrave</td>\n",
       "      <td>0.04</td>\n",
       "      <td>Noun</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>architrave</td>\n",
       "      <td>21.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>21.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6274</th>\n",
       "      <td>calceolaria</td>\n",
       "      <td>calceolaria</td>\n",
       "      <td>0.02</td>\n",
       "      <td>Noun</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>calceolaria</td>\n",
       "      <td>21.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>21.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32931</th>\n",
       "      <td>penury</td>\n",
       "      <td>penury</td>\n",
       "      <td>0.02</td>\n",
       "      <td>Noun</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>penury</td>\n",
       "      <td>20.60</td>\n",
       "      <td>0.28</td>\n",
       "      <td>20.60</td>\n",
       "      <td>0.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25243</th>\n",
       "      <td>kendo</td>\n",
       "      <td>kendo</td>\n",
       "      <td>0.37</td>\n",
       "      <td>Noun</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>kendo</td>\n",
       "      <td>20.50</td>\n",
       "      <td>0.11</td>\n",
       "      <td>20.50</td>\n",
       "      <td>0.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31427</th>\n",
       "      <td>oubliette</td>\n",
       "      <td>oubliette</td>\n",
       "      <td>0.10</td>\n",
       "      <td>Noun</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>oubliette</td>\n",
       "      <td>20.50</td>\n",
       "      <td>0.21</td>\n",
       "      <td>20.50</td>\n",
       "      <td>0.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39919</th>\n",
       "      <td>schottische</td>\n",
       "      <td>schottische</td>\n",
       "      <td>0.04</td>\n",
       "      <td>Noun</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>schottische</td>\n",
       "      <td>20.25</td>\n",
       "      <td>0.22</td>\n",
       "      <td>20.25</td>\n",
       "      <td>0.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46329</th>\n",
       "      <td>thrombocytopenia</td>\n",
       "      <td>thrombocytopenia</td>\n",
       "      <td>0.02</td>\n",
       "      <td>Noun</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>thrombocytopenia</td>\n",
       "      <td>20.17</td>\n",
       "      <td>0.30</td>\n",
       "      <td>20.17</td>\n",
       "      <td>0.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27318</th>\n",
       "      <td>majuscule</td>\n",
       "      <td>majuscule</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>majuscule</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49770</th>\n",
       "      <td>vicuna</td>\n",
       "      <td>vicuna</td>\n",
       "      <td>0.06</td>\n",
       "      <td>Noun</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>vicuna</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32775</th>\n",
       "      <td>pederasty</td>\n",
       "      <td>pederasty</td>\n",
       "      <td>0.02</td>\n",
       "      <td>Noun</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>pederasty</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51483</th>\n",
       "      <td>yakitori</td>\n",
       "      <td>yakitori</td>\n",
       "      <td>0.04</td>\n",
       "      <td>Noun</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>yakitori</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18933</th>\n",
       "      <td>furfural</td>\n",
       "      <td>furfural</td>\n",
       "      <td>0.12</td>\n",
       "      <td>Noun</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>furfural</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20523</th>\n",
       "      <td>guerdon</td>\n",
       "      <td>guerdon</td>\n",
       "      <td>0.02</td>\n",
       "      <td>Noun</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>guerdon</td>\n",
       "      <td>19.75</td>\n",
       "      <td>0.22</td>\n",
       "      <td>19.75</td>\n",
       "      <td>0.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27877</th>\n",
       "      <td>maxilla</td>\n",
       "      <td>maxilla</td>\n",
       "      <td>0.08</td>\n",
       "      <td>Noun</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>maxilla</td>\n",
       "      <td>19.75</td>\n",
       "      <td>0.42</td>\n",
       "      <td>19.75</td>\n",
       "      <td>0.42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49654</th>\n",
       "      <td>vermiform</td>\n",
       "      <td>vermiform</td>\n",
       "      <td>0.02</td>\n",
       "      <td>Adjective</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>vermiform</td>\n",
       "      <td>19.75</td>\n",
       "      <td>0.21</td>\n",
       "      <td>19.75</td>\n",
       "      <td>0.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3964</th>\n",
       "      <td>berkelium</td>\n",
       "      <td>berkelium</td>\n",
       "      <td>0.02</td>\n",
       "      <td>Noun</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>berkelium</td>\n",
       "      <td>19.67</td>\n",
       "      <td>0.16</td>\n",
       "      <td>19.67</td>\n",
       "      <td>0.16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29291</th>\n",
       "      <td>mortmain</td>\n",
       "      <td>mortmain</td>\n",
       "      <td>0.02</td>\n",
       "      <td>Noun</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>mortmain</td>\n",
       "      <td>19.60</td>\n",
       "      <td>0.25</td>\n",
       "      <td>19.60</td>\n",
       "      <td>0.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12824</th>\n",
       "      <td>diethylamide</td>\n",
       "      <td>diethylamide</td>\n",
       "      <td>0.04</td>\n",
       "      <td>Noun</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>diethylamide</td>\n",
       "      <td>19.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>19.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10207</th>\n",
       "      <td>cortices</td>\n",
       "      <td>cortices</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>cortices</td>\n",
       "      <td>19.50</td>\n",
       "      <td>0.10</td>\n",
       "      <td>19.50</td>\n",
       "      <td>0.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49558</th>\n",
       "      <td>velar</td>\n",
       "      <td>velar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>velar</td>\n",
       "      <td>19.50</td>\n",
       "      <td>0.10</td>\n",
       "      <td>19.50</td>\n",
       "      <td>0.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44130</th>\n",
       "      <td>streptomycin</td>\n",
       "      <td>streptomycin</td>\n",
       "      <td>0.12</td>\n",
       "      <td>Noun</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>streptomycin</td>\n",
       "      <td>19.44</td>\n",
       "      <td>0.45</td>\n",
       "      <td>19.44</td>\n",
       "      <td>0.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11328</th>\n",
       "      <td>cytomegalovirus</td>\n",
       "      <td>cytomegalovirus</td>\n",
       "      <td>0.02</td>\n",
       "      <td>Noun</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>cytomegalovirus</td>\n",
       "      <td>19.43</td>\n",
       "      <td>0.37</td>\n",
       "      <td>19.43</td>\n",
       "      <td>0.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39970</th>\n",
       "      <td>scopolamine</td>\n",
       "      <td>scopolamine</td>\n",
       "      <td>0.25</td>\n",
       "      <td>Noun</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>scopolamine</td>\n",
       "      <td>19.40</td>\n",
       "      <td>0.25</td>\n",
       "      <td>19.40</td>\n",
       "      <td>0.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12993</th>\n",
       "      <td>diphthongization</td>\n",
       "      <td>diphthongization</td>\n",
       "      <td>0.02</td>\n",
       "      <td>Noun</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>diphthongization</td>\n",
       "      <td>19.33</td>\n",
       "      <td>0.30</td>\n",
       "      <td>19.33</td>\n",
       "      <td>0.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30960</th>\n",
       "      <td>odalisque</td>\n",
       "      <td>odalisque</td>\n",
       "      <td>0.02</td>\n",
       "      <td>Noun</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>odalisque</td>\n",
       "      <td>19.33</td>\n",
       "      <td>0.17</td>\n",
       "      <td>19.33</td>\n",
       "      <td>0.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28316</th>\n",
       "      <td>methadone</td>\n",
       "      <td>methadone</td>\n",
       "      <td>0.73</td>\n",
       "      <td>Noun</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>methadone</td>\n",
       "      <td>19.21</td>\n",
       "      <td>0.70</td>\n",
       "      <td>19.21</td>\n",
       "      <td>0.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14741</th>\n",
       "      <td>edematous</td>\n",
       "      <td>oedematous</td>\n",
       "      <td>0.06</td>\n",
       "      <td>Adjective</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>edematous</td>\n",
       "      <td>19.20</td>\n",
       "      <td>0.26</td>\n",
       "      <td>19.20</td>\n",
       "      <td>0.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35743</th>\n",
       "      <td>psychosexual</td>\n",
       "      <td>psychosexual</td>\n",
       "      <td>0.14</td>\n",
       "      <td>Adjective</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>psychosexual</td>\n",
       "      <td>19.19</td>\n",
       "      <td>0.76</td>\n",
       "      <td>19.19</td>\n",
       "      <td>0.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22586</th>\n",
       "      <td>hyperparathyroidism</td>\n",
       "      <td>hyperparathyroidism</td>\n",
       "      <td>0.06</td>\n",
       "      <td>Noun</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>hyperparathyroidism</td>\n",
       "      <td>19.11</td>\n",
       "      <td>0.45</td>\n",
       "      <td>19.11</td>\n",
       "      <td>0.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34607</th>\n",
       "      <td>potties</td>\n",
       "      <td>potties</td>\n",
       "      <td>0.06</td>\n",
       "      <td>Noun</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>potty</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.28</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34609</th>\n",
       "      <td>potty</td>\n",
       "      <td>potty</td>\n",
       "      <td>1.69</td>\n",
       "      <td>Noun</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>potty</td>\n",
       "      <td>2.28</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.28</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29043</th>\n",
       "      <td>mom</td>\n",
       "      <td>mom</td>\n",
       "      <td>430.39</td>\n",
       "      <td>Noun</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>mom</td>\n",
       "      <td>2.22</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.22</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29053</th>\n",
       "      <td>moms</td>\n",
       "      <td>moms</td>\n",
       "      <td>4.75</td>\n",
       "      <td>Noun</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>mom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.22</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3279</th>\n",
       "      <td>bantling</td>\n",
       "      <td>bantling</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>bantling</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27393</th>\n",
       "      <td>mamas</td>\n",
       "      <td>mamas</td>\n",
       "      <td>0.71</td>\n",
       "      <td>Noun</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>mama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27395</th>\n",
       "      <td>mamma</td>\n",
       "      <td>mamma</td>\n",
       "      <td>3.02</td>\n",
       "      <td>Noun</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>mama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27392</th>\n",
       "      <td>mama</td>\n",
       "      <td>mama</td>\n",
       "      <td>103.71</td>\n",
       "      <td>Noun</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>mama</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29049</th>\n",
       "      <td>momma</td>\n",
       "      <td>momma</td>\n",
       "      <td>8.08</td>\n",
       "      <td>Noun</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>momma</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29050</th>\n",
       "      <td>mommas</td>\n",
       "      <td>mommas</td>\n",
       "      <td>0.10</td>\n",
       "      <td>Noun</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>momma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>actinium</td>\n",
       "      <td>actinium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>actinium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322</th>\n",
       "      <td>ambuscade</td>\n",
       "      <td>ambuscade</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>ambuscade</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2306</th>\n",
       "      <td>ashlar</td>\n",
       "      <td>ashlar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>ashlar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5095</th>\n",
       "      <td>bosky</td>\n",
       "      <td>bosky</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>bosky</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6404</th>\n",
       "      <td>canaille</td>\n",
       "      <td>canaille</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>canaille</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9004</th>\n",
       "      <td>compeer</td>\n",
       "      <td>compeer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>compeer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9005</th>\n",
       "      <td>compeers</td>\n",
       "      <td>compeers</td>\n",
       "      <td>0.02</td>\n",
       "      <td>Noun</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>compeer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16000</th>\n",
       "      <td>europium</td>\n",
       "      <td>europium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>europium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19065</th>\n",
       "      <td>gallimaufry</td>\n",
       "      <td>gallimaufry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>gallimaufry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22498</th>\n",
       "      <td>hutment</td>\n",
       "      <td>hutment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>hutment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25196</th>\n",
       "      <td>karakul</td>\n",
       "      <td>karakul</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>karakul</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25219</th>\n",
       "      <td>kedge</td>\n",
       "      <td>kedge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>kedge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25575</th>\n",
       "      <td>kyat</td>\n",
       "      <td>kyat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>kyat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32754</th>\n",
       "      <td>peculation</td>\n",
       "      <td>peculation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>peculation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34588</th>\n",
       "      <td>pother</td>\n",
       "      <td>pother</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>pother</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38932</th>\n",
       "      <td>rogation</td>\n",
       "      <td>rogation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>rogation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42089</th>\n",
       "      <td>smilax</td>\n",
       "      <td>smilax</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>smilax</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46368</th>\n",
       "      <td>thulium</td>\n",
       "      <td>thulium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>thulium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50862</th>\n",
       "      <td>wickiup</td>\n",
       "      <td>wickiup</td>\n",
       "      <td>0.27</td>\n",
       "      <td>Noun</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>wickiup</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50941</th>\n",
       "      <td>williwaw</td>\n",
       "      <td>williwaw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>williwaw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51715 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Word Alternative.spelling  Freq_pm Dom_PoS_SUBTLEX  \\\n",
       "14878           eisteddfod           eisteddfod      NaN             NaN   \n",
       "2084            architrave           architrave     0.04            Noun   \n",
       "6274           calceolaria          calceolaria     0.02            Noun   \n",
       "32931               penury               penury     0.02            Noun   \n",
       "25243                kendo                kendo     0.37            Noun   \n",
       "31427            oubliette            oubliette     0.10            Noun   \n",
       "39919          schottische          schottische     0.04            Noun   \n",
       "46329     thrombocytopenia     thrombocytopenia     0.02            Noun   \n",
       "27318            majuscule            majuscule      NaN             NaN   \n",
       "49770               vicuna               vicuna     0.06            Noun   \n",
       "32775            pederasty            pederasty     0.02            Noun   \n",
       "51483             yakitori             yakitori     0.04            Noun   \n",
       "18933             furfural             furfural     0.12            Noun   \n",
       "20523              guerdon              guerdon     0.02            Noun   \n",
       "27877              maxilla              maxilla     0.08            Noun   \n",
       "49654            vermiform            vermiform     0.02       Adjective   \n",
       "3964             berkelium            berkelium     0.02            Noun   \n",
       "29291             mortmain             mortmain     0.02            Noun   \n",
       "12824         diethylamide         diethylamide     0.04            Noun   \n",
       "10207             cortices             cortices      NaN             NaN   \n",
       "49558                velar                velar      NaN             NaN   \n",
       "44130         streptomycin         streptomycin     0.12            Noun   \n",
       "11328      cytomegalovirus      cytomegalovirus     0.02            Noun   \n",
       "39970          scopolamine          scopolamine     0.25            Noun   \n",
       "12993     diphthongization     diphthongization     0.02            Noun   \n",
       "30960            odalisque            odalisque     0.02            Noun   \n",
       "28316            methadone            methadone     0.73            Noun   \n",
       "14741            edematous           oedematous     0.06       Adjective   \n",
       "35743         psychosexual         psychosexual     0.14       Adjective   \n",
       "22586  hyperparathyroidism  hyperparathyroidism     0.06            Noun   \n",
       "...                    ...                  ...      ...             ...   \n",
       "34607              potties              potties     0.06            Noun   \n",
       "34609                potty                potty     1.69            Noun   \n",
       "29043                  mom                  mom   430.39            Noun   \n",
       "29053                 moms                 moms     4.75            Noun   \n",
       "3279              bantling             bantling      NaN             NaN   \n",
       "27393                mamas                mamas     0.71            Noun   \n",
       "27395                mamma                mamma     3.02            Noun   \n",
       "27392                 mama                 mama   103.71            Noun   \n",
       "29049                momma                momma     8.08            Noun   \n",
       "29050               mommas               mommas     0.10            Noun   \n",
       "442               actinium             actinium      NaN             NaN   \n",
       "1322             ambuscade            ambuscade      NaN             NaN   \n",
       "2306                ashlar               ashlar      NaN             NaN   \n",
       "5095                 bosky                bosky      NaN             NaN   \n",
       "6404              canaille             canaille      NaN             NaN   \n",
       "9004               compeer              compeer      NaN             NaN   \n",
       "9005              compeers             compeers     0.02            Noun   \n",
       "16000             europium             europium      NaN             NaN   \n",
       "19065          gallimaufry          gallimaufry      NaN             NaN   \n",
       "22498              hutment              hutment      NaN             NaN   \n",
       "25196              karakul              karakul      NaN             NaN   \n",
       "25219                kedge                kedge      NaN             NaN   \n",
       "25575                 kyat                 kyat      NaN             NaN   \n",
       "32754           peculation           peculation      NaN             NaN   \n",
       "34588               pother               pother      NaN             NaN   \n",
       "38932             rogation             rogation      NaN             NaN   \n",
       "42089               smilax               smilax      NaN             NaN   \n",
       "46368              thulium              thulium      NaN             NaN   \n",
       "50862              wickiup              wickiup     0.27            Noun   \n",
       "50941             williwaw             williwaw      NaN             NaN   \n",
       "\n",
       "       Nletters  Nphon  Nsyll    Lemma_highest_PoS  AoA_Kup  Perc_known  \\\n",
       "14878        10      8      3           eisteddfod    25.00        0.05   \n",
       "2084         10      8      3           architrave    21.00        0.05   \n",
       "6274         11     11      6          calceolaria    21.00        0.11   \n",
       "32931         6      7      3               penury    20.60        0.28   \n",
       "25243         5      5      2                kendo    20.50        0.11   \n",
       "31427         9      6      3            oubliette    20.50        0.21   \n",
       "39919        11      6      2          schottische    20.25        0.22   \n",
       "46329        16     15      6     thrombocytopenia    20.17        0.30   \n",
       "27318         9      8      3            majuscule    20.00        0.05   \n",
       "49770         6      7      3               vicuna    20.00        0.16   \n",
       "32775         9      9      4            pederasty    20.00        0.11   \n",
       "51483         8      8      4             yakitori    20.00        0.06   \n",
       "18933         8      8      3             furfural    20.00        0.06   \n",
       "20523         7      8      3              guerdon    19.75        0.22   \n",
       "27877         7      7      3              maxilla    19.75        0.42   \n",
       "49654         9      9      3            vermiform    19.75        0.21   \n",
       "3964          9      9      4            berkelium    19.67        0.16   \n",
       "29291         8      7      2             mortmain    19.60        0.25   \n",
       "12824        12      9      4         diethylamide    19.50        0.50   \n",
       "10207         8      6      2             cortices    19.50        0.10   \n",
       "49558         5      5      2                velar    19.50        0.10   \n",
       "44130        12     12      4         streptomycin    19.44        0.45   \n",
       "11328        15     15      7      cytomegalovirus    19.43        0.37   \n",
       "39970        11     10      4          scopolamine    19.40        0.25   \n",
       "12993        16     13      5     diphthongization    19.33        0.30   \n",
       "30960         9      6      3            odalisque    19.33        0.17   \n",
       "28316         9      7      3            methadone    19.21        0.70   \n",
       "14741         9      8      4            edematous    19.20        0.26   \n",
       "35743        12     12      5         psychosexual    19.19        0.76   \n",
       "22586        19     17      8  hyperparathyroidism    19.11        0.45   \n",
       "...         ...    ...    ...                  ...      ...         ...   \n",
       "34607         7      5      2                potty      NaN         NaN   \n",
       "34609         5      4      2                potty     2.28        1.00   \n",
       "29043         3      3      1                  mom     2.22        1.00   \n",
       "29053         4      4      1                  mom      NaN         NaN   \n",
       "3279          8      8      3             bantling     2.00        0.05   \n",
       "27393         5      5      2                 mama      NaN         NaN   \n",
       "27395         5      4      2                 mama      NaN         NaN   \n",
       "27392         4      4      2                 mama     1.89        1.00   \n",
       "29049         5      4      2                momma     1.58        1.00   \n",
       "29050         6      5      2                momma      NaN         NaN   \n",
       "442           8      8      4             actinium      NaN        0.00   \n",
       "1322          9      8      3            ambuscade      NaN        0.00   \n",
       "2306          6      5      2               ashlar      NaN        0.00   \n",
       "5095          5      4      2                bosky      NaN        0.00   \n",
       "6404          8      5      2             canaille      NaN        0.00   \n",
       "9004          7      6      3              compeer      NaN        0.00   \n",
       "9005          8      7      3              compeer      NaN         NaN   \n",
       "16000         8      8      4             europium      NaN        0.00   \n",
       "19065        11      9      4          gallimaufry      NaN        0.00   \n",
       "22498         7      7      2              hutment      NaN        0.00   \n",
       "25196         7      7      3              karakul      NaN        0.00   \n",
       "25219         5      3      1                kedge      NaN        0.00   \n",
       "25575         4      4      2                 kyat      NaN        0.00   \n",
       "32754        10     10      4           peculation      NaN        0.00   \n",
       "34588         6      5      2               pother      NaN        0.00   \n",
       "38932         8      7      3             rogation      NaN        0.00   \n",
       "42089         6      7      2               smilax      NaN        0.00   \n",
       "46368         7      6      3              thulium      NaN        0.00   \n",
       "50862         7      6      3              wickiup      NaN        0.00   \n",
       "50941         8      6      3             williwaw      NaN        0.00   \n",
       "\n",
       "       AoA_Kup_lem  Perc_known_lem  AoA_Bird_lem  AoA_Bristol_lem  \\\n",
       "14878        25.00            0.05           NaN              NaN   \n",
       "2084         21.00            0.05           NaN              NaN   \n",
       "6274         21.00            0.11           NaN              NaN   \n",
       "32931        20.60            0.28           NaN              NaN   \n",
       "25243        20.50            0.11           NaN              NaN   \n",
       "31427        20.50            0.21           NaN              NaN   \n",
       "39919        20.25            0.22           NaN              NaN   \n",
       "46329        20.17            0.30           NaN              NaN   \n",
       "27318        20.00            0.05           NaN              NaN   \n",
       "49770        20.00            0.16           NaN              NaN   \n",
       "32775        20.00            0.11           NaN              NaN   \n",
       "51483        20.00            0.06           NaN              NaN   \n",
       "18933        20.00            0.06           NaN              NaN   \n",
       "20523        19.75            0.22           NaN              NaN   \n",
       "27877        19.75            0.42           NaN              NaN   \n",
       "49654        19.75            0.21           NaN              NaN   \n",
       "3964         19.67            0.16           NaN              NaN   \n",
       "29291        19.60            0.25           NaN              NaN   \n",
       "12824        19.50            0.50           NaN              NaN   \n",
       "10207        19.50            0.10           NaN              NaN   \n",
       "49558        19.50            0.10           NaN              NaN   \n",
       "44130        19.44            0.45           NaN              NaN   \n",
       "11328        19.43            0.37           NaN              NaN   \n",
       "39970        19.40            0.25           NaN              NaN   \n",
       "12993        19.33            0.30           NaN              NaN   \n",
       "30960        19.33            0.17           NaN              NaN   \n",
       "28316        19.21            0.70           NaN              NaN   \n",
       "14741        19.20            0.26           NaN              NaN   \n",
       "35743        19.19            0.76           NaN              NaN   \n",
       "22586        19.11            0.45           NaN              NaN   \n",
       "...            ...             ...           ...              ...   \n",
       "34607         2.28            1.00           NaN              NaN   \n",
       "34609         2.28            1.00           NaN              NaN   \n",
       "29043         2.22            1.00           NaN              NaN   \n",
       "29053         2.22            1.00           NaN              NaN   \n",
       "3279          2.00            0.05           NaN              NaN   \n",
       "27393         1.89            1.00           NaN              NaN   \n",
       "27395         1.89            1.00           NaN              NaN   \n",
       "27392         1.89            1.00           NaN              NaN   \n",
       "29049         1.58            1.00           NaN              NaN   \n",
       "29050         1.58            1.00           NaN              NaN   \n",
       "442            NaN            0.00           NaN              NaN   \n",
       "1322           NaN            0.00           NaN              NaN   \n",
       "2306           NaN            0.00           NaN              NaN   \n",
       "5095           NaN            0.00           NaN              NaN   \n",
       "6404           NaN            0.00           NaN              NaN   \n",
       "9004           NaN            0.00           NaN              NaN   \n",
       "9005           NaN            0.00           NaN              NaN   \n",
       "16000          NaN            0.00           NaN              NaN   \n",
       "19065          NaN            0.00           NaN              NaN   \n",
       "22498          NaN            0.00           NaN              NaN   \n",
       "25196          NaN            0.00           NaN              NaN   \n",
       "25219          NaN            0.00           NaN              NaN   \n",
       "25575          NaN            0.00           NaN              NaN   \n",
       "32754          NaN            0.00           NaN              NaN   \n",
       "34588          NaN            0.00           NaN              NaN   \n",
       "38932          NaN            0.00           NaN              NaN   \n",
       "42089          NaN            0.00           NaN              NaN   \n",
       "46368          NaN            0.00           NaN              NaN   \n",
       "50862          NaN            0.00           NaN              NaN   \n",
       "50941          NaN            0.00           NaN              NaN   \n",
       "\n",
       "       AoA_Cort_lem  AoA_Schock  \n",
       "14878           NaN         NaN  \n",
       "2084            NaN         NaN  \n",
       "6274            NaN         NaN  \n",
       "32931           NaN         NaN  \n",
       "25243           NaN         NaN  \n",
       "31427           NaN         NaN  \n",
       "39919           NaN         NaN  \n",
       "46329           NaN         NaN  \n",
       "27318           NaN         NaN  \n",
       "49770           NaN         NaN  \n",
       "32775           NaN         NaN  \n",
       "51483           NaN         NaN  \n",
       "18933           NaN         NaN  \n",
       "20523           NaN         NaN  \n",
       "27877           NaN         NaN  \n",
       "49654           NaN         NaN  \n",
       "3964            NaN         NaN  \n",
       "29291           NaN         NaN  \n",
       "12824           NaN         NaN  \n",
       "10207           NaN         NaN  \n",
       "49558           NaN         NaN  \n",
       "44130           NaN         NaN  \n",
       "11328           NaN         NaN  \n",
       "39970           NaN         NaN  \n",
       "12993           NaN         NaN  \n",
       "30960           NaN         NaN  \n",
       "28316           NaN         NaN  \n",
       "14741           NaN         NaN  \n",
       "35743           NaN         NaN  \n",
       "22586           NaN         NaN  \n",
       "...             ...         ...  \n",
       "34607           NaN        3.95  \n",
       "34609           NaN        3.95  \n",
       "29043           NaN         NaN  \n",
       "29053           NaN         NaN  \n",
       "3279            NaN         NaN  \n",
       "27393           NaN         NaN  \n",
       "27395           NaN         NaN  \n",
       "27392           NaN         NaN  \n",
       "29049           NaN         NaN  \n",
       "29050           NaN         NaN  \n",
       "442             NaN         NaN  \n",
       "1322            NaN         NaN  \n",
       "2306            NaN         NaN  \n",
       "5095            NaN         NaN  \n",
       "6404            NaN         NaN  \n",
       "9004            NaN         NaN  \n",
       "9005            NaN         NaN  \n",
       "16000           NaN         NaN  \n",
       "19065           NaN         NaN  \n",
       "22498           NaN         NaN  \n",
       "25196           NaN         NaN  \n",
       "25219           NaN         NaN  \n",
       "25575           NaN         NaN  \n",
       "32754           NaN         NaN  \n",
       "34588           NaN         NaN  \n",
       "38932           NaN         NaN  \n",
       "42089           NaN         NaN  \n",
       "46368           NaN         NaN  \n",
       "50862           NaN         NaN  \n",
       "50941           NaN         NaN  \n",
       "\n",
       "[51715 rows x 16 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AoA.sort_values(['AoA_Kup_lem'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(AoA[AoA['AoA_Kup_lem'].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Alternative.spelling</th>\n",
       "      <th>Freq_pm</th>\n",
       "      <th>Dom_PoS_SUBTLEX</th>\n",
       "      <th>Nletters</th>\n",
       "      <th>Nphon</th>\n",
       "      <th>Nsyll</th>\n",
       "      <th>Lemma_highest_PoS</th>\n",
       "      <th>AoA_Kup</th>\n",
       "      <th>Perc_known</th>\n",
       "      <th>AoA_Kup_lem</th>\n",
       "      <th>Perc_known_lem</th>\n",
       "      <th>AoA_Bird_lem</th>\n",
       "      <th>AoA_Bristol_lem</th>\n",
       "      <th>AoA_Cort_lem</th>\n",
       "      <th>AoA_Schock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>actinium</td>\n",
       "      <td>actinium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>actinium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322</th>\n",
       "      <td>ambuscade</td>\n",
       "      <td>ambuscade</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>ambuscade</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2306</th>\n",
       "      <td>ashlar</td>\n",
       "      <td>ashlar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>ashlar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5095</th>\n",
       "      <td>bosky</td>\n",
       "      <td>bosky</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>bosky</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6404</th>\n",
       "      <td>canaille</td>\n",
       "      <td>canaille</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>canaille</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9004</th>\n",
       "      <td>compeer</td>\n",
       "      <td>compeer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>compeer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9005</th>\n",
       "      <td>compeers</td>\n",
       "      <td>compeers</td>\n",
       "      <td>0.02</td>\n",
       "      <td>Noun</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>compeer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16000</th>\n",
       "      <td>europium</td>\n",
       "      <td>europium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>europium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19065</th>\n",
       "      <td>gallimaufry</td>\n",
       "      <td>gallimaufry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>gallimaufry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22498</th>\n",
       "      <td>hutment</td>\n",
       "      <td>hutment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>hutment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25196</th>\n",
       "      <td>karakul</td>\n",
       "      <td>karakul</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>karakul</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25219</th>\n",
       "      <td>kedge</td>\n",
       "      <td>kedge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>kedge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25575</th>\n",
       "      <td>kyat</td>\n",
       "      <td>kyat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>kyat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32754</th>\n",
       "      <td>peculation</td>\n",
       "      <td>peculation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>peculation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34588</th>\n",
       "      <td>pother</td>\n",
       "      <td>pother</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>pother</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38932</th>\n",
       "      <td>rogation</td>\n",
       "      <td>rogation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>rogation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42089</th>\n",
       "      <td>smilax</td>\n",
       "      <td>smilax</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>smilax</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46368</th>\n",
       "      <td>thulium</td>\n",
       "      <td>thulium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>thulium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50862</th>\n",
       "      <td>wickiup</td>\n",
       "      <td>wickiup</td>\n",
       "      <td>0.27</td>\n",
       "      <td>Noun</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>wickiup</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50941</th>\n",
       "      <td>williwaw</td>\n",
       "      <td>williwaw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>williwaw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Word Alternative.spelling  Freq_pm Dom_PoS_SUBTLEX  Nletters  \\\n",
       "442       actinium             actinium      NaN             NaN         8   \n",
       "1322     ambuscade            ambuscade      NaN             NaN         9   \n",
       "2306        ashlar               ashlar      NaN             NaN         6   \n",
       "5095         bosky                bosky      NaN             NaN         5   \n",
       "6404      canaille             canaille      NaN             NaN         8   \n",
       "9004       compeer              compeer      NaN             NaN         7   \n",
       "9005      compeers             compeers     0.02            Noun         8   \n",
       "16000     europium             europium      NaN             NaN         8   \n",
       "19065  gallimaufry          gallimaufry      NaN             NaN        11   \n",
       "22498      hutment              hutment      NaN             NaN         7   \n",
       "25196      karakul              karakul      NaN             NaN         7   \n",
       "25219        kedge                kedge      NaN             NaN         5   \n",
       "25575         kyat                 kyat      NaN             NaN         4   \n",
       "32754   peculation           peculation      NaN             NaN        10   \n",
       "34588       pother               pother      NaN             NaN         6   \n",
       "38932     rogation             rogation      NaN             NaN         8   \n",
       "42089       smilax               smilax      NaN             NaN         6   \n",
       "46368      thulium              thulium      NaN             NaN         7   \n",
       "50862      wickiup              wickiup     0.27            Noun         7   \n",
       "50941     williwaw             williwaw      NaN             NaN         8   \n",
       "\n",
       "       Nphon  Nsyll Lemma_highest_PoS  AoA_Kup  Perc_known  AoA_Kup_lem  \\\n",
       "442        8      4          actinium      NaN         0.0          NaN   \n",
       "1322       8      3         ambuscade      NaN         0.0          NaN   \n",
       "2306       5      2            ashlar      NaN         0.0          NaN   \n",
       "5095       4      2             bosky      NaN         0.0          NaN   \n",
       "6404       5      2          canaille      NaN         0.0          NaN   \n",
       "9004       6      3           compeer      NaN         0.0          NaN   \n",
       "9005       7      3           compeer      NaN         NaN          NaN   \n",
       "16000      8      4          europium      NaN         0.0          NaN   \n",
       "19065      9      4       gallimaufry      NaN         0.0          NaN   \n",
       "22498      7      2           hutment      NaN         0.0          NaN   \n",
       "25196      7      3           karakul      NaN         0.0          NaN   \n",
       "25219      3      1             kedge      NaN         0.0          NaN   \n",
       "25575      4      2              kyat      NaN         0.0          NaN   \n",
       "32754     10      4        peculation      NaN         0.0          NaN   \n",
       "34588      5      2            pother      NaN         0.0          NaN   \n",
       "38932      7      3          rogation      NaN         0.0          NaN   \n",
       "42089      7      2            smilax      NaN         0.0          NaN   \n",
       "46368      6      3           thulium      NaN         0.0          NaN   \n",
       "50862      6      3           wickiup      NaN         0.0          NaN   \n",
       "50941      6      3          williwaw      NaN         0.0          NaN   \n",
       "\n",
       "       Perc_known_lem  AoA_Bird_lem  AoA_Bristol_lem  AoA_Cort_lem  AoA_Schock  \n",
       "442               0.0           NaN              NaN           NaN         NaN  \n",
       "1322              0.0           NaN              NaN           NaN         NaN  \n",
       "2306              0.0           NaN              NaN           NaN         NaN  \n",
       "5095              0.0           NaN              NaN           NaN         NaN  \n",
       "6404              0.0           NaN              NaN           NaN         NaN  \n",
       "9004              0.0           NaN              NaN           NaN         NaN  \n",
       "9005              0.0           NaN              NaN           NaN         NaN  \n",
       "16000             0.0           NaN              NaN           NaN         NaN  \n",
       "19065             0.0           NaN              NaN           NaN         NaN  \n",
       "22498             0.0           NaN              NaN           NaN         NaN  \n",
       "25196             0.0           NaN              NaN           NaN         NaN  \n",
       "25219             0.0           NaN              NaN           NaN         NaN  \n",
       "25575             0.0           NaN              NaN           NaN         NaN  \n",
       "32754             0.0           NaN              NaN           NaN         NaN  \n",
       "34588             0.0           NaN              NaN           NaN         NaN  \n",
       "38932             0.0           NaN              NaN           NaN         NaN  \n",
       "42089             0.0           NaN              NaN           NaN         NaN  \n",
       "46368             0.0           NaN              NaN           NaN         NaN  \n",
       "50862             0.0           NaN              NaN           NaN         NaN  \n",
       "50941             0.0           NaN              NaN           NaN         NaN  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AoA[AoA['AoA_Kup_lem'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to impute all Nan values in AoA_Kup_lem as the max AoA value 25, as they appear to be hard words.\n",
    "AoA['AoA_Kup_lem'].fillna(value=AoA['AoA_Kup_lem'].max(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Alternative.spelling</th>\n",
       "      <th>Freq_pm</th>\n",
       "      <th>Dom_PoS_SUBTLEX</th>\n",
       "      <th>Nletters</th>\n",
       "      <th>Nphon</th>\n",
       "      <th>Nsyll</th>\n",
       "      <th>Lemma_highest_PoS</th>\n",
       "      <th>AoA_Kup</th>\n",
       "      <th>Perc_known</th>\n",
       "      <th>AoA_Kup_lem</th>\n",
       "      <th>Perc_known_lem</th>\n",
       "      <th>AoA_Bird_lem</th>\n",
       "      <th>AoA_Bristol_lem</th>\n",
       "      <th>AoA_Cort_lem</th>\n",
       "      <th>AoA_Schock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2306</th>\n",
       "      <td>ashlar</td>\n",
       "      <td>ashlar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>ashlar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38932</th>\n",
       "      <td>rogation</td>\n",
       "      <td>rogation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>rogation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46368</th>\n",
       "      <td>thulium</td>\n",
       "      <td>thulium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>thulium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14878</th>\n",
       "      <td>eisteddfod</td>\n",
       "      <td>eisteddfod</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>eisteddfod</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5095</th>\n",
       "      <td>bosky</td>\n",
       "      <td>bosky</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>bosky</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16000</th>\n",
       "      <td>europium</td>\n",
       "      <td>europium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>europium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22498</th>\n",
       "      <td>hutment</td>\n",
       "      <td>hutment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>hutment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32754</th>\n",
       "      <td>peculation</td>\n",
       "      <td>peculation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>peculation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50862</th>\n",
       "      <td>wickiup</td>\n",
       "      <td>wickiup</td>\n",
       "      <td>0.27</td>\n",
       "      <td>Noun</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>wickiup</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6404</th>\n",
       "      <td>canaille</td>\n",
       "      <td>canaille</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>canaille</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42089</th>\n",
       "      <td>smilax</td>\n",
       "      <td>smilax</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>smilax</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34588</th>\n",
       "      <td>pother</td>\n",
       "      <td>pother</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>pother</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19065</th>\n",
       "      <td>gallimaufry</td>\n",
       "      <td>gallimaufry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>gallimaufry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25219</th>\n",
       "      <td>kedge</td>\n",
       "      <td>kedge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>kedge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322</th>\n",
       "      <td>ambuscade</td>\n",
       "      <td>ambuscade</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>ambuscade</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25196</th>\n",
       "      <td>karakul</td>\n",
       "      <td>karakul</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>karakul</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9004</th>\n",
       "      <td>compeer</td>\n",
       "      <td>compeer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>compeer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50941</th>\n",
       "      <td>williwaw</td>\n",
       "      <td>williwaw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>williwaw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9005</th>\n",
       "      <td>compeers</td>\n",
       "      <td>compeers</td>\n",
       "      <td>0.02</td>\n",
       "      <td>Noun</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>compeer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>actinium</td>\n",
       "      <td>actinium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>actinium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25575</th>\n",
       "      <td>kyat</td>\n",
       "      <td>kyat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>kyat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6274</th>\n",
       "      <td>calceolaria</td>\n",
       "      <td>calceolaria</td>\n",
       "      <td>0.02</td>\n",
       "      <td>Noun</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>calceolaria</td>\n",
       "      <td>21.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>21.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2084</th>\n",
       "      <td>architrave</td>\n",
       "      <td>architrave</td>\n",
       "      <td>0.04</td>\n",
       "      <td>Noun</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>architrave</td>\n",
       "      <td>21.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>21.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32931</th>\n",
       "      <td>penury</td>\n",
       "      <td>penury</td>\n",
       "      <td>0.02</td>\n",
       "      <td>Noun</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>penury</td>\n",
       "      <td>20.60</td>\n",
       "      <td>0.28</td>\n",
       "      <td>20.60</td>\n",
       "      <td>0.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31427</th>\n",
       "      <td>oubliette</td>\n",
       "      <td>oubliette</td>\n",
       "      <td>0.10</td>\n",
       "      <td>Noun</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>oubliette</td>\n",
       "      <td>20.50</td>\n",
       "      <td>0.21</td>\n",
       "      <td>20.50</td>\n",
       "      <td>0.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25243</th>\n",
       "      <td>kendo</td>\n",
       "      <td>kendo</td>\n",
       "      <td>0.37</td>\n",
       "      <td>Noun</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>kendo</td>\n",
       "      <td>20.50</td>\n",
       "      <td>0.11</td>\n",
       "      <td>20.50</td>\n",
       "      <td>0.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39919</th>\n",
       "      <td>schottische</td>\n",
       "      <td>schottische</td>\n",
       "      <td>0.04</td>\n",
       "      <td>Noun</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>schottische</td>\n",
       "      <td>20.25</td>\n",
       "      <td>0.22</td>\n",
       "      <td>20.25</td>\n",
       "      <td>0.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46329</th>\n",
       "      <td>thrombocytopenia</td>\n",
       "      <td>thrombocytopenia</td>\n",
       "      <td>0.02</td>\n",
       "      <td>Noun</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>thrombocytopenia</td>\n",
       "      <td>20.17</td>\n",
       "      <td>0.30</td>\n",
       "      <td>20.17</td>\n",
       "      <td>0.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18933</th>\n",
       "      <td>furfural</td>\n",
       "      <td>furfural</td>\n",
       "      <td>0.12</td>\n",
       "      <td>Noun</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>furfural</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49770</th>\n",
       "      <td>vicuna</td>\n",
       "      <td>vicuna</td>\n",
       "      <td>0.06</td>\n",
       "      <td>Noun</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>vicuna</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29814</th>\n",
       "      <td>napped</td>\n",
       "      <td>napped</td>\n",
       "      <td>0.10</td>\n",
       "      <td>Verb</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>nap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.53</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.63</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29816</th>\n",
       "      <td>napping</td>\n",
       "      <td>napping</td>\n",
       "      <td>1.25</td>\n",
       "      <td>Verb</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>nap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.53</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.63</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29818</th>\n",
       "      <td>naps</td>\n",
       "      <td>naps</td>\n",
       "      <td>1.04</td>\n",
       "      <td>Noun</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>nap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.53</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.63</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29051</th>\n",
       "      <td>mommies</td>\n",
       "      <td>mommies</td>\n",
       "      <td>0.92</td>\n",
       "      <td>Noun</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>mommy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29052</th>\n",
       "      <td>mommy</td>\n",
       "      <td>mommy</td>\n",
       "      <td>70.92</td>\n",
       "      <td>Noun</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>mommy</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43144</th>\n",
       "      <td>spooned</td>\n",
       "      <td>spooned</td>\n",
       "      <td>0.16</td>\n",
       "      <td>Verb</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>spoon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.94</td>\n",
       "      <td>3.75</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43142</th>\n",
       "      <td>spoon</td>\n",
       "      <td>spoon</td>\n",
       "      <td>7.61</td>\n",
       "      <td>Noun</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>spoon</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.94</td>\n",
       "      <td>3.75</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43148</th>\n",
       "      <td>spoons</td>\n",
       "      <td>spoons</td>\n",
       "      <td>2.00</td>\n",
       "      <td>Noun</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>spoon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.94</td>\n",
       "      <td>3.75</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43147</th>\n",
       "      <td>spooning</td>\n",
       "      <td>spooning</td>\n",
       "      <td>0.39</td>\n",
       "      <td>Verb</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>spoon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.94</td>\n",
       "      <td>3.75</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50619</th>\n",
       "      <td>wet</td>\n",
       "      <td>wet</td>\n",
       "      <td>39.22</td>\n",
       "      <td>Adjective</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>wet</td>\n",
       "      <td>2.47</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.47</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.75</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50625</th>\n",
       "      <td>wets</td>\n",
       "      <td>wets</td>\n",
       "      <td>0.35</td>\n",
       "      <td>Verb</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>wet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.47</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.75</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50627</th>\n",
       "      <td>wetter</td>\n",
       "      <td>wetter</td>\n",
       "      <td>0.47</td>\n",
       "      <td>Adjective</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>wet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.47</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.75</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50628</th>\n",
       "      <td>wettest</td>\n",
       "      <td>wettest</td>\n",
       "      <td>0.08</td>\n",
       "      <td>Adjective</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>wet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.47</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.75</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50629</th>\n",
       "      <td>wetting</td>\n",
       "      <td>wetting</td>\n",
       "      <td>0.82</td>\n",
       "      <td>Verb</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>wet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.47</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.75</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31428</th>\n",
       "      <td>ouch</td>\n",
       "      <td>ouch</td>\n",
       "      <td>10.96</td>\n",
       "      <td>Interjection</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>ouch</td>\n",
       "      <td>2.42</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.42</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.31</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50398</th>\n",
       "      <td>waters</td>\n",
       "      <td>waters</td>\n",
       "      <td>10.84</td>\n",
       "      <td>Noun</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>water</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.37</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.83</td>\n",
       "      <td>3.31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50372</th>\n",
       "      <td>water</td>\n",
       "      <td>water</td>\n",
       "      <td>225.06</td>\n",
       "      <td>Noun</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>water</td>\n",
       "      <td>2.37</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.37</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.83</td>\n",
       "      <td>3.31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50380</th>\n",
       "      <td>watered</td>\n",
       "      <td>watered</td>\n",
       "      <td>0.96</td>\n",
       "      <td>Verb</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>water</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.37</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.83</td>\n",
       "      <td>3.31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51564</th>\n",
       "      <td>yeses</td>\n",
       "      <td>yeses</td>\n",
       "      <td>0.04</td>\n",
       "      <td>Noun</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.31</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.47</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51563</th>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>1996.76</td>\n",
       "      <td>Interjection</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.31</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.31</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.47</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34607</th>\n",
       "      <td>potties</td>\n",
       "      <td>potties</td>\n",
       "      <td>0.06</td>\n",
       "      <td>Noun</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>potty</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.28</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34609</th>\n",
       "      <td>potty</td>\n",
       "      <td>potty</td>\n",
       "      <td>1.69</td>\n",
       "      <td>Noun</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>potty</td>\n",
       "      <td>2.28</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.28</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29043</th>\n",
       "      <td>mom</td>\n",
       "      <td>mom</td>\n",
       "      <td>430.39</td>\n",
       "      <td>Noun</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>mom</td>\n",
       "      <td>2.22</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.22</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29053</th>\n",
       "      <td>moms</td>\n",
       "      <td>moms</td>\n",
       "      <td>4.75</td>\n",
       "      <td>Noun</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>mom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.22</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3279</th>\n",
       "      <td>bantling</td>\n",
       "      <td>bantling</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>bantling</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27395</th>\n",
       "      <td>mamma</td>\n",
       "      <td>mamma</td>\n",
       "      <td>3.02</td>\n",
       "      <td>Noun</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>mama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27393</th>\n",
       "      <td>mamas</td>\n",
       "      <td>mamas</td>\n",
       "      <td>0.71</td>\n",
       "      <td>Noun</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>mama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27392</th>\n",
       "      <td>mama</td>\n",
       "      <td>mama</td>\n",
       "      <td>103.71</td>\n",
       "      <td>Noun</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>mama</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29050</th>\n",
       "      <td>mommas</td>\n",
       "      <td>mommas</td>\n",
       "      <td>0.10</td>\n",
       "      <td>Noun</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>momma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29049</th>\n",
       "      <td>momma</td>\n",
       "      <td>momma</td>\n",
       "      <td>8.08</td>\n",
       "      <td>Noun</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>momma</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51715 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Word Alternative.spelling  Freq_pm Dom_PoS_SUBTLEX  \\\n",
       "2306             ashlar               ashlar      NaN             NaN   \n",
       "38932          rogation             rogation      NaN             NaN   \n",
       "46368           thulium              thulium      NaN             NaN   \n",
       "14878        eisteddfod           eisteddfod      NaN             NaN   \n",
       "5095              bosky                bosky      NaN             NaN   \n",
       "16000          europium             europium      NaN             NaN   \n",
       "22498           hutment              hutment      NaN             NaN   \n",
       "32754        peculation           peculation      NaN             NaN   \n",
       "50862           wickiup              wickiup     0.27            Noun   \n",
       "6404           canaille             canaille      NaN             NaN   \n",
       "42089            smilax               smilax      NaN             NaN   \n",
       "34588            pother               pother      NaN             NaN   \n",
       "19065       gallimaufry          gallimaufry      NaN             NaN   \n",
       "25219             kedge                kedge      NaN             NaN   \n",
       "1322          ambuscade            ambuscade      NaN             NaN   \n",
       "25196           karakul              karakul      NaN             NaN   \n",
       "9004            compeer              compeer      NaN             NaN   \n",
       "50941          williwaw             williwaw      NaN             NaN   \n",
       "9005           compeers             compeers     0.02            Noun   \n",
       "442            actinium             actinium      NaN             NaN   \n",
       "25575              kyat                 kyat      NaN             NaN   \n",
       "6274        calceolaria          calceolaria     0.02            Noun   \n",
       "2084         architrave           architrave     0.04            Noun   \n",
       "32931            penury               penury     0.02            Noun   \n",
       "31427         oubliette            oubliette     0.10            Noun   \n",
       "25243             kendo                kendo     0.37            Noun   \n",
       "39919       schottische          schottische     0.04            Noun   \n",
       "46329  thrombocytopenia     thrombocytopenia     0.02            Noun   \n",
       "18933          furfural             furfural     0.12            Noun   \n",
       "49770            vicuna               vicuna     0.06            Noun   \n",
       "...                 ...                  ...      ...             ...   \n",
       "29814            napped               napped     0.10            Verb   \n",
       "29816           napping              napping     1.25            Verb   \n",
       "29818              naps                 naps     1.04            Noun   \n",
       "29051           mommies              mommies     0.92            Noun   \n",
       "29052             mommy                mommy    70.92            Noun   \n",
       "43144           spooned              spooned     0.16            Verb   \n",
       "43142             spoon                spoon     7.61            Noun   \n",
       "43148            spoons               spoons     2.00            Noun   \n",
       "43147          spooning             spooning     0.39            Verb   \n",
       "50619               wet                  wet    39.22       Adjective   \n",
       "50625              wets                 wets     0.35            Verb   \n",
       "50627            wetter               wetter     0.47       Adjective   \n",
       "50628           wettest              wettest     0.08       Adjective   \n",
       "50629           wetting              wetting     0.82            Verb   \n",
       "31428              ouch                 ouch    10.96    Interjection   \n",
       "50398            waters               waters    10.84            Noun   \n",
       "50372             water                water   225.06            Noun   \n",
       "50380           watered              watered     0.96            Verb   \n",
       "51564             yeses                yeses     0.04            Noun   \n",
       "51563               yes                  yes  1996.76    Interjection   \n",
       "34607           potties              potties     0.06            Noun   \n",
       "34609             potty                potty     1.69            Noun   \n",
       "29043               mom                  mom   430.39            Noun   \n",
       "29053              moms                 moms     4.75            Noun   \n",
       "3279           bantling             bantling      NaN             NaN   \n",
       "27395             mamma                mamma     3.02            Noun   \n",
       "27393             mamas                mamas     0.71            Noun   \n",
       "27392              mama                 mama   103.71            Noun   \n",
       "29050            mommas               mommas     0.10            Noun   \n",
       "29049             momma                momma     8.08            Noun   \n",
       "\n",
       "       Nletters  Nphon  Nsyll Lemma_highest_PoS  AoA_Kup  Perc_known  \\\n",
       "2306          6      5      2            ashlar      NaN        0.00   \n",
       "38932         8      7      3          rogation      NaN        0.00   \n",
       "46368         7      6      3           thulium      NaN        0.00   \n",
       "14878        10      8      3        eisteddfod    25.00        0.05   \n",
       "5095          5      4      2             bosky      NaN        0.00   \n",
       "16000         8      8      4          europium      NaN        0.00   \n",
       "22498         7      7      2           hutment      NaN        0.00   \n",
       "32754        10     10      4        peculation      NaN        0.00   \n",
       "50862         7      6      3           wickiup      NaN        0.00   \n",
       "6404          8      5      2          canaille      NaN        0.00   \n",
       "42089         6      7      2            smilax      NaN        0.00   \n",
       "34588         6      5      2            pother      NaN        0.00   \n",
       "19065        11      9      4       gallimaufry      NaN        0.00   \n",
       "25219         5      3      1             kedge      NaN        0.00   \n",
       "1322          9      8      3         ambuscade      NaN        0.00   \n",
       "25196         7      7      3           karakul      NaN        0.00   \n",
       "9004          7      6      3           compeer      NaN        0.00   \n",
       "50941         8      6      3          williwaw      NaN        0.00   \n",
       "9005          8      7      3           compeer      NaN         NaN   \n",
       "442           8      8      4          actinium      NaN        0.00   \n",
       "25575         4      4      2              kyat      NaN        0.00   \n",
       "6274         11     11      6       calceolaria    21.00        0.11   \n",
       "2084         10      8      3        architrave    21.00        0.05   \n",
       "32931         6      7      3            penury    20.60        0.28   \n",
       "31427         9      6      3         oubliette    20.50        0.21   \n",
       "25243         5      5      2             kendo    20.50        0.11   \n",
       "39919        11      6      2       schottische    20.25        0.22   \n",
       "46329        16     15      6  thrombocytopenia    20.17        0.30   \n",
       "18933         8      8      3          furfural    20.00        0.06   \n",
       "49770         6      7      3            vicuna    20.00        0.16   \n",
       "...         ...    ...    ...               ...      ...         ...   \n",
       "29814         6      4      1               nap      NaN         NaN   \n",
       "29816         7      5      2               nap      NaN         NaN   \n",
       "29818         4      4      1               nap      NaN         NaN   \n",
       "29051         7      5      2             mommy      NaN         NaN   \n",
       "29052         5      4      2             mommy     2.50        1.00   \n",
       "43144         7      5      1             spoon      NaN         NaN   \n",
       "43142         5      4      1             spoon     2.50        1.00   \n",
       "43148         6      5      1             spoon      NaN         NaN   \n",
       "43147         8      6      2             spoon      NaN         NaN   \n",
       "50619         3      3      1               wet     2.47        1.00   \n",
       "50625         4      4      1               wet      NaN         NaN   \n",
       "50627         6      4      2               wet      NaN         NaN   \n",
       "50628         7      6      2               wet      NaN         NaN   \n",
       "50629         7      5      2               wet      NaN         NaN   \n",
       "31428         4      2      1              ouch     2.42        1.00   \n",
       "50398         6      5      2             water      NaN         NaN   \n",
       "50372         5      4      2             water     2.37        1.00   \n",
       "50380         7      5      2             water      NaN         NaN   \n",
       "51564         5      5      2               yes      NaN         NaN   \n",
       "51563         3      3      1               yes     2.31        1.00   \n",
       "34607         7      5      2             potty      NaN         NaN   \n",
       "34609         5      4      2             potty     2.28        1.00   \n",
       "29043         3      3      1               mom     2.22        1.00   \n",
       "29053         4      4      1               mom      NaN         NaN   \n",
       "3279          8      8      3          bantling     2.00        0.05   \n",
       "27395         5      4      2              mama      NaN         NaN   \n",
       "27393         5      5      2              mama      NaN         NaN   \n",
       "27392         4      4      2              mama     1.89        1.00   \n",
       "29050         6      5      2             momma      NaN         NaN   \n",
       "29049         5      4      2             momma     1.58        1.00   \n",
       "\n",
       "       AoA_Kup_lem  Perc_known_lem  AoA_Bird_lem  AoA_Bristol_lem  \\\n",
       "2306         25.00            0.00           NaN              NaN   \n",
       "38932        25.00            0.00           NaN              NaN   \n",
       "46368        25.00            0.00           NaN              NaN   \n",
       "14878        25.00            0.05           NaN              NaN   \n",
       "5095         25.00            0.00           NaN              NaN   \n",
       "16000        25.00            0.00           NaN              NaN   \n",
       "22498        25.00            0.00           NaN              NaN   \n",
       "32754        25.00            0.00           NaN              NaN   \n",
       "50862        25.00            0.00           NaN              NaN   \n",
       "6404         25.00            0.00           NaN              NaN   \n",
       "42089        25.00            0.00           NaN              NaN   \n",
       "34588        25.00            0.00           NaN              NaN   \n",
       "19065        25.00            0.00           NaN              NaN   \n",
       "25219        25.00            0.00           NaN              NaN   \n",
       "1322         25.00            0.00           NaN              NaN   \n",
       "25196        25.00            0.00           NaN              NaN   \n",
       "9004         25.00            0.00           NaN              NaN   \n",
       "50941        25.00            0.00           NaN              NaN   \n",
       "9005         25.00            0.00           NaN              NaN   \n",
       "442          25.00            0.00           NaN              NaN   \n",
       "25575        25.00            0.00           NaN              NaN   \n",
       "6274         21.00            0.11           NaN              NaN   \n",
       "2084         21.00            0.05           NaN              NaN   \n",
       "32931        20.60            0.28           NaN              NaN   \n",
       "31427        20.50            0.21           NaN              NaN   \n",
       "25243        20.50            0.11           NaN              NaN   \n",
       "39919        20.25            0.22           NaN              NaN   \n",
       "46329        20.17            0.30           NaN              NaN   \n",
       "18933        20.00            0.06           NaN              NaN   \n",
       "49770        20.00            0.16           NaN              NaN   \n",
       "...            ...             ...           ...              ...   \n",
       "29814         2.53            1.00           NaN              NaN   \n",
       "29816         2.53            1.00           NaN              NaN   \n",
       "29818         2.53            1.00           NaN              NaN   \n",
       "29051         2.50            1.00           NaN              NaN   \n",
       "29052         2.50            1.00           NaN              NaN   \n",
       "43144         2.50            1.00           NaN             3.94   \n",
       "43142         2.50            1.00           NaN             3.94   \n",
       "43148         2.50            1.00           NaN             3.94   \n",
       "43147         2.50            1.00           NaN             3.94   \n",
       "50619         2.47            1.00           NaN              NaN   \n",
       "50625         2.47            1.00           NaN              NaN   \n",
       "50627         2.47            1.00           NaN              NaN   \n",
       "50628         2.47            1.00           NaN              NaN   \n",
       "50629         2.47            1.00           NaN              NaN   \n",
       "31428         2.42            1.00           NaN              NaN   \n",
       "50398         2.37            1.00          3.83             3.31   \n",
       "50372         2.37            1.00          3.83             3.31   \n",
       "50380         2.37            1.00          3.83             3.31   \n",
       "51564         2.31            1.00          3.69              NaN   \n",
       "51563         2.31            1.00          3.69              NaN   \n",
       "34607         2.28            1.00           NaN              NaN   \n",
       "34609         2.28            1.00           NaN              NaN   \n",
       "29043         2.22            1.00           NaN              NaN   \n",
       "29053         2.22            1.00           NaN              NaN   \n",
       "3279          2.00            0.05           NaN              NaN   \n",
       "27395         1.89            1.00           NaN              NaN   \n",
       "27393         1.89            1.00           NaN              NaN   \n",
       "27392         1.89            1.00           NaN              NaN   \n",
       "29050         1.58            1.00           NaN              NaN   \n",
       "29049         1.58            1.00           NaN              NaN   \n",
       "\n",
       "       AoA_Cort_lem  AoA_Schock  \n",
       "2306            NaN         NaN  \n",
       "38932           NaN         NaN  \n",
       "46368           NaN         NaN  \n",
       "14878           NaN         NaN  \n",
       "5095            NaN         NaN  \n",
       "16000           NaN         NaN  \n",
       "22498           NaN         NaN  \n",
       "32754           NaN         NaN  \n",
       "50862           NaN         NaN  \n",
       "6404            NaN         NaN  \n",
       "42089           NaN         NaN  \n",
       "34588           NaN         NaN  \n",
       "19065           NaN         NaN  \n",
       "25219           NaN         NaN  \n",
       "1322            NaN         NaN  \n",
       "25196           NaN         NaN  \n",
       "9004            NaN         NaN  \n",
       "50941           NaN         NaN  \n",
       "9005            NaN         NaN  \n",
       "442             NaN         NaN  \n",
       "25575           NaN         NaN  \n",
       "6274            NaN         NaN  \n",
       "2084            NaN         NaN  \n",
       "32931           NaN         NaN  \n",
       "31427           NaN         NaN  \n",
       "25243           NaN         NaN  \n",
       "39919           NaN         NaN  \n",
       "46329           NaN         NaN  \n",
       "18933           NaN         NaN  \n",
       "49770           NaN         NaN  \n",
       "...             ...         ...  \n",
       "29814          3.63         NaN  \n",
       "29816          3.63         NaN  \n",
       "29818          3.63         NaN  \n",
       "29051           NaN        2.87  \n",
       "29052           NaN        2.87  \n",
       "43144          3.75         NaN  \n",
       "43142          3.75         NaN  \n",
       "43148          3.75         NaN  \n",
       "43147          3.75         NaN  \n",
       "50619          3.75         NaN  \n",
       "50625          3.75         NaN  \n",
       "50627          3.75         NaN  \n",
       "50628          3.75         NaN  \n",
       "50629          3.75         NaN  \n",
       "31428          3.31         NaN  \n",
       "50398           NaN        3.69  \n",
       "50372           NaN        3.69  \n",
       "50380           NaN        3.69  \n",
       "51564          2.47         NaN  \n",
       "51563          2.47         NaN  \n",
       "34607           NaN        3.95  \n",
       "34609           NaN        3.95  \n",
       "29043           NaN         NaN  \n",
       "29053           NaN         NaN  \n",
       "3279            NaN         NaN  \n",
       "27395           NaN         NaN  \n",
       "27393           NaN         NaN  \n",
       "27392           NaN         NaN  \n",
       "29050           NaN         NaN  \n",
       "29049           NaN         NaN  \n",
       "\n",
       "[51715 rows x 16 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AoA.sort_values(['AoA_Kup_lem'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AoA values range from 0 - 25, which means the smaller the AoA value, the easier the word is. We could possibly use the AoA value to give easier words less weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoa_words = list(AoA['Word'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51715"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aoa_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoa_complement = [word for word in words_in_vector if word not in aoa_words]\n",
    "aoa_intersect = [word for word in words_in_vector if word in aoa_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "984"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aoa_complement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['france',\n",
       " 'american',\n",
       " 'english',\n",
       " 'september',\n",
       " 'british',\n",
       " 'calais',\n",
       " 'german',\n",
       " 'october',\n",
       " 'july',\n",
       " 'june',\n",
       " 'april',\n",
       " 'england',\n",
       " 'february',\n",
       " 'french',\n",
       " 'london',\n",
       " 'john',\n",
       " 'ndash',\n",
       " 'germany',\n",
       " 'usually',\n",
       " 'japanese',\n",
       " 'york',\n",
       " 'australia',\n",
       " 'america',\n",
       " 'nord',\n",
       " 'italian',\n",
       " 'aisne',\n",
       " 'europe',\n",
       " 'pakistan',\n",
       " 'spanish',\n",
       " 'greek',\n",
       " 'european',\n",
       " 'india',\n",
       " 'calvados',\n",
       " 'william',\n",
       " 'california',\n",
       " 'basse',\n",
       " 'normandie',\n",
       " 'switzerland',\n",
       " 'george',\n",
       " 'canton',\n",
       " 'commonly',\n",
       " 'canada',\n",
       " 'charles',\n",
       " 'china',\n",
       " 'australian',\n",
       " 'italy',\n",
       " 'loire',\n",
       " 'christian',\n",
       " 'henry',\n",
       " 'gironde',\n",
       " 'scotland',\n",
       " 'canadian',\n",
       " 'ireland',\n",
       " 'africa',\n",
       " 'picardie',\n",
       " 'paul',\n",
       " 'aquitaine',\n",
       " 'florida',\n",
       " 'brazilian',\n",
       " 'generally',\n",
       " 'atlantic',\n",
       " 'latin',\n",
       " 'david',\n",
       " 'robert',\n",
       " 'chinese',\n",
       " 'russian',\n",
       " 'asia',\n",
       " 'paris',\n",
       " 'scottish',\n",
       " 'indian',\n",
       " 'dutch',\n",
       " 'berlin',\n",
       " 'officially',\n",
       " 'richard',\n",
       " 'lower',\n",
       " 'spain',\n",
       " 'iowa',\n",
       " 'especially',\n",
       " 'disney',\n",
       " 'michael',\n",
       " 'thomas',\n",
       " 'peter',\n",
       " 'wales',\n",
       " 'britain',\n",
       " 'wikipedia',\n",
       " 'approximately',\n",
       " 'louis',\n",
       " 'mexico',\n",
       " 'washington',\n",
       " 'pacific',\n",
       " 'virginia',\n",
       " 'edward',\n",
       " 'martin',\n",
       " 'chicago',\n",
       " 'mainly',\n",
       " 'russia',\n",
       " 'texas',\n",
       " 'mary',\n",
       " 'angeles',\n",
       " 'nintendo',\n",
       " 'victoria',\n",
       " 'alpes',\n",
       " 'irish',\n",
       " 'typically',\n",
       " 'nobel',\n",
       " 'african',\n",
       " 'austria',\n",
       " 'brazil',\n",
       " 'widely',\n",
       " 'netherlands',\n",
       " 'belgian',\n",
       " 'oklahoma',\n",
       " 'mario',\n",
       " 'picardy',\n",
       " 'romania',\n",
       " 'zealand',\n",
       " 'joseph',\n",
       " 'jupiter',\n",
       " 'sarthe',\n",
       " 'illinois',\n",
       " 'particularly',\n",
       " 'austrian',\n",
       " 'manchester',\n",
       " 'poland',\n",
       " 'jesus',\n",
       " 'olympic',\n",
       " 'harry',\n",
       " 'jewish',\n",
       " 'elizabeth',\n",
       " 'carolina',\n",
       " 'prix',\n",
       " 'korea',\n",
       " 'previously',\n",
       " 'egypt',\n",
       " 'rome',\n",
       " 'swedish',\n",
       " 'directly',\n",
       " 'probably',\n",
       " 'armenian',\n",
       " 'korean',\n",
       " 'alexander',\n",
       " 'santa',\n",
       " 'scott',\n",
       " 'saturn',\n",
       " 'oxford',\n",
       " 'online',\n",
       " 'recently',\n",
       " 'sweden',\n",
       " 'georgia',\n",
       " 'ohio',\n",
       " 'maria',\n",
       " 'persian',\n",
       " 'vienna',\n",
       " 'melbourne',\n",
       " 'smith',\n",
       " 'kentucky',\n",
       " 'ontario',\n",
       " 'portuguese',\n",
       " 'francisco',\n",
       " 'nazi',\n",
       " 'provence',\n",
       " 'highly',\n",
       " 'isbn',\n",
       " 'columbia',\n",
       " 'pennsylvania',\n",
       " 'linux',\n",
       " 'michigan',\n",
       " 'chris',\n",
       " 'arthur',\n",
       " 'boston',\n",
       " 'islamic',\n",
       " 'marie',\n",
       " 'finally',\n",
       " 'hungary',\n",
       " 'sydney',\n",
       " 'mayenne',\n",
       " 'andrew',\n",
       " 'massachusetts',\n",
       " 'iran',\n",
       " 'microsoft',\n",
       " 'unlike',\n",
       " 'département',\n",
       " 'albert',\n",
       " 'punjab',\n",
       " 'rhine',\n",
       " 'stanley',\n",
       " 'belgium',\n",
       " 'frederick',\n",
       " 'relatively',\n",
       " 'turkish',\n",
       " 'kilometres',\n",
       " 'anne',\n",
       " 'alabama',\n",
       " 'mississippi',\n",
       " 'indiana',\n",
       " 'swiss',\n",
       " 'kelly',\n",
       " 'czech',\n",
       " 'completely',\n",
       " 'kashmir',\n",
       " 'toronto',\n",
       " 'israel',\n",
       " 'kong',\n",
       " 'denmark',\n",
       " 'daniel',\n",
       " 'greece',\n",
       " 'singapore',\n",
       " 'aube',\n",
       " 'frequently',\n",
       " 'saxony',\n",
       " 'walt',\n",
       " 'azur',\n",
       " 'municipalities',\n",
       " 'alaska',\n",
       " 'jackson',\n",
       " 'julian',\n",
       " 'steve',\n",
       " 'cambridge',\n",
       " 'shortly',\n",
       " 'gregorian',\n",
       " 'largely',\n",
       " 'closely',\n",
       " 'moscow',\n",
       " 'traditionally',\n",
       " 'armenia',\n",
       " 'norway',\n",
       " 'taylor',\n",
       " 'asian',\n",
       " 'kansas',\n",
       " 'minnesota',\n",
       " 'portugal',\n",
       " 'fully',\n",
       " 'metres',\n",
       " 'hamilton',\n",
       " 'ardã',\n",
       " 'partement',\n",
       " 'respectively',\n",
       " 'arabic',\n",
       " 'ross',\n",
       " 'caribbean',\n",
       " 'argentina',\n",
       " 'finland',\n",
       " 'robinson',\n",
       " 'pierre',\n",
       " 'colorado',\n",
       " 'munich',\n",
       " 'florence',\n",
       " 'tehsil',\n",
       " 'baden',\n",
       " 'lincoln',\n",
       " 'smackdown',\n",
       " 'grammy',\n",
       " 'abbottabad',\n",
       " 'yorkshire',\n",
       " 'adams',\n",
       " 'jane',\n",
       " 'christ',\n",
       " 'aargau',\n",
       " 'walter',\n",
       " 'johann',\n",
       " 'francis',\n",
       " 'williams',\n",
       " 'dominican',\n",
       " 'montreal',\n",
       " 'hitler',\n",
       " 'wilson',\n",
       " 'hong',\n",
       " 'jews',\n",
       " 'subsequently',\n",
       " 'vietnam',\n",
       " 'muslims',\n",
       " 'christopher',\n",
       " 'tokyo',\n",
       " 'philip',\n",
       " 'benjamin',\n",
       " 'jones',\n",
       " 'danish',\n",
       " 'specifically',\n",
       " 'karl',\n",
       " 'islam',\n",
       " 'pokã',\n",
       " 'bavaria',\n",
       " 'possibly',\n",
       " 'playstation',\n",
       " 'fifa',\n",
       " 'easily',\n",
       " 'johnson',\n",
       " 'subtropical',\n",
       " 'hollywood',\n",
       " 'notably',\n",
       " 'stephen',\n",
       " 'christianity',\n",
       " 'milan',\n",
       " 'wilhelm',\n",
       " 'brian',\n",
       " 'hungarian',\n",
       " 'quebec',\n",
       " 'afghanistan',\n",
       " 'detroit',\n",
       " 'iraq',\n",
       " 'geneva',\n",
       " 'neptune',\n",
       " 'samuel',\n",
       " 'arab',\n",
       " 'madrid',\n",
       " 'taiwan',\n",
       " 'harrison',\n",
       " 'missouri',\n",
       " 'sarah',\n",
       " 'historically',\n",
       " 'arizona',\n",
       " 'colour',\n",
       " 'mexican',\n",
       " 'matt',\n",
       " 'paulo',\n",
       " 'anna',\n",
       " 'maya',\n",
       " 'roger',\n",
       " 'puerto',\n",
       " 'alfred',\n",
       " 'egyptian',\n",
       " 'newly',\n",
       " 'chile',\n",
       " 'extremely',\n",
       " 'norwegian',\n",
       " 'westphalia',\n",
       " 'matthew',\n",
       " 'adam',\n",
       " 'philadelphia',\n",
       " 'friedrich',\n",
       " 'juan',\n",
       " 'warner',\n",
       " 'muhammad',\n",
       " 'vancouver',\n",
       " 'graham',\n",
       " 'vendã',\n",
       " 'entirely',\n",
       " 'birmingham',\n",
       " 'friday',\n",
       " 'simon',\n",
       " 'finnish',\n",
       " 'alongside',\n",
       " 'wisconsin',\n",
       " 'pittsburgh',\n",
       " 'ferdinand',\n",
       " 'philippines',\n",
       " 'patrick',\n",
       " 'ticino',\n",
       " 'bangladesh',\n",
       " 'tony',\n",
       " 'hawaii',\n",
       " 'vaucluse',\n",
       " 'voyager',\n",
       " 'westminster',\n",
       " 'bruce',\n",
       " 'beatles',\n",
       " 'wrestlemania',\n",
       " 'carl',\n",
       " 'monday',\n",
       " 'jefferson',\n",
       " 'xbox',\n",
       " 'lewis',\n",
       " 'bobby',\n",
       " 'caesar',\n",
       " 'phoenix',\n",
       " 'diego',\n",
       " 'ardèche',\n",
       " 'indonesia',\n",
       " 'christians',\n",
       " 'billy',\n",
       " 'arkansas',\n",
       " 'rhône',\n",
       " 'charlotte',\n",
       " 'cuba',\n",
       " 'formally',\n",
       " 'catherine',\n",
       " 'gaelic',\n",
       " 'viii',\n",
       " 'saxe',\n",
       " 'anthony',\n",
       " 'tennessee',\n",
       " 'monroe',\n",
       " 'miller',\n",
       " 'hebrew',\n",
       " 'romans',\n",
       " 'jordan',\n",
       " 'howard',\n",
       " 'americans',\n",
       " 'idaho',\n",
       " 'walloon',\n",
       " 'ukraine',\n",
       " 'liverpool',\n",
       " 'kennedy',\n",
       " 'indo',\n",
       " 'glasgow',\n",
       " 'urdu',\n",
       " 'darwin',\n",
       " 'douglas',\n",
       " 'davis',\n",
       " 'eric',\n",
       " 'orton',\n",
       " 'anglo',\n",
       " 'bach',\n",
       " 'lawrence',\n",
       " 'edinburgh',\n",
       " 'flanders',\n",
       " 'seattle',\n",
       " 'google',\n",
       " 'atlanta',\n",
       " 'cena',\n",
       " 'jerusalem',\n",
       " 'austen',\n",
       " 'lennon',\n",
       " 'uranus',\n",
       " 'iranian',\n",
       " 'alice',\n",
       " 'barcelona',\n",
       " 'louisiana',\n",
       " 'franklin',\n",
       " 'connecticut',\n",
       " 'uefa',\n",
       " 'kevin',\n",
       " 'jeff',\n",
       " 'antonio',\n",
       " 'carlos',\n",
       " 'pakistani',\n",
       " 'russell',\n",
       " 'oliver',\n",
       " 'wagner',\n",
       " 'prussia',\n",
       " 'haiti',\n",
       " 'austin',\n",
       " 'alan',\n",
       " 'percy',\n",
       " 'jacques',\n",
       " 'clinton',\n",
       " 'nicholas',\n",
       " 'marshall',\n",
       " 'celtic',\n",
       " 'hugo',\n",
       " 'homer',\n",
       " 'arnold',\n",
       " 'heavily',\n",
       " 'annually',\n",
       " 'moore',\n",
       " 'manhattan',\n",
       " 'allen',\n",
       " 'britannica',\n",
       " 'giovanni',\n",
       " 'thailand',\n",
       " 'leeds',\n",
       " 'partly',\n",
       " 'tamil',\n",
       " 'carter',\n",
       " 'shakespeare',\n",
       " 'franz',\n",
       " 'hans',\n",
       " 'gordon',\n",
       " 'rapidly',\n",
       " 'hindu',\n",
       " 'otto',\n",
       " 'simpson',\n",
       " 'labour',\n",
       " 'hercules',\n",
       " 'zeus',\n",
       " 'miami',\n",
       " 'napoleon',\n",
       " 'athens',\n",
       " 'serie',\n",
       " 'hesse',\n",
       " 'ecliptic',\n",
       " 'atlantiques',\n",
       " 'serbia',\n",
       " 'ernst',\n",
       " 'bengal',\n",
       " 'canadiens',\n",
       " 'cleveland',\n",
       " 'forbes',\n",
       " 'jura',\n",
       " 'batista',\n",
       " 'baltimore',\n",
       " 'solothurn',\n",
       " 'jammu',\n",
       " 'houston',\n",
       " 'rico',\n",
       " 'amsterdam',\n",
       " 'jonathan',\n",
       " 'hampshire',\n",
       " 'margaret',\n",
       " 'queensland',\n",
       " 'edmund',\n",
       " 'norse',\n",
       " 'operas',\n",
       " 'commons',\n",
       " 'rocky',\n",
       " 'brabant',\n",
       " 'syria',\n",
       " 'frankfurt',\n",
       " 'madison',\n",
       " 'romanian',\n",
       " 'overseas',\n",
       " 'kurt',\n",
       " 'maritimes',\n",
       " 'stuart',\n",
       " 'shah',\n",
       " 'roosevelt',\n",
       " 'greatly',\n",
       " 'brooklyn',\n",
       " 'cooper',\n",
       " 'augustus',\n",
       " 'stewart',\n",
       " 'maryland',\n",
       " 'mcmahon',\n",
       " 'whedon',\n",
       " 'malaysia',\n",
       " 'dakota',\n",
       " 'gradually',\n",
       " 'kent',\n",
       " 'hamburg',\n",
       " 'briefly',\n",
       " 'instal',\n",
       " 'baptist',\n",
       " 'sindh',\n",
       " 'fairly',\n",
       " 'thompson',\n",
       " 'peru',\n",
       " 'tuscany',\n",
       " 'neighbour',\n",
       " 'herbert',\n",
       " 'pokémon',\n",
       " 'josé',\n",
       " 'norman',\n",
       " 'thirteen',\n",
       " 'oscar',\n",
       " 'jerry',\n",
       " 'bouches',\n",
       " 'venice',\n",
       " 'jimmy',\n",
       " 'louise',\n",
       " 'holland',\n",
       " 'renault',\n",
       " 'francesco',\n",
       " 'leonese',\n",
       " 'slovakia',\n",
       " 'indus',\n",
       " 'lithuania',\n",
       " 'sony',\n",
       " 'nasa',\n",
       " 'aberdeen',\n",
       " 'nelson',\n",
       " 'weimar',\n",
       " 'vincent',\n",
       " 'luis',\n",
       " 'clark',\n",
       " 'slavic',\n",
       " 'gustav',\n",
       " 'julius',\n",
       " 'naples',\n",
       " 'johnny',\n",
       " 'mccartney',\n",
       " 'janeiro',\n",
       " 'dave',\n",
       " 'reich',\n",
       " 'guerrero',\n",
       " 'midlands',\n",
       " 'barry',\n",
       " 'michaels',\n",
       " 'wright',\n",
       " 'utah',\n",
       " 'steven',\n",
       " 'luxembourg',\n",
       " 'nuremberg',\n",
       " 'mozart',\n",
       " 'costa',\n",
       " 'luke',\n",
       " 'anton',\n",
       " 'eddie',\n",
       " 'suffolk',\n",
       " 'pyrénées',\n",
       " 'bernard',\n",
       " 'oregon',\n",
       " 'arabia',\n",
       " 'maine',\n",
       " 'gregory',\n",
       " 'simpsons',\n",
       " 'emmy',\n",
       " 'gilbert',\n",
       " 'israeli',\n",
       " 'antarctica',\n",
       " 'anderson',\n",
       " 'croatia',\n",
       " 'buddhism',\n",
       " 'knowles',\n",
       " 'newfoundland',\n",
       " 'wayne',\n",
       " 'croatian',\n",
       " 'strongly',\n",
       " 'internationally',\n",
       " 'donald',\n",
       " 'americas',\n",
       " 'buenos',\n",
       " 'manitoba',\n",
       " 'inland',\n",
       " 'mont',\n",
       " 'suceava',\n",
       " 'ivan',\n",
       " 'successfully',\n",
       " 'unesco',\n",
       " 'terry',\n",
       " 'castile',\n",
       " 'ronald',\n",
       " 'thursday',\n",
       " 'newton',\n",
       " 'leipzig',\n",
       " 'persia',\n",
       " 'barbara',\n",
       " 'khyber',\n",
       " 'thames',\n",
       " 'cameron',\n",
       " 'isaac',\n",
       " 'somewhat',\n",
       " 'orient',\n",
       " 'anglican',\n",
       " 'subspecies',\n",
       " 'programme',\n",
       " 'vendée',\n",
       " 'harvard',\n",
       " 'gary',\n",
       " 'honour',\n",
       " 'thuringia',\n",
       " 'petersburg',\n",
       " 'alps',\n",
       " 'amazon',\n",
       " 'ludwig',\n",
       " 'gabriel',\n",
       " 'ryan',\n",
       " 'kirby',\n",
       " 'saudi',\n",
       " 'dallas',\n",
       " 'antarctic',\n",
       " 'victor',\n",
       " 'organise',\n",
       " 'georg',\n",
       " 'nile',\n",
       " 'harris',\n",
       " 'franco',\n",
       " 'apollo',\n",
       " 'charlie',\n",
       " 'columbus',\n",
       " 'exclusively',\n",
       " 'lucy',\n",
       " 'tibetan',\n",
       " 'salzburg',\n",
       " 'berkeley',\n",
       " 'tampa',\n",
       " 'sierra',\n",
       " 'flemish',\n",
       " 'warsaw',\n",
       " 'publicly',\n",
       " 'richmond',\n",
       " 'nazis',\n",
       " 'nevada',\n",
       " 'orleans',\n",
       " 'extratropical',\n",
       " 'trinity',\n",
       " 'sheffield',\n",
       " 'brandenburg',\n",
       " 'dublin',\n",
       " 'heinrich',\n",
       " 'hugh',\n",
       " 'significantly',\n",
       " 'ubuntu',\n",
       " 'pakhtunkhwa',\n",
       " 'josã',\n",
       " 'campbell',\n",
       " 'marco',\n",
       " 'similarly',\n",
       " 'kane',\n",
       " 'santiago',\n",
       " 'murray',\n",
       " 'iceland',\n",
       " 'ernest',\n",
       " 'ukrainian',\n",
       " 'bulgaria',\n",
       " 'ralph',\n",
       " 'nova',\n",
       " 'michelle',\n",
       " 'sebastian',\n",
       " 'bundesliga',\n",
       " 'colombia',\n",
       " 'buffy',\n",
       " 'sicily',\n",
       " 'jason',\n",
       " 'mali',\n",
       " 'easter',\n",
       " 'batman',\n",
       " 'raymond',\n",
       " 'harbour',\n",
       " 'fourteen',\n",
       " 'sussex',\n",
       " 'chakwal',\n",
       " 'stockholm',\n",
       " 'santo',\n",
       " 'beijing',\n",
       " 'soundgarden',\n",
       " 'morgan',\n",
       " 'carlo',\n",
       " 'blackhawks',\n",
       " 'yugoslavia',\n",
       " 'ferrari',\n",
       " 'vince',\n",
       " 'panama',\n",
       " 'alex',\n",
       " 'emirates',\n",
       " 'tyler',\n",
       " 'manuel',\n",
       " 'saxon',\n",
       " 'prussian',\n",
       " 'bermuda',\n",
       " 'neil',\n",
       " 'hume',\n",
       " 'prague',\n",
       " 'tasmania',\n",
       " 'alberta',\n",
       " 'debian',\n",
       " 'anastasia',\n",
       " 'twentieth',\n",
       " 'alexandra',\n",
       " 'craig',\n",
       " 'lanka',\n",
       " 'lebanon',\n",
       " 'bristol',\n",
       " 'volkswagen',\n",
       " 'tuesday',\n",
       " 'serbian',\n",
       " 'marcus',\n",
       " 'ussr',\n",
       " 'hudson',\n",
       " 'denis',\n",
       " 'loosely',\n",
       " 'jurassic',\n",
       " 'ottawa',\n",
       " 'abraham',\n",
       " 'tommy',\n",
       " 'jamaica',\n",
       " 'pedro',\n",
       " 'theodore',\n",
       " 'tehsils',\n",
       " 'baltic',\n",
       " 'increasingly',\n",
       " 'nicolas',\n",
       " 'orlando',\n",
       " 'dolj',\n",
       " 'sainte',\n",
       " 'joan',\n",
       " 'venezuela',\n",
       " 'parker',\n",
       " 'côte',\n",
       " 'necessarily',\n",
       " 'spencer',\n",
       " 'facto',\n",
       " 'partially',\n",
       " 'norfolk',\n",
       " 'sega',\n",
       " 'arabian',\n",
       " 'keith',\n",
       " 'leonard',\n",
       " 'santos',\n",
       " 'lucas',\n",
       " 'susan',\n",
       " 'esperanto',\n",
       " 'wolfgang',\n",
       " 'alexandria',\n",
       " 'adolf',\n",
       " 'valencia',\n",
       " 'helen',\n",
       " 'medici',\n",
       " 'warren',\n",
       " 'hermann',\n",
       " 'tibet',\n",
       " 'avon',\n",
       " 'arrondissement',\n",
       " 'windsor',\n",
       " 'victorian',\n",
       " 'powell',\n",
       " 'ethiopia',\n",
       " 'edgar',\n",
       " 'germanic',\n",
       " 'fernando',\n",
       " 'grande',\n",
       " 'surrey',\n",
       " 'vegas',\n",
       " 'pradesh',\n",
       " 'delhi',\n",
       " 'rogers',\n",
       " 'bryan',\n",
       " 'europeans',\n",
       " 'independently',\n",
       " 'burton',\n",
       " 'latvia',\n",
       " 'leonardo',\n",
       " 'devon',\n",
       " 'burma',\n",
       " 'chelsea',\n",
       " 'commercially',\n",
       " 'germans',\n",
       " 'thurgau',\n",
       " 'andy',\n",
       " 'georges',\n",
       " 'antilles',\n",
       " 'paramount',\n",
       " 'nigeria',\n",
       " 'fischer',\n",
       " 'jacob',\n",
       " 'claude',\n",
       " 'shawn',\n",
       " 'maurice',\n",
       " 'monaco',\n",
       " 'bruins',\n",
       " 'cornell',\n",
       " 'broadway',\n",
       " 'randy',\n",
       " 'versailles',\n",
       " 'sanskrit',\n",
       " 'brighton',\n",
       " 'collins',\n",
       " 'subfamily',\n",
       " 'floyd',\n",
       " 'silva',\n",
       " 'morris',\n",
       " 'perth',\n",
       " 'pluto',\n",
       " 'wallace',\n",
       " 'sudan',\n",
       " 'newcastle',\n",
       " 'isabella',\n",
       " 'lorenzo',\n",
       " 'harold',\n",
       " 'jose',\n",
       " 'nixon',\n",
       " 'luigi',\n",
       " 'aragon',\n",
       " 'forever',\n",
       " 'andrea',\n",
       " 'fred',\n",
       " 'indians',\n",
       " 'hainaut',\n",
       " 'somerset',\n",
       " 'nascar',\n",
       " 'estonia',\n",
       " 'ncaa',\n",
       " 'stanford',\n",
       " 'bart',\n",
       " 'legally',\n",
       " 'hughes',\n",
       " 'calvin',\n",
       " 'kate',\n",
       " 'malta',\n",
       " 'wednesday',\n",
       " 'romeo',\n",
       " 'lithuanian',\n",
       " 'simultaneously',\n",
       " 'organisation',\n",
       " 'constantine',\n",
       " 'waterloo',\n",
       " 'calgary',\n",
       " 'colin',\n",
       " 'pete',\n",
       " 'hindenburg',\n",
       " 'toyota',\n",
       " 'rudolf',\n",
       " 'karachi',\n",
       " 'antwerp',\n",
       " 'properly',\n",
       " 'pablo',\n",
       " 'limburg',\n",
       " 'keynes',\n",
       " 'apparently',\n",
       " 'webster',\n",
       " 'azerbaijan',\n",
       " 'helsinki',\n",
       " 'mecklenburg',\n",
       " 'kreis',\n",
       " 'melina',\n",
       " 'reagan',\n",
       " 'domingo',\n",
       " 'boeing',\n",
       " 'monte',\n",
       " 'slovenia',\n",
       " 'luther',\n",
       " 'greg',\n",
       " 'danny',\n",
       " 'tanzania',\n",
       " 'chevrolet',\n",
       " 'salvador',\n",
       " 'morocco',\n",
       " 'antoine',\n",
       " 'indonesian',\n",
       " 'slovak',\n",
       " 'greeks',\n",
       " 'aaron',\n",
       " 'buddha',\n",
       " 'derbyshire',\n",
       " 'coburg',\n",
       " 'cruz',\n",
       " 'pichilemu',\n",
       " 'maxwell',\n",
       " 'beyoncé',\n",
       " 'watson',\n",
       " 'scala',\n",
       " 'additionally',\n",
       " 'edmonton',\n",
       " 'normandy',\n",
       " 'chilean',\n",
       " 'chad',\n",
       " 'indianapolis',\n",
       " 'lisa',\n",
       " 'osaka',\n",
       " 'ruth',\n",
       " 'cyrillic',\n",
       " 'dante',\n",
       " 'aang',\n",
       " 'gettysburg',\n",
       " 'lulu',\n",
       " 'nato',\n",
       " 'phil',\n",
       " 'princeton',\n",
       " 'yearly',\n",
       " 'sunderland',\n",
       " 'extensively',\n",
       " 'vladimir',\n",
       " 'lancashire',\n",
       " 'mongol',\n",
       " 'walker',\n",
       " 'oblast',\n",
       " 'andreas',\n",
       " 'marina',\n",
       " 'owen',\n",
       " 'inca',\n",
       " 'oslo',\n",
       " 'nancy',\n",
       " 'nineteenth',\n",
       " 'trojan',\n",
       " 'rttemberg',\n",
       " 'thai',\n",
       " 'bavarian',\n",
       " 'hanover',\n",
       " 'grameen',\n",
       " 'bismarck',\n",
       " 'roberto',\n",
       " 'benoit',\n",
       " 'haute',\n",
       " 'gotha',\n",
       " 'greenland',\n",
       " 'amherst',\n",
       " 'predominantly',\n",
       " 'michel',\n",
       " 'rhode',\n",
       " 'baja',\n",
       " 'albany',\n",
       " 'yokohama',\n",
       " 'czechoslovakia',\n",
       " 'todd',\n",
       " 'stallone',\n",
       " 'edwards',\n",
       " 'viola',\n",
       " 'manga',\n",
       " 'disambiguation',\n",
       " 'eleventh',\n",
       " 'unitary',\n",
       " 'cincinnati',\n",
       " 'denver',\n",
       " 'malcolm',\n",
       " 'sean',\n",
       " 'connor',\n",
       " 'congo',\n",
       " 'montana',\n",
       " 'ipswich',\n",
       " 'memphis',\n",
       " 'amadeus',\n",
       " 'catholics',\n",
       " 'copenhagen',\n",
       " 'felix',\n",
       " 'sexually']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aoa_complement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3305"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aoa_intersect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['state',\n",
       " 'bear',\n",
       " 'city',\n",
       " 'know',\n",
       " 'unite',\n",
       " 'department',\n",
       " 'play',\n",
       " 'region',\n",
       " 'commune',\n",
       " 'time',\n",
       " 'north',\n",
       " 'world',\n",
       " 'football',\n",
       " 'call',\n",
       " 'include',\n",
       " 'people',\n",
       " 'south',\n",
       " 'game',\n",
       " 'work',\n",
       " 'team']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aoa_intersect[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2964"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([word for word in aoa_intersect if word in concrete_intersect])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in aoa_intersect:\n",
    "    word_vectors[word] = word_vectors[word] * AoA[AoA['Word']==word]['AoA_Kup_lem'].values/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.83089001e-02, -6.73406105e-03, -2.39122356e-03,  2.21231813e-03,\n",
       "       -1.77313630e-02, -6.47794595e-03,  6.38337526e-03, -4.89002885e-03,\n",
       "       -4.22425946e-04,  1.58399008e-02,  1.37592945e-02, -1.04790153e-02,\n",
       "       -8.66317935e-03, -1.87549833e-02,  9.25439596e-03,  7.68203335e-03,\n",
       "       -2.00958457e-02, -3.60697485e-03,  6.07690029e-03,  5.68985380e-03,\n",
       "        5.47157973e-03,  1.73947308e-02,  1.23537984e-02,  1.45614659e-02,\n",
       "        1.34279775e-02,  5.92474593e-04,  8.20048898e-03, -7.88125617e-05,\n",
       "        5.17886691e-03,  2.02736352e-02,  2.50376295e-02, -1.09975487e-02,\n",
       "        8.28096829e-03, -9.36565921e-03,  2.06443649e-02,  1.85047258e-02,\n",
       "        1.42631000e-02, -9.15466284e-04, -3.35195404e-03, -4.99832910e-03,\n",
       "       -1.64532475e-02, -1.30192321e-02,  1.69828907e-02, -3.69066074e-02,\n",
       "        1.50059564e-02,  6.99685793e-03,  1.43317366e-02, -1.90753192e-02,\n",
       "       -7.31909974e-03,  6.13468140e-03, -2.80698314e-02, -5.35715546e-04,\n",
       "        5.97059540e-03,  7.83383101e-03, -6.84451405e-03, -1.07877599e-02,\n",
       "        2.02469397e-02,  2.47259364e-02, -1.97022296e-02, -1.91147607e-02,\n",
       "       -3.21602193e-03,  1.13829197e-02, -4.74049896e-02, -1.16843898e-02,\n",
       "       -1.08030997e-03, -1.58140957e-02, -1.29103092e-02, -1.60080427e-03,\n",
       "        2.20998116e-02,  2.65360530e-02,  8.28026701e-03,  7.67990062e-03,\n",
       "        1.52235199e-02, -4.01988346e-03,  1.18419416e-02,  1.69685390e-02,\n",
       "        1.52198775e-02, -3.06669623e-02, -2.69120443e-04,  7.36690732e-03,\n",
       "        1.54966926e-02,  2.89117708e-03, -4.26411517e-02,  1.35558704e-02,\n",
       "       -1.87214222e-02, -1.05250883e-03, -1.46035645e-02, -1.29124513e-02,\n",
       "       -2.98061557e-02,  5.01225237e-03,  3.46729602e-03, -2.39878986e-02,\n",
       "        1.28353378e-02,  2.72786152e-03, -2.35901773e-02, -4.89209546e-03,\n",
       "       -2.59846449e-03, -1.96059532e-02,  3.74991633e-03, -1.34638622e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dense_features(tokenized_text,word_vectors):\n",
    "    dense_list=[]\n",
    "    words=[]\n",
    "    for _ in tokenized_text: \n",
    "        words =[word for word in _ if word in word_vectors.key_to_index]\n",
    "        \n",
    "        if len(words) >0:\n",
    "            dense_list.append(np.mean(word_vectors[words],axis=0))\n",
    "            \n",
    "        else: \n",
    "            dense_list.append(np.zeros(word_vectors.vector_size))\n",
    "            \n",
    "    return np.array(dense_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_wv = generate_dense_features(tokenized_text_train,word_vectors)\n",
    "X_test_wv = generate_dense_features(tokenized_text_test,word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(333414, 100)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_wv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lr_wv = LogisticRegression(random_state=RANDOM_SEED,max_iter=1000).fit(X_train_wv,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/base.py:283: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  indices = (scores > 0).astype(np.int)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5729898985051707"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,lr_wv.predict(X_test_wv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_fun(doc):\n",
    "    return doc\n",
    "vectorizer = TfidfVectorizer(analyzer='word',tokenizer=dummy_fun, preprocessor=dummy_fun, token_pattern=r'(?u)\\b\\w\\w+__\\([\\w\\s]*\\)')\n",
    "X_train_transform = vectorizer.fit_transform(tokenized_text_train)\n",
    "X_test_transform  = vectorizer.transform(tokenized_text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112972"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a_nx',\n",
       " 'aabout',\n",
       " 'aabye',\n",
       " 'aach',\n",
       " 'aachen',\n",
       " 'aafc',\n",
       " 'aage',\n",
       " 'aaiil',\n",
       " 'aalborg',\n",
       " 'aalen',\n",
       " 'aaliyah',\n",
       " 'aaliyahs',\n",
       " 'aall',\n",
       " 'aalst',\n",
       " 'aalten',\n",
       " 'aalter',\n",
       " 'aalto',\n",
       " 'aames',\n",
       " 'aamir',\n",
       " 'aang',\n",
       " 'aangâ',\n",
       " 'aapep',\n",
       " 'aarau',\n",
       " 'aarberg',\n",
       " 'aarburg',\n",
       " 'aarc',\n",
       " 'aarde',\n",
       " 'aardman',\n",
       " 'aardsma',\n",
       " 'aardvark',\n",
       " 'aardvarks',\n",
       " 'aare',\n",
       " 'aargau',\n",
       " 'aargauer',\n",
       " 'aarhus',\n",
       " 'aaron',\n",
       " 'aaroni',\n",
       " 'aarons',\n",
       " 'aarre',\n",
       " 'aarschot',\n",
       " 'aarseth',\n",
       " 'aartselaar',\n",
       " 'aarwangen',\n",
       " 'aasen',\n",
       " 'aashurah',\n",
       " 'aast',\n",
       " 'aastana',\n",
       " 'aave',\n",
       " 'ababa',\n",
       " 'ababba',\n",
       " 'ababda',\n",
       " 'abac',\n",
       " 'abacada',\n",
       " 'abaci',\n",
       " 'aback',\n",
       " 'abacus',\n",
       " 'abacuses',\n",
       " 'abad',\n",
       " 'abagnale',\n",
       " 'abahutu',\n",
       " 'abaj',\n",
       " 'abajo',\n",
       " 'abakan',\n",
       " 'abakanskoye',\n",
       " 'abal',\n",
       " 'abalo',\n",
       " 'abalone',\n",
       " 'abando',\n",
       " 'abandon',\n",
       " 'abandonded',\n",
       " 'abandonment',\n",
       " 'abarat',\n",
       " 'abassi',\n",
       " 'abate',\n",
       " 'abattoirs',\n",
       " 'abatutsi',\n",
       " 'abauzit',\n",
       " 'abavo',\n",
       " 'abazhou',\n",
       " 'abaúj',\n",
       " 'abba',\n",
       " 'abbado',\n",
       " 'abbadon',\n",
       " 'abbados',\n",
       " 'abbandando',\n",
       " 'abbas',\n",
       " 'abbasi',\n",
       " 'abbasid',\n",
       " 'abbasids',\n",
       " 'abbasies',\n",
       " 'abbass',\n",
       " 'abbassid',\n",
       " 'abbay',\n",
       " 'abbaye',\n",
       " 'abbe',\n",
       " 'abbeville',\n",
       " 'abbey',\n",
       " 'abbeydale',\n",
       " 'abbeys',\n",
       " 'abbiamo',\n",
       " 'abbiategrasso',\n",
       " 'abbiati',\n",
       " 'abbie',\n",
       " 'abbiss',\n",
       " 'abbondancieri',\n",
       " 'abbondanzieri',\n",
       " 'abbondio',\n",
       " 'abbot',\n",
       " 'abbotsford',\n",
       " 'abbotsinch',\n",
       " 'abbott',\n",
       " 'abbottabad',\n",
       " 'abbotts',\n",
       " 'abbr',\n",
       " 'abbrev',\n",
       " 'abbreviate',\n",
       " 'abbreviation',\n",
       " 'abbreviations',\n",
       " 'abbruzzese',\n",
       " 'abbs',\n",
       " 'abbud',\n",
       " 'abby',\n",
       " 'abbã',\n",
       " 'abbé',\n",
       " 'abbécourt',\n",
       " 'abcd',\n",
       " 'abcs',\n",
       " 'abdacom',\n",
       " 'abdal',\n",
       " 'abdallah',\n",
       " 'abdel',\n",
       " 'abdelazar',\n",
       " 'abdelhafid',\n",
       " 'abdeljalil',\n",
       " 'abdelwahab',\n",
       " 'abdera',\n",
       " 'abderathe',\n",
       " 'abdest',\n",
       " 'abdi',\n",
       " 'abdicate',\n",
       " 'abdicatio',\n",
       " 'abdication',\n",
       " 'abdirashid',\n",
       " 'abdolah',\n",
       " 'abdollah',\n",
       " 'abdomen',\n",
       " 'abdomens',\n",
       " 'abdominal',\n",
       " 'abdominis',\n",
       " 'abdou',\n",
       " 'abdoulaye',\n",
       " 'abdu',\n",
       " 'abduct',\n",
       " 'abduction',\n",
       " 'abdul',\n",
       " 'abdulahi',\n",
       " 'abdulaziz',\n",
       " 'abdullah',\n",
       " 'abdullaziz',\n",
       " 'abdun',\n",
       " 'abdurrahman',\n",
       " 'abdus',\n",
       " 'abeba',\n",
       " 'abel',\n",
       " 'abela',\n",
       " 'abelard',\n",
       " 'abelardo',\n",
       " 'abele',\n",
       " 'abelian',\n",
       " 'abelisaurid',\n",
       " 'abella',\n",
       " 'abells',\n",
       " 'abelmoschus',\n",
       " 'abelshauser',\n",
       " 'abelson',\n",
       " 'abendroth',\n",
       " 'abenobashi',\n",
       " 'abenon',\n",
       " 'abenteuer',\n",
       " 'aber',\n",
       " 'abercrombie',\n",
       " 'abercromby',\n",
       " 'aberdeen',\n",
       " 'aberdeenshire',\n",
       " 'aberdeenshires',\n",
       " 'aberdour',\n",
       " 'aberdovey',\n",
       " 'aberdyfi',\n",
       " 'aberfan',\n",
       " 'aberford',\n",
       " 'aberfoyle',\n",
       " 'abergavenny',\n",
       " 'abergement',\n",
       " 'abergynolwyn',\n",
       " 'aberlin',\n",
       " 'aberrant',\n",
       " 'aberration',\n",
       " 'aberrations',\n",
       " 'aberson',\n",
       " 'abert',\n",
       " 'abertay',\n",
       " 'aberystwyth',\n",
       " 'aberystwyththe',\n",
       " 'abet',\n",
       " 'abeyie',\n",
       " 'abgar',\n",
       " 'abgebräunt',\n",
       " 'abgrenzung',\n",
       " 'abhainn',\n",
       " 'abhanga',\n",
       " 'abhangas',\n",
       " 'abhinav',\n",
       " 'abhiras',\n",
       " 'abhor',\n",
       " 'abhorrèd',\n",
       " 'abid',\n",
       " 'abidal',\n",
       " 'abide',\n",
       " 'abidine',\n",
       " 'abidjan',\n",
       " 'abidos',\n",
       " 'abierta',\n",
       " 'abigail',\n",
       " 'abilene',\n",
       " 'abilities',\n",
       " 'ability',\n",
       " 'abimael',\n",
       " 'abin',\n",
       " 'abingdon',\n",
       " 'abington',\n",
       " 'abiogenesis',\n",
       " 'abiotic',\n",
       " 'abiotically',\n",
       " 'abire',\n",
       " 'abisalovich',\n",
       " 'abispa',\n",
       " 'abitur',\n",
       " 'abiword',\n",
       " 'abjadi',\n",
       " 'abjads',\n",
       " 'abjuration',\n",
       " 'abkai',\n",
       " 'abkco',\n",
       " 'abkhaz',\n",
       " 'abkhazia',\n",
       " 'abkhazian',\n",
       " 'ablanedo',\n",
       " 'ablation',\n",
       " 'ablative',\n",
       " 'ablaze',\n",
       " 'able',\n",
       " 'abled',\n",
       " 'ablest',\n",
       " 'ablon',\n",
       " 'abloy',\n",
       " 'ablutions',\n",
       " 'abma',\n",
       " 'abner',\n",
       " 'abney',\n",
       " 'abnicum',\n",
       " 'abnormal',\n",
       " 'abnormalities',\n",
       " 'abnormality',\n",
       " 'abnormally',\n",
       " 'aboard',\n",
       " 'abobrã',\n",
       " 'abol',\n",
       " 'abolish',\n",
       " 'abolishment',\n",
       " 'abolition',\n",
       " 'abolitionism',\n",
       " 'abolitionist',\n",
       " 'abolitionists',\n",
       " 'abominations',\n",
       " 'abong',\n",
       " 'aboolian',\n",
       " 'aboot',\n",
       " 'aboriginal',\n",
       " 'aboriginals',\n",
       " 'aborigine',\n",
       " 'aborigines',\n",
       " 'abort',\n",
       " 'abortifacient',\n",
       " 'abortion',\n",
       " 'abortions',\n",
       " 'abortive',\n",
       " 'abou',\n",
       " 'abound',\n",
       " 'aboutus',\n",
       " 'aboveground',\n",
       " 'abovyan',\n",
       " 'abra',\n",
       " 'abracadabra',\n",
       " 'abraham',\n",
       " 'abrahamic',\n",
       " 'abrahams',\n",
       " 'abram',\n",
       " 'abramczik',\n",
       " 'abramovich',\n",
       " 'abrams',\n",
       " 'abrantes',\n",
       " 'abrasion',\n",
       " 'abrasions',\n",
       " 'abraxas',\n",
       " 'abraã',\n",
       " 'abreaction',\n",
       " 'abreu',\n",
       " 'abrictosaurus',\n",
       " 'abridge',\n",
       " 'abridgment',\n",
       " 'abril',\n",
       " 'abroad',\n",
       " 'abrogant',\n",
       " 'abrogate',\n",
       " 'abronia',\n",
       " 'abrowse',\n",
       " 'abrsm',\n",
       " 'abrupt',\n",
       " 'abruptly',\n",
       " 'abruzzi',\n",
       " 'abruzzo',\n",
       " 'abrä',\n",
       " 'abscess',\n",
       " 'abscesses',\n",
       " 'abscissa',\n",
       " 'abscond',\n",
       " 'absecon',\n",
       " 'absence',\n",
       " 'absences',\n",
       " 'absent',\n",
       " 'absentee',\n",
       " 'absentia',\n",
       " 'absentpelagic',\n",
       " 'absinth',\n",
       " 'absinthe',\n",
       " 'absinthes',\n",
       " 'absinthium',\n",
       " 'absolut',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absolutepunk',\n",
       " 'absolution',\n",
       " 'absolutist',\n",
       " 'absolutive',\n",
       " 'absolve',\n",
       " 'absorb',\n",
       " 'absorbance',\n",
       " 'absorbances',\n",
       " 'absorbent',\n",
       " 'absorber',\n",
       " 'absorbers',\n",
       " 'absorption',\n",
       " 'absorptive',\n",
       " 'abstain',\n",
       " 'abstention',\n",
       " 'abstentionism',\n",
       " 'abstinence',\n",
       " 'abstract',\n",
       " 'abstraction',\n",
       " 'abstractionists',\n",
       " 'abstractions',\n",
       " 'absurd',\n",
       " 'absurde',\n",
       " 'absurdism',\n",
       " 'absurdist',\n",
       " 'absurdity',\n",
       " 'abtwil',\n",
       " 'abub',\n",
       " 'abubakari',\n",
       " 'abugida',\n",
       " 'abugidas',\n",
       " 'abuja',\n",
       " 'abukuma',\n",
       " 'abul',\n",
       " 'abuladze',\n",
       " 'abulkhair',\n",
       " 'abulm',\n",
       " 'abuls',\n",
       " 'abulédu',\n",
       " 'abundance',\n",
       " 'abundant',\n",
       " 'abundantly',\n",
       " 'aburish',\n",
       " 'abuse',\n",
       " 'abusive',\n",
       " 'abusively',\n",
       " 'abut',\n",
       " 'abutere',\n",
       " 'abutments',\n",
       " 'aby',\n",
       " 'abydos',\n",
       " 'abyssal',\n",
       " 'abzekh',\n",
       " 'abéché',\n",
       " 'abélard',\n",
       " 'acacia',\n",
       " 'acacias',\n",
       " 'acad',\n",
       " 'acadamias',\n",
       " 'academe',\n",
       " 'academia',\n",
       " 'academic',\n",
       " 'academical',\n",
       " 'academically',\n",
       " 'academician',\n",
       " 'academics',\n",
       " 'academie',\n",
       " 'academies',\n",
       " 'academkniga',\n",
       " 'academy',\n",
       " 'acadia',\n",
       " 'acadians',\n",
       " 'acadã',\n",
       " 'acadème',\n",
       " 'académie',\n",
       " 'acamprosate',\n",
       " 'acanthaceae',\n",
       " 'acanthaclisinae',\n",
       " 'acanthocephala',\n",
       " 'acanthodii',\n",
       " 'acanthomintha',\n",
       " 'acanthomyops',\n",
       " 'acanthophis',\n",
       " 'acanthophylla',\n",
       " 'acanthostega',\n",
       " 'acapulco',\n",
       " 'acari',\n",
       " 'acarology',\n",
       " 'acaso',\n",
       " 'acasta',\n",
       " 'acca',\n",
       " 'accademia',\n",
       " 'accadian',\n",
       " 'accede',\n",
       " 'accelerate',\n",
       " 'accelerateur',\n",
       " 'acceleration',\n",
       " 'accelerations',\n",
       " 'accelerator',\n",
       " 'accelerators',\n",
       " 'acceleratorsâ',\n",
       " 'accelerometer',\n",
       " 'accelerometers',\n",
       " 'accends',\n",
       " 'accent',\n",
       " 'accentschurmann',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'acceptably',\n",
       " 'acceptance',\n",
       " 'acceptor',\n",
       " 'access',\n",
       " 'accessibility',\n",
       " 'accessible',\n",
       " 'accession',\n",
       " 'accessories',\n",
       " 'accessory',\n",
       " 'acchieved',\n",
       " 'acchouhouri',\n",
       " 'acciaiuoli',\n",
       " 'acciarito',\n",
       " 'accident',\n",
       " 'accidental',\n",
       " 'accidentally',\n",
       " 'accidentals',\n",
       " 'accidents',\n",
       " 'accidie',\n",
       " 'accies',\n",
       " 'acciona',\n",
       " 'accipiter',\n",
       " 'accipitridae',\n",
       " 'acciã',\n",
       " 'acción',\n",
       " 'acclaim',\n",
       " 'acclamation',\n",
       " 'acclamations',\n",
       " 'acclimatation',\n",
       " 'acclimate',\n",
       " 'acclimatisation',\n",
       " 'accolade',\n",
       " 'accolades',\n",
       " 'accomack',\n",
       " 'accommodate',\n",
       " 'accommodation',\n",
       " 'accommodations',\n",
       " 'accommodative',\n",
       " 'accompaniment',\n",
       " 'accompanist',\n",
       " 'accompany',\n",
       " 'accomping',\n",
       " 'accomplice',\n",
       " 'accomplices',\n",
       " 'accomplish',\n",
       " 'accomplishers',\n",
       " 'accomplishment',\n",
       " 'accomplishments',\n",
       " 'accomptant',\n",
       " 'accons',\n",
       " 'accord',\n",
       " 'accordance',\n",
       " 'accordingly',\n",
       " 'accordion',\n",
       " 'accordionist',\n",
       " 'accordo',\n",
       " 'accost',\n",
       " 'accouchement',\n",
       " 'account',\n",
       " 'accountability',\n",
       " 'accountable',\n",
       " 'accountancy',\n",
       " 'accountant',\n",
       " 'accountants',\n",
       " 'accountn',\n",
       " 'accountsare',\n",
       " 'accous',\n",
       " 'accouterments',\n",
       " 'accoutrement',\n",
       " 'accoyer',\n",
       " 'accra',\n",
       " 'accredit',\n",
       " 'accreditation',\n",
       " 'accreditor',\n",
       " 'accreta',\n",
       " 'accrete',\n",
       " 'accretion',\n",
       " 'accrington',\n",
       " 'accross',\n",
       " 'accrue',\n",
       " 'acculturate',\n",
       " 'accumbens',\n",
       " 'accumulate',\n",
       " 'accumulation',\n",
       " 'accumulations',\n",
       " 'accuracy',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'accusamus',\n",
       " 'accusantium',\n",
       " 'accusation',\n",
       " 'accusations',\n",
       " 'accuse',\n",
       " 'accustom',\n",
       " 'ace',\n",
       " 'acedia',\n",
       " 'aceldama',\n",
       " 'aceman',\n",
       " 'acephala',\n",
       " 'acequia',\n",
       " 'acer',\n",
       " 'aceraceae',\n",
       " 'aceramic',\n",
       " 'acerbic',\n",
       " 'acerbo',\n",
       " 'acetaldehyde',\n",
       " 'acetaminophen',\n",
       " 'acetate',\n",
       " 'acetic',\n",
       " 'acetobacter',\n",
       " 'acetone',\n",
       " 'acetyl',\n",
       " 'acetylate',\n",
       " 'acetylation',\n",
       " 'acetylcholine',\n",
       " 'acetylene',\n",
       " 'acetylide',\n",
       " 'acetylsalicylic',\n",
       " 'acevedo',\n",
       " 'achab',\n",
       " 'achaea',\n",
       " 'achaemenid',\n",
       " 'achaius',\n",
       " 'achard',\n",
       " 'acharya',\n",
       " 'achawã',\n",
       " 'ache',\n",
       " 'achebe',\n",
       " 'achelate',\n",
       " 'acheloos',\n",
       " 'achelous',\n",
       " 'achenbach',\n",
       " 'achenes',\n",
       " 'acheron',\n",
       " 'acherontia',\n",
       " 'achery',\n",
       " 'acheulean',\n",
       " 'achhim',\n",
       " 'achi',\n",
       " 'achicourt',\n",
       " 'achiet',\n",
       " 'achievable',\n",
       " 'achieve',\n",
       " 'achievement',\n",
       " 'achievements',\n",
       " 'achila',\n",
       " 'achiles',\n",
       " 'achille',\n",
       " 'achillea',\n",
       " 'achilles',\n",
       " 'achillobator',\n",
       " 'achim',\n",
       " 'achiote',\n",
       " 'achiral',\n",
       " 'achlorhydria',\n",
       " 'achmad',\n",
       " 'achmed',\n",
       " 'achna',\n",
       " 'achoholic',\n",
       " 'acholi',\n",
       " 'achondrite',\n",
       " 'achondroplasia',\n",
       " 'achondroplastic',\n",
       " 'achonry',\n",
       " 'achromasia',\n",
       " 'achromatopsia',\n",
       " 'achromatosis',\n",
       " 'achromia',\n",
       " 'achterhoek',\n",
       " 'achtice',\n",
       " 'achtung',\n",
       " 'achy',\n",
       " 'achzarit',\n",
       " 'achã',\n",
       " 'aché',\n",
       " 'achí',\n",
       " 'acib',\n",
       " 'acid',\n",
       " 'acidic',\n",
       " 'acidification',\n",
       " 'acidify',\n",
       " 'acidity',\n",
       " 'acidosis',\n",
       " 'acids',\n",
       " 'acinar',\n",
       " 'acis',\n",
       " 'ackerman',\n",
       " 'ackery',\n",
       " 'ackley',\n",
       " 'acklins',\n",
       " 'acknowledge',\n",
       " 'acknowledgement',\n",
       " 'acknowledgment',\n",
       " 'acknowledgments',\n",
       " 'ackworth',\n",
       " 'acland',\n",
       " 'aclare',\n",
       " 'acme',\n",
       " 'acmi',\n",
       " 'acne',\n",
       " 'acnielsen',\n",
       " 'acolyte',\n",
       " 'acolytes',\n",
       " 'acomyinae',\n",
       " 'acomys',\n",
       " 'aconcagua',\n",
       " 'aconite',\n",
       " 'aconitum',\n",
       " 'acorah',\n",
       " 'acorn',\n",
       " 'acorns',\n",
       " 'acosta',\n",
       " 'acou',\n",
       " 'acoustic',\n",
       " 'acoustical',\n",
       " 'acoustically',\n",
       " 'acoustician',\n",
       " 'acousticly',\n",
       " 'acoustics',\n",
       " 'acpb',\n",
       " 'acquaint',\n",
       " 'acquaintance',\n",
       " 'acquaintances',\n",
       " 'acquarossa',\n",
       " 'acqueville',\n",
       " 'acquiesce',\n",
       " 'acquieses',\n",
       " 'acquin',\n",
       " 'acquire',\n",
       " 'acquisition',\n",
       " 'acquisitions',\n",
       " 'acquit',\n",
       " 'acquittal',\n",
       " 'acre',\n",
       " 'acrea',\n",
       " 'acrelã',\n",
       " 'acres',\n",
       " 'acrisius',\n",
       " 'acritarch',\n",
       " 'acritarchs',\n",
       " 'acrobat',\n",
       " 'acrobates',\n",
       " 'acrobatic',\n",
       " 'acrobatics',\n",
       " 'acrobaticâ',\n",
       " 'acrobats',\n",
       " 'acron',\n",
       " 'acronis',\n",
       " 'acronym',\n",
       " 'acronymic',\n",
       " 'acronymous',\n",
       " 'acronyms',\n",
       " 'acropolis',\n",
       " 'acrossmanhattan',\n",
       " 'acrylic',\n",
       " 'acrymia',\n",
       " 'acst',\n",
       " 'act',\n",
       " 'acta',\n",
       " 'acte',\n",
       " 'actias',\n",
       " 'actin',\n",
       " 'actinide',\n",
       " 'actinides',\n",
       " 'actinidia',\n",
       " 'actinium',\n",
       " 'actinobacteria',\n",
       " 'actinoid',\n",
       " 'actinolite',\n",
       " 'actinomorphic',\n",
       " 'actinomycetes',\n",
       " 'actinopterygii',\n",
       " 'actinopterygius',\n",
       " 'actinosporea',\n",
       " 'actinotrocha',\n",
       " 'action',\n",
       " 'actionscript',\n",
       " 'actium',\n",
       " 'actius',\n",
       " 'activate',\n",
       " 'activation',\n",
       " 'activator',\n",
       " 'active',\n",
       " 'activebass',\n",
       " 'actively',\n",
       " 'actives',\n",
       " 'activestats',\n",
       " 'activeworlds',\n",
       " 'activex',\n",
       " 'activision',\n",
       " 'activism',\n",
       " 'activist',\n",
       " 'activists',\n",
       " 'activities',\n",
       " 'activitist',\n",
       " 'activitiy',\n",
       " 'activity',\n",
       " 'activités',\n",
       " 'acton',\n",
       " 'actopan',\n",
       " 'actor',\n",
       " 'actors',\n",
       " 'actress',\n",
       " 'actresses',\n",
       " 'actual',\n",
       " 'actuality',\n",
       " 'actualités',\n",
       " 'actually',\n",
       " 'actuaries',\n",
       " 'actuate',\n",
       " 'actuations',\n",
       " 'actus',\n",
       " 'acuatic',\n",
       " 'acuca',\n",
       " 'acuity',\n",
       " 'aculeata',\n",
       " 'aculeatus',\n",
       " 'acupressure',\n",
       " 'acupuncture',\n",
       " 'acura',\n",
       " 'acute',\n",
       " 'acutely',\n",
       " 'acuteness',\n",
       " 'acutus',\n",
       " 'acyclic',\n",
       " 'acyl',\n",
       " 'acácio',\n",
       " 'adachi',\n",
       " 'adad',\n",
       " 'adage',\n",
       " 'adages',\n",
       " 'adagh',\n",
       " 'adagio',\n",
       " 'adair',\n",
       " 'adairville',\n",
       " 'adak',\n",
       " 'adal',\n",
       " 'adalbert',\n",
       " 'adam',\n",
       " 'adama',\n",
       " 'adamantine',\n",
       " 'adamantium',\n",
       " 'adamey',\n",
       " 'adaminaby',\n",
       " 'adamite',\n",
       " 'adamkus',\n",
       " 'adamlarina',\n",
       " 'adamle',\n",
       " 'adams',\n",
       " 'adamski',\n",
       " 'adamson',\n",
       " 'adamsville',\n",
       " 'adana',\n",
       " 'adapiformes',\n",
       " 'adapt',\n",
       " 'adaptability',\n",
       " 'adaptable',\n",
       " 'adaptation',\n",
       " 'adaptations',\n",
       " 'adapter',\n",
       " 'adapters',\n",
       " 'adaption',\n",
       " 'adaptions',\n",
       " 'adaptive',\n",
       " 'adaptively',\n",
       " 'adaptor',\n",
       " 'adas',\n",
       " 'adasaurus',\n",
       " 'adashim',\n",
       " 'adastra',\n",
       " 'adav',\n",
       " 'add',\n",
       " 'adda',\n",
       " 'addai',\n",
       " 'addakhil',\n",
       " 'addams',\n",
       " 'addax',\n",
       " 'addenbrooke',\n",
       " 'addendum',\n",
       " 'adder',\n",
       " 'adderley',\n",
       " 'adders',\n",
       " 'addicks',\n",
       " 'addict',\n",
       " 'addiction',\n",
       " 'addictions',\n",
       " 'addictive',\n",
       " 'addington',\n",
       " 'addis',\n",
       " 'addiscombe',\n",
       " 'addison',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'additionally',\n",
       " 'additionals',\n",
       " 'additions',\n",
       " 'additive',\n",
       " 'additively',\n",
       " 'additives',\n",
       " 'addon',\n",
       " 'address',\n",
       " 'addressability',\n",
       " 'addressable',\n",
       " 'adegboyega',\n",
       " 'adegem',\n",
       " 'adel',\n",
       " 'adela',\n",
       " 'adelaide',\n",
       " 'adelante',\n",
       " 'adelbert',\n",
       " 'adelboden',\n",
       " 'adele',\n",
       " 'adelekan',\n",
       " 'adelheid',\n",
       " 'adeline',\n",
       " 'adelir',\n",
       " 'adell',\n",
       " 'adella',\n",
       " 'adelomyrmex',\n",
       " 'adelong',\n",
       " 'adelphi',\n",
       " 'adelphotheos',\n",
       " 'adelsheim',\n",
       " 'ademar',\n",
       " 'ademir',\n",
       " 'ademola',\n",
       " 'aden',\n",
       " 'adenauer',\n",
       " 'adenine',\n",
       " 'adenoidectomy',\n",
       " 'adenoids',\n",
       " 'adenoma',\n",
       " 'adenosine',\n",
       " 'adephaga',\n",
       " 'adept',\n",
       " 'adequality',\n",
       " 'adequate',\n",
       " 'adequately',\n",
       " 'aderbal',\n",
       " 'adetokunbo',\n",
       " 'adeus',\n",
       " 'adha',\n",
       " 'adhaerens',\n",
       " 'adhan',\n",
       " 'adhana',\n",
       " 'adhd',\n",
       " 'adhemar',\n",
       " 'adhere',\n",
       " 'adherence',\n",
       " 'adherent',\n",
       " 'adherents',\n",
       " 'adhesion',\n",
       " 'adhesions',\n",
       " 'adhesive',\n",
       " 'adhesives',\n",
       " 'adhlaka',\n",
       " 'adhur',\n",
       " 'adiabatic',\n",
       " 'adiabene',\n",
       " 'adibuddha',\n",
       " 'adic',\n",
       " 'adichie',\n",
       " 'adidas',\n",
       " 'adiel',\n",
       " 'adieu',\n",
       " 'adige',\n",
       " 'adikalar',\n",
       " 'adil',\n",
       " 'adin',\n",
       " 'adinath',\n",
       " 'adine',\n",
       " 'adinfer',\n",
       " 'adingaheim',\n",
       " 'adiperukku',\n",
       " 'adipisci',\n",
       " 'adipocytes',\n",
       " 'adipose',\n",
       " 'adiposity',\n",
       " 'adipperukku',\n",
       " 'adiri',\n",
       " 'adirondack',\n",
       " 'adit',\n",
       " 'adits',\n",
       " 'aditya',\n",
       " 'adiyiah',\n",
       " 'adjacent',\n",
       " 'adjacã',\n",
       " 'adjacé',\n",
       " 'adjascent',\n",
       " 'adjectival',\n",
       " 'adjectivally',\n",
       " 'adjective',\n",
       " 'adjectives',\n",
       " 'adjei',\n",
       " 'adjemian',\n",
       " 'adjoin',\n",
       " 'adjud',\n",
       " 'adjudge',\n",
       " 'adjudicate',\n",
       " 'adjudication',\n",
       " 'adjudicator',\n",
       " 'adjudicators',\n",
       " 'adjunct',\n",
       " 'adjunctive',\n",
       " 'adjuncts',\n",
       " 'adjuration',\n",
       " 'adjust',\n",
       " 'adjustable',\n",
       " 'adjustment',\n",
       " 'adjustments',\n",
       " 'adjutant',\n",
       " 'adjutants',\n",
       " 'adjuvants',\n",
       " 'adkins',\n",
       " 'adlai',\n",
       " 'adlaka',\n",
       " 'adleman',\n",
       " 'adler',\n",
       " 'adliswil',\n",
       " 'adlon',\n",
       " 'admin',\n",
       " 'adminer',\n",
       " 'administer',\n",
       " 'administeriet',\n",
       " 'administraciã',\n",
       " 'administración',\n",
       " 'administrate',\n",
       " 'administration',\n",
       " 'administrations',\n",
       " 'administrative',\n",
       " 'administrator',\n",
       " 'administrators',\n",
       " 'admins',\n",
       " 'adminship',\n",
       " 'admira',\n",
       " 'admirable',\n",
       " 'admirably',\n",
       " 'admiral',\n",
       " 'admirals',\n",
       " 'admiralspalast',\n",
       " 'admiralty',\n",
       " 'admiration',\n",
       " 'admire',\n",
       " 'admirer',\n",
       " 'admirers',\n",
       " 'admiringly',\n",
       " 'admission',\n",
       " 'admissions',\n",
       " 'admit',\n",
       " 'admittance',\n",
       " 'admittedly',\n",
       " 'admixture',\n",
       " ...]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<333414x112972 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2880606 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lr_bow = LogisticRegression(random_state=RANDOM_SEED,max_iter=1000).fit(X_train_transform,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/base.py:283: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  indices = (scores > 0).astype(np.int)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6602802504978765"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,lr_bow.predict(X_test_transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_word = set(word_vectors.index_to_key) #around 6k words in the Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4289"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3106"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_word.intersection(concreteset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.0907188e-02, -8.7361513e-03,  3.9428174e-03, -1.6098885e-02,\n",
       "       -2.3995241e-02, -1.9995170e-02, -1.3755680e-03,  3.7939691e-03,\n",
       "        2.1346841e-02,  3.0121708e-02,  1.8377090e-02, -2.2600330e-02,\n",
       "        9.0839397e-03,  9.2565566e-03, -3.3966653e-02, -1.8434165e-02,\n",
       "        5.2208877e-03, -8.7929126e-03,  6.5757879e-03,  3.2320705e-03,\n",
       "       -1.3878779e-02,  2.7096823e-02,  5.9531401e-03, -2.5492635e-02,\n",
       "        2.1421451e-02,  1.7575338e-02,  5.1505417e-03,  2.5347199e-03,\n",
       "       -1.8050051e-03, -9.8061236e-03, -2.1091940e-02, -1.9069891e-02,\n",
       "       -9.5165968e-03, -3.9247149e-03,  5.1220912e-03,  1.1341183e-02,\n",
       "       -3.3533562e-03, -2.6030161e-03, -5.0849514e-03, -1.7330131e-02,\n",
       "        7.8444439e-04,  2.6780590e-02, -1.4229974e-02,  1.0003803e-02,\n",
       "       -3.0219250e-03, -2.6559418e-03, -5.0560674e-03, -3.3413894e-02,\n",
       "       -1.0309764e-02, -1.9357007e-02,  6.9867079e-03, -1.8718753e-03,\n",
       "       -4.5989989e-03, -8.2336282e-03, -5.0827902e-04, -2.0011526e-02,\n",
       "       -1.9966557e-03, -1.2733388e-02, -2.2775106e-02,  5.8333813e-03,\n",
       "       -2.7261223e-03,  4.4595827e-03, -1.0119287e-02,  8.9132544e-03,\n",
       "       -1.2571471e-02,  1.3682665e-02, -1.4333643e-02,  8.3818082e-03,\n",
       "       -2.1857832e-02, -3.3393364e-02, -2.2353882e-02,  1.4727975e-02,\n",
       "        1.0376228e-02, -1.5812840e-02, -1.9044934e-03,  2.2129463e-03,\n",
       "       -1.1256911e-02, -1.0908911e-03, -5.3942768e-04,  3.2524392e-02,\n",
       "        1.4565587e-03,  9.9168038e-03,  1.7455829e-03,  1.5683735e-02,\n",
       "       -4.0164157e-03,  1.2843185e-02,  1.2192810e-02,  1.4121744e-02,\n",
       "       -1.2009847e-02,  8.1076045e-03, -1.7995786e-02, -2.2088625e-02,\n",
       "       -3.8078288e-03, -8.1206476e-03, -3.8330316e-05,  2.2302814e-02,\n",
       "        1.0865253e-02,  1.4452551e-02,  4.3548457e-03,  5.5257138e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors['live']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "word_list = []\n",
    "for word in model_word: \n",
    "    word_list.append((word,lemmatizer.lemmatize(word.lower())))\n",
    "df = pd.DataFrame(word_list,columns=['Original','word'])\n",
    "df = df.merge(AoA,left_on='word',right_on='Word',how='left')\n",
    "df = df[['Original','word','Perc_known','AoA_Kup_lem']]\n",
    "word_not_matched = set(df[df['Perc_known'].isnull()].word.values)\n",
    "\n",
    "for i in range(len(df)):   \n",
    "    if df['word'][i][0] in set(('0','1','2','3','4','5','6','7','8','9')) or len(df['word'][i])==1:\n",
    "        df['AoA_Kup_lem'][i] = 3\n",
    "mean_value = df['AoA_Kup_lem'].mean()\n",
    "df['AoA_Kup_lem'].fillna(value=mean_value,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original</th>\n",
       "      <th>word</th>\n",
       "      <th>Perc_known</th>\n",
       "      <th>AoA_Kup_lem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4145</th>\n",
       "      <td>weapon</td>\n",
       "      <td>weapon</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Original    word  Perc_known  AoA_Kup_lem\n",
       "4145   weapon  weapon         1.0         6.95"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.loc[df['Original']==['troops','weapons']]\n",
    "df[df['Original'].isin(['troops','weapon'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_perc_known(tokenized_text,df):\n",
    "    avg_perc_know=None\n",
    "    perc_know_list=[]\n",
    "    for _ in tokenized_text: \n",
    "        words =[word for word in _ if word in word_vectors.key_to_index]\n",
    "        \n",
    "        if len(words) >0:\n",
    "            avg_perc_know = np.mean(df[df['Original'].isin(words)]['AoA_Kup_lem'])\n",
    "            perc_know_list.append(avg_perc_know)\n",
    "        else: \n",
    "            \n",
    "            perc_know_list.append(0)\n",
    "            \n",
    "    return perc_know_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(X_train_wv)\n",
    "df_train['year'] = generate_perc_known(tokenized_text_train,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(X_test_wv)\n",
    "df_test['year'] = generate_perc_known(tokenized_text_test,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=RANDOM_SEED,max_iter=1000).fit(df_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/base.py:283: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  indices = (scores > 0).astype(np.int)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5726539818125105"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,lr.predict(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost as xgb\n",
    "# yz\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=100, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "       subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(df_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62.53%\n"
     ]
    }
   ],
   "source": [
    "y_pred_xgb = model.predict(df_test)\n",
    "predictions = [round(value) for value in y_pred_xgb]\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_bow = DummyClassifier(strategy='uniform',random_state=RANDOM_SEED).fit(X_train_transform,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5011277203253593"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, dummy_bow.predict(X_test_transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_wv = DummyClassifier(strategy='uniform',random_state=RANDOM_SEED).fit(X_train_wv,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5011277203253593"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,dummy_wv.predict(X_test_wv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lr_bow = LogisticRegression(random_state=RANDOM_SEED,max_iter=1000).fit(X_train_transform,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/base.py:283: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  indices = (scores > 0).astype(np.int)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6602802504978765"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,lr_bow.predict(X_test_transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/base.py:283: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  indices = (scores > 0).astype(np.int)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0, 0.5, 'False'), Text(0, 1.5, 'True')]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmatrix_lr_bow=metrics.confusion_matrix(y_test, lr_bow.predict(X_test_transform))\n",
    "\n",
    "ax = sns.heatmap(cmatrix_lr_bow, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['False','True'])\n",
    "ax.yaxis.set_ticklabels(['False','True'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lr_wv = LogisticRegression(random_state=RANDOM_SEED,max_iter=1000).fit(X_train_wv,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/base.py:283: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  indices = (scores > 0).astype(np.int)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5537106797514216"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,lr_wv.predict(X_test_wv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/base.py:283: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  indices = (scores > 0).astype(np.int)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0, 0.5, 'False'), Text(0, 1.5, 'True')]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmatrix_lr_wv=metrics.confusion_matrix(y_test, lr_wv.predict(X_test_wv))\n",
    "\n",
    "ax = sns.heatmap(cmatrix_lr_wv, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['False','True'])\n",
    "ax.yaxis.set_ticklabels(['False','True'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_bow = RandomForestClassifier(n_estimators=500,max_depth=5,random_state=RANDOM_SEED).fit(X_train_transform,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6416968591789236"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,rf_bow.predict(X_test_transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:487: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_store_unique_indices = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n"
     ]
    }
   ],
   "source": [
    "rf_wv = RandomForestClassifier(n_estimators=100,max_depth=5,random_state=RANDOM_SEED).fit(X_train_wv,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/base.py:158: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5918132303188809"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,rf_wv.predict(X_test_wv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_bow = XGBClassifier(random_state=RANDOM_SEED).fit(X_train_transform,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6146675624445138"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,xgb_bow.predict(X_test_transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0.5, 'False'), Text(0, 1.5, 'True')]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAFACAYAAABdg9xlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XecVNX9xvHPs7uUVaoNVFBRsaBR1FhiiUaNLTbUWGLXSGxR037RxJ4YjUk0MZZYI2pUrLH3bgTEiigqWFAQQRGQKrB8f3/cszgsW2ZhZ8vM8+Z1X8yce+49587Mfufcc8+cq4jAzMyKW1lLV8DMzArPwd7MrAQ42JuZlQAHezOzEuBgb2ZWAhzszcxKgIN9E5J0rqRbWroehSBpXUmvS5ou6ZSl2M+/JJ3VlHVrCZJmSFqzgPt/RNKR9ay/UdIf89zXGpJCUkUeeXeQNK4xdW2Kba3wSjLYS9pW0kuSpkn6StL/JG3e0vVaWpLapy+c0ZJmSvpY0g2S1miC3f8f8GxEdI6Iy5Z0JxFxfET8oQnqs4h03FHzi0jSaSn93Dz386yknzaULyI6RcSHS1jdBkXE7hExKNXpKEkvFqosKw0lF+wldQEeBP4JLAesCpwHfNOS9apJUvkSbHYXsDfwE6ArsDHwKrBTE1RpdeDtJthPIb0P1GwNH5HSm0Q+rWOz1qjkgj2wDkBE3BYRVRExOyIej4gR1RkkHSNplKQpkh6TtHrOun9I+lTS15JelbRdjf13lDQ4dXe8JmnjnG3XTy3HqZLelrR3zrobJV0l6WFJM4EfpLQrJD2U9jdM0lq1HZSknYEfAvtExPCImB8R0yLiioi4PuVZRdL96WxmjKTjcrY/V9Idkm5KZb0t6btp3dPAD4DLU/fFOjVbwLmtT2UulTQpnT2NkLRhznH+MWe741Jdvkp1WyVnXUg6Pp2pTEmvhep5b4cDy0jaIG2/AVCZ0qv32V3Sg5K+SPt8UFKvtO4CYLuc47w8px4nSRoNjM5JWzudTb0h6ecpvTydKZ5dy3vUJ733Zen5dZIm5ay/RdJp6fGzkn4qaX3gX8D3Up2m5uyyez6fjVrqcXT6fE+X9KGkn9WS53eSvlR2dnhoTnoHSX+V9Imkicq65SrrKOe3ksanct6T1BSNDltCpRjs3weqJA2StLuk7rkrJe0L/A7YD1gReAG4LSfLcKA/2VnBrcCdkjrmrN8HuDNn/X8ltZPUDngAeBxYCfg58B9J6+Zs+xPgAqAzUH3afgjZmUd3YExaX5udgZcj4tN6jv02YBywCnAA8Kcaf4B7A7cD3YD7gcsBImLH9DqcnLovGmop7wJ8n+yLtRtwEDC5ZiZJOwIXAgcCKwNjU/m59gQ2JztLORDYtYGybyZrzUPWyr+pxvoy4N9kZyqrAbNzjvP3NY7z5Jzt9gW2BPrl7iwi5gKHAeenwHw6UE4t71NEfAR8DWySkrYDZqTtIHvNnquxzSjgeGBIqlO3nNX5fjZqmkT2unYBjgYulbRpzvqewApkZ71HAtfkfE7/TPa+9gfWTnlq+2JbFzgZ2DwiOpO9bx/nWT8rgJIL9hHxNbAtEMC1wBepRdkjZfkZcGFEjIqI+cCfgP5KrfuIuCUiJqeW89+ADkBuwH41Iu6KiHnAJUBHYKu0dAIuioi5EfE0WXfSITnb3hcR/4uIBRExJ6XdExEvp7r8h+yPrDbLAxPqOm5JvdNx/zYi5kTEG8B1wOE52V6MiIcjooosaG5cy67yMY/sC2s9QOm1rK1uhwI3RMRrEfENcAZZC3aNnDwXRcTUiPgEeIa6j7/aLcAh6cv14PR8ofTe3R0RsyJiOlmA3D6PY7owIr6KiNk1V0TESOCPwL3Ar4HD02tYm+eA7SX1TM/vSs/7kAXfN/OoS7V8Pxs16/tQRHwQmefIGiA1z1DPiohv0vqHgAPTWdVxwC/SazGd7O/j4FqKqSL72+gnqV1EfBwRHzTi2KyJlVywh6y1FBFHRUQvYEOylu7f0+rVgX+k0+2pwFeAyFowSPpVOgWeltZ3JWsFVfs0p5wFfNuSXgX4NKVVG1u935rb5vg85/Essi+M2kwmax3XZRWg+g+0rvJrltVRS9BHnb7ILgeuACZKukbZtZLa6jQ2Z7sZZMdRX53qOv7qfXxC1sr9EzC65pmOpGUkXS1prKSvgeeBbmr4Gkl9Z0wAg4A1gIcjYnQ9+Z4DdiBrxT8PPEv2ZbM98EKNz0dDGvXaVEtntENT19lUYA8W/QxPiYiZOc/Hkr1XKwLLAK/m/H08mtIXERFjgNOAc4FJkm7P7aKz5leSwT5XRLwL3EgW9CH7o/5ZRHTLWSoj4iVl/fO/JetO6J5OqaeRfRlU6139IPXN9gI+S0vv6v7aZDVgfG51luJQngS2qO5/rsVnwHKSOtdTfmPMJPvDr9Yzd2VEXBYRmwEbkJ32/6aOOuVeD1mW7AxlSetU7SbgVyzehUNKXxfYMiK6kAVd+PY9rOs9aOi9uZLsTG1XSdvWk+85slb0Dunxi8A2ZMH+uTq2abKpaSV1AO4G/gr0SJ/hh1n0M9w9vRfVViN7r74k6/baIOdvo2tE1PolExG3RsS2ZO9xkHUBWQspuWAvab3UOq++KNebrCtlaMryL+CMnIt8XSX9OK3rDMwHvgAq0kW4mi3WzSTtl1rEp5GN8hkKDCMLkP+X+vB3APZi8T7qJRIRTwJPAPdK2kxShaTOyi5wHpNauC8BF0rqKGkj4Fiy0/8l8QawX2opr532BYCkzSVtmbpSZgJzyE7ra7oVOFpS/xSE/gQMi4iPl7BO1QaTXTe4o5Z1nckC1lRJywHn1Fg/EWjU+HlJhwObAUcBpwCDJNUVAEen8g8Dnk/dihOB/ak72E8Eeklq35h61aE9WffKF8B8SbuTvVY1nafs4vN2ZP37d6azjmvJ+vhXApC0qqTFrqMo+13Gjul9nUN2zHV1bVkzKLlgD0wnu9A2TNmol6HASLIWHxFxL1kL5PZ0mj8S2D1t+xjwCNlF3rFkH+Kap/f3kV2QnELWH75fRMxLF/L2Tvv6kqwleEQ6s2gqB5C10gaTnXGMBL5L1uqH7EttDbJW2r3AORHxxBKWdSkwlywQDWLRL40uZEFhCtnrNJmsJbmIiHgKOIuspTkBWIva+38bJY2werK2/nWy7rpKsvdgKFk3RK5/AAcoG6nT4O8JJK2W9nlERMyIiFuBV8hen7o8B0xOXU7VzwW8Xkf+p8mGvX4u6cuG6lSf1I13CtkX4RSyQQH318j2eVr3Gdn7enzO5/S3ZN1kQ9Pfx5Mses2qWgfgIrLX+XOyQQm/W5q629JR+OYlZmZFrxRb9mZmJcfB3sysBDjYm5mVAAd7M7MS4GBvZlYCHOzNzEqAg72ZWQlwsDczKwEO9mZmJcDB3sysBDjYm5mVAAd7M7MS4GBvZlYCHOzNzEqAg72ZWQlwsDczKwEO9mZmJcDB3sysBDjYm5mVAAd7M7MS4GBvZlYCHOzNzEqAg72ZWQlwsDczKwEO9mZmJcDB3sysBDjYm5mVAAd7M7MS4GBvZlYCHOzNzEqAg72ZWQlwsDczKwEO9mZmJcDB3sysBDjYm5mVgIqWrkBdKjc5OVq6Dtb6TBl+eUtXwVqhjhVoaffRmJgz+/XLl7q85tZqg72ZWbNScXd0ONibmQGozTXWG8XB3swM3LI3MysJbtmbmZWAsvKWrkFBOdibmYG7cczMSoK7cczMSoBb9mZmJcAtezOzEuALtGZmJcDdOGZmJcDB3sysBJS5z97MrPi5ZW9mVgI8GsfMrAR4NI6ZWQlwN46ZWQlwN46ZWQlwy97MrAS4ZW9mVgJ8gdbMrAS4G8fMrAQ42JuZlQD32ZuZlQC37M3MSoBb9mZmJcCjcczMip/csjczK34O9mZmpaC4Yz3FffnZzCxPkvJeGthPR0kvS3pT0tuSzkvpfSQNkzRa0mBJ7VN6h/R8TFq/Rs6+zkjp70naNSd9t5Q2RtLp+Ryfg72ZGU0X7IFvgB0jYmOgP7CbpK2APwOXRkRfYApwbMp/LDAlItYGLk35kNQPOBjYANgNuFJSuaRy4Apgd6AfcEjKWy8HezMzoKysLO+lPpGZkZ62S0sAOwJ3pfRBwL7p8T7pOWn9Tsq+UfYBbo+IbyLiI2AMsEVaxkTEhxExF7g95a3/+PJ7GczMipwasTS0q6wF/gYwCXgC+ACYGhHzU5ZxwKrp8arApwBp/TRg+dz0GtvUlV4vB3szMxrXjSNpoKRXcpaBufuKiKqI6A/0ImuJr19LkVFddB3rGpteL4/GMTOjcUMvI+Ia4Jo88k2V9CywFdBNUkVqvfcCPkvZxgG9gXGSKoCuwFc56dVyt6krvU5u2ZuZ0aSjcVaU1C09rgR2BkYBzwAHpGxHAvelx/en56T1T0dEpPSD02idPkBf4GVgONA3je5pT3YR9/6Gjs8tezMzQGVNNtB+ZWBQGjVTBtwREQ9Kege4XdIfgdeB61P+64GbJY0ha9EfDBARb0u6A3gHmA+cFBFVAJJOBh4DyoEbIuLthirlYG9mRtP9gjYiRgCb1JL+IVn/fc30OcCP69jXBcAFtaQ/DDzcmHo52JuZ4ekSzMxKgoO9mVkpKO5Y72BvZgZu2S+V9JPfQ4E1I+J8SasBPSPi5UKWa2bWWA1Ng9DWFfrorgS+BxySnk8nm8DHzKxVacKJ0FqlQnfjbBkRm0p6HSAiplRP62lm1qq0zRiet0IH+3nphwUB2S/LgAUFLtPMrNHaaos9X4UO9pcB9wIrSbqA7KfAZxa4TDOzRnOwXwoR8R9JrwI7kZ0k7RsRowpZppnZkij2YF/QC7SS1gI+iogrgJHAD6snCCpmHdpX8MLNv2bY4NN59a7fc+bxe9SZd8DO/Zn9+uVs2m+1pS539VWW5/mbfs1b953NzRcdTbuK8oKVZY3z8UcfcuB++yxctt5iU2656cZF8jz04P0cMGAvDhiwF0ccejDvvfvuUpc7d+5cfvOr09hztx9y6ME/Zvz4cQC8NWLEwrr8eMDePPXkE0tdVlunMuW9tEWFHo1zN1AlaW3gOqAPcGuBy2xx38ydz24DL2PLgy5iy4MvZJet+7HFd9ZYLF+nZTpw4iE78PKIjxq1/8P22pLf/2zxL5ALTt2Hf/7nGb6zz/lMmT6bowZ8b6nLsqaxRp81ueOe+7jjnvu47c576Nixkh13/uEieVZdtRc33HgLd937AAOPP4Hzzz0r7/2PHz+OY486fLH0e+++ky5duvDgo09w2BFH8fdL/grA2n37cusdd3PHPfdx5TXX8Yfzzmb+/PmLbV9Kin00TqGD/YI0d/N+wD8i4hdkM8IVvZmz5wLQrqKciopyshlLF3XOiXtyyY1PMmfut39kZWXiT6fty4u3/IaXB5/Bsftvk3eZ22++Dvc8+ToA/3lgGHvtsHG9ZVnLGDZ0CL1792aVVRa9uVD/TTalS9euAGy0UX8mTvx84boHH7iPnxx0AAfutw/nn3s2VVVVeZX1zNNPs/c+AwD44S678vLQIUQElZWVVFRkvbjffPNNmw1gTcnBfunMk3QIcATwYEprV+AyW4WyMjH09tP55KmLeHrouwwfOXaR9Ruv24tePbvzyAsjF0k/at+tmTZjNtse9he2PewvHL3fNqy+yvINlrd8t2WZNn02VVXZYKfxE6ewykpd6y3LWsajjzzEbnvsWW+ee++5i223+z4AH37wAY898giDbrmNO+65j/KyMh5+8IG8ypo0aSI9e2btq4qKCjp17szUqVMAGDHiTQbs/SMO2Hdvzjz7vIXBv1QVe7Av9Lt7NHA8cEFEfJQm4L+lrszp1l4DASp67UDFChsUuHqFs2BBsNXBF9G1UyWDLzmOfmutzDsfTACyD9XFv96f486+ebHtdv7eemzYd1UG7JzNkNq1U0fWXm1Fps+cw8NX/xyA5bosQ7t2Fez1g40AOPbMm5g4+evF9hVRf1nW/ObNnctzzzzNqaf9qs48Lw8byr333MWNN2c9nsOGDmHUOyM59KDsvhdzvpnDcstnDYDTTjmJz8aNY968eUyYMIED98vuO/2Tw49g3wH713pGWR2sNtpoY+69/yE+/OADzvzdb9l2u+/ToUOHJj3eNqVtxvC8FXo0zjvAKTnPPwIuqif/wlt9VW5ycoP3VGwLps2YzfOvjGaXrfstDPadl+1Av7VW5vHrTgWgx/JduOvvP+OA065GEr/88508OWTxQUtbHZy9dIfttSWrr7I8F1y96HTWXTtXUl5eRlXVAlbt0Z0JX0yrt6zX3vmkkIdutXjxxedZr98GLL/CCrWuf/+9dznvnDO54l/X0q1bdwCCYK99BnDqLxb/gvj7ZdkP0sePH8fZvz+D629c9Eu9R4+efP75BHr07Mn8+fOZMX06XbsuOkZizbXWorKykjGj32eDDb/TFIfZJnm6hCUg6S1JI+paClFma7JC90507VQJQMcO7dhxy3V57+OJC9d/PWMOvXc8nfV+dA7r/egcXn7r44XB94mXRjHwx9tSUZG9NWuvthLLdMzvR8fPv/I++6UzgkP32pIHnx1Rb1nW/B55+CF23+NHta6b8Nln/PLUn3PBhRezxhp9FqZvueX3ePLxx5g8eTIA06ZO5bPPxudV3g4/2JH777sXgCcef4wtttwKSYwb9+nCC7KffTaesR9/xCqrrlrfroqelP/SFhWqZV9/h2SR67lCF649/3DKy8ooKxN3P/Eaj7wwkrNO+BGvvfMJDz33Vp3b/vvel1h9leUYcuvpSPDllBkc+MsG72sMwO//cR83X3Q055y4J2++9yk3/ndIUx2SNYHZs2cz9KWXOOuc8xem3TH4NgAOPOgQrv7XFUydNpU//eE8AMoryrntjntYa+21OemU0zjhuGNYEAuoqGjH7848e7ELvLUZsP8B/P7037Dnbj+kS9euXPzXSwF4/bVXueG6a2lXUYHKyvjdWefSvftyBTjqtqOt9sXnS7X16bUGxdKNY01ryvDLW7oK1gp1rFj6Hvd1/u/RvGPO+xfv1ua+GQr9o6qtJA2XNEPSXElVkha/kmhm1sI8GmfpXE52p/Q7ge+SDcFcu8Blmpk1WhuN4Xkr+MDaiBgjqTwiqoB/S3qp0GWamTVWeXlxR/tCB/tZaf76NyRdDEwAli1wmWZmjdZWu2fyVeiBpYenMk4GZgK9gf0LXKaZWaN56OUSkLRaRHwSEdVzBMwBzitEWWZmTcEt+yXz3+oHku4uUBlmZk3Go3GWTO6rsWaByjAzazJtNIbnrVDBPup4bGbWKpW10ZuS5KtQwX7j9OMpAZU5P6QSEBHRpUDlmpktkbbaPZOvggT7iChvOJeZWetR5LG+8D+qMjNrC4q9ZV/cEzibmeWpqcbZS+ot6RlJoyS9LenUlH6upPGS3kjLHjnbnCFpjKT3JO2ak75bShsj6fSc9D6ShkkaLWlw+vFqvRzszczILtDmuzRgPvCriFgf2Ao4SVK/tO7SiOiflocB0rqDgQ2A3YArJZVLKgeuAHYH+gGH5Oznz2lffYEpwLENHl9jXgwzs2LVVOPsI2JCRLyWHk8HRgH13XxgH+D2iPgm3c1vDLBFWsZExIcRMRe4HdhHWQV2BO5K2w8C9m3o+BzszcwozHQJktYANgGGpaST0x37bpDUPaWtCnyas9m4lFZX+vLA1IiYXyO9Xg72ZmY0rmUvaaCkV3KWgbXsrxNwN3BaRHwNXAWsBfQnmxTyb9VZa6lOLEF6vTwax8yMxrXYI+IaoM77hUpqRxbo/xMR96RtJuasvxZ4MD0dRzZJZLVewGfpcW3pXwLdJFWk1n1u/jq5ZW9mRtP12ac+9euBURFxSU76yjnZBgAj0+P7gYMldZDUB+gLvAwMB/qmkTftyS7i3h/ZvWSfAQ5I2x8J3NfQ8TUY7CWdKqmLMtdLek3SLg1tZ2bWljThaJxtyKZ337HGMMuLJb0laQTwA+AXABHxNnAH8A7wKHBSRFSlVvvJwGNkF3nvSHkBfgv8UtIYsj786xuqVD7dOMdExD/S2M8VgaOBfwOP57GtmVmb0FQ/qoqIF6m9X/3hera5ALiglvSHa9suIj4kG62Tt3yCfXWl9wD+HRFvqth/amZmJafYo1o+wf5VSY8DfYAzJHUGFhS2WmZmzavY27D5BPtjyYYKfRgRsyQtT9aVY2ZWNIo81uc1GifIfqp7Snq+LNCxYDUyM2sB5WXKe2mL8gn2VwLfAw5Jz6eTzddgZlY0fFtC2DIiNpX0OkBETMlnhjUzs7akjTbY85ZPsJ+XZl8LAEkr4gu0ZlZk2mqLPV/5dONcBtwLrCTpAuBF4E8FrZWZWTMrxERorUmDLfuI+I+kV4GdyMbc7xsRowpeMzOzZqRafwdVPBoM9pJWA2YBD+SmRcQnhayYmVlzaqujbPKVT5/9Q3w7rWZHsh9XvUd2VxUzs6LQVrtn8pVPN853cp9L2hT4WcFqZGbWAsqKPNo3ej77iHhN0uaFqIyZWUsp8lifV5/9L3OelgGbAl8UrEZmZi2g2Ide5tOy75zzeD5ZH/7dhamOmVnLKPJYn1ef/XnNUREzs5ZUXuTRvs5gL+kB6rmJbUTsXZAamZm1gFLuxvlrs9XCzKyFFfkw+7qDfUQ815wVMTNrSaXcsgdAUl/gQrI57RfOYx8RaxawXmZmzarIY31eo3H+DZwDXEp2R/Sjqf1mumZmbVaxT5eQz6yXlRHxFKCIGBsR5wI7FrZaZmbNyzcvgTmSyoDRkk4GxgMrFbZaZmbNq22G8Pzl07I/DViG7B60mwGHAUcWslJmZs2tTMp7aYvqG2d/APBgRAxPSTPI+uvNzIpOG43heauvZX8o8ImkmyTtnm5NaGZWlIq9z77OYB8RA4C1gafIunA+lXSVpO83V+XMzJpLeZnyXtqievvsI+LriBgUEbsD3wHeAP4p6dNmqZ2ZWTMp+XvQAkjqDuwHHAQsRzPMernpTw4qdBHWBt395riWroK1Qodu1mup99FWu2fyVd8F2s7AvsAhZHPY3w/8EXgmIuqcIM3MrC3KZ2hiW1Zfy/4j4DHgKuDRiJjXPFUyM2t+xd6yr+/LbLWIODQiHnCgN7NiV6b8l/pI6i3pGUmjJL0t6dSUvpykJySNTv93T+mSdJmkMZJGpPt8V+/ryJR/tKQjc9I3k/RW2uYy5fFNVd9onFkNvzxmZsWhCUfjzAd+FRHrA1sBJ0nqB5wOPBURfclGOZ6e8u8O9E3LQLLeFCQtRzYv2ZbAFsA51V8QKc/AnO12a6hSxd5NZWaWl6Zq2UfEhIh4LT2eDowCVgX2AQalbIPIromS0m+KzFCgm6SVgV2BJyLiq4iYAjwB7JbWdYmIIen66U05+6pTXqNxzMyKXSG67CWtAWwCDAN6RMQEyL4QJFXPMbYqkDucfVxKqy99XC3p9fJtCc3MoFFz3kgaSNaNUu2aiLimRp5OZMPUT4uIr+vpVq9tRSxBer18W0IzMxrXp50C+zV1rZfUjizQ/yci7knJEyWtnFr1KwOTUvo4oHfO5r2Az1L6DjXSn03pvWrJXy/fltDMjKa7eUkaGXM9MCoiLslZdT/ZjMEXpf/vy0k/WdLtZBdjp6UvhMeAP+VclN0FOCMivpI0XdJWZN1DRwD/bKhevi2hmRlN2me/DXA48JakN1La78iC/B2SjgU+AX6c1j0M7AGMAWaRZhdOQf0PQPXMw+dHxFfp8QnAjUAl8Eha6uXbEpqZ0fAom3xFxIvUHSN3qiV/ACfVsa8bgBtqSX8F2LAx9fJtCc3MKOGbl+TwbQnNrOi10RietyW5LeHh+LaEZlZkmupHVa1Vgy1735bQzEpBeZE37fMZjfMMtQzYjwj325tZ0WirLfZ85dNn/+ucxx2B/ckm+jEzKxrFPsVxPt04r9ZI+p8k/+DKzIpKybfs0zSb1crILtL2LFiNzMxaQJE37PPqxnmVbyffmU92B6tjC1kpM7Pm1lbHz+crn2C/fkTMyU2Q1KFA9TEzaxHlRX53j3wO76Va0oY0dUXMzFpSGcp7aYvqm8++J9mE+JWSNuHbuR66kP3IysysaBR5L0693Ti7AkeRzZX8N74N9l+TzeBmZlY0SnY0TkQMAgZJ2j8i7m7GOpmZNbtiv0CbT5/9ZpK6VT+R1F3SHwtYJzOzZldepryXtiifYL97REytfpLucr5H4apkZtb8pPyXtiifoZflkjpExDcAkioBD700s6JS5CMv8wr2twBPSfo32Y+rjgFuKmitzMyamefGibhY0ghgZ7IROX+IiMcKXjMzs2ZU3KE+v5Y9EfEo8CiApG0kXRERtd4z0cysLSr20Th5BXtJ/YFDgIPI5sa5p5CVMjNrbm10kE3e6vsF7TrAwWRBfjIwmOym4z9oprqZmTWbUu6zfxd4AdgrIsYASPpFs9TKzKyZFftonPqOb3/gc+AZSddK2oniv4ZhZiVKUt5LW1RnsI+IeyPiIGA94FngF0APSVdJ2qWZ6mdm1izUiKUtavDMJSJmRsR/ImJPsknR3gBOL3jNzMyaUbG37PMajVMtIr4Crk6LmVnRKG+jQTxfjQr2ZmbFqrhDvYO9mRnQdic4y5eDvZkZtNnbDebLwd7MjOJv2Rf77wjMzPJSJuW9NETSDZImSRqZk3aupPGS3kjLHjnrzpA0RtJ7knbNSd8tpY2RdHpOeh9JwySNljRYUvsGj69Rr4aZWZEqQ3kvebgR2K2W9Esjon9aHgaQ1I9sapoN0jZXSiqXVA5cAewO9AMOSXkB/pz21ReYAhzb8PEVmCTf6MTMWr2mvFNVRDwPfJVn0fsAt0fENxHxETAG2CItYyLiw4iYC9wO7KNsoP+OwF1p+0HAvg0VUrBgL2kLSW8Bo9PzjSX9s1DlmZktjWa6LeHJkkakbp7uKW1V4NOcPONSWl3pywNTI2J+jfR6FbJlfxmwJ9mMmUTEm4BnzDSzVkmN+ScNlPRKzjIwjyKuAtYC+gMTgL8tLHpxsQTp9SrkaJyyiBhb46fFVQUsz8xsiTVmPvuIuAa4pjH7j4iJ1Y8lXQs8mJ6OA3rnZO0FfJYe15b+JdBNUkWFYUrIAAAQUUlEQVRq3efmr1MhW/afStoCiHSx4TTg/QKWZ2a2xJpyNE5tJK2c83QAUD1S537gYEkdJPUB+gIvA8OBvmnkTXuyi7j3R0QAzwAHpO2PBO5rqPxCtuxPIOvKWQ2YCDyZ0oraSp3bc9Ye67Lcsu2JCO5783PufG3RL91NenflogH9mDBtDgDPvT+Zfw/5ZKnKbVcuztpjXdbt0Ylps+dx9gPv8vnX3yxc36NzB245ZjNueGkstw0fv1Rl2ZK5/+q/8P7rQ1m2SzdOuPj6xda/9MBg3nrpKQAWVFXx5fhP+PXVd1PZqcsSlzl/3lz+e9WfmfDR+1R26sIBp5xFtxV7Llw/7cuJXPmbY9h+/yPZes8Dl7icYqAm/FGVpNuAHYAVJI0DzgF2SHf9C+Bj4GcAEfG2pDuAd4D5wEkRUZX2czLwGFAO3BARb6cifgvcLumPwOvA4h+oGgoW7CNiEtk3UUmpWhD885kPeX/STJZpV871R/Rn+NipfDx51iL53hw3jf+7551G779nlw78fvd1+PngtxZJ3/M7PZk+Zz4HXfcKO623Iidu34ezH3h34fpTdlyToR/lOzjACmHj7+/K5rvsw3+v+nOt67fe6yC23usgAN579SWGPZJ/oJ/6xefc96+LOfKsSxZJf/3ZR6hcthM/v/RmRr70NE/edi0HnHLWwvWP3XwVa2+8xRIeUXFpytsSRsQhtSTXGZAj4gLgglrSHwYeriX9Q7LROnkrWLBPfVKLXTSIiHwuZLRZk2fOY/LMeQDMmlfF2MmzWbFT+8WCfV126bciP950VdqVi7cnTOdvT4xhQYOXXmC7tZfn+pfGAvDse1/wy53WWmTdZ1PnMHueL5m0pNXX34ipX3yeV963hzzDhlvvuPD5iBef4OVH76Wqaj6rrrUeexxzKmVl5Q3u571XXmL7/Y8AoN+W2/PIjf8kIpDEu8NfpPtKK9OuQ8clO6Ai05Qt+9aokH32TwJPpeV/wErAN/VuUWR6dulA3x7L8vaE6Yut23CVLtx45Cb8df8N6LP8MgCsvlwlO627Isff+iZHDXqdBQuCXfqtlFdZK3Zqz6TUbVMVMHPufLpWVtCxXRmHbdmLG9IXgbV+876Zw5g3h7P+FtsB8MX4sbw95FmOPvcyfnbhNZSVlfPWi0/lta/pU76k6/LZZ6isvJyOyyzL7OlfM3fObP73wO0Lvwis2YZetphCduMMzn0u6WbgiUKV19pUtivjgn3W57KnP2TW3EVb1O9NnMH+V7/M7HkL+F6f7lw4oB8HX/cK3129G+v17MT1h/cHoENFGVNmZWcJf9p3fVbp2pGKsjJ6dOnAjUduAsAdr37GwyMn1voBjIBjt1mdwa+MZ/a8BYU9YGsy7782hN7rbLCwC+ejka8z4aPRXHfWiQDMn/sNy3TpBsDgS85m6hefUzV/HtO+nMTVZ2Qnzlvuuh/9d9gt+xDUJHj27kFstccBtO9Y2TwH1QZ4Pvum0wdYvb4MaazqQIA19/s1Pbfauznq1eTKy8QF+/Tj8VFf8NzoyYutzw3+Qz6awq/KRNfKCoR4ZOQk/vXCx4tt87v/jgLq7rOfNH0uK3XpwBcz5lIuWLZ9BV/Pmc8GK3fmB+uswInb96FThwoigrnzF3D36xOa9qCtyYys0YUDwcbf34WdDv7pYnkP+uX5QN199p2XW5FpkyfRZfkVWVBVxZxZM6ns1IXxY0YxatjzPHnrNcyZNQOpjIp27dli1wZ/iFm0ijvUF7bPfgrf9tmXkf10uN7bGeaOXd3mLy/k0VPdOp2xW1/GTp7F4FdqH/Wy3LLt+Cr166/fsxMSTJs9n1c+mcpFA/px+6vjmTprHp07VrBM+3Imft1w79eLH0xmjw168PZn09lh3RV59ZOpAJx424iFeY7ZejVmz6tyoG/F5syawdhRIxhw4hkL0/pssAmD/3Y2W+2+P8t27c7sGV/zzezZdFuxR4P7W3ez7zHihcfpvc4GvDPsOfpssAmSOPqcfyzM8+xdg2jfsbKkAz1Q9NG+IME+zd2wMVAd7RaksaFFb6NVu7D7Bj0Y88XMhV0tVz//MT26ZFME/ffNz/nBOiswoP/KzF+QtbLPSaNmPp48i2tf+Ji//3hDJDG/agGXPPlBXsH+wRGfc9aP1mXwT7/L13PmL9yntR53//OPjB31JrOmT+PSkw9ih/2PpKoqO8v77s57AfDu8BdZ6zubLdK9smKvNfjBgUdzy0W/JRYsoLy8gt2PPiWvYL/JDntw75UX8s9fHE7lsp3Z/+dnFubgikCxX6BVoWKwpFcjYrMl3b4tt+ytcE7csU9LV8FaoUM367XUkfrlD6flHXO2WLNrm/tmKORonJclbVrA/ZuZNRk1YmmLmrwbJ2e+hm2B4yR9AMwke40iIvwFYGatjjwap9FeBjYlj/mVzcxaiyKP9QUJ9gKIiA8KsG8zs4Io8lhfkGC/oqRf1rUyIi6pa52ZWYsp8mhfiGBfDnSi6F86MysmxT70shDBfkJEnF+A/ZqZFYz77BuvyF8yMytGDvaNt1MB9mlmVlDuxmmkiPAdMsyszXHL3sysBBR5rHewNzMDij7aO9ibmQFlRd6P42BvZkbRN+wd7M3MgKKP9g72ZmZ46KWZWUko8i57B3szMyj6XhwHezMz8M1LzMxKQpHHegd7MzNwN46ZWWko8mjvYG9mhodempmVhGLvsy9r6QqYmbUGUv5Lw/vSDZImSRqZk7acpCckjU7/d0/pknSZpDGSRkjaNGebI1P+0ZKOzEnfTNJbaZvLlMdQIgd7MzOybpx8/+XhRmC3GmmnA09FRF/gqfQcYHegb1oGAldB9uUAnANsCWwBnFP9BZHyDMzZrmZZi3GwNzOjaVv2EfE8UPNGTvsAg9LjQcC+Oek3RWYo0E3SysCuwBMR8VVETAGeAHZL67pExJCICOCmnH3VycHezIxsME7eizRQ0is5y8A8iugRERMA0v8rpfRVgU9z8o1LafWlj6slvV6+QGtmRuMu0EbENcA1TVV0bUUsQXq93LI3MyObLiHfZQlNTF0wpP8npfRxQO+cfL2AzxpI71VLer0c7M3MaFw3zhK6H6geUXMkcF9O+hFpVM5WwLTUzfMYsIuk7unC7C7AY2nddElbpVE4R+Tsq07uxjEzo2nH2Uu6DdgBWEHSOLJRNRcBd0g6FvgE+HHK/jCwBzAGmAUcDRARX0n6AzA85Ts/Iqov+p5ANuKnEngkLfVysDczo2l/QRsRh9Sxaqda8gZwUh37uQG4oZb0V4ANG1MnB3szM/DcOGZmpaDIY72DvZkZQFmRT47jYG9mBkXftHewNzOj6GO9g72ZGRT/FMcO9mZm+OYlZmYlwS17M7MS4GBvZlYC3I1jZlYC3LI3MysBRR7rHezNzICij/YO9mZmeLoEM7OSUNyh3sHezCxT5NHewd7MjOIfeqnsJinWmkkamO5mb7aQPxfWGL7heNswsKUrYK2SPxeWNwd7M7MS4GBvZlYCHOzbBvfLWm38ubC8+QKtmVkJcMvezKwEONibmZUA/6iqBUiqAt7KSdo3Ij6uI+8awIMRsWHha2YtTdLywFPpaU+gCvgiPd8iIua2SMWszXOwbxmzI6J/S1fCWp+ImAz0B5B0LjAjIv6am0eSyK63LWj+Glpb5W6cVkLSGpJekPRaWrauJc8Gkl6W9IakEZL6pvTDctKvllTe/EdghSRpbUkjJf0LeA3oLWlqzvqDJV2XHveQdI+kV9LnYquWqre1Hg72LaMyBeY3JN2b0iYBP4yITYGDgMtq2e544B/prOC7wDhJ66f826T0KuDQwh+CtYB+wPURsQkwvp58lwEXR8R3gQOB65qjcta6uRunZdTWjdMOuFxSdcBep5bthgC/l9QLuCciRkvaCdgMGJ6d3VNJ9sVhxeeDiBieR76dgXX17fzs3SVVRsTswlXNWjsH+9bjF8BEYGOyM645NTNExK2ShgE/Ah6T9FOyiVkHRcQZzVlZaxEzcx4vYNFJeTvmPBa+mGs1uBun9egKTEgX3Q4HFut3l7Qm8GFEXAbcD2xENnLjAEkrpTzLSVq9+aptLSF9TqZI6iupDBiQs/pJ4KTqJ+ls0Uqcg33rcSVwpKShZF04M2vJcxAwUtIbwHrATRHxDnAm8LikEcATwMrNVGdrWb8FHiX7wh+Xk34SsE26iP8OcFxLVM5aF0+XYGZWAtyyNzMrAQ72ZmYlwMHezKwEONibmZUAB3szsxLgYG9mVgIc7M3MSoCDvZlZCXCwNzMrAQ72ZmYlwMHezKwEONibmZUAB3szsxLgYG9mVgIc7M3MSoCDvZlZCXCwt4UkVUl6Q9JISXdKWmYp9rWDpAfT470lnV5P3m6STlyCMs6V9Otayh1SI61C0kRJdd7Bq7Z9mRUTB3vLNTsi+kfEhsBc4Pjclco0+jMTEfdHxEX1ZOkGNDrY1+F5oJekNXLSdgZGRsSEJirDrM1xsLe6vACsLWkNSaMkXQm8BvSWtIukIZJeS2cAnQAk7SbpXUkvAvtV70jSUZIuT497SLpX0ptp2Rq4CFgrnVX8JeX7jaTh6T6q5+Xs6/eS3pP0JLBuzUqnG3HfSXa/3moHA7el7Y9L+31T0t21nb1IelbSd9PjFSR9nB6XS/pLTr1+ltJXlvR8zlnRdkv6opsVioO9LUZSBbA78FZKWpfs5uabkN0I/Uxg54jYFHgF+KWkjsC1wF7AdkDPOnZ/GfBcRGwMbAq8DZwOfJDOKn4jaRegL7AF0B/YTNL3JW1GFrg3Ifsy2byOMm5L+ZDUAdgDuDutuyciNk/ljwKObcRLcywwLSI2T2UfJ6kP8BPgsYjoD2wMvNGIfZo1i4qWroC1KpWSqgPVC8D1wCrA2IgYmtK3AvoB/5ME0B4YAqwHfBQRowEk3QIMrKWMHYEjACKiCpgmqXuNPLuk5fX0vBNZ8O8M3BsRs1IZ99d2EBExXFInSesC6wNDI2JKWr2hpD+SdR11Ah5r8FVZtF4bSTogPe+a6jUcuEFSO+C/EeFgb62Og73lmp1apwulgD4zNwl4IiIOqZGvPxBNVA8BF0bE1TXKOK0RZdxO1rpfn9SFk9wI7BsRb0o6Ctihlm3n8+1Zb8ca9fp5RCz2BSHp+8CPgJsl/SUibsqznmbNwt041lhDgW0krQ0gaRlJ6wDvAn0krZXyHVLH9k8BJ6RtyyV1AaaTtdqrPQYck3MtYFVJK5FdfB0gqVJSZ7Iuo7rcBhxGdiaRewbQGZiQWuGH1rHtx8Bm6fEBOemPASekbZG0jqRlJa0OTIqIa8nOhjatp15mLcIte2uUiPgitYhvS/3hAGdGxPuSBgIPSfoSeBHYsJZdnApcI+lYoAo4ISKGSPqfpJHAI6nffn1gSDqzmAEcFhGvSRpM1ic+lqyrqa56viNpFvBqROSemZwFDEvbv8WiXzLV/grcIelw4Omc9OuANYDXlFXsC2BfsrOD30ial+p6RF31MmspimiqM28zM2ut3I1jZlYCHOzNzEqAg72ZWQlwsDczKwEO9mZmJcDB3sysBDjYm5mVAAd7M7MS8P/96sxU+ODiFgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "cmatrix_xgb_bow=metrics.confusion_matrix(y_test, xgb_bow.predict(X_test_transform))\n",
    "\n",
    "ax = sns.heatmap(cmatrix_xgb_bow, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['False','True'])\n",
    "ax.yaxis.set_ticklabels(['False','True'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:487: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_store_unique_indices = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n"
     ]
    }
   ],
   "source": [
    "xgb_wv = RandomForestClassifier(random_state=RANDOM_SEED).fit(X_train_wv,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/base.py:158: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6253449144612137"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,xgb_wv.predict(X_test_wv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiranzhou/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/base.py:158: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0, 0.5, 'False'), Text(0, 1.5, 'True')]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "cmatrix_xgb_wv=metrics.confusion_matrix(y_test, xgb_wv.predict(X_test_wv))\n",
    "\n",
    "ax = sns.heatmap(cmatrix_xgb_wv, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['False','True'])\n",
    "ax.yaxis.set_ticklabels(['False','True'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Unsupervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2,random_state=RANDOM_SEED).fit(X_train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df = pd.DataFrame({'cluster':kmeans.labels_,'y_label':y_train,'text':X_train})\n",
    "cluster_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA Topic Modeling - Consider NMF to create a document-topic matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from nltk.stem.porter import *\n",
    "def lemmatize_stemming(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    #Un-hash next line to use stemming\n",
    "    #return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "    #Un-hash next line to NOT use stemming\n",
    "    return WordNetLemmatizer().lemmatize(text, pos='v')\n",
    "# Tokenize and lemmatize\n",
    "def preprocess(text):\n",
    "    result=[]\n",
    "    for token in gensim.utils.simple_preprocess(text) :\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            #Un-hash next line to use stemming\n",
    "            result.append(lemmatize_stemming(token))\n",
    "            #Un-hash next line to NOT use stemming\n",
    "            #result.append(token)\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"There is manuscript evidence that Austen continued to work on these pieces as late as the period 1809 Ã¢ '' 11 , and that her niece and nephew , Anna and James Edward Austen , made further additions as late as 1814 .\""
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['original_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['manuscript',\n",
       " 'evidence',\n",
       " 'austen',\n",
       " 'continue',\n",
       " 'work',\n",
       " 'piece',\n",
       " 'late',\n",
       " 'period',\n",
       " 'niece',\n",
       " 'nephew',\n",
       " 'anna',\n",
       " 'jam',\n",
       " 'edward',\n",
       " 'austen',\n",
       " 'additions',\n",
       " 'late']"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(df['original_text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell will run about 2 minutes\n",
    "processed_docs = [preprocess(text) for text in df['original_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.corpora.dictionary.Dictionary at 0x1567b848520>"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "#bow_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "416768"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bow_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell will run 10 minutes\n",
    "#lda_model =  gensim.models.LdaMulticore(bow_corpus, \n",
    "#                                   num_topics = 8, \n",
    "#                                   id2word = dictionary,                                    \n",
    "#                                   passes = 10,\n",
    "#                                   workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for idx, topic in lda_model.print_topics(-1):\n",
    "#    print(\"Topic: {} \\nWords: {}\".format(idx, topic ))\n",
    "#    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
